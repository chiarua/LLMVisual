{"version":3,"sources":["../node_modules/tslib/tslib.es6.js","../node_modules/clone/clone.js","../node_modules/fast-json-stable-stringify/index.js","../node_modules/vega-util/src/accessor.js","../node_modules/vega-util/src/error.js","../node_modules/vega-util/src/splitAccessPath.js","../node_modules/vega-util/src/isArray.js","../node_modules/vega-util/src/isObject.js","../node_modules/vega-util/src/isString.js","../node_modules/vega-util/src/stringValue.js","../node_modules/vega-util/src/accessors.js","../node_modules/vega-util/src/field.js","../node_modules/vega-util/src/logger.js","../node_modules/vega-util/src/isBoolean.js","../node_modules/vega-util/src/toSet.js","../node_modules/vega-lite/src/util.ts","../node_modules/vega-lite/src/channel.ts","../node_modules/vega-lite/src/axis.ts","../node_modules/vega-lite/src/legend.ts","../node_modules/vega-lite/src/log/index.ts","../node_modules/vega-lite/src/log/message.ts","../node_modules/vega-lite/src/type.ts","../node_modules/vega-lite/src/scale.ts","../node_modules/datalib/src/util.js","../src/util.ts","../src/property.ts","../node_modules/vega-lite/src/mark.ts","../node_modules/vega-lite/src/datetime.ts","../node_modules/vega-lite/src/timeunit.ts","../src/wildcard.ts","../src/config.ts","../node_modules/vega-lite/src/aggregate.ts","../node_modules/vega-lite/src/bin.ts","../node_modules/vega-lite/src/channeldef.ts","../src/query/expandedtype.ts","../node_modules/vega-lite/src/compile/scale/type.ts","../src/propindex.ts","../node_modules/vega-lite/src/encoding.ts","../node_modules/vega-lite/src/stack.ts","../src/query/spec.ts","../src/query/shorthand.ts","../src/query/encoding.ts","../node_modules/d3-time/build/d3-time.js","../node_modules/datalib/src/time.js","../node_modules/datalib/src/bins/bins.js","../node_modules/datalib/src/import/type.js","../node_modules/datalib/src/generate.js","../node_modules/datalib/src/stats.js","../src/schema.ts","../src/constraint/base.ts","../src/constraint/field.ts","../src/constraint/value.ts","../src/constraint/encoding.ts","../src/constraint/spec.ts","../src/enumerator.ts","../src/query/groupby.ts","../src/nest.ts","../src/wildcardindex.ts","../src/model.ts","../src/query/normalize.ts","../src/result.ts","../src/ranking/effectiveness/type.ts","../src/ranking/effectiveness/base.ts","../src/ranking/effectiveness/typechannel.ts","../src/ranking/effectiveness/mark.ts","../src/ranking/effectiveness/index.ts","../src/ranking/effectiveness/axis.ts","../src/ranking/effectiveness/dimension.ts","../src/ranking/effectiveness/facet.ts","../src/ranking/effectiveness/sizechannel.ts","../src/ranking/aggregation.ts","../src/ranking/fieldorder.ts","../src/ranking/ranking.ts","../src/stylize.ts","../src/generate.ts","../src/recommend.ts"],"names":["__rest","s","e","t","p","Object","prototype","hasOwnProperty","call","indexOf","getOwnPropertySymbols","i","length","clone","_instanceof","obj","type","nativeMap","nativeSet","nativePromise","Map","_","Set","Promise","parent","circular","depth","includeNonEnumerable","allParents","allChildren","useBuffer","Buffer","Infinity","_clone","child","proto","resolve","reject","then","value","err","__isArray","__isRegExp","RegExp","source","__getRegExpFlags","lastIndex","__isDate","Date","getTime","isBuffer","allocUnsafe","copy","Error","create","getPrototypeOf","index","push","forEach","key","keyChild","valueChild","set","entryChild","add","attrs","getOwnPropertyDescriptor","symbols","symbol","descriptor","enumerable","defineProperty","allPropertyNames","getOwnPropertyNames","propertyName","__objToStr","o","toString","re","flags","global","ignoreCase","multiline","clonePrototype","c","module","exports","fastJsonStableStringify","data","opts","cmp","f","cycles","node","a","b","aobj","bobj","seen","stringify","toJSON","undefined","isFinite","JSON","out","Array","isArray","TypeError","seenIndex","keys","sort","splice","accessor","fn","fields","name","fname","error","message","splitAccessPath","j","path","q","n","substring","isObject","isString","$","x","map","replace","empty","field","code","stringValue","join","Function","log","method","level","input","msg","concat","slice","console","None","Warn","Info","Debug","isBoolean","toSet","this","stableStringify","contains","array","item","flagKeys","getFirstDefined","args","arg","ROW","COLUMN","FACET","X","Y","X2","Y2","LATITUDE","LONGITUDE","LATITUDE2","LONGITUDE2","COLOR","FILL","STROKE","SHAPE","SIZE","OPACITY","FILLOPACITY","STROKEOPACITY","STROKEWIDTH","TEXT","ORDER","DETAIL","KEY","TOOLTIP","HREF","UNIT_CHANNEL_INDEX","assign","y","x2","y2","longitude","longitude2","latitude","latitude2","color","fill","stroke","opacity","fillOpacity","strokeOpacity","strokeWidth","size","shape","order","text","detail","tooltip","href","isColorChannel","channel","CHANNEL_INDEX","row","column","facet","CHANNELS","NONPOSITION_CHANNEL_INDEX","NONPOSITION_CHANNELS","POSITION_SCALE_CHANNEL_INDEX","NONPOSITION_SCALE_CHANNEL_INDEX","SCALE_CHANNEL_INDEX","isScaleChannel","supportMark","mark","point","tick","rule","circle","square","bar","rect","line","trail","area","geoshape","getSupportedMark","rangeType","COMMON_AXIS_PROPERTIES_INDEX","orient","bandPosition","domain","domainColor","domainDash","domainDashOffset","domainOpacity","domainWidth","format","formatType","grid","gridColor","gridDash","gridDashOffset","gridOpacity","gridWidth","labelAlign","labelAngle","labelBaseline","labelBound","labelColor","labelFlush","labelFlushOffset","labelFont","labelFontSize","labelFontStyle","labelFontWeight","labelLimit","labelOpacity","labelOverlap","labelPadding","labels","labelSeparation","maxExtent","minExtent","offset","position","tickColor","tickCount","tickDash","tickDashOffset","tickExtra","tickMinStep","tickOffset","tickOpacity","tickRound","ticks","tickSize","tickWidth","title","titleAlign","titleAnchor","titleAngle","titleBaseline","titleColor","titleFont","titleFontSize","titleFontStyle","titleFontWeight","titleLimit","titleOpacity","titlePadding","titleX","titleY","values","zindex","AXIS_PROPERTIES_INDEX","encoding","AXIS_PROPERTIES","gridScale","scale","encode","COMMON_LEGEND_PROPERTY_INDEX","clipHeight","columnPadding","columns","cornerRadius","direction","fillColor","gradientLength","gradientOpacity","gradientStrokeColor","gradientStrokeWidth","gradientThickness","gridAlign","labelOffset","legendX","legendY","padding","rowPadding","strokeColor","symbolDash","symbolDashOffset","symbolFillColor","symbolOffset","symbolOpacity","symbolSize","symbolStrokeColor","symbolStrokeWidth","symbolType","titleOrient","LEGEND_PROPERTIES","local","ancestor","transform","channels","opt","parentProjection","projection","scaleType","zeroFalse","aggregate","newType","fieldDef","newChannel","markOrFacet","when","hasX2","hasY2","original","actual","prop","defaultScaleType","propName","property","propertyOf","v1","v2","unitName","fullTimeUnit","d","center","extent","compositeMark","main","arguments","warn","info","debug","current","apply","TYPE_INDEX","quantitative","ordinal","temporal","nominal","geojson","QUANTITATIVE","ORDINAL","TEMPORAL","NOMINAL","GEOJSON","getFullName","toLowerCase","ScaleType","LINEAR","LOG","POW","SQRT","SYMLOG","TIME","UTC","QUANTILE","QUANTIZE","THRESHOLD","BIN_ORDINAL","POINT","BAND","SCALE_TYPES","linear","pow","sqrt","symlog","time","utc","bin-ordinal","band","quantile","quantize","threshold","CONTINUOUS_TO_CONTINUOUS_SCALES","CONTINUOUS_TO_CONTINUOUS_INDEX","CONTINUOUS_TO_DISCRETE_INDEX","CONTINUOUS_DOMAIN_INDEX","DISCRETE_DOMAIN_INDEX","hasDiscreteDomain","isContinuousToContinuous","SCALE_PROPERTY_INDEX","range","rangeStep","scheme","bins","reverse","round","clamp","nice","base","exponent","constant","interpolate","zero","paddingInner","paddingOuter","SCALE_PROPERTIES","fieldDefType","generateScaleTypeIndexKey","channelSupportScaleType","scaleTypeSupportDataType","generateScaleTypeIndex","scaleTypeSupportProperty","channelScalePropertyIncompatability","log.message","cannotUseScalePropertyWithNonColor","specifiedType","TYPE.ORDINAL","TYPE.NOMINAL","TYPE.TEMPORAL","TYPE.QUANTITATIVE","CHANNEL.X","CHANNEL.Y","CHANNEL.SIZE","CHANNEL.STROKEWIDTH","CHANNEL.OPACITY","CHANNEL.FILLOPACITY","CHANNEL.STROKEOPACITY","CHANNEL.COLOR","CHANNEL.FILL","CHANNEL.STROKE","CHANNEL.SHAPE","u","namedfunc","identity","true","false","duplicate","parse","equal","extend","len","k","vals","toMap","list","reduce","keystr","String","isFunction","isNumber","isDate","isValid","number","boolean","date","str","field_re","strrep","truncateOnWord","rev","cnt","tok","split","truncate_word_re","filter","w","trim","match","mutator","v","$func","op","$valid","$length","$in","comparator","sign","numcmp","stablesort","sortBy","keyFn","indices","idx","sa","sb","permute","swap","m","Math","floor","random","pad","pos","padchar","ceil","truncate","word","ellipsis","l","max","l1","l2","every","arr","thisArg","some","without","excludedItems","nestedMap","isEncodingNestedProp","ENCODING_TOPLEVEL_PROP_INDEX","autoCount","bin","timeUnit","hasFn","stack","axis","legend","ENCODING_TOPLEVEL_PROPS","isEncodingTopLevelProperty","ENCODING_NESTED_PROP_PARENT_INDEX","isEncodingNestedParent","BIN_CHILD_PROPS","SORT_CHILD_PROPS","BIN_PROPS","SORT_PROPS","SCALE_PROPS","AXIS_PROPS","LEGEND_PROPS","ENCODING_NESTED_PROPS","VIEW_PROPS","PROP_KEY_DELIMITER","toKey","fromKey","ENCODING_NESTED_PROP_INDEX","getEncodingNestedProp","isEncodingProperty","ALL_ENCODING_PROPS","DEFAULT_PROP_PRECEDENCE","Property","MARK","TRANSFORM","STACK","FORMAT","CHANNEL","AGGREGATE","AUTOCOUNT","BIN","HAS_FN","TIMEUNIT","FIELD","TYPE","SORT","SCALE","AXIS","LEGEND","WIDTH","HEIGHT","BACKGROUND","PADDING","TITLE","AREA","BAR","CIRCLE","SQUARE","isPathMark","MONTHS","DAYS","substr","TimeUnit","YEAR","MONTH","DAY","DATE","HOURS","MINUTES","SECONDS","MILLISECONDS","YEARMONTH","YEARMONTHDATE","YEARMONTHDATEHOURS","YEARMONTHDATEHOURSMINUTES","YEARMONTHDATEHOURSMINUTESSECONDS","MONTHDATE","MONTHDATEHOURS","HOURSMINUTES","HOURSMINUTESSECONDS","MINUTESSECONDS","SECONDSMILLISECONDS","QUARTER","YEARQUARTER","QUARTERMONTH","YEARQUARTERMONTH","UTCYEAR","UTCMONTH","UTCDAY","UTCDATE","UTCHOURS","UTCMINUTES","UTCSECONDS","UTCMILLISECONDS","UTCYEARMONTH","UTCYEARMONTHDATE","UTCYEARMONTHDATEHOURS","UTCYEARMONTHDATEHOURSMINUTES","UTCYEARMONTHDATEHOURSMINUTESSECONDS","UTCMONTHDATE","UTCMONTHDATEHOURS","UTCHOURSMINUTES","UTCHOURSMINUTESSECONDS","UTCMINUTESSECONDS","UTCSECONDSMILLISECONDS","UTCQUARTER","UTCYEARQUARTER","UTCQUARTERMONTH","UTCYEARQUARTERMONTH","LOCAL_SINGLE_TIMEUNIT_INDEX","year","quarter","month","day","hours","minutes","seconds","milliseconds","TIMEUNIT_PARTS","isLocalSingleTimeUnit","UTC_SINGLE_TIMEUNIT_INDEX","utcyear","utcquarter","utcmonth","utcday","utcdate","utchours","utcminutes","utcseconds","utcmilliseconds","isUtcSingleTimeUnit","UTC_MULTI_TIMEUNIT_INDEX","utcyearquarter","utcyearquartermonth","utcyearmonth","utcyearmonthdate","utcyearmonthdatehours","utcyearmonthdatehoursminutes","utcyearmonthdatehoursminutesseconds","utcquartermonth","utcmonthdate","utcmonthdatehours","utchoursminutes","utchoursminutesseconds","utcminutesseconds","utcsecondsmilliseconds","UTC_TIMEUNIT_INDEX","TIMEUNIT_INDEX","yearquarter","yearquartermonth","yearmonth","yearmonthdate","yearmonthdatehours","yearmonthdatehoursminutes","yearmonthdatehoursminutesseconds","quartermonth","monthdate","monthdatehours","hoursminutes","hoursminutesseconds","minutesseconds","secondsmilliseconds","SET_DATE_METHOD","convert","unit","isUTC","result","timeUnitPart","containsTimeUnit","getDateMethod","setDateMethod","dateMethods","singleUnit","isUtc","rawSetDateMethod","charAt","SHORT_WILDCARD","isWildcard","isShortWildcard","isWildcardDef","enum","initWildcard","defaultName","defaultEnumValues","initNestedPropName","fullNames","has","fullName","initialIndices","toUpperCase","shortName","shortNameWithNo","DEFAULT_NAME","binProps","maxbins","min","step","steps","minstep","divide","sortProps","scaleProps","axisProps","legendProps","getDefaultName","DEFAULT_BOOLEAN_ENUM","DEFAULT_BIN_PROPS_ENUM","binned","anchor","DEFAULT_SORT_PROPS","DEFAULT_SCALE_PROPS_ENUM","DEFAULT_AXIS_PROPS_ENUM","DEFAULT_LEGEND_PROPS_ENUM","DEFAULT_ENUM_INDEX","MARK.POINT","MARK.BAR","MARK.AREA","getDefaultEnumValues","schema","fieldNames","val","DEFAULT_QUERY_CONFIG","verbose","defaultSpecConfig","useUnaggregatedDomain","propertyPrecedence","numberNominalProportion","numberNominalLimit","constraintManuallySpecifiedValue","autoAddCount","hasAppropriateGraphicTypeForMark","omitAggregate","omitAggregatePlotWithDimensionOnlyOnFacet","omitAggregatePlotWithoutDimension","omitBarLineAreaWithOcclusion","omitBarTickWithSize","omitMultipleNonPositionalChannels","omitRaw","omitRawContinuousFieldForAggregatePlot","omitRepeatedField","omitNonPositionalOrFacetOverPositionalChannels","omitTableWithOcclusionIfAutoAddCount","omitVerticalDotPlot","omitInvalidStackSpec","omitNonSumStack","preferredBinAxis","preferredTemporalAxis","preferredOrdinalAxis","preferredNominalAxis","preferredFacet","CHANNEL.ROW","minCardinalityForBin","maxCardinalityForCategoricalColor","maxCardinalityForFacet","maxCardinalityForShape","timeUnitShouldHaveVariation","typeMatchesSchemaType","stylize","smallRangeStepForHighCardinalityOrFacet","maxCardinality","nominalColorScaleForHighCardinality","palette","xAxisOnTopForHighYCardinalityWithoutColumn","maxGoodCardinalityForFacet","maxGoodCardinalityForColor","minPercentUniqueForKey","minCardinalityForKey","extendNestedEnumIndex","enumIndex","AGGREGATE_OP_INDEX","argmax","argmin","average","count","distinct","mean","median","missing","q1","q3","ci0","ci1","stderr","stdev","stdevp","sum","valid","variance","variancep","isArgminDef","isArgmaxDef","isAggregateOp","SUM_OPS","isBinning","isBinParams","autoMaxBins","hasConditionalFieldDef","channelDef","condition","isFieldDef","isStringFieldDef","vgField","prefix","suffix","argAccessor","isCount","isInternalField","nofn","isOpFieldDef","normalizeBin","alphanumericS","varName","binToString","binSuffix","forAs","expr","datum","flatAccessWithDatum","isDiscrete","invalidFieldType","isContinuous","getTypedFieldDef","COMPATIBLE","compatible","channelCompatibility","warning","facetChannelShouldBeDiscrete","ExpandedType","specifiedScale","log.warn","discreteChannelCannotEncode","util.contains","defaultType","scaleTypeNotWorkWithFieldDef","scaleTypeNotWorkWithChannel","fieldType","PropIndex","[object Object]","channelHasField","entries","STACK_OFFSET_INDEX","normalize","STACKABLE_MARKS","STACK_BY_DEFAULT_MARKS","stackConfig","isMarkDef","fieldChannel","xDef","yDef","potentialStackedChannel","stackedFieldDef","stackedField","dimensionChannel","dimensionDef","dimensionField","stackBy","sc","cDef","disallowNonLinearStack","cannotStackNonLinearScale","cannotStackRangedMark","stackNonSummativeAggregate","groupbyChannel","impute","fromSpec","spec","width","height","background","encodings","encQ","isFieldQuery","config","isAggregate","specQ","isEnabledAutoCountQuery","getVlStack","hasRequiredStackProperties","toEncoding","wildcardMode","getStackOffset","getStackChannel","requiredEncodingProps","exclude","isDisabledAutoCountQuery","objectContainsWildcard","childProp","getReplacerIndex","replaceIndex","r","getReplacer","replacer","REPLACE_NONE","INCLUDE_ALL","pi","PROPERTY_SUPPORTED_CHANNELS","include","parts","get","encQs","viewProp","propString","fieldDefStr","isValueQuery","isAutoCountQuery","fieldQ","func","props","localeCompare","parentValue","nestedPropChildren","nestedProp","nestedPropObject","fieldDefProps","fieldAndParams","splitWithTail","delim","indexOfDelim","shorthandParser","rawFieldDef","fieldDefPart","partParams","closingBraceIndex","parsedValue","propEqualSignIndex","openingBraceIndex","getClosingIndex","openingBracketIndex","closingBracketIndex","propIndex","nextCommaIndex","closingChar","fieldDefShorthand","fnEnumIndex","encodingProperty","insideFnParts","encQMixins","vlspec","shorthand","splitShorthand","splitPart","splitPartKey","splitPartValue","DEFAULT_PROPS","params","toValueDef","toFieldDef","valueQ","ordinalDomain","fieldSchema","isMeasure","isDimension","vlChannelDef.isDiscrete","compileScaleType","vlChannelDef.isContinuous","t0","t1","newInterval","floori","offseti","interval","d0","d1","start","stop","test","setTime","end","millisecond","second","setMilliseconds","getSeconds","minute","setSeconds","getMinutes","hour","setMinutes","getHours","setHours","setDate","getDate","getTimezoneOffset","weekday","getDay","sunday","monday","tuesday","wednesday","thursday","friday","saturday","setMonth","getMonth","getFullYear","setFullYear","utcSecond","setUTCMilliseconds","getUTCSeconds","utcMinute","setUTCSeconds","getUTCMinutes","utcHour","setUTCMinutes","getUTCHours","utcDay","setUTCHours","setUTCDate","getUTCDate","utcWeekday","getUTCDay","utcSunday","utcMonday","utcTuesday","utcWednesday","utcThursday","utcFriday","utcSaturday","utcMonth","setUTCMonth","getUTCMonth","getUTCFullYear","utcYear","setUTCFullYear","days","sundays","mondays","tuesdays","wednesdays","thursdays","fridays","saturdays","weeks","months","years","utcMillisecond","utcMilliseconds","utcSeconds","utcMinutes","utcHours","utcDays","utcSundays","utcMondays","utcTuesdays","utcWednesdays","utcThursdays","utcFridays","utcSaturdays","utcWeeks","utcMonths","utcYears","version","week","utcWeek","factory","tempDate","baseDate","utcBaseDate","entry","locale","d3_time","STEPS","toUnitMap","units","find","span","minb","maxb","utc_1","EPSILON","precision","eps","logb","div","lo","hi","mid","util","bisect","date_value","date_index","dmin","dmax","minbins","raw","bins_1","TYPES","PARSERS","integer","string","TESTS","isNaN","bracket","fieldName","infer","types","annotation","all","inferAll","parsers","type_1","gen","repeat","zeros","uniform","samples","pdf","cdf","icdf","NaN","normal","next","rds","exp","PI","cd","z","Z","abs","SQRT2","bootstrap","smooth","stats","ztest1","nullH","nullh","gaussian","mu","SE","ztestP","n1","n2","diffs","ztest2","meanDiff","unique","results","quartile","H","h","geometric","harmonic","delta","M2","modeskew","avg","med","std","dot","dist","L2","cohensd","x1","s1","s2","covariance","vx","vy","xm","ym","rank","tie","cor","mua","mub","sda","sdb","ra","rb","aa","bb","ab","A","mat","B","linearRegression","res","xy","sx","sy","slope","icept","fit","intercept","R","rss","ci","N","alpha","bs","means","paired","M","entropy","counts","LN2","mutual","px","py","I","profile","sd","summary","__summary__","dlBin","dlBin_","Schema","tableSchema","_tableSchema","vlType","_fieldSchemaIndex","fieldSchemas","originalIndex","augmentTimeUnitDomain","excludeInvalid","binStats","binSummary","timeStats","timeSummary","invalidCount","dateEncQ","cardinality","singleUnitEncQ","fieldQueryParts","PrimitiveType","DATETIME","INTEGER","NUMBER","oldUnique","newUnique","bucket","Number","binUnique","timeunit","dateString","prev","cur","summaries","tableSchemaFieldIndex","fieldProfile","dataEntry","orgFieldSchema","derivedTableSchema","AbstractConstraintModel","constraint","description","properties","strict","EncodingConstraintModel","super","encWildcardIndex","allowWildcardForProperties","hasAllRequiredPropertiesSpecific","satisfy","FIELD_CONSTRAINTS","__","___","fieldQwithoutBin","timeUnitHasVariation","sType","scaleProp","sProp","primitiveType","BOOLEAN","STRING","CHANNEL.COLUMN","ec","FIELD_CONSTRAINTS_BY_PROPERTY","VALUE_CONSTRAINTS","VALUE_CONSTRAINTS_BY_PROPERTY","checkEncoding","wildcard","specM","encodingConstraints","getEncodingQueryByIndex","wildcardIndex","violatedConstraint","toShorthand","valueContraints","NONPOSITION_CHANNELS_INDEX","SpecConstraintModel","specConstraint","getMark","getEncodings","SPEC_CONSTRAINTS","usedChannel","encodingIndicesByProperty","channelUsed","CHANNEL.TEXT","MARK.CIRCLE","MARK.SQUARE","hasProperty","hasNonFacetDim","hasDim","hasEnumeratedFacetDim","specQuery","hasEncodingProperty","channelEncodingField","nonPositionChannelCount","hasEnumeratedNonPositionChannel","hasNonPositionalChannelOrFacet","hasEnumeratedNonPositionOrFacetChannel","hasX","hasY","CHANNEL.DETAIL","fieldUsed","fieldEnumerated","xEncQ","getEncodingQueryByChannel","yEncQ","xIsMeasure","yIsMeasure","xIsDimension","yIsDimension","colorEncQ","colorIsQuantitative","colorIsOrdinal","correctChannels","correctColor","stackProps","specStack","stackParentEncQ","SPEC_CONSTRAINT_INDEX","SPEC_CONSTRAINTS_BY_PROPERTY","checkSpec","specConstraints","ENUMERATOR_INDEX","getEnumerator","EncodingPropertyGeneratorFactory","answerSet","enumerate","jobIndex","propWildcard","getEncodingProperty","propVal","setEncodingProperty","resetEncodingProperty","setMark","resetMark","isExtendedGroupBy","g","parseGroupBy","groupBy","grpBy","setByKey","GROUP_BY_FIELD_TRANSFORM","GROUP_BY_ENCODING","*","valFrom","valTo","groupRegistry","registerKeyFn","nest","specModels","queryNest","rootGroup","items","groupIndex","includes","replaces","replacers","parsedGroupBy","group","orderGroupBy","specShorthand","PARSED_GROUP_BY_FIELD","getGroupByKey","PARSED_GROUP_BY_FIELD_TRANSFORM","PARSED_GROUP_BY_ENCODING","WildcardIndex","_mark","_encodings","_encodingIndicesByProperty","encodingsIndex","indicesByProp","SpecQueryModel","wildcardAssignment","_rankingScore","_spec","_channelFieldCount","_wildcardIndex","_assignedWildcardIndex","_opt","_schema","defaultWildcardName","propObj","countEncQ","specEncoding","rankingName","score","orderBy","normalizedQ","chooseBy","isResultTree","getTopResultTreeItem","topItem","ExtendedType","mapLeaves","Scorer","scoreIndex","initScore","feature","Q","BIN_Q","T","TIMEUNIT_T","TIMEUNIT_O","O","K","NONE","getExtendedType","TERRIBLE","featurize","xType","yType","hasOcclusion","SCORERS","pAxis","features","featureScore","getFeatureScore","maxFScore","MEASURES","DISCRETE_OR_NONE","SCORE","feature2","ttMark","tdMark","ddMark","init","bar_size","tick_size","featureScores","CONTINUOUS_TYPE_CHANNEL_SCORE","ORDERED_TYPE_CHANNEL_SCORE","NOMINAL_TYPE_CHANNEL_SCORE","encodingQueryByField","fieldKey","bestFieldFeature","best","effectiveness","scorer","scores","getScore","isRawContinuous","hasCount","hasBin","aggregationQualityFeature","fieldWildcardIndices","numFields","totalScore","fieldWildcard","fieldIndex","rankingRegistry","register","query","subgroup","groupComparatorFactory","comparatorFactory","m1","m2","getScoreDifference","g1","g2","scoreDifference","model","getRankingScore","setRankingScore","aggregation.name","aggregation.score","fieldOrder.score","encQIndex","yScaleType","xScaleType","generate","build","propKey","reducer","enumerator"],"mappings":"gMAwCO,SAASA,EAAOC,EAAGC,GACtB,IAAIC,EAAI,GACR,IAAK,IAAIC,KAAKH,EAAOI,OAAOC,UAAUC,eAAeC,KAAKP,EAAGG,IAAMF,EAAEO,QAAQL,GAAK,IAC9ED,EAAEC,GAAKH,EAAEG,IACb,GAAS,MAALH,GAAqD,mBAAjCI,OAAOK,sBACtB,CAAA,IAAIC,EAAI,EAAb,IAAgBP,EAAIC,OAAOK,sBAAsBT,GAAIU,EAAIP,EAAEQ,OAAQD,IAAST,EAAEO,QAAQL,EAAEO,IAAM,IAC1FR,EAAEC,EAAEO,IAAMV,EAAEG,EAAEO,KACtB,OAAOR,0NC/CX,IAAIU,EAAQ,WAGZ,SAASC,EAAYC,EAAKC,GACxB,OAAe,MAARA,GAAgBD,aAAeC,EAGxC,IAAIC,EASAC,EAOAC,EAfJ,IACEF,EAAYG,IACZ,MAAMC,GAGNJ,EAAY,aAId,IACEC,EAAYI,IACZ,MAAMD,GACNH,EAAY,aAId,IACEC,EAAgBI,QAChB,MAAMF,GACNF,EAAgB,aAwBlB,SAASN,EAAMW,EAAQC,EAAUC,EAAOpB,EAAWqB,GACzB,iBAAbF,IACTC,EAAQD,EAASC,MACjBpB,EAAYmB,EAASnB,UACrBqB,EAAuBF,EAASE,qBAChCF,EAAWA,EAASA,UAItB,IAAIG,EAAa,GACbC,EAAc,GAEdC,EAA6B,oBAAVC,OA0IvB,YAxIuB,IAAZN,IACTA,GAAW,QAEO,IAATC,IACTA,EAAQM,EAAAA,GAGV,SAASC,EAAOT,EAAQE,GAEtB,GAAe,OAAXF,EACF,OAAO,KAET,GAAc,IAAVE,EACF,OAAOF,EAET,IAAIU,EACAC,EACJ,GAAqB,iBAAVX,EACT,OAAOA,EAGT,GAAIV,EAAYU,EAAQP,GACtBiB,EAAQ,IAAIjB,OACP,GAAIH,EAAYU,EAAQN,GAC7BgB,EAAQ,IAAIhB,OACP,GAAIJ,EAAYU,EAAQL,GAC7Be,EAAQ,IAAIf,EAAc,SAAUiB,EAASC,GAC3Cb,EAAOc,KAAK,SAASC,GACnBH,EAAQH,EAAOM,EAAOb,EAAQ,KAC7B,SAASc,GACVH,EAAOJ,EAAOO,EAAKd,EAAQ,aAG1B,GAAIb,EAAM4B,UAAUjB,GACzBU,EAAQ,QACH,GAAIrB,EAAM6B,WAAWlB,GAC1BU,EAAQ,IAAIS,OAAOnB,EAAOoB,OAAQC,EAAiBrB,IAC/CA,EAAOsB,YAAWZ,EAAMY,UAAYtB,EAAOsB,gBAC1C,GAAIjC,EAAMkC,SAASvB,GACxBU,EAAQ,IAAIc,KAAKxB,EAAOyB,eACnB,CAAA,GAAInB,GAAaC,OAAOmB,SAAS1B,GAStC,OANEU,EAFEH,OAAOoB,YAEDpB,OAAOoB,YAAY3B,EAAOZ,QAG1B,IAAImB,OAAOP,EAAOZ,QAE5BY,EAAO4B,KAAKlB,GACLA,EACEpB,EAAYU,EAAQ6B,OAC7BnB,EAAQ7B,OAAOiD,OAAO9B,QAEE,IAAblB,GACT6B,EAAQ9B,OAAOkD,eAAe/B,GAC9BU,EAAQ7B,OAAOiD,OAAOnB,KAGtBD,EAAQ7B,OAAOiD,OAAOhD,GACtB6B,EAAQ7B,GAIZ,GAAImB,EAAU,CACZ,IAAI+B,EAAQ5B,EAAWnB,QAAQe,GAE/B,IAAc,GAAVgC,EACF,OAAO3B,EAAY2B,GAErB5B,EAAW6B,KAAKjC,GAChBK,EAAY4B,KAAKvB,GAiBnB,IAAK,IAAIvB,KAdLG,EAAYU,EAAQP,IACtBO,EAAOkC,QAAQ,SAASnB,EAAOoB,GAC7B,IAAIC,EAAW3B,EAAO0B,EAAKjC,EAAQ,GAC/BmC,EAAa5B,EAAOM,EAAOb,EAAQ,GACvCQ,EAAM4B,IAAIF,EAAUC,KAGpB/C,EAAYU,EAAQN,IACtBM,EAAOkC,QAAQ,SAASnB,GACtB,IAAIwB,EAAa9B,EAAOM,EAAOb,EAAQ,GACvCQ,EAAM8B,IAAID,KAIAvC,EAAQ,CACpB,IAAIyC,EACA9B,IACF8B,EAAQ5D,OAAO6D,yBAAyB/B,EAAOxB,IAG7CsD,GAAsB,MAAbA,EAAMH,MAGnB5B,EAAMvB,GAAKsB,EAAOT,EAAOb,GAAIe,EAAQ,IAGvC,GAAIrB,OAAOK,sBACT,CAAA,IAAIyD,EAAU9D,OAAOK,sBAAsBc,GAC3C,IAASb,EAAI,EAAGA,EAAIwD,EAAQvD,OAAQD,IAAK,CAGvC,IAAIyD,EAASD,EAAQxD,MACjB0D,EAAahE,OAAO6D,yBAAyB1C,EAAQ4C,KACtCC,EAAWC,YAAe3C,KAG7CO,EAAMkC,GAAUnC,EAAOT,EAAO4C,GAAS1C,EAAQ,GAC1C2C,EAAWC,YACdjE,OAAOkE,eAAerC,EAAOkC,EAAQ,CACnCE,YAAY,MAMpB,GAAI3C,EACF,CAAA,IAAI6C,EAAmBnE,OAAOoE,oBAAoBjD,GAClD,IAASb,EAAI,EAAGA,EAAI6D,EAAiB5D,OAAQD,IAAK,CAChD,IACI0D,EADAK,EAAeF,EAAiB7D,IAChC0D,EAAahE,OAAO6D,yBAAyB1C,EAAQkD,KACvCL,EAAWC,aAG7BpC,EAAMwC,GAAgBzC,EAAOT,EAAOkD,GAAehD,EAAQ,GAC3DrB,OAAOkE,eAAerC,EAAOwC,EAAc,CACzCJ,YAAY,MAKlB,OAAOpC,EAGFD,CAAOT,EAAQE,GAqBxB,SAASiD,EAAWC,GAClB,OAAOvE,OAAOC,UAAUuE,SAASrE,KAAKoE,GAmBxC,SAAS/B,EAAiBiC,GACxB,IAAIC,EAAQ,GAIZ,OAHID,EAAGE,SAAQD,GAAS,KACpBD,EAAGG,aAAYF,GAAS,KACxBD,EAAGI,YAAWH,GAAS,KACpBA,EAIT,OAxCAlE,EAAMsE,eAAiB,SAAwB3D,GAC7C,GAAe,OAAXA,EACF,OAAO,KAET,IAAI4D,EAAI,aAER,OADAA,EAAE9E,UAAYkB,EACP,IAAI4D,GAQbvE,EAAM8D,WAAaA,EAKnB9D,EAAMkC,SAHN,SAAkB6B,GAChB,MAAoB,iBAANA,GAAoC,kBAAlBD,EAAWC,IAO7C/D,EAAM4B,UAHN,SAAmBmC,GACjB,MAAoB,iBAANA,GAAoC,mBAAlBD,EAAWC,IAO7C/D,EAAM6B,WAHN,SAAoBkC,GAClB,MAAoB,iBAANA,GAAoC,oBAAlBD,EAAWC,IAW7C/D,EAAMgC,iBAAmBA,EAElBhC,EA3PK,GA8PRwE,EAAqCC,UACvCD,EAAAC,QAAiBzE,SC7PnB0E,EAAiB,SAAUC,EAAMC,GACxBA,IAAMA,EAAO,IACE,mBAATA,IAAqBA,EAAO,CAAEC,IAAKD,IAC9C,IAEiCE,EAF7BC,EAAiC,kBAAhBH,EAAKG,QAAwBH,EAAKG,OAEnDF,EAAMD,EAAKC,MAAkBC,EAQ9BF,EAAKC,IAPG,SAAUG,GACb,OAAO,SAAUC,EAAGC,GAChB,IAAIC,EAAO,CAAErC,IAAKmC,EAAGvD,MAAOsD,EAAKC,IAC7BG,EAAO,CAAEtC,IAAKoC,EAAGxD,MAAOsD,EAAKE,IACjC,OAAOJ,EAAEK,EAAMC,MAKvBC,EAAO,GACX,OAAO,SAAUC,EAAWN,GAKxB,GAJIA,GAAQA,EAAKO,QAAiC,mBAAhBP,EAAKO,SACnCP,EAAOA,EAAKO,eAGHC,IAATR,EAAJ,CACA,GAAmB,iBAARA,EAAkB,OAAOS,SAAST,GAAQ,GAAKA,EAAO,OACjE,GAAoB,iBAATA,EAAmB,OAAOU,KAAKJ,UAAUN,GAEpD,IAAIlF,EAAG6F,EACP,GAAIC,MAAMC,QAAQb,GAAO,CAErB,IADAW,EAAM,IACD7F,EAAI,EAAGA,EAAIkF,EAAKjF,OAAQD,IACrBA,IAAG6F,GAAO,KACdA,GAAOL,EAAUN,EAAKlF,KAAO,OAEjC,OAAO6F,EAAM,IAGjB,GAAa,OAATX,EAAe,MAAO,OAE1B,IAA4B,IAAxBK,EAAKzF,QAAQoF,GAAc,CAC3B,GAAID,EAAQ,OAAOW,KAAKJ,UAAU,aAClC,MAAM,IAAIQ,UAAU,yCAGxB,IAAIC,EAAYV,EAAKzC,KAAKoC,GAAQ,EAC9BgB,EAAOxG,OAAOwG,KAAKhB,GAAMiB,KAAKpB,GAAOA,EAAIG,IAE7C,IADAW,EAAM,GACD7F,EAAI,EAAGA,EAAIkG,EAAKjG,OAAQD,IAAK,CAC9B,IAAIgD,EAAMkD,EAAKlG,GACX4B,EAAQ4D,EAAUN,EAAKlC,IAEtBpB,IACDiE,IAAKA,GAAO,KAChBA,GAAOD,KAAKJ,UAAUxC,GAAO,IAAMpB,GAGvC,OADA2D,EAAKa,OAAOH,EAAW,GAChB,IAAMJ,EAAM,KAtChB,CAuCJhB,ICzDQ,SAAAwB,EAASC,EAAIC,EAAQC,GAGlC,OAFAF,EAAGC,OAASA,GAAU,GACtBD,EAAGG,MAAQD,EACJF,ECHM,SAAAI,EAASC,GACtB,MAAMjE,MAAMiE,GCCC,SAAAC,EAASnH,GACtB,IAKIO,EAAG6G,EAAGpC,EALNqC,EAAO,GACPC,EAAI,KACJ3B,EAAI,EACJ4B,EAAIvH,EAAEQ,OACNX,EAAI,GAKR,SAASwD,IACPgE,EAAKhE,KAAKxD,EAAIG,EAAEwH,UAAUjH,EAAG6G,IAC7BvH,EAAI,GACJU,EAAI6G,EAAI,EAGV,IARApH,GAAQ,GAQHO,EAAE6G,EAAE,EAAGA,EAAEG,IAAKH,EAEjB,GAAU,QADVpC,EAAIhF,EAAEoH,IAEJvH,GAAKG,EAAEwH,UAAUjH,EAAG6G,GACpB7G,IAAM6G,OACD,GAAIpC,IAAMsC,EACfjE,IACAiE,EAAI,KACJ3B,GAAK,MACA,CAAA,GAAI2B,EACT,SACS/G,IAAMoF,GAAW,MAANX,GACpBzE,EAAI6G,EAAI,EACRE,EAAItC,GACKzE,IAAMoF,GAAW,MAANX,GACpBzE,EAAI6G,EAAI,EACRE,EAAItC,GACW,MAANA,GAAcW,EAMR,MAANX,GACLoC,EAAI7G,GAAG8C,IACXsC,EAAIpF,EAAI6G,EAAI,GACG,MAANpC,IACJW,GAAGsB,EAAM,qCAAuCjH,GACjD2F,EAAI,GAAGtC,IACXsC,EAAI,EACJpF,EAAI6G,EAAI,GAZJA,EAAI7G,EACN8C,IAEA9C,EAAI6G,EAAI,EAqBd,OARIzB,GAAGsB,EAAM,wCAA0CjH,GACnDsH,GAAGL,EAAM,sCAAwCjH,GAEjDoH,EAAI7G,IACN6G,IACA/D,KAGKgE,EC5DT,IAAAf,EAAeD,MAAMC,QCAN,SAAAmB,EAASxG,GACtB,OAAOA,IAAMhB,OAAOgB,GCDP,SAAAyG,EAASzG,GACtB,MAAoB,iBAANA,ECGD,SAAS0G,EAAEC,GACxB,OAAOtB,EAAQsB,GAAK,IAAMA,EAAEC,IAAIF,GAAK,IACjCF,EAASG,IAAMF,EAASE,GAGxBzB,KAAKJ,UAAU6B,GAAGE,QAAQ,SAAS,WAAWA,QAAQ,SAAU,WAChEF,ECPN,IAAIG,EAAQ,ICCG,SAASC,EAAOjB,GAC7B,IAAIM,EAAOF,EAAgBa,GACvBC,EAAO,YAAcZ,EAAKQ,IAAIK,GAAaC,KAAK,MAAQ,KAErDvB,EACLwB,SAAS,IAAKH,GACd,CAAED,EAAsB,IAAdX,EAAK7G,OAAa6G,EAAK,GAAKW,GACtCjB,GAAQiB,IDNIA,CAAM,MAEApB,EAAS,SAAS3F,GAAK,OAAOA,GAAM8G,EAAO,YAE/CnB,EAAS,WAAa,OAAO,GAAMmB,EAAO,QAE3CnB,EAAS,WAAa,OAAO,GAAMmB,EAAO,OAEvCnB,EAAS,WAAa,OAAO,GAASmB,EAAO,QAE9CnB,EAAS,WAAa,OAAO,GAAUmB,EAAO,SEfjE,SAASM,EAAIC,EAAQC,EAAOC,GAC1B,IAAIC,EAAM,CAACF,GAAOG,OAAO,GAAGC,MAAMvI,KAAKoI,IACvCI,QAAQN,MAAWG,GAGd,IAAII,EAAQ,EACR5F,EAAQ,EACR6F,EAAQ,EACRC,EAAQ,EACRC,EAAQ,ECTJ,SAAAC,EAAShI,GACtB,MAAoB,kBAANA,ECDD,SAAAiI,EAASjI,GACtB,IAAK,IAAIpB,EAAE,GAAIU,EAAE,EAAGgH,EAAEtG,EAAET,OAAQD,EAAEgH,IAAKhH,EAAGV,EAAEoB,EAAEV,KAAM,EACpD,OAAOV,ECwCTqB,IAAIhB,UAAkB,OAAI,WACxB,aAAc,IAAIiJ,MAAMtB,IAAID,GAAKwB,EAAgBxB,IAAIO,KAAK,SAMrD,MAAMpC,EAAYqD,EAEzB,SA6BgBC,EAAYC,EAAYC,GACtC,OAAOD,EAAMjJ,QAAQkJ,IAAS,EAwLzB,MAAM9C,EAAOxG,OAAOwG,KAE3B,SA2BgB+C,EAA2BjE,GACzC,OAAOkB,EAAKlB,GA6Gd,SAAgBkE,KAAsBC,GACpC,IAAK,MAAMC,KAAOD,EAChB,QAAYzD,IAAR0D,EACF,OAAOA,ECzYN,MAAMC,EAAa,MACbC,EAAmB,SAEnBC,EAAiB,QAGjBC,EAAS,IACTC,EAAS,IACTC,EAAW,KACXC,EAAW,KAEXC,EAAuB,WACvBC,EAAyB,YACzBC,EAAyB,YACzBC,EAA2B,aAG3BC,EAAiB,QAEjBC,EAAe,OAEfC,EAAmB,SAEnBC,EAAiB,QACjBC,EAAe,OACfC,EAAqB,UACrBC,EAA6B,cAE7BC,EAAiC,gBAEjCC,EAA6B,cAG7BC,EAAe,OACfC,EAAiB,QACjBC,EAAmB,SACnBC,EAAa,MAEbC,EAAqB,UACrBC,EAAe,OAuCtBC,EAAkBrL,OAAAsL,OAAA,CAEtB3D,EAAG,EACH4D,EAAG,EACHC,GAAI,EACJC,GAAI,GAd6D,CACjEC,UAAW,EACXC,WAAY,EACZC,SAAU,EACVC,UAAW,GAYiB,CAG5BC,MAAO,EACPC,KAAM,EACNC,OAAQ,EAGRC,QAAS,EACTC,YAAa,EACbC,cAAe,EAEfC,YAAa,EACbC,KAAM,EACNC,MAAO,EAGPC,MAAO,EACPC,KAAM,EACNC,OAAQ,EACRnJ,IAAK,EACLoJ,QAAS,EACTC,KAAM,IAKR,SAAgBC,EAAeC,GAC7B,MAAmB,UAAZA,GAAmC,SAAZA,GAAkC,WAAZA,EAKtD,MAQMC,EAAa9M,OAAAsL,OAAA,GACdD,EAT8D,CACjE0B,IAAK,EACLC,OAAQ,EACRC,MAAO,IAUIC,GAAW3D,EAASuD,GAEHnN,EAAAmN,EAAA,CAAA,QAAA,WACkCnN,EAAAmN,EAAA,CAAA,QAAA,SAAA,MAAA,SAAA,UA8EhE,MAWEK,GAAAxN,EAAA0L,EAAA,CAAA,IAAA,IAAA,KAAA,KAAA,WAAA,YAAA,YAAA,eAGW+B,GAAuB7D,EAAS4D,IAIvCE,GAA6C,CAAC1F,EAAG,EAAG4D,EAAG,GAgB3D+B,IAfqC/D,EAAS8D,IAe9C1N,EAAAwN,GAAA,CAAA,OAAA,UAAA,OAAA,SAAA,MAAA,WA8BII,GAAmBvN,OAAAsL,OAAA,GACpB+B,GACAC,IAGL,SAIgBE,GAAeX,GAC7B,QAASU,GAAoBV,GAW/B,SAAgBY,GAAYZ,EAAkBa,GAC5C,OAQF,SAA0Bb,GACxB,OAAQA,GACN,KAAKvC,EACL,KAAKC,EACL,KAAKC,EAGL,KAAKS,EACL,KAAKC,EACL,KAAKC,EACL,KAAKC,EACL,KAAKJ,EACL,KAAKL,EACL,KAAKC,EACL,KAAKC,EACL,KAAKC,EAGL,KAAKjB,EACL,KAAKF,EACL,KAAKC,EACH,MAAO,CAEL+D,MAAO,SACPC,KAAM,SACNC,KAAM,SACNC,OAAQ,SACRC,OAAQ,SACRC,IAAK,SACLC,KAAM,SACNC,KAAM,SACNC,MAAO,SACPC,KAAM,SACN5B,KAAM,SACN6B,SAAU,UAEd,KAAKvE,EACL,KAAKC,EACL,KAAKG,EACL,KAAKC,EACH,MAAO,CAELwD,MAAO,SACPC,KAAM,SACNC,KAAM,SACNC,OAAQ,SACRC,OAAQ,SACRC,IAAK,SACLC,KAAM,SACNC,KAAM,SACNC,MAAO,SACPC,KAAM,SACN5B,KAAM,UAEV,KAAKxC,EACL,KAAKC,EACL,KAAKG,EACL,KAAKC,EACH,MAAO,CACLwD,KAAM,SACNG,IAAK,SACLC,KAAM,SACNG,KAAM,SACNN,OAAQ,SACRH,MAAO,SACPI,OAAQ,SACRH,KAAM,UAEV,KAAKlD,EACH,MAAO,CACLiD,MAAO,SACPC,KAAM,SACNC,KAAM,SACNC,OAAQ,SACRC,OAAQ,SACRC,IAAK,SACLxB,KAAM,SACN0B,KAAM,SACNC,MAAO,UAEX,KAAK1D,EACH,MAAO,CAACkD,MAAO,SAAUU,SAAU,UACrC,KAAKtD,EACH,MAAO,CAACyB,KAAM,WA3FX8B,CAAiBzB,GAASa,GA+FnC,SAAgBa,GAAU1B,GACxB,OAAQA,GACN,KAAK/C,EACL,KAAKC,EACL,KAAKW,EACL,KAAKI,EACL,KAAKH,EACL,KAAKC,EACL,KAAKC,EAGL,KAAKb,EACL,KAAKC,EACH,OAEF,KAAKJ,EACL,KAAKF,EACL,KAAKC,EACL,KAAKa,EAEL,KAAKM,EACL,KAAKI,EACL,KAAKC,EACH,MAAO,WAGT,KAAKd,EACL,KAAKC,EACL,KAAKC,EACH,MAAO,WAIT,KAAKN,EACL,KAAKC,EACL,KAAKC,EACL,KAAKC,EACL,KAAKY,EACL,KAAKC,EACL,KAAKF,EACH,OAGJ,MAAM,IAAIhI,MAAM,iCAAmC6J,GCzNrD,MAAM2B,GAA4D,CAChEC,OAAQ,EAERC,aAAc,EACdC,OAAQ,EACRC,YAAa,EACbC,WAAY,EACZC,iBAAkB,EAClBC,cAAe,EACfC,YAAa,EACbC,OAAQ,EACRC,WAAY,EACZC,KAAM,EACNC,UAAW,EACXC,SAAU,EACVC,eAAgB,EAChBC,YAAa,EACbC,UAAW,EACXC,WAAY,EACZC,WAAY,EACZC,cAAe,EACfC,WAAY,EACZC,WAAY,EACZC,WAAY,EACZC,iBAAkB,EAClBC,UAAW,EACXC,cAAe,EACfC,eAAgB,EAChBC,gBAAiB,EACjBC,WAAY,EACZC,aAAc,EACdC,aAAc,EACdC,aAAc,EACdC,OAAQ,EACRC,gBAAiB,EACjBC,UAAW,EACXC,UAAW,EACXC,OAAQ,EACRC,SAAU,EACVC,UAAW,EACXC,UAAW,EACXC,SAAU,EACVC,eAAgB,EAChBC,UAAW,EACXC,YAAa,EACbC,WAAY,EACZC,YAAa,EACbC,UAAW,EACXC,MAAO,EACPC,SAAU,EACVC,UAAW,EACXC,MAAO,EACPC,WAAY,EACZC,YAAa,EACbC,WAAY,EACZC,cAAe,EACfC,WAAY,EACZC,UAAW,EACXC,cAAe,EACfC,eAAgB,EAChBC,gBAAiB,EACjBC,WAAY,EACZC,aAAc,EACdC,aAAc,EACdC,OAAQ,EACRC,OAAQ,EACRC,OAAQ,EACRC,OAAQ,GAGJC,GAAqB3S,OAAAsL,OAAA,GACtBkD,GAA4B,CAC/BoE,SAAU,IAiBCC,IAdiB7S,OAAAsL,OAAA,CAC5BwH,UAAW,EACXC,MAAO,GACJvE,GAA4B,CAC/BwE,OAAQ,IAUqBzJ,EAASoJ,KClHlCM,GAAgE,CACpEC,WAAY,EACZC,cAAe,EACfC,QAAS,EACTC,aAAc,EACdC,UAAW,EACXC,UAAW,EACXtE,OAAQ,EACRC,WAAY,EACZsE,eAAgB,EAChBC,gBAAiB,EACjBC,oBAAqB,EACrBC,oBAAqB,EACrBC,kBAAmB,EACnBC,UAAW,EACXpE,WAAY,EACZE,cAAe,EACfE,WAAY,EACZG,UAAW,EACXC,cAAe,EACfC,eAAgB,EAChBC,gBAAiB,EACjBC,WAAY,EACZ0D,YAAa,EACbzD,aAAc,EACdC,aAAc,EACdC,aAAc,EACdE,gBAAiB,EACjBsD,QAAS,EACTC,QAAS,EACTpD,OAAQ,EACRnC,OAAQ,EACRwF,QAAS,EACTC,WAAY,EACZC,YAAa,EACbC,WAAY,EACZC,iBAAkB,EAClBC,gBAAiB,EACjBC,aAAc,EACdC,cAAe,EACfC,WAAY,EACZC,kBAAmB,EACnBC,kBAAmB,EACnBC,WAAY,EACZ7D,UAAW,EACXI,YAAa,EACbO,MAAO,EACPC,WAAY,EACZC,YAAa,EACbE,cAAe,EACfC,WAAY,EACZC,UAAW,EACXC,cAAe,EACfC,eAAgB,EAChBC,gBAAiB,EACjBC,WAAY,EACZC,aAAc,EACdwC,YAAa,EACbvC,aAAc,EACd3R,KAAM,EACN8R,OAAQ,EACRC,OAAQ,GAgBGoC,IAbiB9U,OAAAsL,OAAA,GACzB2H,GAA4B,CAE/BhH,QAAS,EACTK,MAAO,EACPN,OAAQ,EACRD,KAAM,EACNM,KAAM,EACND,YAAa,EAEb4G,OAAQ,IAGuBzJ,EAAS0J,KCtRnC,MAAMhM,+BCWe,8BAGE,+FAEgB,uGAG9C,SAAmD4F,GACjD,yDAA0DA,0DAG5D,SAA+Ca,GAC7C,sDAAuDA,kCAGzD,SAAsCA,GACpC,qCAAsCA,2BAGxC,SAAkC5G,GAChC,wCAAyCA,gCAIzC,mHAEoC,mFAGtC,SAAoCiB,GAClC,iCAAkCA,iCAGpC,SAA0CpH,GACxC,qDAAsDA,sDAKtD,4HAIA,iHAGF,SAAkCZ,GAChC,6BAA8BA,sBAGhC,SAA+BgI,EAAegN,EAAeC,GAC3D,mCAAoCjN,SAAaiN,6CAAoDD,8BAIvG,SAAwCE,GACtC,wCAAyCnP,EAAUmP,0BAInD,0JAIF,SAAmCC,GACjC,wBAAyBA,EAAShN,KAAK,gBAAoC,IAApBgN,EAAS3U,OAAe,KAAO,wCAExF,SAAqC4U,GACnC,MAAMC,iBAACA,EAAgBC,WAAEA,GAAcF,EACvC,mCAAoCrP,EAAUsP,0CAAyDtP,EACrGuP,2BAIJ,SACExI,EACAlM,EACAuB,GAEA,iBAAkB2K,UAAgBlM,2BAA8BmF,EAAU5D,yBAG5E,SAAiCvB,GAC/B,6BAA8BA,qCAGhC,SACE+M,EACAb,EACAsI,GAQA,WANkBA,EAAIG,aACfH,EAAIG,kBACPH,EAAII,UACJ,wBACA,mEAEuC7H,OAAUb,oCACvC,MAAZA,EAAkB,QAAU,mBACnBa,2HAGb,SAAkD/M,EAAY6U,GAC5D,6BAA8B7U,sBAAyB6U,sDAGzD,SAAiCA,GAC/B,uCAAwCA,uBAG1C,SAAiC3I,EAAkB4I,GACjD,mCAAoC5I,cAAoB4I,6BAE1D,SAA8B9U,EAA+BwU,GAC3D,MAAMpJ,KAACA,EAAIC,OAAEA,GAAUmJ,EACvB,wBACoBxU,2BAAgCoL,GAAQC,EAAS,kBAAoBD,EAAO,OAAS,yBAI3G,SAA8B2J,EAAiC7I,GAC7D,kBAAmB/G,EAAU4P,oBAA2B7I,uEAE1D,SAAkCA,EAAkBlM,EAAYgV,GAC9D,SAAU9I,wBAA8BlM,mCAAsCgV,sCAI9E,uHAEF,SAAoC9I,EAAkB+I,EAA6CC,GACjG,SAAUhJ,yCAA+C+I,KAAeC,WAAgBA,IAAS,8BAGnG,SAAuChJ,GACrC,SAAUA,4BAAkCA,mEAG9C,SAA6CA,GAC3C,SAAUA,mFAGZ,SAAoCqI,GAClC,mCAAoCA,EAAShN,KAAK,YAAYgN,EAAS3U,OAAS,EAAI,MAAQ,oDAG9F,SAA4CsM,EAAkBlM,GAC5D,iCAAkCkM,iBAAuBlM,oDAC9C,YAATA,EAAqB,QAAU,wDAMjC,oHAEF,SAA8BmV,EAAgBC,GAE5C,wEADiBD,GAASC,EAAQ,YAAcD,EAAQ,KAAO,6EAIjE,SAAiCE,EAAkBC,GACjD,2BAA4BD,uBAA8BC,mDAK1D,2GAEF,SAAmDC,GACjD,wCAAyCA,sEAG3C,SAAwDR,GACtD,iEAAkE5P,EAAU4P,+CAG9E,SAAuDF,GACrD,iDAAkDA,4GAGpD,SAA+CE,GAC7C,qEAAsE5P,EAAU4P,yCAGlF,SAAiDhI,GAC/C,iDAAkDA,wBAGpD,SAAiCb,GAC/B,wBAAyBA,8BAAgD,MAAZA,EAAkB,QAAU,qDAG3F,SAA4CA,EAAkByI,EAAsBa,GAClF,kBAAmBtJ,0BAAgCyI,2BAAmCa,kDAGxF,SAA6Cb,EAAsBa,GACjE,sCAAuCb,2BAAmCa,uDAG5E,SAAkDb,EAAsBc,EAAkBvJ,GACxF,SAAUA,cAAoBuJ,0CAAiDd,qCAGjF,SAAyC5H,EAAY4H,GACnD,qBAAsBA,+BAAuC5H,gCAG/D,SACE2I,EACAC,EACAC,EACAC,GAEA,qBAAsBF,EAAW9R,wBAAwB6R,EAAS7R,gBAAgBsB,EAAUyQ,UAAWzQ,EACrG0Q,eACY1Q,EAAUyQ,6CAG1B,SAAsD1J,GACpD,kDAAmDA,gGAGrD,SAAkCpG,GAChC,gCAAiCX,EAAUW,qFAGN,6CAGrC,qHAGsC,kDAGxC,SAAsCoG,GACpC,uBAAwBA,2BAAiCA,iCAG3D,SAA0CyI,GACxC,wCAAyCA,iCAG3C,SAA2CE,GACzC,mFAAoFA,uBAItF,SAAgCiB,EAAkBvU,GAChD,iBAAkBuU,MAAa3Q,EAAU5D,0BAG3C,SAAoCwU,GAClC,oBAAqBA,iDAA4DA,EAAa7O,QAC5F,MACA,uBAIJ,SAA2B8O,GACzB,oCAAqC7Q,EAAU6Q,sFAGjD,SAAoDC,EAAwBC,GAC1E,SAAUA,EAAS,UAAY,KAAKA,GAAUD,EAAS,OAAS,KAAKA,EAAS,UAAY,KACxFC,GAAUD,EAAS,OAAS,iFAIhC,SACEA,EACAC,EACAnJ,GAEA,SAAUkJ,8BAAmCC,SAAcnJ,mDAG7D,SACE8H,EACAsB,GAEA,yEAA0EtB,MAAcsB,2DAG1F,SAA0CD,EAAwBnJ,GAChE,iDAAkDA,oBAAuBmJ,4BAG3E,SAAsCR,GACpC,wCAAyCA,8BAI3C,SAAyCxJ,GACvC,iBAAkBA,kEAGpB,SAAgDA,GAC9C,oBAAqBA,uCDnTjBkK,IPAAzO,GOAcO,GPADD,EACV,CACLN,MAAO,SAAStH,GACd,OAAIgW,UAAUzW,QACZ+H,IAAStH,EACFkI,MAEAZ,IAGXtB,MAAO,WAEL,OADIsB,IAAStF,GAAOoF,EAAIC,IAAU,QAAS,QAAS2O,WAC7C9N,MAET+N,KAAM,WAEJ,OADI3O,IAASO,GAAMT,EAAIC,IAAU,OAAQ,OAAQ2O,WAC1C9N,MAETgO,KAAM,WAEJ,OADI5O,IAASQ,GAAMV,EAAIC,IAAU,MAAO,OAAQ2O,WACzC9N,MAETiO,MAAO,WAEL,OADI7O,IAASS,GAAOX,EAAIC,IAAU,MAAO,QAAS2O,WAC3C9N,QAzBE,IAAYb,GACrBC,GOCN,IAAI8O,GAA2BL,GA4D/B,SAAgBE,MAAQjW,GACtBoW,GAAQH,KAAKI,MAAMD,GAASJ,WEtEvB,MAAMM,GAAyB,CACpCC,aAAc,EACdC,QAAS,EACTC,SAAU,EACVC,QAAS,EACTC,QAAS,GAOEC,GAA+B,eAC/BC,GAAqB,UACrBC,GAAuB,WACvBC,GAAqB,UAErBC,GAAqB,UAWlC,SAAgBC,GAAYtX,GAC1B,GAAIA,EAEF,OADAA,EAAOA,EAAKuX,eAEV,IAAK,IACL,KAAKN,GACH,MAAO,eACT,IAAK,IACL,KAAKE,GACH,MAAO,WACT,IAAK,IACL,KAAKD,GACH,MAAO,UACT,IAAK,IACL,KAAKE,GACH,MAAO,UACT,KAAKC,GACH,MAAO,eCtCEG,IAAjB,SAAiBA,GAEFA,EAAAC,OAAmB,SACnBD,EAAAE,IAAa,MACbF,EAAAG,IAAa,MACbH,EAAAI,KAAe,OACfJ,EAAAK,OAAmB,SAEnBL,EAAAM,KAAe,OACfN,EAAAO,IAAa,MAGbP,EAAAQ,SAAuB,WACvBR,EAAAS,SAAuB,WACvBT,EAAAU,UAAyB,YACzBV,EAAAW,YAA6B,cAG7BX,EAAAN,QAAqB,UACrBM,EAAAY,MAAiB,QACjBZ,EAAAa,KAAe,OApB9B,CAAiBb,KAAAA,GAAS,KA2C1B,MAoBac,GAAczS,EAjBvB,CACF0S,OAAQ,UACR9Q,IAAK,UACL+Q,IAAK,UACLC,KAAM,UACNC,OAAQ,UACRC,KAAM,OACNC,IAAK,OACL/B,QAAS,UACTgC,cAAe,cACf7L,MAAO,mBACP8L,KAAM,mBACNC,SAAU,eACVC,SAAU,eACVC,UAAW,iBAoDAC,GAA+C,CAAC,SAAU,MAAO,MAAO,OAAQ,SAAU,OAAQ,OACzGC,GAAiC7Q,EAAM4Q,IAGvCE,GAA+B9Q,EADqB,CAAC,WAAY,WAAY,cAQ7E+Q,GAA0B/Q,EALqB4Q,GAAgCpR,OAAO,CAC1F,WACA,WACA,eAKIwR,GAAwBhR,EADqB,CAAC,UAAW,cAAe,QAAS,SAGvF,SAEgBiR,GAAkBvZ,GAChC,OAAOA,KAAQsZ,GASjB,SAAgBE,GACdxZ,GAEA,OAAOA,KAAQmZ,GAkfjB,MAAMM,GAA0C,CAC9CzZ,KAAM,EACNgO,OAAQ,EACR0L,MAAO,EACPC,UAAW,EACXC,OAAQ,EACRC,KAAM,EAENC,QAAS,EACTC,MAAO,EAEPC,MAAO,EACPC,KAAM,EAENC,KAAM,EACNC,SAAU,EACVC,SAAU,EACVC,YAAa,EACbC,KAAM,EAENhH,QAAS,EACTiH,aAAc,EACdC,aAAc,GAGHC,GAAmB7R,EAAS6Q,IAQvCza,EAAAya,GAAA,CAAA,OAAA,SAAA,QAAA,YAAA,WAwJF,WACE,MAAMjX,EAAwB,GAC9B,IAAK,MAAM0J,KAAWK,GACpB,IAAK,MAAMmO,KAAgB7U,EAAK8Q,IAC9B,IAAK,MAAMhC,KAAa2D,GAAa,CACnC,MAAM3V,EAAMgY,GAA0BzO,EAASwO,GAC3CE,GAAwB1O,EAASyI,IAAckG,GAAyBlG,EAAW+F,KACrFlY,EAAMG,GAAOH,EAAMG,IAAQ,GAC3BH,EAAMG,GAAKF,KAAKkS,KA3JMmG,GAEhC,SAAgBC,GAAyBpG,EAAsBc,GAC7D,OAAQA,GACN,IAAK,OACL,IAAK,SACL,IAAK,UACL,IAAK,QACH,OAAO,EACT,IAAK,SACL,IAAK,cACH,OAAQhN,EAAS,CAAC,QAAS,OAAQ,YAAakM,GAClD,IAAK,OACH,OAAQlM,EAAS,CAAC,QAAS,OAAQ,WAAY,WAAYkM,GAC7D,IAAK,QACH,OAAO6E,GAAyB7E,IAA4B,SAAdA,GAAsC,UAAdA,EACxE,IAAK,UACH,OAAO6E,GAAyB7E,IAAclM,EAAS,CAAC,QAAS,QAASkM,GAC5E,IAAK,eACL,IAAK,YACH,OAAOlM,EAAS,CAAC,QAAS,QAASkM,GACrC,IAAK,eACH,MAAqB,SAAdA,EACT,IAAK,QACH,OAAO6E,GAAyB7E,GAClC,IAAK,OACH,OAAO6E,GAAyB7E,IAA4B,aAAdA,GAA0C,cAAdA,EAC5E,IAAK,WACH,MAAqB,QAAdA,EACT,IAAK,OACH,MAAqB,QAAdA,EACT,IAAK,WACH,MAAqB,WAAdA,EACT,IAAK,OACH,OACsBA,KAjkBX0E,KAkkBR5Q,EACC,CACE,MACA,OACA,MACA,YACA,YAEFkM,GAKR,MAAM,IAAItS,gCAAgCoT,MAM5C,SAAgBuF,GAAoC9O,EAAkBuJ,GACpE,OAAQA,GACN,IAAK,cACL,IAAK,SACH,OAAKxJ,EAAeC,QAGpB,EAFS+O,GAAYC,mCAAmChP,GAG1D,IAAK,OACL,IAAK,OACL,IAAK,SACL,IAAK,QACL,IAAK,OACL,IAAK,WACL,IAAK,WACL,IAAK,OACL,IAAK,UACL,IAAK,eACL,IAAK,eACL,IAAK,YACL,IAAK,UACL,IAAK,QACL,IAAK,QACL,IAAK,OACH,OAGJ,MAAM,IAAI7J,iCAAiCoT,OAG7C,SAAgBoF,GAAyBM,EAA0BT,GACjE,OAAIjS,EAAS,CAAC2S,GAAcC,IAAeX,QAChBrV,IAAlB8V,GAA+B5B,GAAkB4B,GAC/CT,IAAiBY,GACnB7S,EAAS,CAAC+O,GAAUM,KAAMN,GAAUO,SAAK1S,GAAY8V,GACnDT,IAAiBa,IACnB9S,EACL,CACE+O,GAAUE,IACVF,GAAUG,IACVH,GAAUI,KACVJ,GAAUK,OACVL,GAAUQ,SACVR,GAAUS,SACVT,GAAUU,UACVV,GAAUC,YACVpS,GAEF8V,GAON,SAAgBP,GAAwB1O,EAAkByI,GACxD,OAAQzI,GACN,KAAKsP,EACL,KAAKC,EACH,OAAOjC,GAAyB7E,IAAclM,EAAS,CAAC,OAAQ,SAAUkM,GAC5E,KAAK+G,EACL,KAAKC,EACL,KAAKC,EACL,KAAKC,EACL,KAAKC,EAGH,OACEtC,GAAyB7E,IACFA,KAhpBdyE,IAipBT3Q,EAAS,CAAC,OAAQ,SAAUkM,GAEhC,KAAKoH,EACL,KAAKC,EACL,KAAKC,EACH,MAAqB,SAAdtH,EACT,KAAKuH,EACH,MAAqB,YAAdvH,EAGX,OAAO,EA4BT,SAASgG,GAA0BzO,EAAkBwO,GACnD,OAAOxO,EAAU,IAAMwO,uBCt1BzB,IAAIyB,EAAI9X,EAAOC,QAMf6X,EAAEC,UAAY,SAASjW,EAAMxB,GAAK,OAAQA,EAAO,SAAIwB,EAAMxB,GAE3DwX,EAAEhW,KAAO,SAASxB,GAAK,OAAU,MAAHA,EAAU,KAAOA,EAAO,UAEtDwX,EAAEE,SAAW,SAASrV,GAAK,OAAOA,GAElCmV,EAAEG,KAAOH,EAAEC,UAAU,OAAQ,WAAa,OAAO,IAEjDD,EAAEI,MAAQJ,EAAEC,UAAU,QAAS,WAAa,OAAO,IAEnDD,EAAEK,UAAY,SAASzc,GACrB,OAAOwF,KAAKkX,MAAMlX,KAAKJ,UAAUpF,KAGnCoc,EAAEO,MAAQ,SAAS5X,EAAGC,GACpB,OAAOQ,KAAKJ,UAAUL,KAAOS,KAAKJ,UAAUJ,IAG9CoX,EAAEQ,OAAS,SAAS5c,GAClB,IAAK,IAAIiH,EAAGb,EAAMxG,EAAE,EAAGid,EAAIvG,UAAUzW,OAAQD,EAAEid,IAAOjd,EAEpD,IAAKwG,KADLa,EAAIqP,UAAU1W,GACII,EAAIoG,GAAQa,EAAEb,GAElC,OAAOpG,GAGToc,EAAEvc,OAAS,SAASoH,GAClB,OAAY,MAALA,GAAyB,MAAZA,EAAEpH,OAAiBoH,EAAEpH,OAAS,MAGpDuc,EAAEtW,KAAO,SAASmB,GAChB,IAAe6V,EAAXhX,EAAO,GACX,IAAKgX,KAAK7V,EAAGnB,EAAKpD,KAAKoa,GACvB,OAAOhX,GAGTsW,EAAEW,KAAO,SAAS9V,GAChB,IAAe6V,EAAXC,EAAO,GACX,IAAKD,KAAK7V,EAAG8V,EAAKra,KAAKuE,EAAE6V,IACzB,OAAOC,GAGTX,EAAEY,MAAQ,SAASC,EAAMrY,GACvB,OAAQA,EAAIwX,EAAEpV,EAAEpC,IACdqY,EAAKC,OAAO,SAASld,EAAKiH,GAAK,OAAQjH,EAAI4E,EAAEqC,IAAM,EAAGjH,GAAS,IAC/Did,EAAKC,OAAO,SAASld,EAAKiH,GAAK,OAAQjH,EAAIiH,GAAK,EAAGjH,GAAS,KAGhEoc,EAAEe,OAAS,SAASpL,GAElB,IAAInL,EAAImL,EAAOlS,OACf,IAAK+G,EAAG,MAAO,GACf,IAAK,IAAI1H,EAAEke,OAAOrL,EAAO,IAAKnS,EAAE,EAAGA,EAAEgH,IAAKhH,EACxCV,GAAK,IAAMke,OAAOrL,EAAOnS,IAE3B,OAAOV,GAKT,IAAI4E,EAAWxE,OAAOC,UAAUuE,SAEhCsY,EAAEtV,SAAW,SAAS9G,GACpB,OAAOA,IAAQV,OAAOU,IAGxBoc,EAAEiB,WAAa,SAASrd,GACtB,MAA8B,sBAAvB8D,EAASrE,KAAKO,IAGvBoc,EAAErV,SAAW,SAAS/G,GACpB,MAAwB,iBAAVwB,OAA6C,oBAAvBsC,EAASrE,KAAKO,IAGpDoc,EAAEzW,QAAUD,MAAMC,SAAW,SAAS3F,GACpC,MAA8B,mBAAvB8D,EAASrE,KAAKO,IAGvBoc,EAAEkB,SAAW,SAAStd,GACpB,MAAsB,iBAARA,GAA2C,oBAAvB8D,EAASrE,KAAKO,IAGlDoc,EAAE9T,UAAY,SAAStI,GACrB,OAAe,IAARA,IAAwB,IAARA,GAAuC,oBAAtB8D,EAASrE,KAAKO,IAGxDoc,EAAEmB,OAAS,SAASvd,GAClB,MAA8B,kBAAvB8D,EAASrE,KAAKO,IAGvBoc,EAAEoB,QAAU,SAASxd,GACnB,OAAc,MAAPA,GAAeA,GAAQA,GAGhCoc,EAAEja,SAA8B,mBAAXnB,QAAyBA,OAAOmB,UAAaia,EAAEI,MAIpEJ,EAAEqB,OAAS,SAASve,GAClB,OAAY,MAALA,GAAmB,KAANA,EAAW,MAAQA,GAGzCkd,EAAEsB,QAAU,SAASxe,GACnB,OAAY,MAALA,GAAmB,KAANA,EAAW,KAAW,UAAJA,KAAwBA,GAIhEkd,EAAEuB,KAAO,SAASze,EAAGqP,GACnB,IAAI0H,EAAI1H,GAAkBtM,KAC1B,OAAY,MAAL/C,GAAmB,KAANA,EAAW,KAAO+W,EAAEyG,MAAMxd,IAGhDkd,EAAEzT,MAAQ,SAAS1B,GACjB,OAAY,MAALA,EAAamV,EAAEzW,QAAQsB,GAAKA,EAAI,CAACA,GAAM,IAGhDmV,EAAEwB,IAAM,SAAS3W,GACf,OAAOmV,EAAEzW,QAAQsB,GAAK,IAAMA,EAAEC,IAAIkV,EAAEwB,KAAO,IACvCxB,EAAEtV,SAASG,IAAMmV,EAAErV,SAASE,GAG5BzB,KAAKJ,UAAU6B,GAAGE,QAAQ,SAAS,WAAWA,QAAQ,SAAU,WAChEF,GAKN,IAAI4W,EAAW,qBA+Hf,SAASC,EAAOlX,EAAGgX,GACjB,IAAYhe,EAARV,EAAI,GACR,IAAKU,EAAE,EAAGA,EAAEgH,IAAKhH,EAAGV,GAAK0e,EACzB,OAAO1e,EAsBT,SAAS6e,EAAe7e,EAAG2d,EAAKmB,GAC9B,IAAIC,EAAM,EAAGC,EAAMhf,EAAEif,MAAMC,GAQ3B,OANElf,EADE8e,GACGE,EAAMA,EAAInE,WACZsE,OAAO,SAASC,GAAsB,OAAjBL,GAAOK,EAAEze,SAAsBgd,IACpD9C,UAECmE,EAAIG,OAAO,SAASC,GAAsB,OAAjBL,GAAOK,EAAEze,SAAsBgd,KAErDhd,OAASX,EAAEsI,KAAK,IAAI+W,OAASL,EAAI,GAAGlW,MAAM,EAAG6U,GA/JxDT,EAAE/U,MAAQ,SAASzC,GACjB,OAAOwY,OAAOxY,GAAG4Z,MAAMX,GAAU3W,IAAI,SAAS+O,GAC5C,MAAgB,MAATA,EAAE,GAAaA,EACX,MAATA,EAAE,IAAuB,MAATA,EAAE,GAAaA,EAAEjO,MAAM,GAAI,GAC3CiO,EAAEjO,MAAM,GAAI,GAAGb,QAAQ,YAAa,SAI1CiV,EAAEnW,SAAW,SAASrB,GAEpB,OAAU,MAAHA,GAAWwX,EAAEiB,WAAWzY,GAAKA,EAClCwX,EAAEC,UAAUzX,EAAG6C,SAAS,IAAK,YAAc2U,EAAE/U,MAAMzC,GAAGsC,IAAIkV,EAAEwB,KAAKpW,KAAK,MAAQ,QAIlF4U,EAAEpV,EAAIoV,EAAEnW,SAERmW,EAAEqC,QAAU,SAAS7Z,GACnB,IAAI1F,EACJ,OAAOkd,EAAErV,SAASnC,KAAO1F,EAAEkd,EAAE/U,MAAMzC,IAAI/E,OAAS,EAC9C,SAASoH,EAAGyX,GACV,IAAK,IAAI9e,EAAE,EAAGA,EAAEV,EAAEW,OAAO,IAAKD,EAAGqH,EAAIA,EAAE/H,EAAEU,IACzCqH,EAAE/H,EAAEU,IAAM8e,GAEZ,SAASzX,EAAGyX,GAAKzX,EAAErC,GAAK8Z,IAI5BtC,EAAEuC,MAAQ,SAASvY,EAAMwY,GACvB,OAAO,SAASha,GACdA,EAAIwX,EAAEpV,EAAEpC,IAAMwX,EAAEE,SAChB,IAAI1V,EAAIR,GAAQgW,EAAEhW,KAAKxB,GAAK,IAAIwX,EAAEhW,KAAKxB,GAAK,IAC5C,OAAOwX,EAAEC,UAAUzV,EAAG,SAASqP,GAAK,OAAO2I,EAAGha,EAAEqR,QAIpDmG,EAAEyC,OAAUzC,EAAEuC,MAAM,QAASvC,EAAEoB,SAC/BpB,EAAE0C,QAAU1C,EAAEuC,MAAM,SAAUvC,EAAEvc,QAEhCuc,EAAE2C,IAAM,SAASna,EAAGmN,GAClBnN,EAAIwX,EAAEpV,EAAEpC,GACR,IAAIsC,EAAMkV,EAAEzW,QAAQoM,GAAUqK,EAAEY,MAAMjL,GAAUA,EAChD,OAAO,SAASkE,GAAK,QAAS/O,EAAItC,EAAEqR,MAKtCmG,EAAE4C,WAAa,SAASjZ,GACtB,IAAIkZ,EAAO,GASX,YARa3Z,IAATS,IAAoBA,EAAO,IAC/BA,EAAOqW,EAAEzT,MAAM5C,GAAMmB,IAAI,SAAStC,GAChC,IAAI1F,EAAI,EAIR,MAHkB,MAAT0F,EAAE,IAAc1F,GAAK,EAAG0F,EAAIA,EAAEoD,MAAM,IAC3B,MAATpD,EAAE,KAAc1F,EAAI,EAAI0F,EAAIA,EAAEoD,MAAM,IAC7CiX,EAAKvc,KAAKxD,GACHkd,EAAEnW,SAASrB,KAEb,SAASG,EAAGC,GACjB,IAAIpF,EAAGgH,EAAGhC,EAAGP,EACb,IAAKzE,EAAE,EAAGgH,EAAEb,EAAKlG,OAAQD,EAAEgH,IAAKhH,EAG9B,GAFAgF,EAAImB,EAAKnG,GACTyE,EAAI+X,EAAEzX,IAAIC,EAAEG,GAAIH,EAAEI,IACX,OAAOX,EAAI4a,EAAKrf,GAEzB,OAAO,IAIXwc,EAAEzX,IAAM,SAASI,EAAGC,GAClB,OAAQD,EAAIC,GAAU,MAALD,IAAmB,MAALC,GAAa,GACzCD,EAAIC,GAAU,MAALA,IAAmB,MAALD,EAAY,GAClCC,EAAIA,aAAa/C,MAAQ+C,EAAIA,GAC7BD,EAAIA,aAAa9C,MAAQ8C,EAAIA,KAAQA,GAAKC,GAAMA,GAAK,EACvDA,GAAMA,GAAKD,GAAMA,EAAI,EAAI,IAG7BqX,EAAE8C,OAAS,SAASna,EAAGC,GAAK,OAAOD,EAAIC,GAEvCoX,EAAE+C,WAAa,SAASxW,EAAOyW,EAAQC,GACrC,IAAIC,EAAU3W,EAAMuU,OAAO,SAASqC,EAAKb,EAAG9e,GAC1C,OAAQ2f,EAAIF,EAAMX,IAAM9e,EAAG2f,GAC1B,IASH,OAPA5W,EAAM5C,KAAK,SAAShB,EAAGC,GACrB,IAAIwa,EAAKJ,EAAOra,GACZ0a,EAAKL,EAAOpa,GAChB,OAAOwa,EAAKC,GAAM,EAAID,EAAKC,EAAK,EACxBH,EAAQD,EAAMta,IAAMua,EAAQD,EAAMra,MAGrC2D,GAITyT,EAAEsD,QAAU,SAAS3a,GAKnB,IAJA,IACI4a,EACA/f,EAFAggB,EAAI7a,EAAElF,OAIH+f,GACLhgB,EAAIigB,KAAKC,MAAMD,KAAKE,SAAWH,KAC/BD,EAAO5a,EAAE6a,GACT7a,EAAE6a,GAAK7a,EAAEnF,GACTmF,EAAEnF,GAAK+f,GAMXvD,EAAE4D,IAAM,SAAS9gB,EAAGW,EAAQogB,EAAKC,GAC/BA,EAAUA,GAAW,IACrB,IAAIjK,EAAIpW,EAASX,EAAEW,OACnB,GAAIoW,GAAK,EAAG,OAAO/W,EACnB,OAAQ+gB,GACN,IAAK,OACH,OAAOnC,EAAO7H,EAAGiK,GAAWhhB,EAC9B,IAAK,SACL,IAAK,SACH,OAAO4e,EAAO+B,KAAKC,MAAM7J,EAAE,GAAIiK,GAC5BhhB,EAAI4e,EAAO+B,KAAKM,KAAKlK,EAAE,GAAIiK,GAChC,QACE,OAAOhhB,EAAI4e,EAAO7H,EAAGiK,KAU3B9D,EAAEgE,SAAW,SAASlhB,EAAGW,EAAQogB,EAAKI,EAAMC,GAC1C,IAAIzD,EAAM3d,EAAEW,OACZ,GAAIgd,GAAOhd,EAAQ,OAAOX,EAC1BohB,OAAwBhb,IAAbgb,EAAyBlD,OAAOkD,GAAY,IACvD,IAAIC,EAAIV,KAAKW,IAAI,EAAG3gB,EAASygB,EAASzgB,QAEtC,OAAQogB,GACN,IAAK,OACH,OAAOK,GAAYD,EAAOtC,EAAe7e,EAAEqhB,EAAE,GAAKrhB,EAAE8I,MAAM6U,EAAI0D,IAChE,IAAK,SACL,IAAK,SACH,IAAIE,EAAKZ,KAAKM,KAAKI,EAAE,GAAIG,EAAKb,KAAKC,MAAMS,EAAE,GAC3C,OAAQF,EAAOtC,EAAe7e,EAAEuhB,GAAMvhB,EAAE8I,MAAM,EAAEyY,IAC9CH,GAAYD,EAAOtC,EAAe7e,EAAEwhB,EAAG,GAAKxhB,EAAE8I,MAAM6U,EAAI6D,IAC5D,QACE,OAAQL,EAAOtC,EAAe7e,EAAEqhB,GAAKrhB,EAAE8I,MAAM,EAAEuY,IAAMD,IAgB3D,IAAIlC,EAAmB,wSC9RP1V,GAASC,EAAcC,GACrC,OAAgC,IAAzBD,EAAMjJ,QAAQkJ,GACtB,SAEe+X,GAASC,EAAUhc,GACjC,IAAK,IAAIhF,EAAI,EAAGA,EAAIghB,EAAI/gB,OAAQD,IAC9B,IAAKgF,EAAEgc,EAAIhhB,GAAIA,GACb,OAAO,EAGX,OAAO,EACR,SAEe+C,GAAQ3C,EAAU4E,EAAqDic,GACrF,GAAI7gB,EAAI2C,QACN3C,EAAI2C,QAAQlD,KAAKohB,EAASjc,QAE1B,IAAK,IAAIkY,KAAK9c,EACZ4E,EAAEnF,KAAKohB,EAAS7gB,EAAI8c,GAAIA,EAAG9c,GAGhC,SAEe8gB,GAAQF,EAAUhc,GAChC,IAAWkY,EAAPld,EAAI,EACR,IAAKkd,KAAK8D,EACR,GAAIhc,EAAEgc,EAAI9D,GAAIA,EAAGld,KACf,OAAO,EAGX,OAAO,EAaT,SAAgBmhB,GAAWpY,EAAiBqY,GAC1C,OAAOrY,EAAM0V,OAAO,SAASzV,GAC3B,OAAQF,GAASsY,EAAepY,KAIpC,SAAgBC,GAA2BjE,GACzC,OAAOtF,OAAOwG,KAAKlB,sFAnBpB,SAEeqc,EAAUtY,EAAc/D,GACtC,OAAO+D,EAAMzB,IAAKnC,GACZY,GAAQZ,GACHkc,EAAUlc,EAAGH,GAEfA,EAAEG,+GCFGmc,GAAqB7hB,GACnC,QAASA,EAAU,OAGrB,MAAM8hB,GAA2D,CAC/DhV,QAAS,EACT2I,UAAW,EACXsM,UAAW,EACXC,IAAK,EACLC,SAAU,EACVC,MAAO,EACPxb,KAAM,EACNyb,MAAO,EACPna,MAAO,EACPpH,KAAM,EACNsO,OAAQ,EACR8D,MAAO,EACPoP,KAAM,EACNC,OAAQ,EACRlgB,MAAO,GAGImgB,GAA0B9Y,GAASsY,IAEhD,SAAgBS,GAA2BviB,GACzC,OAAOA,KAAK8hB,GAKd,MAAMU,GAAoE,CACxER,IAAK,EACLhP,MAAO,EACPtM,KAAM,EACN0b,KAAM,EACNC,OAAQ,GAGV,SAAgBI,GAAuBtM,GACrC,OAAOqM,GAAkCrM,GAIpC,MAAMuM,GAAuC,CAAC,UAAW,SAAU,SAAU,OAAQ,OAAQ,QAAS,WAChGC,GAAwD,CAAC,QAAS,KAAM,SAE/EC,GAAYF,GAAgB7a,IAC/B7C,IACQ,CAAC5D,OAAQ,MAAOU,MAAOkD,KAIrB6d,GAAaF,GAAiB9a,IACxC7C,IACQ,CAAC5D,OAAQ,OAAQU,MAAOkD,KAItB8d,GAAczH,GAAiBxT,IACzC7C,IACQ,CAAC5D,OAAQ,QAASU,MAAOkD,KAI9B+d,GAAajQ,GAAgBjL,IAChC7C,IACQ,CAAC5D,OAAQ,OAAQU,MAAOkD,KAI7Bge,GAAejO,GAAkBlN,IACpC7C,IACQ,CAAC5D,OAAQ,SAAUU,MAAOkD,KAIxBie,GAAyB,GAA4Bva,OAChEka,GACAC,GACAC,GACAC,GACAC,IAGWE,GAAyB,CAAC,QAAS,SAAU,aAAc,UAAW,SAE7EC,GAAqB,IAE3B,SAAgBC,GAAMpjB,GACpB,OAAI6hB,GAAqB7hB,GAChBA,EAAEoB,OAAS+hB,GAAqBnjB,EAAE8B,MAEpC9B,EAGT,SAAgBqjB,GAAQ5F,GACtB,MAAMqB,EAAQrB,EAAEqB,MAAMqE,IAEtB,GAAqB,IAAjBrE,EAAMte,OACR,OAAOid,EACF,GAAqB,IAAjBqB,EAAMte,OACf,MAAO,CACLY,OAAQ0d,EAAM,GACdhd,MAAOgd,EAAM,IAGf,KAAM,6BAA+BA,EAAMte,OAAS,UAAYid,EAIpE,MAAM6F,GAA6BL,GAAsBpF,OAAO,CAACtd,EAAG4V,KAClE5V,EAAE4V,EAAK/U,QAAUb,EAAE4V,EAAK/U,SAAW,GACnCb,EAAE4V,EAAK/U,QAAQ+U,EAAKrU,OAASqU,EACtB5V,GACN,IAGH,SAAgBgjB,GAAsBniB,EAA8BU,GAClE,OAAQwhB,GAA2BliB,IAAW,IAAIU,GAGpD,SAAgB0hB,GAAmBxjB,GACjC,OAAOuiB,GAA2BviB,IAAM6hB,GAAqB7hB,GAGxD,MAAMyjB,GAAsB,GAAkB/a,OAAO4Z,GAAyBW,IAExES,GAAuC,CAClD,OACA,QAGA,MACA,WACA,YACA,YAGA,UAGA,OACA,QAEA,QACA,OACA,OACA,UACehb,OAAOka,GAAWE,GAAaC,GAAYC,GAAcH,IAE1E,IAAiBc,IAAjB,SAAiBA,GACFA,EAAAC,KAAe,OAEfD,EAAAE,UAAyB,YAEzBF,EAAAG,MAAiB,QAEjBH,EAAAI,OAAmB,SAKnBJ,EAAAK,QAAqB,UACrBL,EAAAM,UAAyB,YACzBN,EAAAO,UAAyB,YACzBP,EAAAQ,IAAa,MAEbR,EAAAS,OAAkB,QAClBT,EAAAU,SAAuB,WACvBV,EAAAW,MAAiB,QACjBX,EAAAY,KAAe,OAEfZ,EAAAa,KAAe,OAEfb,EAAAc,MAAiB,QACjBd,EAAAe,KAAe,OAEff,EAAAgB,OAAmB,SAEnBhB,EAAAiB,MAAiB,QACjBjB,EAAAkB,OAAmB,SACnBlB,EAAAmB,WAA2B,aAC3BnB,EAAAoB,QAAqB,UACrBpB,EAAAqB,MAAiB,QAjChC,CAAiBrB,KAAAA,GAAQ,iYChMlB,MAAMsB,GAAe,OACfC,GAAa,MAEblM,GAAiB,QAMjBmM,GAAmB,SACnBC,GAAmB,SAoChC,SAIgBC,GAAW9E,GACzB,OAAOlX,EAAS,CAAC,OAAQ,OAAQ,SAAUkX,GA+EhBrX,EA5EEM,EAvBM,CACnC6E,KAAM,EACNJ,IAAK,EACLE,KAAM,EACNP,MAAO,EACPnB,KAAM,EACNoB,KAAM,EACNO,MAAO,EACPF,KAAM,EACNI,SAAU,EACVR,KAAM,EACNC,OAAQ,EACRC,OAAQ,KCqFH,MAAMsX,GAAS,CACpB,UACA,WACA,QACA,QACA,MACA,OACA,OACA,SACA,YACA,UACA,WACA,YAIWC,IAFeD,GAAOzd,IAAI0Y,GAAKA,EAAEiF,OAAO,EAAG,IAEpC,CAAC,SAAU,SAAU,UAAW,YAAa,WAAY,SAAU,aAC7DD,GAAK1d,IAAI+O,GAAKA,EAAE4O,OAAO,EAAG,QClJnCC,IAAjB,SAAiBA,GACFA,EAAAC,KAAe,OACfD,EAAAE,MAAiB,QACjBF,EAAAG,IAAa,MACbH,EAAAI,KAAe,OACfJ,EAAAK,MAAiB,QACjBL,EAAAM,QAAqB,UACrBN,EAAAO,QAAqB,UACrBP,EAAAQ,aAA+B,eAC/BR,EAAAS,UAAyB,YACzBT,EAAAU,cAAiC,gBACjCV,EAAAW,mBAA2C,qBAC3CX,EAAAY,0BAAyD,4BACzDZ,EAAAa,iCACX,mCAGWb,EAAAc,UAAyB,YACzBd,EAAAe,eAAmC,iBACnCf,EAAAgB,aAA+B,eAC/BhB,EAAAiB,oBAA6C,sBAC7CjB,EAAAkB,eAAmC,iBACnClB,EAAAmB,oBAA6C,sBAC7CnB,EAAAoB,QAAqB,UACrBpB,EAAAqB,YAA6B,cAC7BrB,EAAAsB,aAA+B,eAC/BtB,EAAAuB,iBAAuC,mBACvCvB,EAAAwB,QAAqB,UACrBxB,EAAAyB,SAAuB,WACvBzB,EAAA0B,OAAmB,SACnB1B,EAAA2B,QAAqB,UACrB3B,EAAA4B,SAAuB,WACvB5B,EAAA6B,WAA2B,aAC3B7B,EAAA8B,WAA2B,aAC3B9B,EAAA+B,gBAAqC,kBACrC/B,EAAAgC,aAA+B,eAC/BhC,EAAAiC,iBAAuC,mBACvCjC,EAAAkC,sBAAiD,wBACjDlC,EAAAmC,6BAA+D,+BAC/DnC,EAAAoC,oCACX,sCAGWpC,EAAAqC,aAA+B,eAC/BrC,EAAAsC,kBAAyC,oBACzCtC,EAAAuC,gBAAqC,kBACrCvC,EAAAwC,uBAAmD,yBACnDxC,EAAAyC,kBAAyC,oBACzCzC,EAAA0C,uBAAmD,yBACnD1C,EAAA2C,WAA2B,aAC3B3C,EAAA4C,eAAmC,iBACnC5C,EAAA6C,gBAAqC,kBACrC7C,EAAA8C,oBAA6C,sBApD5D,CAAiB9C,KAAAA,GAAQ,KAmEzB,MAAM+C,GAAyD,CAC7DC,KAAM,EACNC,QAAS,EACTC,MAAO,EACPC,IAAK,EACLtK,KAAM,EACNuK,MAAO,EACPC,QAAS,EACTC,QAAS,EACTC,aAAc,GAGHC,GAAiBzf,EAASgf,IAEvC,SAAgBU,GAAsBjH,GACpC,QAASuG,GAA4BvG,GAcvC,MAAMkH,GAAqD,CACzDC,QAAS,EACTC,WAAY,EACZC,SAAU,EACVC,OAAQ,EACRC,QAAS,EACTC,SAAU,EACVC,WAAY,EACZC,WAAY,EACZC,gBAAiB,GAGnB,SAAgBC,GAAoB5H,GAClC,QAASkH,GAA0BlH,GAsBrC,MAuCM6H,GAAmD,CACvDC,eAAgB,EAChBC,oBAAqB,EAErBC,aAAc,EACdC,iBAAkB,EAClBC,sBAAuB,EACvBC,6BAA8B,EAC9BC,oCAAqC,EAErCC,gBAAiB,EAEjBC,aAAc,EACdC,kBAAmB,EAEnBC,gBAAiB,EACjBC,uBAAwB,EAExBC,kBAAmB,EAEnBC,uBAAwB,GAQpBC,GAAkB5qB,OAAAsL,OAAA,GACnB4d,GACAW,IAaL,MAAMgB,GAAc7qB,OAAAsL,OAAA,GACfid,GACAW,GApFwD,CAC3D4B,YAAa,EACbC,iBAAkB,EAElBC,UAAW,EACXC,cAAe,EACfC,mBAAoB,EACpBC,0BAA2B,EAC3BC,iCAAkC,EAElCC,aAAc,EAEdC,UAAW,EACXC,eAAgB,EAEhBC,aAAc,EACdC,oBAAqB,EAErBC,eAAgB,EAEhBC,oBAAqB,GAkElB9B,IAWL,MAAM+B,GAA+D,CACnEpD,KAAM,cACNE,MAAO,WACPrK,KAAM,UACNuK,MAAO,WACPC,QAAS,aACTC,QAAS,aACTC,aAAc,kBAEdN,QAAS,KACTE,IAAK,MAQP,SAAgBkD,GAAQC,EAAgBzN,GACtC,MAAM0N,IA3CGnB,GA2CmBkB,GAC5B,MAAME,EAAeD,EAEjB,IAAIppB,KAAKA,KAAK+V,IAAI,KAAM,EAAG,EAAG,EAAG,EAAG,EAAG,IACvC,IAAI/V,KAAK,KAAM,EAAG,EAAG,EAAG,EAAG,EAAG,GAClC,IAAK,MAAMspB,KAAgBjD,GACzB,GAAIkD,GAAiBJ,EAAMG,GACzB,OAAQA,GACN,KAAKzG,GAASG,IACZ,MAAM,IAAI3iB,MAAM,gDAClB,KAAKwiB,GAASoB,QAAS,CACrB,MAAMuF,cAACA,EAAaC,cAAEA,GAAiBC,GAAY,QAASN,GAE5DC,EAAOI,GAAuD,EAAxC7L,KAAKC,MAAMnC,EAAK8N,KAAmB,IACzD,MAEF,QAAS,CACP,MAAMA,cAACA,EAAaC,cAAEA,GAAiBC,GAAYJ,EAAcF,GACjEC,EAAOI,GAAe/N,EAAK8N,OAKnC,OAAOH,EAGT,SAASK,GAAYC,EAA4BC,GAC/C,MAAMC,EAAmBZ,GAAgBU,GAGzC,MAAO,CAACF,cAFcG,EAAQ,SAAWC,EAAiBjH,OAAO,GAAKiH,EAE/CL,cADD,OAASI,EAAQ,MAAQ,IAAMC,EAAiBjH,OAAO,IAc/E,SAAgB2G,GAAiBxV,EAAwBsL,GACvD,MAAM7e,EAAQuT,EAAatW,QAAQ4hB,GACnC,OACE7e,GAAS,IAAM6e,IAAawD,GAASO,SAAqB,IAAV5iB,GAAkD,MAAnCuT,EAAa+V,OAAOtpB,EAAQ,ICxRxF,MAAMupB,GAAiC,IAkB9C,SAAgBC,GAAWzW,GACzB,OAAO0W,GAAgB1W,IAAS2W,GAAc3W,GAGhD,SAAgB0W,GAAgB1W,GAC9B,OAAOA,IAASwW,GAGlB,SAAgBG,GAAc3W,GAC5B,aAAgBlQ,IAATkQ,GAA8B,MAARA,IAAmBA,EAAK4W,OAAU5W,EAAKpP,MAAUT,GAAQ6P,IAGxF,SAAgB6W,GACd7W,EACA8W,EACAC,GAEA,OAAO3P,GACL,GACA,CACExW,KAAMkmB,EACNF,KAAMG,GAER/W,IAASwW,GAAiB,GAAKxW,GAQnC,SAASgX,GAAmBC,GAC1B,IAAIhqB,EAAQ,GACRiqB,EAAM,GACV,IAAK,MAAMC,KAAYF,EAAW,CAChC,MAAMG,EAAiB,CAAC,GACxB,IAAK,IAAIhtB,EAAI,EAAGA,EAAI+sB,EAAS9sB,OAAQD,IAC/B+sB,EAASZ,OAAOnsB,GAAGitB,gBAAkBF,EAASZ,OAAOnsB,IACvDgtB,EAAelqB,KAAK9C,GAGxB,IAAIktB,EAAYF,EACb1lB,IAAItH,GAAK+sB,EAASZ,OAAOnsB,IACzB4H,KAAK,IACLgQ,cACH,GAAKkV,EAAII,GAMT,GAAIF,EAAeA,EAAe/sB,OAAS,KAAO8sB,EAAS9sB,OAAS,GAM7D6sB,EALLI,EAAYF,EACT7kB,OAAO,CAAC4kB,EAAS9sB,OAAS,IAC1BqH,IAAItH,GAAK+sB,EAASZ,OAAOnsB,IACzB4H,KAAK,IACLgQ,eAOL,IAAK,IAAI5X,EAAI,GAAI6C,EAAMkqB,GAAW/sB,IAAK,CACrC,IAAImtB,EAAkBD,EAAY,IAAMltB,EACxC,IAAK8sB,EAAIK,GAAkB,CACzBtqB,EAAMkqB,GAAYI,EAClBL,EAAIK,IAAmB,EACvB,YAVAtqB,EAAMkqB,GAAYG,EAClBJ,EAAII,IAAa,OAbnBrqB,EAAMkqB,GAAYG,EAClBJ,EAAII,IAAa,EAyBrB,OAAOrqB,EAGF,MAAMuqB,GAAe,CAC1BhgB,KAAM,IACNb,QAAS,IACT2I,UAAW,IACXsM,UAAW,IACXG,MAAO,IACPF,IAAK,IACLtb,KAAM,KACNyb,MAAO,KACPnP,MAAO,IACP9D,OAAQ,IACRkT,KAAM,KACNC,OAAQ,IACRlgB,MAAO,IAEP8f,SAAU,KACVja,MAAO,IACPpH,KAAM,IAENgtB,SAAU,CACRC,QAAS,KACTC,IAAK,KACL3M,IAAK,KACLrG,KAAM,IACNiT,KAAM,IACNC,MAAO,KACPC,QAAS,KACTC,OAAQ,KAEVC,UAAW,CACTnmB,MAAO,IACPuX,GAAI,IACJ/S,MAAO,MAET4hB,WAAYjB,GAAmB9R,IAC/BgT,UAAWlB,GAAmBra,IAC9Bwb,YAAanB,GAAmBpY,KAGlC,SAAgBwZ,GAAepY,GAC7B,GAAI0L,GAAqB1L,GACvB,OAAOwX,GAAaxX,EAAK/U,QAAU,IAAMusB,GAAaxX,EAAK/U,OAAS,SAAS+U,EAAKrU,OAEpF,GAAI6rB,GAAaxX,GACf,OAAOwX,GAAaxX,GAGtB,MAAM,IAAIlT,MAAM,8BAAgCkT,GAQlD,MAAMqY,GAAuB,EAAC,GAAO,GAuB/BC,GAAkD,CACtDZ,QAAS,CAAC,EAAG,GAAI,IACjB/W,OAAQ,MAAC7Q,GACT6U,KAAM,CAAC,IACPiT,KAAM,MAAC9nB,GACP+nB,MAAO,MAAC/nB,GACRgoB,QAAS,MAAChoB,GACVioB,OAAQ,CAAC,CAAC,EAAG,IACbQ,OAAQ,EAAC,GACTC,OAAQ,MAAC1oB,GACT4U,KAAM,EAAC,IAGH+T,GAA8D,CAClE5mB,MAAO,MAAC/B,GACRsZ,GAAI,CAAC,MAAO,QACZ/S,MAAO,CAAC,YAAa,eAGjBqiB,GAAgD,CACpDjuB,KAAM,MAACqF,EAAWmS,GAAUE,KAC5B1J,OAAQ,MAAC3I,GACT6U,KAAM,MAAC7U,GACP8U,SAAU,CAAC,EAAG,GACdC,SAAU,MAAC/U,GAEXwU,KAAM,MAACxU,GAEP2U,MAAO4T,GACP3T,KAAM2T,GACN9T,QAAS8T,GACT7T,MAAO6T,GACPtT,KAAMsT,GAENta,QAAS,MAACjO,GACVkV,aAAc,MAAClV,GACfmV,aAAc,MAACnV,GAEfgV,YAAa,MAAChV,GAEdqU,MAAO,MAACrU,GACRsU,UAAW,CAAC,GAAI,IAChBC,OAAQ,MAACvU,IAGL6oB,GAA8C,CAClDnc,OAAQ,CAAC,EAAG,GACZ9B,OAAQ,MAAC5K,GACTyI,OAAQ,MAACzI,GACTyM,OAAQ,MAACzM,GAET0I,aAAc,MAAC1I,GACf4M,SAAU,MAAC5M,GAEX2I,OAAQ4f,GACR3f,YAAa,MAAC5I,GACd6I,WAAY,MAAC7I,GACb8I,iBAAkB,MAAC9I,GACnB+I,cAAe,MAAC/I,GAChBgJ,YAAa,MAAChJ,GAEdkJ,WAAY,MAAClJ,GAEbmJ,KAAMof,GACNnf,UAAW,MAACpJ,GACZqJ,SAAU,MAACrJ,GACXsJ,eAAgB,MAACtJ,GACjBuJ,YAAa,MAACvJ,GACdwJ,UAAW,MAACxJ,GAEZiJ,OAAQ,MAACjJ,GACTwK,OAAQ+d,GACR9e,WAAY,MAACzJ,GACb0J,WAAY,MAAC1J,GACb2J,cAAe,MAAC3J,GAChB6J,WAAY,MAAC7J,GACb+J,iBAAkB,MAAC/J,GACnBgK,UAAW,MAAChK,GACZiK,cAAe,MAACjK,GAChBkK,eAAgB,MAAClK,GACjBmK,gBAAiB,MAACnK,GAClBoK,WAAY,MAACpK,GACbqK,aAAc,MAACrK,GACfyK,gBAAiB,MAACzK,GAClBsK,aAAc,MAACtK,GACfuK,aAAc,MAACvK,GACf4J,WAAY,MAAC5J,GACb8J,WAAY,MAAC9J,GAEb0K,UAAW,MAAC1K,GACZ2K,UAAW,MAAC3K,GACZ6K,SAAU,MAAC7K,GAEXuL,MAAOgd,GACPzd,UAAW,MAAC9K,GACZ+K,UAAW,MAAC/K,GACZgL,SAAU,MAAChL,GACXkL,UAAW,MAAClL,GACZiL,eAAgB,MAACjL,GACjBmL,YAAa,MAACnL,GACdoL,WAAY,MAACpL,GACbqL,YAAa,MAACrL,GACdsL,UAAW,MAACtL,GACZwL,SAAU,MAACxL,GACXyL,UAAW,MAACzL,GAEZ0L,MAAO,MAAC1L,GACR2L,WAAY,MAAC3L,GACb4L,YAAa,MAAC5L,GACd6L,WAAY,MAAC7L,GACb8L,cAAe,MAAC9L,GAChB+L,WAAY,MAAC/L,GACbgM,UAAW,MAAChM,GACZiM,cAAe,MAACjM,GAChBkM,eAAgB,MAAClM,GACjBmM,gBAAiB,MAACnM,GAClBoM,WAAY,MAACpM,GACbqM,aAAc,MAACrM,GACfsM,aAAc,MAACtM,GACfuM,OAAQ,MAACvM,GACTwM,OAAQ,MAACxM,IAGL8oB,GAAkD,CACtDrgB,OAAQ,CAAC,OAAQ,SACjBQ,OAAQ,MAACjJ,GACTrF,KAAM,MAACqF,GACPyM,OAAQ,MAACzM,GACT0M,OAAQ,MAAC1M,GAETkN,WAAY,MAAClN,GACbmN,cAAe,MAACnN,GAChBoN,QAAS,MAACpN,GACVqN,aAAc,MAACrN,GACfsN,UAAW,MAACtN,GACZ4M,SAAU,MAAC5M,GACXuN,UAAW,MAACvN,GACZkJ,WAAY,MAAClJ,GACb6N,UAAW,MAAC7N,GACZ4K,OAAQ,MAAC5K,GACTiO,QAAS,MAACjO,GACVkO,WAAY,MAAClO,GACbmO,YAAa,MAACnO,GAEdyJ,WAAY,MAACzJ,GACb2J,cAAe,MAAC3J,GAChB6J,WAAY,MAAC7J,GACbgK,UAAW,MAAChK,GACZiK,cAAe,MAACjK,GAChBkK,eAAgB,MAAClK,GACjBmK,gBAAiB,MAACnK,GAClBoK,WAAY,MAACpK,GACb8N,YAAa,MAAC9N,GACdqK,aAAc,MAACrK,GACfsK,aAAc,MAACtK,GACfuK,aAAc,MAACvK,GACfyK,gBAAiB,MAACzK,GAElB+N,QAAS,MAAC/N,GACVgO,QAAS,MAAChO,GAEVwN,eAAgB,MAACxN,GACjByN,gBAAiB,MAACzN,GAClB0N,oBAAqB,MAAC1N,GACtB2N,oBAAqB,MAAC3N,GACtB4N,kBAAmB,MAAC5N,GAEpBoO,WAAY,MAACpO,GACbqO,iBAAkB,MAACrO,GACnBsO,gBAAiB,MAACtO,GAClBuO,aAAc,MAACvO,GACfwO,cAAe,MAACxO,GAChByO,WAAY,MAACzO,GACb0O,kBAAmB,MAAC1O,GACpB2O,kBAAmB,MAAC3O,GACpB4O,WAAY,MAAC5O,GAEb+K,UAAW,MAAC/K,GACZmL,YAAa,MAACnL,GAEd0L,MAAO,MAAC1L,GACR4L,YAAa,MAAC5L,GACd2L,WAAY,MAAC3L,GACb8L,cAAe,MAAC9L,GAChB+L,WAAY,MAAC/L,GACbgM,UAAW,MAAChM,GACZiM,cAAe,MAACjM,GAChBkM,eAAgB,MAAClM,GACjBmM,gBAAiB,MAACnM,GAClBoM,WAAY,MAACpM,GACbqM,aAAc,MAACrM,GACf6O,YAAa,MAAC7O,GACdsM,aAAc,MAACtM,IAIJ+oB,GAAgC,CAC3CrhB,KAAM,CAACshB,GAAYC,GH1XO,OG0XcC,GHxXd,OAGA,OADA,QGuX1BriB,QAAS,CAAC/C,EAAGC,EAAGJ,EAAKC,EAAQc,EAAMJ,GAEnCkL,UAAW,MAACxP,EAAW,QACvB8b,UAAWyM,GACXxM,IAAKwM,GACLtM,MAAOsM,GACPvM,SAAU,MAAChc,EAAWwf,GAASC,KAAMD,GAASE,MAAOF,GAASM,QAASN,GAASO,SAEhFhe,MAAO,MAAC/B,GACRrF,KAAM,CAACqb,GAAcD,GAAcG,GAAmBD,IAEtDxV,KAAM,CAAC,YAAa,cACpByb,MAAO,CAAC,OAAQ,YAAa,SAAU,MACvChgB,MAAO,MAAC8D,GAERiJ,OAAQ,MAACjJ,GACT0L,MAAO,MAAC1L,GACR+M,MAAO,EAAC,GACRoP,KAAMoM,GACNnM,OAAQmM,GAERZ,SAAUa,GACVN,UAAWS,GACXR,WAAYS,GACZR,UAAWS,GACXR,YAAaS,IAIf,SAAgBK,GAAqBjZ,EAAgBkZ,EAAgBja,GACnE,GAAa,UAATe,GAAqB0L,GAAqB1L,IAAyB,SAAhBA,EAAK/U,QAAoC,UAAf+U,EAAKrU,MAEpF,OAAOutB,EAAOC,aAGhB,IAAIC,EAOJ,QAAYtpB,KALVspB,EADE1N,GAAqB1L,GACjBf,EAAI2X,KAAK5W,EAAK/U,OAAS,SAAS+U,EAAKrU,OAErCsT,EAAI2X,KAAK5W,IAIf,OAAOoZ,EAIT,MAAM,IAAItsB,MAAM,6BAA+BkD,KAAKJ,UAAUoQ,gMClWzD,MAAMqZ,GAAoC,CAC/CC,SAAS,EACTC,kBAAmB,CACjBvhB,KAAM,CAACP,OAAO,GACdoF,MAAO,CAAC2c,uBAAuB,IAEjCC,mBAAoBlM,GAAwB7b,IAAIub,IAChD2J,KAAMiC,GAENa,wBAAyB,IACzBC,mBAAoB,GAGpBC,kCAAkC,EAElCC,cAAc,EAEdC,kCAAkC,EAClCC,eAAe,EACfC,2CAA2C,EAC3CC,mCAAmC,EACnCC,8BAA8B,EAC9BC,qBAAqB,EACrBC,mCAAmC,EACnCC,SAAS,EACTC,wCAAwC,EACxCC,mBAAmB,EACnBC,gDAAgD,EAChDC,sCAAsC,EACtCC,qBAAqB,EACrBC,sBAAsB,EACtBC,iBAAiB,EAEjBC,iBAAkB5U,EAClB6U,sBAAuB7U,EACvB8U,qBAAsB7U,EACtB8U,qBAAsB9U,EACtB+U,eAAgBC,EAGhBC,qBAAsB,GACtBC,kCAAmC,GACnCC,uBAAwB,GACxBC,uBAAwB,EACxBC,6BAA6B,EAC7BC,uBAAuB,EAGvBC,SAAS,EACTC,wCAAyC,CAACC,eAAgB,GAAIvX,UAAW,IACzEwX,oCAAqC,CAACD,eAAgB,GAAIE,QAAS,cACnEC,2CAA4C,CAACH,eAAgB,IAG7DI,2BAA4B,EAC5BC,2BAA4B,EAG5BC,uBAAwB,GACxBC,qBAAsB,IAuBxB,SAASC,GAAsBC,EAA+Bpc,GAC5D,OAAAlW,OAAAsL,OAAA,GACKyjB,GAAmB7Y,EAAO,SAC1Boc,EAAUpc,EAAO,qEAvBxB,SAA6Bf,GAC3B,OAAAnV,OAAAsL,OAAA,GACKikB,GACApa,EAAG,CACN2X,MAIqBwF,EAJCnd,EAAI2X,KAKf9sB,OAAAsL,OAAA,GACRyjB,GACAuD,EAAS,CACZ3E,SAAU0E,GAAsBC,EAAW,OAC3CnE,WAAYkE,GAAsBC,EAAW,SAC7ClE,UAAWiE,GAAsBC,EAAW,QAC5CjE,YAAagE,GAAsBC,EAAW,eAPlD,IAAyBA,KCjJzB,MAAMC,GAAwC,CAC5CC,OAAQ,EACRC,OAAQ,EACRC,QAAS,EACTC,MAAO,EACPC,SAAU,EACV1R,IAAK,EACL2R,KAAM,EACNC,OAAQ,EACRjF,IAAK,EACLkF,QAAS,EACTC,GAAI,EACJC,GAAI,EACJC,IAAK,EACLC,IAAK,EACLC,OAAQ,EACRC,MAAO,EACPC,OAAQ,EACRC,IAAK,EACLC,MAAO,EACP/gB,OAAQ,EACRghB,SAAU,EACVC,UAAW,GAab,SAAgBC,GAAYluB,GAC1B,QAASA,KAAOA,EAAU,OAG5B,SAAgBmuB,GAAYnuB,GAC1B,QAASA,KAAOA,EAAU,OAG5B,SAEgBouB,GAAcpuB,GAC5B,OAAOgC,EAAShC,MAAQ8sB,GAAmB9sB,GActC,MAAMquB,GAAyB,CAAC,QAAS,MAAO,WAAY,QAAS,WAOtC7qB,EAFU,CAAC,OAAQ,UAAW,SAAU,KAAM,KAAM,MAAO,QCsCjG,SAAgB8qB,GAAUhS,GACxB,OAAe,IAARA,GAAiBiS,GAAYjS,KAASA,EAAI0M,OAUnD,SAAgBuF,GAAYjS,GAC1B,OAAOva,EAASua,GAGlB,SAAgBkS,GAAYpnB,GAC1B,OAAQA,GACN,KAAKlD,EACL,KAAKC,EACL,KAAKc,EACL,KAAKJ,EACL,KAAKC,EACL,KAAKC,EACL,KAAKM,EACL,KAAKH,EACL,KAAKC,EACL,KAAKC,EAGL,KAAKJ,EACH,OAAO,EACT,QACE,OAAO,ICwQb,SAAgBypB,GACdC,GAEA,QAASA,KAAgBA,EAAWC,YAAc/tB,EAAQ8tB,EAAWC,YAAcC,GAAWF,EAAWC,WAS3G,SAAgBC,GACdF,GASA,SAASA,IAAiBA,EAAkB,OAAiC,UAA5BA,EAAsB,WAOzE,SAAgBG,GAAiBH,GAC/B,OAAOE,GAAWF,IAAe1sB,EAAS0sB,EAAWpsB,OAwDvD,SAAgBwsB,GACd7e,EACAP,EAAsB,IAEtB,IAAIpN,EAAQ2N,EAAS3N,MACrB,MAAMysB,EAASrf,EAAIqf,OACnB,IAAIC,EAAStf,EAAIsf,OAEbC,EAAc,GAElB,GAAIC,GAAQjf,GACV3N,ElB/DJ,SAAgCjB,GAC9B,OAA8B,IAAvBA,EAAK1G,QAAQ,MAJbw0B,CADqB9tB,EkBmEJ,SlBlEOA,OAAYA,QkBmEpC,CACL,IAAIF,EAEJ,IAAKuO,EAAI0f,KACP,GAzBN,SACEnf,GAEA,QAASA,EAAa,GAsBdof,CAAapf,GACf9O,EAAK8O,EAAS4J,OACT,CACL,MAAMyC,IAACA,EAAGvM,UAAEA,EAASwM,SAAEA,GAAYtM,EAC/Bqe,GAAUhS,IACZnb,EDlaV,SAA4Bmb,GAI1B,OAHI/Y,EAAU+Y,KACZA,EAAMgT,GAAahT,OAAK/b,IAGxB,MACAQ,EAAKub,GACFna,IAAI7H,IjB8MX,SAAwBH,GAEtB,MAAMo1B,EAAgBp1B,EAAEiI,QAAQ,MAAO,KAGvC,OAAQjI,EAAEsf,MAAM,QAAU,IAAM,IAAM8V,GiBnNxBC,KAAYl1B,KAAKgiB,EAAIhiB,OAC9BmI,KAAK,IC0ZGgtB,CAAYnT,GACjB0S,GAAUtf,EAAIggB,WAAa,KAAOhgB,EAAIsf,QAAU,KACvCjf,EACLoe,GAAYpe,IACdkf,MAAkB3sB,IAClBA,YAAkByN,EAAUgd,UACnBmB,GAAYne,IACrBkf,MAAkB3sB,IAClBA,YAAkByN,EAAUid,UAE5B7rB,EAAKkX,OAAOtI,GAELwM,IACTpb,EAAKkX,OAAOkE,IAKdpb,IACFmB,EAAQA,KAAWnB,KAAMmB,IAAUnB,GlBpHzC,IAoB8BE,EkB4G5B,OARI2tB,IACF1sB,KAAWA,KAAS0sB,KAGlBD,IACFzsB,KAAWysB,KAAUzsB,KAGnBoN,EAAIigB,MACCrtB,EACEoN,EAAIkgB,KlB9KjB,SAAoCjuB,EAAckuB,EAA4C,SAC5F,SAAUA,KAASrtB,EAAYf,EAAgBE,GAAMc,KAAK,SkB+KjDqtB,CAAoBxtB,EAAOoN,EAAIkgB,MAAQX,KlBvKtCxtB,EkB0KkBa,GlBzKzBH,IAAI7H,GAAKA,EAAE8H,QAAQ,IAAK,QACxBK,KAAK,SkBwK6BwsB,EAIvC,SAAgBc,GAAW9f,GACzB,OAAQA,EAAS/U,MACf,IAAK,UACL,IAAK,UACL,IAAK,UACH,OAAO,EACT,IAAK,eACH,QAAS+U,EAASqM,IACpB,IAAK,WACH,OAAO,EAEX,MAAM,IAAI/e,MAAM4Y,GAAY6Z,iBAAiB/f,EAAS/U,OAGxD,SAAgB+0B,GAAahgB,GAC3B,OAAQ8f,GAAW9f,GAGrB,SAAgBif,GAAQjf,GACtB,MAA8B,UAAvBA,EAASF,UAwIlB,SAAgBmgB,GAAkCxB,GAChD,OAAIE,GAAWF,GACNA,EACED,GAAuBC,GACzBA,EAAWC,eADb,EAiGT,SAAgBW,GAAahT,EAAqClV,GAChE,OAAI7D,EAAU+Y,GACL,CAAC6L,QAASqG,GAAYpnB,IACZ,WAARkV,EACF,CACL0M,QAAQ,GAEA1M,EAAI6L,SAAY7L,EAAI+L,KAGvB/L,EAFP/hB,OAAAsL,OAAA,GAAWyW,EAAG,CAAE6L,QAASqG,GAAYpnB,KAMzC,MAAM+oB,GAAa,CAACC,YAAY,GAChC,SAAgBC,GACdpgB,EACA7I,GAEA,MAAMlM,EAAO+U,EAAS/U,KAEtB,GAAa,YAATA,GAAkC,UAAZkM,EACxB,MAAO,CACLgpB,YAAY,EACZE,mBAAoBlpB,6CAIxB,OAAQA,GACN,IAAK,MACL,IAAK,SACL,IAAK,QACH,OAAI6oB,GAAahgB,GACR,CACLmgB,YAAY,EACZE,QAASna,GAAYoa,6BAA6BnpB,IAG/C+oB,GAET,IAAK,IACL,IAAK,IACL,IAAK,QACL,IAAK,OACL,IAAK,SACL,IAAK,OACL,IAAK,SACL,IAAK,MACL,IAAK,UACL,IAAK,OACH,OAAOA,GAET,IAAK,YACL,IAAK,aACL,IAAK,WACL,IAAK,YACH,OAAIj1B,IAASiX,GACJ,CACLie,YAAY,EACZE,mBAAoBlpB,wDAA8D6I,EAAS/U,eAGxFi1B,GAET,IAAK,UACL,IAAK,cACL,IAAK,gBACL,IAAK,cACL,IAAK,OACL,IAAK,KACL,IAAK,KACH,MAAa,YAATj1B,GAAuB+U,EAAe,KAMnCkgB,GALE,CACLC,YAAY,EACZE,mBAAoBlpB,yDAK1B,IAAK,QACH,OAAKzD,EAAS,CAAC,UAAW,UAAW,WAAYsM,EAAS/U,MAMnDi1B,GALE,CACLC,YAAY,EACZE,QAAS,2EAKf,IAAK,QACH,MAAsB,YAAlBrgB,EAAS/U,MAAwB,SAAU+U,EAMxCkgB,GALE,CACLC,YAAY,EACZE,QAAS,kFAKjB,MAAM,IAAI/yB,MAAM,oDAAsD6J,OCr4BvDopB,GCYjB,SAAgB3gB,GACd4gB,EACArpB,EACA6I,EACAhI,GAEA,MAAMyI,EA8BR,SAAqBtJ,EAAkB6I,EAAiChI,GACtE,OAAQgI,EAAS/U,MACf,IAAK,UACL,IAAK,UACH,GAAIiM,EAAeC,IAAmC,aAAvB0B,GAAU1B,GAIvC,MAHgB,UAAZA,GAAyC,YAAlB6I,EAAS/U,MAClCw1B,GAASva,GAAYwa,4BAA4BvpB,EAAS,YAErD,UAGT,GAAIwpB,EAAc,CAAC,IAAK,KAAMxpB,GAAU,CACtC,GAAIwpB,EAAc,CAAC,OAAQ,MAAO,QAAS3oB,GAGzC,MAAO,OAET,GAAa,QAATA,EACF,MAAO,OAIX,MAAO,QAET,IAAK,WACH,OAAId,EAAeC,GACV,OACyB,aAAvB0B,GAAU1B,IACnBspB,GAASva,GAAYwa,4BAA4BvpB,EAAS,aAEnD,WAEF,OAET,IAAK,eACH,OAAID,EAAeC,GACbknB,GAAUre,EAASqM,KACd,cAGF,SACyB,aAAvBxT,GAAU1B,IACnBspB,GAASva,GAAYwa,4BAA4BvpB,EAAS,iBAEnD,WAGF,SAET,IAAK,UACH,OAIJ,MAAM,IAAI7J,MAAM4Y,GAAY6Z,iBAAiB/f,EAAS/U,OApF7B21B,CAAYzpB,EAAS6I,EAAUhI,IAClD/M,KAACA,GAAQu1B,EAEf,OAAK1oB,GAAeX,QAIP7G,IAATrF,EAEG4a,GAAwB1O,EAASlM,GAMjC6a,GAAyB7a,EAAM+U,EAAS/U,MAKtCA,GAJLw1B,GAASva,GAAY2a,6BAA6B51B,EAAMwV,IACjDA,IAPPggB,GAASva,GAAY4a,4BAA4B3pB,EAASlM,EAAMwV,IACzDA,GAYJA,EAlBE,KDbX,SAAgBqf,GAAWiB,GACzB,OAAOA,IAAc1a,IAAgB0a,IAAcza,IAAgBya,IAAcR,GAAa/qB,KAXhG,SAAiB+qB,GACFA,EAAAre,aAAesE,GACf+Z,EAAApe,QAAUkE,GACVka,EAAAne,SAAWmE,GACXga,EAAAle,QAAUiE,GACVia,EAAA/qB,IAAa,MAL5B,CAAiB+qB,KAAAA,GAAY,KEU7B,MAAaS,GAGXC,YAAYr2B,EAAa,MACvB4I,KAAK/F,MAAQ7C,EAACN,OAAAsL,OAAA,GAAQhL,GAAM,GAGvBq2B,IAAI52B,GACT,OAAOojB,GAAMpjB,KAAMmJ,KAAK/F,MAGnBwzB,IAAI52B,GACT,OAAOmJ,KAAK/F,MAAMggB,GAAMpjB,IAGnB42B,IAAI52B,EAAamC,GAEtB,OADAgH,KAAK/F,MAAMggB,GAAMpjB,IAAMmC,EAChBgH,KAGFytB,SAASrzB,EAAapB,GAC3BgH,KAAK/F,MAAMG,GAAOpB,EAGby0B,IAAOrxB,GACZ,MAAMhF,EAAI,IAAIo2B,GACd,IAAK,MAAMlZ,KAAKtU,KAAK/F,MACnB7C,EAAE6C,MAAMqa,GAAKlY,EAAE4D,KAAK/F,MAAMqa,IAE5B,OAAOld,EAGFq2B,OACL,OAAOnwB,GAAK0C,KAAK/F,OAAO5C,OAGnBo2B,YACL,OAAO,IAAID,GAAaxtB,KAAK/F,iBC6KjByzB,GAAiChkB,EAAgC/F,GAC/E,MAAMsnB,EAAavhB,GAAYA,EAAS/F,GACxC,QAAIsnB,IACE9tB,EAAQ8tB,GtBlIhB,SAAwB7S,EAAUhc,GAChC,IAAIhF,EAAI,EACR,IAAK,MAAOkd,EAAG/X,KAAM6b,EAAIuV,UACvB,GAAIvxB,EAAEG,EAAG+X,EAAGld,KACV,OAAO,EAGX,OAAO,EsB4HIkhB,CAAK2S,EAAYze,KAAcA,EAAS3N,OAExCssB,GAAWF,IAAeD,GAAuBC,ICjN9D,MAAM2C,GAAwC,CAC5C7b,KAAM,EACNrE,OAAQ,EACRmgB,UAAW,GA+BN,MAAMC,GAAkB,CAAC/R,GAAKD,GZ5CT,OY4CqBjM,GAAOmM,GAAQC,GZ/CpC,OAIA,OACA,QY2Cf8R,GAAyB,CAAChS,GAAKD,IAgC5C,SAAgB9C,GACd5B,EACA1N,EACAskB,EACA/hB,EAEI,IAEJ,MAAMzH,EZoCR,SAA0BA,GACxB,OAAOA,EAAW,KYrCLypB,CAAU7W,GAAKA,EAAE3f,KAAO2f,EAErC,IAAKlX,EAAS4tB,GAAiBtpB,GAC7B,OAAO,KAGT,MAAM0pB,EA5CR,SAAiCxkB,GAC/B,MAAMykB,EAAOzkB,EAASjL,EAChB2vB,EAAO1kB,EAASrH,EAEtB,GAAI8oB,GAAWgD,IAAShD,GAAWiD,GACjC,GAAkB,iBAAdD,EAAK12B,MAAyC,iBAAd22B,EAAK32B,KAAyB,CAChE,GAAI02B,EAAKnV,MACP,MAAO,IACF,GAAIoV,EAAKpV,MACd,MAAO,IAGT,KAAMmV,EAAK7hB,aAAgB8hB,EAAK9hB,UAC9B,OAAO6hB,EAAK7hB,UAAY,IAAM,QAE3B,CAAA,GAAkB,iBAAd6hB,EAAK12B,KACd,MAAO,IACF,GAAkB,iBAAd22B,EAAK32B,KACd,MAAO,QAEJ,CAAA,GAAI0zB,GAAWgD,IAAuB,iBAAdA,EAAK12B,KAClC,MAAO,IACF,GAAI0zB,GAAWiD,IAAuB,iBAAdA,EAAK32B,KAClC,MAAO,KAqBY42B,CAAwB3kB,GAC7C,IAAKwkB,EACH,OAAO,KAGT,MAAMI,EAAkB5kB,EAASwkB,GAC3BK,EAAenD,GAAiBkD,GAAmBjD,GAAQiD,EAAiB,SAAMxxB,EAElF0xB,EAAoC,MAAjBN,EAAuB,IAAM,IAChDO,EAAe/kB,EAAS8kB,GACxBE,EAAiBtD,GAAiBqD,GAAgBpD,GAAQoD,EAAc,SAAM3xB,EAG9E6xB,EAAUzqB,GAAqBwQ,OAAO,CAACka,EAAIjrB,KAE/C,GAAgB,YAAZA,GAAyB+pB,GAAgBhkB,EAAU/F,GAAU,CAC/D,MAAMsnB,EAAavhB,EAAS/F,IAC3BxG,EAAQ8tB,GAAcA,EAAa,CAACA,IAAa9wB,QAAQ00B,IACxD,MAAMriB,EAAWigB,GAAiBoC,GAClC,GAAIriB,EAASF,UACX,OAIF,MAAMlQ,EAAIgvB,GAAiB5e,GAAY6e,GAAQ7e,EAAU,SAAM1P,IAG5DV,GAEAA,IAAMsyB,GAAkBtyB,IAAMmyB,IAE/BK,EAAG10B,KAAK,CAACyJ,QAAAA,EAAS6I,SAAAA,MAIxB,OAAOoiB,GACN,IAEH,GAAuB,IAAnBD,EAAQt3B,OACV,OAAO,KAIT,IAAIqQ,EAcJ,KAXIA,OAF0B5K,IAA1BwxB,EAAgBtV,MACdlZ,EAAUwuB,EAAgBtV,OACnBsV,EAAgBtV,MAAQ,OAAS,KAEjCsV,EAAgBtV,MAElB9Y,EAAS6tB,GAAwBvpB,GAEjClE,EAAgB0tB,EAAa,QAE7BA,KAhIFJ,GAmIqBlmB,GAC5B,OAAO,KAIT,GAAI4mB,EAAgBzkB,OAASykB,EAAgBzkB,MAAMpS,MAAQ62B,EAAgBzkB,MAAMpS,OAASwX,GAAUC,OAAQ,CAC1G,GAAIjD,EAAI6iB,uBACN,OAAO,KAEP7B,GAASva,GAAYqc,0BAA0BT,EAAgBzkB,MAAMpS,OAKzE,OAAIi2B,GAAgBhkB,EAAUwkB,IAAiBttB,EAAIE,EAAKC,SACxBjE,IAA1BwxB,EAAgBtV,OAClBiU,GAASva,GAAYsc,sBAAsBd,IAEtC,OAILI,EAAgBhiB,YAAcpM,EAAS0qB,GAAS0D,EAAgBhiB,YAClE2gB,GAASva,GAAYuc,2BAA2BX,EAAgBhiB,YAG3D,CACL4iB,eAAgBT,EAAeD,OAAmB1xB,EAClDoxB,aAAAA,EACAiB,OAAQjT,GAAW1X,GACnBmqB,QAAAA,EACAjnB,OAAAA,IC5GJ,SAAgB0nB,GAASC,GACvB,OAAOjb,GACLib,EAAKpzB,KAAO,CAACA,KAAMozB,EAAKpzB,MAAQ,GAChCozB,EAAKtjB,UAAY,CAACA,UAAWsjB,EAAKtjB,WAAa,GAC/CsjB,EAAKC,MAAQ,CAACA,MAAOD,EAAKC,OAAS,GACnCD,EAAKE,OAAS,CAACA,OAAQF,EAAKE,QAAU,GACtCF,EAAKG,WAAa,CAACA,WAAYH,EAAKG,YAAc,GAClDH,EAAKtkB,QAAU,CAACA,QAASskB,EAAKtkB,SAAW,GACzCskB,EAAK7mB,MAAQ,CAACA,MAAO6mB,EAAK7mB,OAAS,GACnC,CACEhE,KAAM6qB,EAAK7qB,KACXirB,UAAWnyB,GAAK+xB,EAAK3lB,UAAUhL,IAAKiF,IAClC,IAAI+rB,EAAsB,CAAC/rB,QAASA,GAChCsnB,EAAaoE,EAAK3lB,SAAS/F,GAE/B,IAAK,MAAMqJ,KAAQie,EACb7R,GAA2BpM,SAA0ClQ,IAArBmuB,EAAWje,KAGzD9M,GAAS,CAAC,MAAO,QAAS,OAAQ,UAAW8M,IAA8B,OAArBie,EAAWje,GACnE0iB,EAAK1iB,IAAQ,EAEb0iB,EAAK1iB,GAAQie,EAAWje,IAS9B,OAJI2iB,GAAaD,IAA4B,UAAnBA,EAAKpjB,YAA0BojB,EAAK7wB,QAC5D6wB,EAAK7wB,MAAQ,KAGR6wB,KAGXL,EAAKO,OAAS,CAACA,OAAQP,EAAKO,QAAU,IAI1C,SAAgBC,GAAYC,GAC1B,OAAOxX,GAAKwX,EAAML,UAAYC,GACpBC,GAAaD,KAAUjM,GAAWiM,EAAKpjB,cAAgBojB,EAAKpjB,WAAcyjB,GAAwBL,IAQ9G,SAAgBM,GAAWF,GACzB,IAAKG,GAA2BH,GAC9B,OAAO,KAGT,MAAMpmB,EAAWwmB,GAAWJ,EAAML,UAAW,CAACvJ,OAAQ,KAAMiK,aAAc,SAG1E,OAAOnX,GAFM8W,EAAMtrB,KAEAkF,OAAU5M,EAAW,CAACgyB,wBAAwB,IAOnE,SAAgBsB,GAAeN,GAC7B,IAAK,MAAMJ,KAAQI,EAAML,UACvB,QAA6B3yB,IAAzB4yB,EAAKlV,GAASG,SAAyB8I,GAAWiM,EAAKlV,GAASG,QAClE,OAAO+U,EAAKlV,GAASG,OAU3B,SAAgB0V,GAAgBP,GAC9B,IAAK,MAAMJ,KAAQI,EAAML,UACvB,QAA6B3yB,IAAzB4yB,EAAKlV,GAASG,SAAyB8I,GAAWiM,EAAK/rB,SACzD,OAAO+rB,EAAK/rB,QAGhB,OAAO,KAQT,SAAgBssB,GAA2BH,GAGzC,GAAIrM,GAAWqM,EAAMtrB,MACnB,OAAO,EAGT,MAAM8rB,EAAwB,CAC5B9V,GAASG,MACTH,GAASK,QACTL,GAASC,KACTD,GAASW,MACTX,GAASM,UACTN,GAASO,UACTP,GAASc,MACTlB,GAAsB,QAAS,QAC/BI,GAASY,MAELmV,EAAU/b,GAAM+D,GAAQ+B,GAAoBgW,IAE5Cb,EAAYK,EAAML,UAAU5Z,OAAO6Z,IAASc,GAAyBd,IAC3E,IAAK,MAAMA,KAAQD,EACjB,GAAIgB,GAAuBf,EAAM,CAACa,QAASA,IACzC,OAAO,EAGX,OAAO,EAUT,SAASE,GAAuBj5B,EAAUyU,EAAsC,IAC9E,IAAK3N,GAAS9G,GACZ,OAAO,EAGT,IAAK,MAAMk5B,KAAal5B,EACtB,GAAIA,EAAIR,eAAe05B,GAAY,CAEjC,GADiBjN,GAAWjsB,EAAIk5B,OACbzkB,EAAIskB,UAAYtkB,EAAIskB,QAAQG,KAAgBD,GAAuBj5B,EAAIk5B,GAAYzkB,GACpG,OAAO,EAIb,OAAO,gJAST,SAA4B6jB,EAAkB7jB,EAA8B,IAC1E,MAAMskB,EAAUtkB,EAAIskB,QAAU/b,GAAMvI,EAAIskB,QAAQ7xB,IAAIub,KAAU,GAC9D,GAAIwJ,GAAWqM,EAAMtrB,QAAU+rB,EAAc,KAC3C,OAAO,EAGT,IAAK,MAAMb,KAAQI,EAAML,UACvB,GAAIgB,GAAuBf,EAAMa,GAC/B,OAAO,EAGX,OAAO,cC7MOI,GAAiBC,GAC/B,OAAOA,EAAalyB,IAAImyB,GAAKC,GAAYD,IAG3C,SAAgBC,GAAYnyB,GAC1B,OAAQjI,QACaoG,IAAf6B,EAAQjI,GACHiI,EAAQjI,GAEVA,EAIX,SAAgBsC,GAAMkd,EAAQ6a,GAC5B,OAAItN,GAAWvN,IAERwN,GAAgBxN,IAAMA,EAAE0N,KACpBJ,GAAiBxmB,KAAKJ,UAAUsZ,EAAE0N,MAElCJ,GAGPuN,EACKA,EAAS7a,GAEXA,EAGT,SAAgBvX,GAAQuX,EAAQ6a,GAC9B,OAAIA,EACKA,EAAS7a,GAEXA,EAGF,MAAM8a,GAAe,IAAIxD,GAEnByD,GAEX,GACG1xB,OAAOgb,GAAyBb,GAAY,CAACc,GAASE,UAAWF,GAASG,OAAQZ,IAClFrF,OAAO,CAACwc,EAAIlkB,IAAmBkkB,EAAG32B,IAAIyS,GAAM,GAAO,IAAIwgB,IAWrD,MAAM2D,GAA8B,CACzClY,KAAM,CAACxa,GAAG,EAAM4D,GAAG,EAAMwB,KAAK,EAAMC,QAAQ,GAC5CoV,OAAQ,CAACtW,OAAO,EAAMG,SAAS,EAAMI,MAAM,EAAMC,OAAO,GACxDyG,MAAO,CAACpL,GAAG,EAAM4D,GAAG,EAAMO,OAAO,EAAMG,SAAS,EAAMc,KAAK,EAAMC,QAAQ,EAAMX,MAAM,EAAMC,OAAO,GAClG7F,KAAM,CAACkB,GAAG,EAAM4D,GAAG,EAAMnE,MAAM,EAAMmF,OAAO,GAC5C2V,MAAO,CAACva,GAAG,EAAM4D,GAAG,IAStB,SAAgBgtB,GACdS,EACAsB,EAA8BH,GAC9BtyB,EAA+BqyB,IAE/B,MAAMK,EAAkB,GAUxB,IAAIrY,EAKJ,GAbIoY,EAAQE,IAAI9W,GAASC,OACvB4W,EAAMn3B,KAAKlB,GAAM82B,EAAMtrB,KAAM7F,EAAQ2yB,IAAI9W,GAASC,QAGhDqV,EAAM/jB,WAAa+jB,EAAM/jB,UAAU1U,OAAS,GAC9Cg6B,EAAMn3B,KAAK,aAAe8C,KAAKJ,UAAUkzB,EAAM/jB,YAI7CqlB,EAAQE,IAAI9W,GAASG,SACvB3B,EAAQgX,GAAWF,IAGjBA,EAAML,UAAW,CACnB,MAAMA,EAAYK,EAAML,UACrB/a,OAAO,CAAC6c,EAAO7B,KAEd,IAAKc,GAAyBd,GAAO,CACnC,IAAIta,GAEFA,EADI4D,GAAS0W,EAAK/rB,UAAYqV,EAAMkV,aAC9BxkB,GAAQ5S,OAAAsL,OAAA,GAAKstB,EAAI,CAAE1W,MAAOA,EAAMtR,SAAS0pB,EAASzyB,GAElD+K,GAASgmB,EAAM0B,EAASzyB,KAI9B4yB,EAAMr3B,KAAKkb,GAGf,OAAOmc,GACN,IACFh0B,OACAyB,KAAK,KAEJywB,GACF4B,EAAMn3B,KAAKu1B,GAIf,IAAK,IAAI+B,KAAYzX,GAAY,CAC/B,MAAM0X,EAAaD,EAASl2B,WAC5B,GAAI81B,EAAQE,IAAIE,IAAe1B,EAAM2B,GAAa,CAChD,MAAMz4B,EAAQ82B,EAAM2B,GACpBJ,EAAMn3B,QAAQu3B,KAAcz0B,KAAKJ,UAAU5D,OAI/C,OAAOq4B,EAAMryB,KAAK,KASpB,SAAgB0K,GACdgmB,EACA0B,EAA8BH,GAC9BtyB,EAA+BqyB,IAE/B,MAAMK,EAAQ,GAKd,GAJID,EAAQE,IAAI9W,GAASK,UACvBwW,EAAMn3B,KAAKlB,GAAM02B,EAAK/rB,QAAShF,EAAQ2yB,IAAI9W,GAASK,WAGlD8U,GAAaD,GAAO,CACtB,MAAMgC,EAAcllB,GAASkjB,EAAM0B,EAASzyB,GAExC+yB,GACFL,EAAMn3B,KAAKw3B,QAEJC,GAAajC,GACtB2B,EAAMn3B,KAAKw1B,EAAK12B,OACP44B,GAAiBlC,IAC1B2B,EAAMn3B,KAAK,eAGb,OAAOm3B,EAAMryB,KAAK,KASpB,SAAgBwN,GACdkjB,EACA0B,EAA8BH,GAC9BF,EAAgCC,IAEhC,GAAII,EAAQE,IAAI9W,GAASM,YAAc0V,GAAyBd,GAC9D,MAAO,IAGT,MAAMhyB,EAyCR,SAAcm0B,EAAoBT,EAA6BL,GAC7D,GAAIK,EAAQE,IAAI9W,GAASM,YAAc+W,EAAOvlB,YAAcmX,GAAWoO,EAAOvlB,WAC5E,OAAO3N,GAAQkzB,EAAOvlB,UAAWykB,EAASO,IAAI9W,GAASM,YAClD,GAAIsW,EAAQE,IAAI9W,GAASM,YAAciV,GAAwB8B,GAEpE,OAAOlzB,GAAQ,QAASoyB,EAASO,IAAI9W,GAASM,YACzC,GAAIsW,EAAQE,IAAI9W,GAASU,WAAa2W,EAAO/Y,WAAa2K,GAAWoO,EAAO/Y,UACjF,OAAOna,GAAQkzB,EAAO/Y,SAAUiY,EAASO,IAAI9W,GAASU,WACjD,GAAIkW,EAAQE,IAAI9W,GAASQ,MAAQ6W,EAAOhZ,MAAQ4K,GAAWoO,EAAOhZ,KACvE,MAAO,MACF,CACL,IAAInb,EAAU,KACd,IAAK,MAAMsP,IAAQ,CAACwN,GAASM,UAAWN,GAASO,UAAWP,GAASU,SAAUV,GAASQ,KAAM,CAC5F,MAAMoL,EAAMyL,EAAO7kB,GACfokB,EAAQE,IAAItkB,IAAS6kB,EAAO7kB,IAASyW,GAAW2C,MAElD1oB,EAAKA,GAAM,IACRsP,GAAQ0W,GAAgB0C,GAAOA,EAAMA,EAAIxC,MAMhD,OAHIlmB,GAAMm0B,EAAO9Y,QACfrb,EAAGqb,OAAQ,GAENrb,GAhEEo0B,CAAKpC,EAAM0B,EAASL,GACzBgB,EAsER,SAAuBF,EAAoBT,EAA6BL,GAEtE,MAAMgB,EAAkD,GAGxD,IAAKjyB,GAAU+xB,EAAOhZ,OAAS6K,GAAgBmO,EAAOhZ,KAAM,CAC1D,MAAMA,EAAMgZ,EAAOhZ,IACnB,IAAK,MAAMlgB,KAASkgB,EAAK,CACvB,MAAM7L,EAAOoN,GAAsB,MAAOzhB,GACtCqU,GAAQokB,EAAQE,IAAItkB,SAAwBlQ,IAAf+b,EAAIlgB,IACnCo5B,EAAM73B,KAAK,CACTE,IAAKzB,EACLK,MAAOA,GAAM6f,EAAIlgB,GAAQo4B,EAASO,IAAItkB,MAK5C+kB,EAAMx0B,KAAK,CAAChB,EAAGC,IAAMD,EAAEnC,IAAI43B,cAAcx1B,EAAEpC,MAG7C,IAAK,MAAMnC,IAAU,CAACuiB,GAASc,MAAOd,GAASa,KAAMb,GAASG,MAAOH,GAASe,KAAMf,GAASgB,QAC3F,IAAKiI,GAAWoO,EAAOluB,UAAawtB,GAA4Bl5B,GAAQ45B,EAAOluB,WAI3EytB,EAAQE,IAAIr5B,SAA8B6E,IAAnB+0B,EAAO55B,GAAuB,CACvD,MAAMg6B,EAAcJ,EAAO55B,GAC3B,GAAI6H,GAAUmyB,IAAgC,OAAhBA,EAE5BF,EAAM73B,KAAK,CACTE,IAAKnC,EAAS,GACde,MAAOi5B,IAAe,SAEnB,GAAI1zB,GAAS0zB,GAElBF,EAAM73B,KAAK,CACTE,IAAKnC,EAAS,GACde,MAAO2F,GAAQ3B,KAAKJ,UAAUq1B,GAAclB,EAASO,IAAIr5B,UAEtD,CACL,IAAIi6B,EAAqB,GACzB,IAAK,MAAMv5B,KAASs5B,EAAa,CAC/B,MAAME,EAAa/X,GAAsBniB,EAAQU,GAC7Cw5B,GAAcf,EAAQE,IAAIa,SAAsCr1B,IAAvBm1B,EAAYt5B,IACvDu5B,EAAmBh4B,KAAK,CACtBE,IAAKzB,EACLK,MAAOA,GAAMi5B,EAAYt5B,GAAQo4B,EAASO,IAAIa,MAKpD,GAAID,EAAmB76B,OAAS,EAAG,CACjC,MAAM+6B,EAAmBF,EACtB30B,KAAK,CAAChB,EAAGC,IAAMD,EAAEnC,IAAI43B,cAAcx1B,EAAEpC,MACrCsa,OAAO,CAACrZ,EAAG+E,KACV/E,EAAE+E,EAAKhG,KAAOgG,EAAKpH,MACZqC,GACN,IAGL02B,EAAM73B,KAAK,CACTE,IAAKnC,EAAS,GACde,MAAOgE,KAAKJ,UAAUw1B,OAMhC,OAAOL,EA1IOM,CAAc3C,EAAM0B,EAASL,GAE3C,IAAIuB,EACJ,GAAI3C,GAAaD,GAAO,CAItB,GAFA4C,EAAiBlB,EAAQE,IAAI,SAAWt4B,GAAM02B,EAAK7wB,MAAOkyB,EAASO,IAAI,UAAY,MAE/EF,EAAQE,IAAI9W,GAASY,MACvB,GAAIqI,GAAWiM,EAAKj4B,MAClB66B,GAAkB,IAAMt5B,GAAM02B,EAAKj4B,KAAMs5B,EAASO,IAAI9W,GAASY,WAC1D,CAELkX,GAAkB,IAAMt5B,KADJ02B,EAAKj4B,MAAQub,IAAqB,IAAIqJ,OAAO,EAAG,GAC3B0U,EAASO,IAAI9W,GAASY,OAInEkX,GAAkBP,EACfrzB,IAAI7H,IACH,IAAIuvB,EAAMvvB,EAAEmC,iBAAiBkE,MAAQ,IAAMrG,EAAEmC,MAAQ,IAAMnC,EAAEmC,MAC7D,MAAO,IAAMnC,EAAEuD,IAAM,IAAMgsB,IAE5BpnB,KAAK,SACC4yB,GAAiBlC,KAC1B4C,EAAiB,OAGnB,IAAKA,EACH,OAAO,KAET,GAAI50B,EAAI,CAGN,OAFea,GAASb,GAAMA,EAAK8lB,IAAkBlmB,GAAKI,GAAIrG,OAAS,EAAI2F,KAAKJ,UAAUc,GAAM,KAE9E,IAAM40B,EAAiB,IAE3C,OAAOA,EAgJT,SAAgBC,GAAcnd,EAAaod,EAAe/I,GACxD,IAAI3G,EAAS,GACTvpB,EAAY,EAEhB,IAAK,IAAInC,EAAI,EAAGA,EAAIqyB,EAAOryB,IAAK,CAC9B,IAAIq7B,EAAerd,EAAIle,QAAQs7B,EAAOj5B,GAEtC,IAAsB,IAAlBk5B,EAIF,MAHA3P,EAAO5oB,KAAKkb,EAAI/W,UAAU9E,EAAWk5B,IACrCl5B,EAAYk5B,EAAe,EAU/B,GAJA3P,EAAO5oB,KAAKkb,EAAIiH,OAAO9iB,IAInBupB,EAAOzrB,SAAWoyB,EAAQ,EAC5B,KAAO3G,EAAOzrB,SAAWoyB,EAAQ,GAC/B3G,EAAO5oB,KAAK,IAIhB,OAAO4oB,EAGT,IAAiB4P,IAAjB,SAAiBA,GAYf,SAAgBC,EAAYC,GAC1B,MAAMf,EAAyB,GAC/BA,EAAOhzB,MAAQ+zB,EAAa,GAC5Bf,EAAOp6B,KAAOsX,GAAY6jB,EAAa,GAAGvO,gBAAkB,IAE5D,IAAIwO,EAAaD,EAAa,GAC1BE,EAAoB,EACpB17B,EAAI,EAER,KAAOA,EAAIy7B,EAAWx7B,QAAQ,CAC5B,IACI07B,EADAC,EAAqBH,EAAW37B,QAAQ,IAAKE,GAEjD,IAA4B,IAAxB47B,EA0CF,MA1C6B,CAC7B,IAAIhmB,EAAO6lB,EAAWx0B,UAAUjH,EAAG47B,GACnC,GAAwC,MAApCH,EAAWz7B,EAAI4V,EAAK3V,OAAS,GAAY,CAC3C,IAAI47B,EAAoB77B,EAAI4V,EAAK3V,OAAS,EAC1Cy7B,EAAoBI,EAAgBD,EAAmBJ,EAAY,KACnE,MAAM75B,EAAQ65B,EAAWx0B,UAAU40B,EAAmBH,EAAoB,GAC1EC,EAAc/1B,KAAKkX,MAAMlb,GAGzB5B,EAAI07B,EAAoB,OACnB,GAAwC,MAApCD,EAAWz7B,EAAI4V,EAAK3V,OAAS,GAAY,CAElD,IAAI87B,EAAsB/7B,EAAI4V,EAAK3V,OAAS,EACxC+7B,EAAsBF,EAAgBC,EAAqBN,EAAY,KAC3E,MAAM75B,EAAQ65B,EAAWx0B,UAAU80B,EAAqBC,EAAsB,GAC9EL,EAAc/1B,KAAKkX,MAAMlb,GAGzB5B,EAAIg8B,EAAsB,MACrB,CACL,IAAIC,EAAYj8B,EAEZk8B,EAAiBT,EAAW37B,QAAQ,IAAKE,EAAI4V,EAAK3V,SAC9B,IAApBi8B,IACFA,EAAiBT,EAAWx7B,QAG9BD,EAAIk8B,EAAiB,EAErBP,EAAc/1B,KAAKkX,MAAM2e,EAAWx0B,UAAUg1B,EAAYrmB,EAAK3V,OAAS,EAAGi8B,IAGzEha,GAAuBtM,GACzB6kB,EAAO7kB,GAAQ+lB,GAGflB,EAAOhZ,IAAMgZ,EAAOhZ,KAAO,GAC3BgZ,EAAOhZ,IAAI7L,GAAQ+lB,IAQzB,OAAOlB,EAGT,SAAgBqB,EAAgBD,EAA2B7d,EAAame,GACtE,IAAK,IAAIn8B,EAAI67B,EAAmB77B,EAAIge,EAAI/d,OAAQD,IAC9C,GAAIge,EAAIhe,KAAOm8B,EACb,OAAOn8B,EAKb,SAAgBsG,EAAG81B,GACjB,MAAM3B,EAAyB,GAE/B,GAA6B,MAAzB2B,EAAkB,GAAY,CAChC,IAAIV,EAAoBI,EAAgB,EAAGM,EAAmB,KAE1DC,EAAcz2B,KAAKkX,MAAMsf,EAAkBn1B,UAAU,EAAGy0B,EAAoB,IAEhF,IAAK,IAAIY,KAAoBD,EACvBt2B,GAAQs2B,EAAYC,IACtB7B,EAAO6B,GAAoB,CAAC9P,KAAM6P,EAAYC,IAG9C7B,EAAO6B,GAAoBD,EAAYC,GAI3C,OAAA58B,OAAAsL,OAAA,GACKyvB,EACAc,EACDJ,GAAciB,EAAkBn1B,UAAUy0B,EAAoB,EAAGU,EAAkBn8B,OAAS,GAAI,IAAK,KAGpG,CACL,IAAIy6B,EAAO0B,EAAkBn1B,UAAU,EAAGm1B,EAAkBt8B,QAAQ,MAEhEy8B,EAAgBpB,GADLiB,EAAkBn1B,UAAUyzB,EAAKz6B,OAAS,EAAGm8B,EAAkBn8B,OAAS,GAC3C,IAAK,GAEjD,GAAIszB,GAAcmH,GAChB,OAAAh7B,OAAAsL,OAAA,CACEkK,UAAWwlB,GACRa,EAAYgB,IAEZ,GZzSFhS,GYySiBmQ,GACpB,OAAAh7B,OAAAsL,OAAA,CACE0W,SAAUgZ,GACPa,EAAYgB,IAEZ,GAAa,QAAT7B,EACT,OAAAh7B,OAAAsL,OAAA,CACEyW,IAAK,IACF8Z,EAAYgB,KAxHPjB,EAAAhpB,SAAhB,SAAyB/F,EAAmC6vB,GAC1D,IAAII,GACkC,IAApCJ,EAAkBt8B,QAAQ,KACtBwG,EAAG81B,GACHb,EAAYJ,GAAciB,EAAmB,IAAK,IACxD,OAAA18B,OAAAsL,OAAA,CACEuB,QAAAA,GACGiwB,IAISlB,EAAAC,YAAWA,EA4DXD,EAAAQ,gBAAeA,EAQfR,EAAAh1B,GAAEA,EAhFpB,CAAiBg1B,KAAAA,GAAe,wHA7UhC,SACEmB,EACAzC,EAA8BH,GAC9BtyB,EAA+BqyB,IAG/B,OAAO3B,GADOD,GAASyE,GACJzC,EAASzyB,yEAsQ9B,SAAsBm1B,GAGpB,IAAIC,EAAiBD,EAAUne,MAAM,KAEjCma,EAAmB,CACrBtrB,KAAMuvB,EAAe,GACrBtE,UAAW,IAGb,IAAK,IAAIr4B,EAAI,EAAGA,EAAI28B,EAAe18B,OAAQD,IAAK,CAE9C,MAAM48B,EAAYzB,GADPwB,EAAe38B,GACY,IAAK,GACrC68B,EAAeD,EAAU,GACzBE,EAAiBF,EAAU,GAEjC,GxBtKOpwB,EwBsKOqwB,IAAkC,MAAjBA,EAA/B,CACE,MAAMvE,EAAOgD,GAAgBhpB,SAASuqB,EAAcC,GACpDpE,EAAML,UAAUv1B,KAAKw1B,OAIF,cAAjBuE,IACFnE,EAAM/jB,UAAY/O,KAAKkX,MAAMggB,IAKjC,OAAOpE,gECnVO6B,GAAajC,GAC3B,OAAOA,MAAAA,QAAyD5yB,IAAlB4yB,EAAY,MAG5D,SAAgBC,GAAaD,GAC3B,OAAOA,MAAAA,IAAwCA,EAAY,OAA2B,UAAtBA,EAAgB,WAGlF,SAAgBkC,GAAiBlC,GAC/B,OAAOA,MAAAA,GAAuC,cAAeA,EAG/D,SAAgBc,GAAyBd,GACvC,OAAOkC,GAAiBlC,KAA4B,IAAnBA,EAAK9W,UAGxC,SAAgBmX,GAAwBL,GACtC,OAAOkC,GAAiBlC,KAA4B,IAAnBA,EAAK9W,UAsExC,MAAMub,GAAgB,CACpB3Z,GAASM,UACTN,GAASQ,IACTR,GAASU,SACTV,GAASW,MACTX,GAASY,KACTZ,GAASc,MACTd,GAASa,KACTb,GAASe,KACTf,GAASgB,OACThB,GAASG,MACTH,GAASI,QASX,SAAgBsV,GAAWqB,EAAwB6C,GAEjD,IAAI1qB,EAA6B,GAEjC,IAAK,MAAMgmB,KAAQ6B,EAAO,CACxB,GAAIf,GAAyBd,GAC3B,SAGF,MAAM/rB,QAACA,GAAW+rB,EAGlB,GAAIjM,GAAW9f,GACb,MAAM,IAAI7J,MAAM,sDAElB,MAAMmxB,EAAa0G,GAAajC,GAAQ2E,GAAW3E,GAAQ4E,GAAW5E,EAAM0E,GAE5E,GAAmB,OAAfnJ,EAQJvhB,EAAS/F,GAAWsnB,OAPlB,GAA4B,SAAxBmJ,EAAOjE,aAET,OAAO,KAOb,OAAOzmB,EAGT,SAAgB2qB,GAAWE,GACzB,MAAMv7B,MAACA,GAASu7B,EAChB,OAAI9Q,GAAWzqB,GACN,KAEF,CAACA,MAAAA,GAGV,SAAgBs7B,GACd5E,EACA0E,EAA2B,IAE3B,MAAMrC,MAACA,EAAQoC,GAAajO,OAAEA,EAAMiK,aAAEA,EAAe,QAAUiE,EAE/D,GAAIzE,GAAaD,GAAO,CACtB,MAAMljB,EAAW,GACjB,IAAK,MAAMQ,KAAQ+kB,EAAO,CACxB,IAAI2B,EAAmBhE,EAAK1iB,GAC5B,GAAIyW,GAAWiQ,GAAmB,CAChC,GAAqB,SAAjBvD,EAAyB,SAC7B,OAAO,KAGT,QAAyBrzB,IAArB42B,EAAgC,CAIlC,MADGvC,GAA4BnkB,IAASmkB,GAA4BnkB,GAAM0iB,EAAK/rB,UAE7E,SAGF,GAAI2V,GAAuBtM,IAAS1O,GAASo1B,GAAmB,CAC9DA,EAAgB58B,OAAAsL,OAAA,GAAOsxB,GACvB,IAAK,MAAMhD,KAAagD,EAEtB,GAAIjQ,GAAWiQ,EAAiBhD,IAAa,CAC3C,GAAqB,SAAjBP,EACF,OAAO,YAEFuD,EAAiBhD,IAK9B,GAAa,QAAT1jB,IAAuC,IAArB0mB,EACpB,SACkB,SAAT1mB,GAAwC,QAArB0mB,EAC5BlnB,EAAS/U,KAAO,UAEhB+U,EAASQ,GAAQ0mB,EAIrB,GAAI1mB,IAASwN,GAASc,OAAS4K,GAAUwJ,EAAKj4B,OAASob,GAAc,CACnE,MAAMhJ,EAAQ6lB,EAAK7lB,OACb2qB,cAACA,GAAiBtO,EAAOuO,YAAY/E,EAAK7wB,OAElC,OAAVgL,GAAkB2qB,IACpBhoB,EAASgO,GAASc,OAAMxkB,OAAAsL,OAAA,CACtBqD,OAAQ+uB,GAEJl2B,GAASuL,GAASA,EAAQ,MAKtC,OAAO2C,EAEP,IAAuB,IAAnBkjB,EAAK9W,UACP,MAAM,IAAI9e,MAAM,sDAEhB,MAAO,CACLwS,UAAW,QACXzN,MAAO,IACPpH,KAAM,gBAiBd,SAAgBi9B,GAAUhF,GACxB,OAAIC,GAAaD,IACPiF,GAAYjF,IAAuB,aAAdA,EAAKj4B,KAE7Bm6B,GAAiBlC,GAO1B,SAAgBiF,GAAYjF,GAC1B,GAAIC,GAAaD,GAAO,CACtB,MAAMljB,EAAW8nB,GAAW5E,EAAM,CAACqC,MAAO,CAAC,MAAO,WAAY,UAC9D,OAAO6C,GAAwBpoB,MAAeA,EAASsM,SAEzD,OAAO,EAST,SAAgB1M,GAAUylB,GACxB,MAAMhoB,GAAqC,IAAjBgoB,EAAOhoB,OAAkBgoB,EAAOhoB,QAAU2Z,GAAiB,GAAKqO,EAAOhoB,OAAS,IAEpGpS,KAACA,EAAIkM,QAAEA,EAAOmV,SAAEA,EAAQD,IAAEA,GAAOgZ,EAUvC,GAAIpO,GAAW5Z,EAAMpS,OAASgsB,GAAWhsB,IAASgsB,GAAW9f,IAAY8f,GAAW5K,GAClF,OAIF,GAAIhP,EAAMpS,KACR,OAAOoS,EAAMpS,KAIf,GAAa,aAATA,GAAuBgsB,GAAW3K,GACpC,OAIF,GAAa,iBAATrhB,GAA2BgsB,GAAW5K,GACxC,OAKF,MAAMrM,EAAW,CACf/U,KAHyBA,IAASs1B,GAAa/qB,IAAM,UAAYvK,EAIjEqhB,SAAUA,EACVD,IAAKA,GAEP,OAAOgc,GAAiB,CAACp9B,KAAMoS,EAAMpS,MAAOkM,EAAS6I,OA5B9B1P,2LA3CzB,SAA6B4yB,GAC3B,OAAIC,GAAaD,GACRoF,GAA0BR,GAAW5E,EAAM,CAACqC,MAAO,CAAC,MAAO,WAAY,QAAS,WAElFH,GAAiBlC,mEChQlB,SAAU3zB,GAEhB,IAAIg5B,EAAK,IAAIt7B,KACTu7B,EAAK,IAAIv7B,KACb,SAASw7B,EAAYC,EAAQC,EAAS1L,EAAO5qB,GAE3C,SAASu2B,EAASjgB,GAChB,OAAO+f,EAAO/f,EAAO,IAAI1b,MAAM0b,IAAQA,EAyDzC,OAtDAigB,EAAS9d,MAAQ8d,EAEjBA,EAAS5jB,MAAQ,SAAS2D,GACxB,IAAIkgB,EAAK,IAAI57B,MAAM0b,GACfmgB,EAAK,IAAI77B,KAAK0b,EAAO,GAEzB,OADA+f,EAAOG,GAAKH,EAAOI,GAAKH,EAAQG,EAAI,GAC7BngB,EAAOkgB,EAAKC,EAAKngB,EAAOkgB,EAAKC,GAGtCF,EAASzd,KAAO,SAASxC,GACvB,OAAO+f,EAAO/f,EAAO,IAAI1b,KAAK0b,EAAO,IAAKggB,EAAQhgB,EAAM,GAAIA,GAG9DigB,EAAS1tB,OAAS,SAASyN,EAAMyP,GAC/B,OAAOuQ,EAAQhgB,EAAO,IAAI1b,MAAM0b,GAAe,MAARyP,EAAe,EAAIvN,KAAKC,MAAMsN,IAAQzP,GAG/EigB,EAASjkB,MAAQ,SAASokB,EAAOC,EAAM5Q,GACrC,IAAIzT,EAAQ,GAIZ,GAHAokB,EAAQ,IAAI97B,KAAK87B,EAAQ,GACzBC,EAAO,IAAI/7B,MAAM+7B,GACjB5Q,EAAe,MAARA,EAAe,EAAIvN,KAAKC,MAAMsN,KAC/B2Q,EAAQC,GAAW5Q,EAAO,GAAI,OAAOzT,EAG3C,IAFAgkB,EAAQI,EAAO,GAAIL,EAAOK,GACtBA,EAAQC,GAAMrkB,EAAMjX,KAAK,IAAIT,MAAM87B,IAChCJ,EAAQI,EAAO3Q,GAAOsQ,EAAOK,GAAQA,EAAQC,GAAMrkB,EAAMjX,KAAK,IAAIT,MAAM87B,IAC/E,OAAOpkB,GAGTikB,EAASvf,OAAS,SAAS4f,GACzB,OAAOR,EAAY,SAAS9f,GAC1B,KAAO+f,EAAO/f,IAAQsgB,EAAKtgB,IAAOA,EAAKugB,QAAQvgB,EAAO,IACrD,SAASA,EAAMyP,GAChB,OAASA,GAAQ,GAAG,KAAOuQ,EAAQhgB,EAAM,IAAKsgB,EAAKtgB,SAInDsU,IACF2L,EAAS3L,MAAQ,SAAS8L,EAAOI,GAG/B,OAFAZ,EAAGW,SAASH,GAAQP,EAAGU,SAASC,GAChCT,EAAOH,GAAKG,EAAOF,GACZ3d,KAAKC,MAAMmS,EAAMsL,EAAIC,KAG9BI,EAASjd,MAAQ,SAASyM,GAExB,OADAA,EAAOvN,KAAKC,MAAMsN,GACV7nB,SAAS6nB,IAAWA,EAAO,EAC3BA,EAAO,EACTwQ,EAASvf,OAAOhX,EACZ,SAAS4O,GAAK,OAAO5O,EAAM4O,GAAKmX,GAAS,GACzC,SAASnX,GAAK,OAAO2nB,EAAS3L,MAAM,EAAGhc,GAAKmX,GAAS,IAH3CwQ,EADoB,OAQrCA,EAGT,IAAIQ,EAAcX,EAAY,aAE3B,SAAS9f,EAAMyP,GAChBzP,EAAKugB,SAASvgB,EAAOyP,IACpB,SAAS2Q,EAAOI,GACjB,OAAOA,EAAMJ,IAIfK,EAAYzd,MAAQ,SAAS7D,GAE3B,OADAA,EAAI+C,KAAKC,MAAMhD,GACVvX,SAASuX,IAAQA,EAAI,EACpBA,EAAI,EACH2gB,EAAY,SAAS9f,GAC1BA,EAAKugB,QAAQre,KAAKC,MAAMnC,EAAOb,GAAKA,IACnC,SAASa,EAAMyP,GAChBzP,EAAKugB,SAASvgB,EAAOyP,EAAOtQ,IAC3B,SAASihB,EAAOI,GACjB,OAAQA,EAAMJ,GAASjhB,IANJshB,EADgB,MAWvC,IAAIC,EAASZ,EAAY,SAAS9f,GAChCA,EAAK2gB,gBAAgB,IACpB,SAAS3gB,EAAMyP,GAChBzP,EAAKugB,SAASvgB,EAAc,IAAPyP,IACpB,SAAS2Q,EAAOI,GACjB,OAAQA,EAAMJ,GAAS,KACtB,SAASpgB,GACV,OAAOA,EAAK4gB,eAGVC,EAASf,EAAY,SAAS9f,GAChCA,EAAK8gB,WAAW,EAAG,IAClB,SAAS9gB,EAAMyP,GAChBzP,EAAKugB,SAASvgB,EAAc,IAAPyP,IACpB,SAAS2Q,EAAOI,GACjB,OAAQA,EAAMJ,GAAS,KACtB,SAASpgB,GACV,OAAOA,EAAK+gB,eAGVC,EAAOlB,EAAY,SAAS9f,GAC9BA,EAAKihB,WAAW,EAAG,EAAG,IACrB,SAASjhB,EAAMyP,GAChBzP,EAAKugB,SAASvgB,EAAc,KAAPyP,IACpB,SAAS2Q,EAAOI,GACjB,OAAQA,EAAMJ,GAAS,MACtB,SAASpgB,GACV,OAAOA,EAAKkhB,aAGV5W,EAAMwV,EAAY,SAAS9f,GAC7BA,EAAKmhB,SAAS,EAAG,EAAG,EAAG,IACtB,SAASnhB,EAAMyP,GAChBzP,EAAKohB,QAAQphB,EAAKqhB,UAAY5R,IAC7B,SAAS2Q,EAAOI,GACjB,OAAQA,EAAMJ,EAAgE,KAAvDI,EAAIc,oBAAsBlB,EAAMkB,sBAA8B,OACpF,SAASthB,GACV,OAAOA,EAAKqhB,UAAY,IAG1B,SAASE,EAAQt/B,GACf,OAAO69B,EAAY,SAAS9f,GAC1BA,EAAKmhB,SAAS,EAAG,EAAG,EAAG,GACvBnhB,EAAKohB,QAAQphB,EAAKqhB,WAAarhB,EAAKwhB,SAAW,EAAIv/B,GAAK,IACvD,SAAS+d,EAAMyP,GAChBzP,EAAKohB,QAAQphB,EAAKqhB,UAAmB,EAAP5R,IAC7B,SAAS2Q,EAAOI,GACjB,OAAQA,EAAMJ,EAAgE,KAAvDI,EAAIc,oBAAsBlB,EAAMkB,sBAA8B,SAIzF,IAAIG,EAASF,EAAQ,GACjBG,EAASH,EAAQ,GACjBI,EAAUJ,EAAQ,GAClBK,EAAYL,EAAQ,GACpBM,EAAWN,EAAQ,GACnBO,EAASP,EAAQ,GACjBQ,EAAWR,EAAQ,GAEnBlX,EAAQyV,EAAY,SAAS9f,GAC/BA,EAAKmhB,SAAS,EAAG,EAAG,EAAG,GACvBnhB,EAAKohB,QAAQ,IACZ,SAASphB,EAAMyP,GAChBzP,EAAKgiB,SAAShiB,EAAKiiB,WAAaxS,IAC/B,SAAS2Q,EAAOI,GACjB,OAAOA,EAAIyB,WAAa7B,EAAM6B,WAAyD,IAA3CzB,EAAI0B,cAAgB9B,EAAM8B,gBACrE,SAASliB,GACV,OAAOA,EAAKiiB,aAGV9X,EAAO2V,EAAY,SAAS9f,GAC9BA,EAAKmhB,SAAS,EAAG,EAAG,EAAG,GACvBnhB,EAAKgiB,SAAS,EAAG,IAChB,SAAShiB,EAAMyP,GAChBzP,EAAKmiB,YAAYniB,EAAKkiB,cAAgBzS,IACrC,SAAS2Q,EAAOI,GACjB,OAAOA,EAAI0B,cAAgB9B,EAAM8B,eAChC,SAASliB,GACV,OAAOA,EAAKkiB,gBAGVE,EAAYtC,EAAY,SAAS9f,GACnCA,EAAKqiB,mBAAmB,IACvB,SAASriB,EAAMyP,GAChBzP,EAAKugB,SAASvgB,EAAc,IAAPyP,IACpB,SAAS2Q,EAAOI,GACjB,OAAQA,EAAMJ,GAAS,KACtB,SAASpgB,GACV,OAAOA,EAAKsiB,kBAGVC,EAAYzC,EAAY,SAAS9f,GACnCA,EAAKwiB,cAAc,EAAG,IACrB,SAASxiB,EAAMyP,GAChBzP,EAAKugB,SAASvgB,EAAc,IAAPyP,IACpB,SAAS2Q,EAAOI,GACjB,OAAQA,EAAMJ,GAAS,KACtB,SAASpgB,GACV,OAAOA,EAAKyiB,kBAGVC,EAAU5C,EAAY,SAAS9f,GACjCA,EAAK2iB,cAAc,EAAG,EAAG,IACxB,SAAS3iB,EAAMyP,GAChBzP,EAAKugB,SAASvgB,EAAc,KAAPyP,IACpB,SAAS2Q,EAAOI,GACjB,OAAQA,EAAMJ,GAAS,MACtB,SAASpgB,GACV,OAAOA,EAAK4iB,gBAGVC,EAAS/C,EAAY,SAAS9f,GAChCA,EAAK8iB,YAAY,EAAG,EAAG,EAAG,IACzB,SAAS9iB,EAAMyP,GAChBzP,EAAK+iB,WAAW/iB,EAAKgjB,aAAevT,IACnC,SAAS2Q,EAAOI,GACjB,OAAQA,EAAMJ,GAAS,OACtB,SAASpgB,GACV,OAAOA,EAAKgjB,aAAe,IAG7B,SAASC,EAAWhhC,GAClB,OAAO69B,EAAY,SAAS9f,GAC1BA,EAAK8iB,YAAY,EAAG,EAAG,EAAG,GAC1B9iB,EAAK+iB,WAAW/iB,EAAKgjB,cAAgBhjB,EAAKkjB,YAAc,EAAIjhC,GAAK,IAChE,SAAS+d,EAAMyP,GAChBzP,EAAK+iB,WAAW/iB,EAAKgjB,aAAsB,EAAPvT,IACnC,SAAS2Q,EAAOI,GACjB,OAAQA,EAAMJ,GAAS,SAI3B,IAAI+C,EAAYF,EAAW,GACvBG,EAAYH,EAAW,GACvBI,EAAaJ,EAAW,GACxBK,EAAeL,EAAW,GAC1BM,EAAcN,EAAW,GACzBO,EAAYP,EAAW,GACvBQ,EAAcR,EAAW,GAEzBS,EAAW5D,EAAY,SAAS9f,GAClCA,EAAK8iB,YAAY,EAAG,EAAG,EAAG,GAC1B9iB,EAAK+iB,WAAW,IACf,SAAS/iB,EAAMyP,GAChBzP,EAAK2jB,YAAY3jB,EAAK4jB,cAAgBnU,IACrC,SAAS2Q,EAAOI,GACjB,OAAOA,EAAIoD,cAAgBxD,EAAMwD,cAAkE,IAAjDpD,EAAIqD,iBAAmBzD,EAAMyD,mBAC9E,SAAS7jB,GACV,OAAOA,EAAK4jB,gBAGVE,EAAUhE,EAAY,SAAS9f,GACjCA,EAAK8iB,YAAY,EAAG,EAAG,EAAG,GAC1B9iB,EAAK2jB,YAAY,EAAG,IACnB,SAAS3jB,EAAMyP,GAChBzP,EAAK+jB,eAAe/jB,EAAK6jB,iBAAmBpU,IAC3C,SAAS2Q,EAAOI,GACjB,OAAOA,EAAIqD,iBAAmBzD,EAAMyD,kBACnC,SAAS7jB,GACV,OAAOA,EAAK6jB,mBAGVnZ,EAAe+V,EAAYzkB,MAC3ByO,EAAUiW,EAAO1kB,MACjBwO,EAAUqW,EAAO7kB,MACjBuO,EAAQyW,EAAKhlB,MACbgoB,EAAO1Z,EAAItO,MACXioB,EAAUxC,EAAOzlB,MACjBkoB,EAAUxC,EAAO1lB,MACjBmoB,EAAWxC,EAAQ3lB,MACnBooB,EAAaxC,EAAU5lB,MACvBqoB,EAAYxC,EAAS7lB,MACrBsoB,EAAUxC,EAAO9lB,MACjBuoB,EAAYxC,EAAS/lB,MACrBwoB,EAAQ/C,EAAOzlB,MACfyoB,EAASpa,EAAMrO,MACf0oB,EAAQva,EAAKnO,MAEb2oB,EAAiBlE,EACjBmE,EAAkBla,EAClBma,EAAazC,EAAUpmB,MACvB8oB,EAAavC,EAAUvmB,MACvB+oB,EAAWrC,EAAQ1mB,MACnBgpB,EAAUnC,EAAO7mB,MACjBipB,GAAa9B,EAAUnnB,MACvBkpB,GAAa9B,EAAUpnB,MACvBmpB,GAAc9B,EAAWrnB,MACzBopB,GAAgB9B,EAAatnB,MAC7BqpB,GAAe9B,EAAYvnB,MAC3BspB,GAAa9B,EAAUxnB,MACvBupB,GAAe9B,EAAYznB,MAC3BwpB,GAAWrC,EAAUnnB,MACrBypB,GAAY/B,EAAS1nB,MACrB0pB,GAAW5B,EAAQ9nB,MAIvBpV,EAAQ++B,QAFM,QAGd/+B,EAAQ8jB,aAAeA,EACvB9jB,EAAQ6jB,QAAUA,EAClB7jB,EAAQ4jB,QAAUA,EAClB5jB,EAAQ2jB,MAAQA,EAChB3jB,EAAQo9B,KAAOA,EACfp9B,EAAQq9B,QAAUA,EAClBr9B,EAAQs9B,QAAUA,EAClBt9B,EAAQu9B,SAAWA,EACnBv9B,EAAQw9B,WAAaA,EACrBx9B,EAAQy9B,UAAYA,EACpBz9B,EAAQ09B,QAAUA,EAClB19B,EAAQ29B,UAAYA,EACpB39B,EAAQ49B,MAAQA,EAChB59B,EAAQ69B,OAASA,EACjB79B,EAAQ89B,MAAQA,EAChB99B,EAAQ+9B,eAAiBA,EACzB/9B,EAAQg+B,gBAAkBA,EAC1Bh+B,EAAQi+B,WAAaA,EACrBj+B,EAAQk+B,WAAaA,EACrBl+B,EAAQm+B,SAAWA,EACnBn+B,EAAQo+B,QAAUA,EAClBp+B,EAAQq+B,WAAaA,GACrBr+B,EAAQs+B,WAAaA,GACrBt+B,EAAQu+B,YAAcA,GACtBv+B,EAAQw+B,cAAgBA,GACxBx+B,EAAQy+B,aAAeA,GACvBz+B,EAAQ0+B,WAAaA,GACrB1+B,EAAQ2+B,aAAeA,GACvB3+B,EAAQ4+B,SAAWA,GACnB5+B,EAAQ6+B,UAAYA,GACpB7+B,EAAQ8+B,SAAWA,GACnB9+B,EAAQ65B,YAAcA,EACtB75B,EAAQ85B,OAASA,EACjB95B,EAAQi6B,OAASA,EACjBj6B,EAAQo6B,KAAOA,EACfp6B,EAAQ0jB,IAAMA,EACd1jB,EAAQ66B,OAASA,EACjB76B,EAAQ86B,OAASA,EACjB96B,EAAQ+6B,QAAUA,EAClB/6B,EAAQg7B,UAAYA,EACpBh7B,EAAQi7B,SAAWA,EACnBj7B,EAAQk7B,OAASA,EACjBl7B,EAAQm7B,SAAWA,EACnBn7B,EAAQg/B,KAAOnE,EACf76B,EAAQyjB,MAAQA,EAChBzjB,EAAQujB,KAAOA,EACfvjB,EAAQw7B,UAAYA,EACpBx7B,EAAQ27B,UAAYA,EACpB37B,EAAQ87B,QAAUA,EAClB97B,EAAQi8B,OAASA,EACjBj8B,EAAQu8B,UAAYA,EACpBv8B,EAAQw8B,UAAYA,EACpBx8B,EAAQy8B,WAAaA,EACrBz8B,EAAQ08B,aAAeA,EACvB18B,EAAQ28B,YAAcA,EACtB38B,EAAQ48B,UAAYA,EACpB58B,EAAQ68B,YAAcA,EACtB78B,EAAQi/B,QAAU1C,EAClBv8B,EAAQ88B,SAAWA,EACnB98B,EAAQk9B,QAAUA,EAClBl9B,EAAQq5B,SAAWH,EA9VnBgG,CAAuEl/B,KCCrEm/B,GAAW,IAAIzhC,KACf0hC,GAAW,IAAI1hC,KAAK,EAAG,EAAG,GAAG69B,YAAY,GACzC8D,GAAc,IAAI3hC,KAAKA,KAAK+V,IAAI,EAAG,EAAG,IAAI0pB,eAAe,GAE7D,SAAS/jB,GAAK1H,GACZ,OAAQytB,GAASxF,SAASjoB,GAAIytB,GAIhC,SAASG,GAAM5jC,EAAM0d,EAAMyN,EAAMgC,EAAMD,EAAK3M,GAC1C,IAAIrhB,EAAI,CACNc,KAAMA,EACN0d,KAAMA,EACNyN,KAAMA,GASR,OAPIgC,EACFjuB,EAAEiuB,KAAOA,EAETjuB,EAAEmuB,QAAU,EAEH,MAAPH,IAAahuB,EAAEguB,IAAMA,GACd,MAAP3M,IAAarhB,EAAEqhB,IAAMA,GAClBrhB,EAGT,SAASoD,GAAOtC,EAAMmrB,EAAMjR,EAAMiT,EAAMD,EAAK3M,GAC3C,OAAOqjB,GAAM5jC,EACX,SAASgW,GAAK,OAAOmV,EAAKlb,OAAOiK,EAAMlE,IACvC,SAASA,GAAK,OAAOmV,EAAK6G,MAAM9X,EAAMlE,IACtCmX,EAAMD,EAAK3M,GAGf,IAAIsjB,GAAS,CACXvhC,GAAO,SAAUwhC,GAAQ1F,OAAQsF,IACjCphC,GAAO,SAAUwhC,GAAQvF,OAAQmF,IACjCphC,GAAO,OAAUwhC,GAAQpF,KAAQgF,IACjCphC,GAAO,MAAUwhC,GAAQ9b,IAAQ0b,GAAU,CAAC,EAAG,IAC/CphC,GAAO,QAAUwhC,GAAQ/b,MAAQ2b,GAAU,CAAC,EAAG,EAAG,IAClDphC,GAAO,OAAUwhC,GAAQjc,KAAQ6b,IAGjCE,GAAM,UACJ,SAAS5tB,GAAK,OAAO,IAAIhU,KAAK,KAAM,EAAG,EAAG,EAAG,EAAGgU,IAChD,SAASA,GAAK,OAAO0H,GAAK1H,GAAGsoB,cAC7B,KAAM,EAAG,IAEXsF,GAAM,UACJ,SAAS5tB,GAAK,OAAO,IAAIhU,KAAK,KAAM,EAAG,EAAG,EAAGgU,IAC7C,SAASA,GAAK,OAAO0H,GAAK1H,GAAGyoB,cAC7B,KAAM,EAAG,IAEXmF,GAAM,QACJ,SAAS5tB,GAAK,OAAO,IAAIhU,KAAK,KAAM,EAAG,EAAGgU,IAC1C,SAASA,GAAK,OAAO0H,GAAK1H,GAAG4oB,YAC7B,KAAM,EAAG,IAEXgF,GAAM,WACJ,SAAS5tB,GAAK,OAAO,IAAIhU,KAAK,KAAM,EAAG,EAAEgU,IACzC,SAASA,GAAK,OAAO0H,GAAK1H,GAAGkpB,UAC7B,CAAC,GAAI,EAAG,GAEV0E,GAAM,QACJ,SAAS5tB,GAAK,OAAO,IAAIhU,KAAK,KAAM,EAAGgU,IACvC,SAASA,GAAK,OAAO0H,GAAK1H,GAAG+oB,WAC7B,CAAC,GAAI,EAAG,IAEV6E,GAAM,SACJ,SAAS5tB,GAAK,OAAO,IAAIhU,KAAK,KAAMgU,EAAI,GAAI,IAC5C,SAASA,GAAK,OAAO0H,GAAK1H,GAAG2pB,YAC7B,CAAC,GAAI,EAAG,KAIR/mB,GAAM,CACRtW,GAAO,SAAUwhC,GAAQhE,UAAW6D,IACpCrhC,GAAO,SAAUwhC,GAAQ7D,UAAW0D,IACpCrhC,GAAO,OAAUwhC,GAAQ1D,QAAWuD,IACpCrhC,GAAO,MAAUwhC,GAAQvD,OAAWoD,GAAa,CAAC,EAAG,IACrDrhC,GAAO,QAAUwhC,GAAQ1C,SAAWuC,GAAa,CAAC,EAAG,EAAG,IACxDrhC,GAAO,OAAUwhC,GAAQtC,QAAWmC,IAGpCC,GAAM,UACJ,SAAS5tB,GAAK,OAAO,IAAIhU,KAAKA,KAAK+V,IAAI,KAAM,EAAG,EAAG,EAAG,EAAG/B,KACzD,SAASA,GAAK,OAAO0H,GAAK1H,GAAGgqB,iBAC7B,KAAM,EAAG,IAEX4D,GAAM,UACJ,SAAS5tB,GAAK,OAAO,IAAIhU,KAAKA,KAAK+V,IAAI,KAAM,EAAG,EAAG,EAAG/B,KACtD,SAASA,GAAK,OAAO0H,GAAK1H,GAAGmqB,iBAC7B,KAAM,EAAG,IAEXyD,GAAM,QACJ,SAAS5tB,GAAK,OAAO,IAAIhU,KAAKA,KAAK+V,IAAI,KAAM,EAAG,EAAG/B,KACnD,SAASA,GAAK,OAAO0H,GAAK1H,GAAGsqB,eAC7B,KAAM,EAAG,IAEXsD,GAAM,WACJ,SAAS5tB,GAAK,OAAO,IAAIhU,KAAKA,KAAK+V,IAAI,KAAM,EAAG,EAAE/B,KAClD,SAASA,GAAK,OAAO0H,GAAK1H,GAAG4qB,aAC7B,CAAC,GAAI,EAAG,GAEVgD,GAAM,QACJ,SAAS5tB,GAAK,OAAO,IAAIhU,KAAKA,KAAK+V,IAAI,KAAM,EAAG/B,KAChD,SAASA,GAAK,OAAO0H,GAAK1H,GAAG0qB,cAC7B,CAAC,GAAI,EAAG,IAEVkD,GAAM,SACJ,SAAS5tB,GAAK,OAAO,IAAIhU,KAAKA,KAAK+V,IAAI,KAAM/B,EAAI,GAAI,KACrD,SAASA,GAAK,OAAO0H,GAAK1H,GAAGsrB,eAC7B,CAAC,GAAI,EAAG,KAIRyC,GAAQ,CACV,CAAC,QAAS,GACV,CAAC,OAAQ,GACT,CAAC,OAAQ,GACT,CAAC,QAAS,GACV,CAAC,OAAQ,GACT,CAAC,OAAQ,GACT,CAAC,MAAO,GACR,CAAC,MAAO,GACR,CAAC,MAAO,GACR,CAAC,MAAO,GACR,CAAC,KAAM,GACP,CAAC,KAAM,GACP,CAAC,IAAK,GACN,CAAC,IAAK,GACN,CAAC,IAAK,GACN,CAAC,IAAK,GACN,CAAC,KAAM,GACP,CAAC,IAAK,GACN,CAAC,IAAK,IAqBR,SAASC,GAAUC,GACjB,IAActkC,EAAGgH,EAAbM,EAAM,GACV,IAAKtH,EAAE,EAAGgH,EAAEs9B,EAAMrkC,OAAQD,EAAEgH,IAAKhH,EAC/BsH,EAAIg9B,EAAMtkC,GAAGK,MAAQikC,EAAMtkC,GAK7B,OAHAsH,EAAIi9B,KAAO,SAASC,EAAMC,EAAMC,GAC9B,OAxBJ,SAAcJ,EAAOE,EAAMC,EAAMC,GAC/B,IAAqB1kC,EAAGgH,EAAGkT,EAAvBsT,EAAO4W,GAAM,GAEjB,IAAKpkC,EAAE,EAAGgH,EAAEo9B,GAAMnkC,OAAQD,EAAEgH,IAAKhH,EAE/B,GAAIwkC,GADJhX,EAAO4W,GAAMpkC,IACG,GAAI,CAElB,IADAka,EAAOsqB,EAAOhX,EAAK,IACRkX,EACT,OAAOJ,EAAMF,GAAMpkC,EAAE,GAAG,IAE1B,GAAIka,GAAQuqB,EACV,OAAOH,EAAM9W,EAAK,IAIxB,OAAO8W,EAAMF,GAAMp9B,EAAE,GAAG,IASfu9B,CAAKD,EAAOE,EAAMC,EAAMC,IAE1Bp9B,EAGT,IAAA0R,GAAiBqrB,GAAUH,IAC3BS,GAAqBN,GAAUprB,cCxK/B,IAAI2rB,GAEU,MAEd,SAAS1qB,GAAKrF,GACZ,IAAKA,EAAO,MAAMnS,MAAM,4BAGxB,IAOI8qB,EAAMxlB,EAAO0lB,EAASmX,EAAW/lB,EAAG9e,EAAG8kC,EAPvCJ,EAAO7vB,EAAIyY,SAAW,GACtB/S,EAAO1F,EAAI0F,MAAQ,GACnBwqB,EAAO9kB,KAAKnY,IAAIyS,GAChByqB,EAAMnwB,EAAImwB,KAAO,CAAC,EAAG,GACrBzX,EAAM1Y,EAAI0Y,IACV3M,EAAM/L,EAAI+L,IACV4jB,EAAO5jB,EAAM2M,EAGjB,GAAI1Y,EAAI2Y,KAENA,EAAO3Y,EAAI2Y,UACN,GAAI3Y,EAAI4Y,MAEbD,EAAO3Y,EAAI4Y,MAAMxN,KAAKsN,IACpB1Y,EAAI4Y,MAAMxtB,OAAS,EAuCzB,SAAgBkF,EAAGkC,EAAG49B,EAAIC,GACxB,KAAOD,EAAKC,GAAI,CACd,IAAIC,EAAMF,EAAKC,IAAO,EAClBE,GAAKrgC,IAAII,EAAEggC,GAAM99B,GAAK,EAAK49B,EAAKE,EAAM,EACnCD,EAAKC,EAEd,OAAOF,EA5CHI,CAAOxwB,EAAI4Y,MAAO+W,EAAKE,EAAM,EAAG7vB,EAAI4Y,MAAMxtB,cAEvC,CAUL,IARA+H,EAAQiY,KAAKM,KAAKN,KAAKnY,IAAI48B,GAAQK,GACnCrX,EAAU7Y,EAAI6Y,SAAW,EACzBF,EAAOvN,KAAKW,IACV8M,EACAzN,KAAKpH,IAAI0B,EAAM0F,KAAK7F,MAAM6F,KAAKnY,IAAI08B,GAAQO,GAAQ/8B,IAI9CiY,KAAKM,KAAKikB,EAAKhX,GAAQkX,GAAQlX,GAAQjT,EAG9C,IAAKva,EAAE,EAAGA,EAAEglC,EAAI/kC,SAAUD,GACxB8e,EAAI0O,EAAOwX,EAAIhlC,KACN0tB,GAAW8W,EAAO1lB,GAAK4lB,IAAMlX,EAAO1O,GAWjD,OALA+lB,GADA/lB,EAAImB,KAAKnY,IAAI0lB,KACI,EAAI,EAAoB,MAAZ1O,EAAIimB,GACjCD,EAAM7kB,KAAKpH,IAAI0B,GAAOsqB,EAAY,GAI3B,CACL1G,MAJF5Q,EAAMtN,KAAKsN,IAAIA,EAAKtN,KAAKC,MAAMqN,EAAMC,EAAOsX,GAAOtX,GAKjD4Q,KAJFxd,EAAMX,KAAKM,KAAKK,EAAM4M,GAAQA,EAK5BA,KAAOA,EACPhC,KAAO,CAACqZ,UAAWA,GACnBjjC,MAAOA,GACPiB,MAAOA,IAaX,SAASjB,GAAMkd,GACb,OAAOlW,KAAK4kB,KAAOvN,KAAKC,MAAMpB,EAAIlW,KAAK4kB,KAAOoX,IAGhD,SAAS/hC,GAAMic,GACb,OAAOmB,KAAKC,OAAOpB,EAAIlW,KAAKu1B,OAASv1B,KAAK4kB,KAAOoX,IAGnD,SAASU,GAAWxmB,GAClB,OAAOlW,KAAK4iB,KAAKzN,KAAKnc,GAAM/B,KAAK+I,KAAMkW,IAGzC,SAASymB,GAAWzmB,GAClB,OAAOjc,GAAMhD,KAAK+I,KAAMA,KAAK4iB,KAAKA,KAAK1M,IAGzC5E,GAAK6D,KAAO,SAASlJ,GACnB,IAAKA,EAAO,MAAMnS,MAAM,iCAGxB,IAAI4hC,EAAQzvB,EAAIoE,IAAMD,GAAKC,IAAMD,GAC7BwsB,EAAO3wB,EAAI0Y,IACXkY,EAAO5wB,EAAI+L,IACX8jB,EAAO7vB,EAAIyY,SAAW,GACtBmX,EAAO5vB,EAAI6wB,SAAW,EACtBlB,GAASiB,GAAUD,EACnBha,EAAO3W,EAAI2W,KAAO8Y,EAAMzvB,EAAI2W,MAAQ8Y,EAAMC,KAAKC,EAAMC,EAAMC,GAC3DzM,EAAO/d,GAAK,CACVqT,IAAqB,MAAZ/B,EAAK+B,IAAc/B,EAAK+B,IAAM/B,EAAKA,KAAKga,GACjD5kB,IAAqB,MAAZ4K,EAAK5K,IAAc4K,EAAK5K,IAAM4K,EAAKA,KAAKia,GACjDnY,QAASoX,EACThX,QAASlC,EAAKkC,QACdD,MAASjC,EAAKgC,OAMpB,OAHAyK,EAAKzM,KAAOA,EACZyM,EAAKp1B,MAAQ0iC,GACR1wB,EAAI8wB,MAAK1N,EAAKr2B,MAAQ0jC,IACpBrN,GAGT,IAAA2N,GAAiB1rB,GC9Gb2rB,GAAQ,YAERC,GAAU,CACZhoB,QAASsnB,GAAKtnB,QACdioB,QAASX,GAAKvnB,OACdA,OAASunB,GAAKvnB,OACdE,KAASqnB,GAAKrnB,KACdioB,OAAS,SAAS3+B,GAAK,OAAY,MAALA,GAAmB,KAANA,EAAW,KAAOA,EAAI,KAG/D4+B,GAAQ,CACVnoB,QAAS,SAASzW,GAAK,MAAW,SAAJA,GAAkB,UAAJA,GAAe+9B,GAAK18B,UAAUrB,IAC1E0+B,QAAS,SAAS1+B,GAAK,OAAO4+B,GAAMpoB,OAAOxW,KAAOA,GAAGA,MAASA,GAC9DwW,OAAQ,SAASxW,GAAK,OAAQ6+B,OAAO7+B,KAAO+9B,GAAKznB,OAAOtW,IACxD0W,KAAM,SAAS1W,GAAK,OAAQ6+B,MAAM7jC,KAAKya,MAAMzV,MAQ/C,SAAS0nB,GAAWiG,GAClB,OAAOoQ,GAAKl/B,KAAK8uB,GAGnB,SAASmR,GAAQC,GACf,MAAO,IAAMA,EAAY,IAG3B,SAAS/lC,GAAK8R,EAAQnN,GAGpB,IAAI8Z,EAAG9e,EAAGgH,EAGV,GALAmL,EAASizB,GAAKr8B,MAAMoJ,GACpBnN,EAAIogC,GAAKh+B,EAAEpC,GAIPmN,EAAO0zB,MACT/mB,EAAI9Z,EAAEmN,EAAO0zB,KACTT,GAAKj+B,SAAS2X,IAAI,OAAOA,EAG/B,IAAK9e,EAAE,EAAGgH,EAAEmL,EAAOlS,QAASmlC,GAAKxnB,QAAQkB,IAAM9e,EAAEgH,IAAKhH,EACpD8e,EAAI9Z,EAAIA,EAAEmN,EAAOnS,IAAMmS,EAAOnS,GAGhC,OAAOolC,GAAKznB,OAAOmB,GAAK,OACtBsmB,GAAK1nB,SAASoB,GAAQ,SACtBsmB,GAAK18B,UAAUoW,GAAO,UACtBsmB,GAAKj+B,SAAS2X,GAAQ,SAAW,KAWrC,SAASunB,GAAMl0B,EAAQnN,GAGrB,IAAIhF,EAAG6G,EAAGiY,EAFV3M,EAASizB,GAAKr8B,MAAMoJ,GACpBnN,EAAIogC,GAAKh+B,EAAEpC,GAIX,IAAIshC,EAAQ,CAAC,UAAW,UAAW,SAAU,QAE7C,IAAKtmC,EAAE,EAAGA,EAAEmS,EAAOlS,SAAUD,EAAG,CAI9B,IAFA8e,EAAI9Z,EAAIA,EAAEmN,EAAOnS,IAAMmS,EAAOnS,GAEzB6G,EAAE,EAAGA,EAAEy/B,EAAMrmC,SAAU4G,EACtBu+B,GAAKxnB,QAAQkB,KAAOmnB,GAAMK,EAAMz/B,IAAIiY,KACtCwnB,EAAMlgC,OAAOS,EAAG,GAChBA,GAAK,GAIT,GAAqB,IAAjBy/B,EAAMrmC,OAAc,MAAO,SAGjC,OAAOqmC,EAAM,GAWfjmC,GAAKkmC,WA3EL,SAAoB1hC,EAAMyhC,GACxB,IAAKA,EAAO,OAAOzhC,GAAQA,EAAKghC,KAAU,KAC1ChhC,EAAKghC,IAASS,GA0EhBjmC,GAAKmmC,IA1CL,SAAiB3hC,EAAM0B,GACrB,GAAK1B,EAAK5E,OAAV,CACA,IAAIi6B,EAAM3zB,EAAS6+B,GAAK1oB,UAAYnW,EAASwoB,GAAWlqB,EAAK,IAAKshC,IAClE,OAAO5/B,EAAO+W,OAAO,SAASgpB,EAAOthC,GACnC,OAAQshC,EAAMthC,GAAK3E,GAAKwE,EAAMq1B,EAAIl1B,IAAKshC,GACtC,MAsCLjmC,GAAKgmC,MAAQA,GACbhmC,GAAKomC,SAXL,SAAkB5hC,EAAM0B,GACtB,IAAI2zB,EAAM3zB,EAAS6+B,GAAK1oB,UAAYnW,EAASwoB,GAAWlqB,EAAK,IAAKshC,IAClE,OAAO5/B,EAAO+W,OAAO,SAASgpB,EAAOthC,GAEnC,OADAshC,EAAMthC,GAAKqhC,GAAMxhC,EAAMq1B,EAAIl1B,IACpBshC,GACN,KAOLjmC,GAAKqmC,QAAUZ,GACf,IAAAa,GAAiBtmC,mCCnGjB,IAAIumC,EACMliC,EAAOC,QAEjBiiC,EAAIC,OAAS,SAAS7X,EAAKhoB,GACzB,IAAkBhH,EAAdmF,EAAIW,MAAMkB,GACd,IAAKhH,EAAE,EAAGA,EAAEgH,IAAKhH,EAAGmF,EAAEnF,GAAKgvB,EAC3B,OAAO7pB,GAGTyhC,EAAIE,MAAQ,SAAS9/B,GACnB,OAAO4/B,EAAIC,OAAO,EAAG7/B,IAGvB4/B,EAAI7sB,MAAQ,SAASokB,EAAOC,EAAM5Q,GAQhC,GAPI9W,UAAUzW,OAAS,IACrButB,EAAO,EACH9W,UAAUzW,OAAS,IACrBm+B,EAAOD,EACPA,EAAQ,KAGPC,EAAOD,GAAS3Q,GAAQnsB,EAAAA,EAAU,MAAM,IAAIqB,MAAM,kBACvD,IAAwBmE,EAApBkT,EAAQ,GAAI/Z,GAAK,EACrB,GAAIwtB,EAAO,EAAG,MAAQ3mB,EAAIs3B,EAAQ3Q,IAASxtB,GAAKo+B,GAAMrkB,EAAMjX,KAAK+D,QAC5D,MAAQA,EAAIs3B,EAAQ3Q,IAASxtB,GAAKo+B,GAAMrkB,EAAMjX,KAAK+D,GACxD,OAAOkT,GAGT6sB,EAAIzmB,OAAS,GAEbymB,EAAIzmB,OAAO4mB,QAAU,SAASxZ,EAAK3M,QACrBlb,IAARkb,IACFA,OAAclb,IAAR6nB,EAAoB,EAAIA,EAC9BA,EAAM,GAER,IAAIlX,EAAIuK,EAAM2M,EACVvoB,EAAI,WACN,OAAOuoB,EAAMlX,EAAI4J,KAAKE,UAcxB,OAZAnb,EAAEgiC,QAAU,SAAShgC,GACnB,OAAO4/B,EAAIE,MAAM9/B,GAAGM,IAAItC,IAE1BA,EAAEiiC,IAAM,SAAS5/B,GACf,OAAQA,GAAKkmB,GAAOlmB,GAAKuZ,EAAO,EAAEvK,EAAI,GAExCrR,EAAEkiC,IAAM,SAAS7/B,GACf,OAAOA,EAAIkmB,EAAM,EAAIlmB,EAAIuZ,EAAM,GAAKvZ,EAAIkmB,GAAOlX,GAEjDrR,EAAEmiC,KAAO,SAAS1nC,GAChB,OAAQA,GAAK,GAAKA,GAAK,EAAK8tB,EAAM9tB,EAAE4W,EAAI+wB,KAEnCpiC,GAGT4hC,EAAIzmB,OAAO4lB,QAAU,SAAS5gC,EAAGC,QACrBM,IAANN,IACFA,EAAID,EACJA,EAAI,GAEN,IAAIkR,EAAIjR,EAAID,EACRH,EAAI,WACN,OAAOG,EAAI8a,KAAKC,MAAM7J,EAAI4J,KAAKE,WAejC,OAbAnb,EAAEgiC,QAAU,SAAShgC,GACnB,OAAO4/B,EAAIE,MAAM9/B,GAAGM,IAAItC,IAE1BA,EAAEiiC,IAAM,SAAS5/B,GACf,OAAQA,IAAM4Y,KAAKC,MAAM7Y,IAAMA,GAAKlC,GAAKkC,EAAIjC,EAAK,EAAEiR,EAAI,GAE1DrR,EAAEkiC,IAAM,SAAS7/B,GACf,IAAIyX,EAAImB,KAAKC,MAAM7Y,GACnB,OAAOyX,EAAI3Z,EAAI,EAAI2Z,GAAK1Z,EAAI,GAAK0Z,EAAI3Z,EAAI,GAAKkR,GAEhDrR,EAAEmiC,KAAO,SAAS1nC,GAChB,OAAQA,GAAK,GAAKA,GAAK,EAAK0F,EAAI,EAAI8a,KAAKC,MAAMzgB,EAAE4W,GAAK+wB,KAEjDpiC,GAGT4hC,EAAIzmB,OAAOknB,OAAS,SAAS9U,EAAMQ,GAGjC,IAAIuU,EAFJ/U,EAAOA,GAAQ,EACfQ,EAAQA,GAAS,EAEjB,IAAI/tB,EAAI,WACN,IAAkBuiC,EAAK9iC,EAAnB4C,EAAI,EAAG4D,EAAI,EACf,QAAavF,IAAT4hC,EAGF,OAFAjgC,EAAIigC,EACJA,OAAO5hC,EACA2B,EAET,GAGEkgC,GAFAlgC,EAAkB,EAAd4Y,KAAKE,SAAW,GAEZ9Y,GADR4D,EAAkB,EAAdgV,KAAKE,SAAW,GACNlV,QACC,IAARs8B,GAAaA,EAAM,GAG5B,OAFA9iC,EAAIwb,KAAKnH,MAAM,EAAEmH,KAAKnY,IAAIy/B,GAAKA,GAC/BD,EAAO/U,EAAOtnB,EAAExG,EAAEsuB,EACXR,EAAOlrB,EAAE5C,EAAEsuB,GAwDpB,OAtDA/tB,EAAEgiC,QAAU,SAAShgC,GACnB,OAAO4/B,EAAIE,MAAM9/B,GAAGM,IAAItC,IAE1BA,EAAEiiC,IAAM,SAAS5/B,GACf,IAAImgC,EAAMvnB,KAAKunB,IAAIvnB,KAAKpH,IAAIxR,EAAEkrB,EAAM,KAAO,EAAItS,KAAKpH,IAAIka,EAAO,KAC/D,OAAQ,GAAKA,EAAQ9S,KAAKnH,KAAK,EAAEmH,KAAKwnB,KAAQD,GAEhDxiC,EAAEkiC,IAAM,SAAS7/B,GAGf,IAAIqgC,EACAC,GAAKtgC,EAAIkrB,GAAQQ,EACjB6U,EAAI3nB,KAAK4nB,IAAIF,GACjB,GAAIC,EAAI,GACNF,EAAK,MACA,CACL,IAASF,EAAMvnB,KAAKunB,KAAKI,EAAEA,EAAE,GACzBA,EAAI,kBAONF,EAAKF,QANC,kBAAuBI,EAAI,kBACrBA,EAAI,kBACJA,EAAI,iBACJA,EAAI,kBACJA,EAAI,kBACJA,EAAI,kBAShBF,SAPM,kBAAuBE,EAAI,kBACrBA,EAAI,iBACJA,EAAI,kBACJA,EAAI,kBACJA,EAAI,kBACJA,EAAI,kBACJA,EAAI,kBAQhBF,EAAKF,GADCI,EAAI,GADJA,EAAI,GADJA,EAAI,GADJA,EAAI,GADJA,EAAI,SAKO,eAGrB,OAAOD,EAAI,EAAI,EAAID,EAAKA,GAE1B1iC,EAAEmiC,KAAO,SAAS1nC,GAEhB,GAAIA,GAAK,GAAKA,GAAK,EAAG,OAAO2nC,IAC7B,IAAI//B,EAAI,EAAE5H,EAAI,EACVqf,EAAK,GAAKmB,KAAKwnB,GAAK,IAAO,EAAIxnB,KAAKwnB,IAAM,EAAExnB,KAAKwnB,KACjDtiC,EAAK,GAAK8a,KAAKwnB,GAAG3oB,GAAOmB,KAAKnY,IAAI,EAAImY,KAAKpH,IAAIxR,EAAE,IAAM,EACvDjC,EAAI6a,KAAKnY,IAAI,EAAKT,EAAEA,GAAMyX,EAC1Bxf,GAAK+H,EAAI,EAAI,GAAK,GAAK4Y,KAAKnH,KAAKmH,KAAKnH,KAAM3T,EAAEA,EAAKC,GAAKD,GAC5D,OAAOotB,EAAOQ,EAAQ9S,KAAK6nB,MAAQxoC,GAE9B0F,GAGT4hC,EAAIzmB,OAAO4nB,UAAY,SAAS15B,EAAQ25B,GAGtC,IAAIhZ,EAAM3gB,EAAOoQ,OAAO2mB,GAAKxnB,SACzBX,EAAM+R,EAAI/uB,OACV4B,EAAMmmC,EAASpB,EAAIzmB,OAAOknB,OAAO,EAAGW,GAAU,KAC9ChjC,EAAI,WACN,OAAOgqB,KAAO/O,KAAKE,SAASlD,KAASpb,EAAMA,IAAQ,IAKrD,OAHAmD,EAAEgiC,QAAU,SAAShgC,GACnB,OAAO4/B,EAAIE,MAAM9/B,GAAGM,IAAItC,IAEnBA,sBCpKT,IAAIijC,EAAQvjC,EAAOC,QAqfnB,SAASujC,EAAOrzB,EAAKrL,EAAGxE,GACtB,IAAImjC,EAAQtzB,GAAOA,EAAIuzB,OAAS,EAC5BC,EAAWzB,GAAIzmB,OAAOknB,OAAO,EAAG,GAChCiB,EAAKL,EAAM1V,KAAK/oB,EAAExE,GAClBujC,EAAKN,EAAMlV,MAAMvpB,EAAExE,GAAKib,KAAKnH,KAAKmvB,EAAM5V,MAAMa,MAAM1pB,EAAExE,IAE1D,GAAS,IAALujC,EAEF,OAAQD,EAAKH,GAAW,EAAI,EAAI,EAGlC,IAAIR,GAAKW,EAAKH,GAASI,EACvB,OAAO,EAAIF,EAASnB,KAAKjnB,KAAK4nB,IAAIF,IAIpC,SAASa,EAAO3zB,EAAK1C,EAAQhN,EAAGC,GAC9B,IAIqBpF,EAJjBwJ,EAAIpE,EAAI+M,EAAO7K,IAAI89B,GAAKh+B,EAAEjC,IAAMgN,EAChC1I,EAAIrE,EAAI+M,EAAO7K,IAAI89B,GAAKh+B,EAAEhC,IAAMD,EAChCsjC,EAAKR,EAAM5V,MAAM7oB,GACjBk/B,EAAKT,EAAM5V,MAAM5oB,GACjBk/B,EAAQ7iC,QAEZ,GAAI2iC,IAAOC,EACT,MAAMhmC,MAAM,6BAEd,IAAK1C,EAAE,EAAGA,EAAEyoC,IAAMzoC,EAEZolC,GAAKxnB,QAAQpU,EAAExJ,KAAOolC,GAAKxnB,QAAQnU,EAAEzJ,KACvC2oC,EAAM7lC,KAAK0G,EAAExJ,GAAKyJ,EAAEzJ,IAGxB,OAAOioC,EAAMN,EAAEtJ,KAAKsK,EAAO9zB,GAAOA,EAAIuzB,OAAS,GAIjD,SAASQ,EAAO/zB,EAAK1C,EAAQhN,EAAGC,GAC9B,IAAIoE,EAAIpE,EAAI+M,EAAO7K,IAAI89B,GAAKh+B,EAAEjC,IAAMgN,EAChC1I,EAAIrE,EAAI+M,EAAO7K,IAAI89B,GAAKh+B,EAAEhC,IAAMD,EAChCsjC,EAAKR,EAAM5V,MAAMa,MAAM1pB,GACvBk/B,EAAKT,EAAM5V,MAAMa,MAAMzpB,GACvB4+B,EAAWzB,GAAIzmB,OAAOknB,OAAO,EAAG,GAChCwB,EAAWZ,EAAM1V,KAAK/oB,GAAKy+B,EAAM1V,KAAK9oB,IAAMoL,GAAOA,EAAIuzB,OAAS,GAChEG,EAAKtoB,KAAKnH,KAAKmvB,EAAM9U,SAAS3pB,GAAGi/B,EAAKR,EAAM9U,SAAS1pB,GAAGi/B,GAE5D,GAAS,IAALH,EAEF,OAAkB,IAAXM,EAAe,EAAI,EAG5B,IAAIlB,EAAIkB,EAAWN,EACnB,OAAO,EAAIF,EAASnB,KAAKjnB,KAAK4nB,IAAIF,IApiBpCM,EAAMa,OAAS,SAAS32B,EAAQnN,EAAG+jC,GACjC/jC,EAAIogC,GAAKh+B,EAAEpC,GACX+jC,EAAUA,GAAW,GACrB,IAAYjqB,EAAG9e,EAAGgH,EAAdwV,EAAI,GACR,IAAKxc,EAAE,EAAGgH,EAAEmL,EAAOlS,OAAQD,EAAEgH,IAAKhH,GAChC8e,EAAI9Z,EAAIA,EAAEmN,EAAOnS,IAAMmS,EAAOnS,MACrBwc,IACTA,EAAEsC,GAAK,EACPiqB,EAAQjmC,KAAKgc,IAEf,OAAOiqB,GAITd,EAAM5V,MAAQ,SAASlgB,GACrB,OAAOA,GAAUA,EAAOlS,QAAU,GAIpCgoC,EAAM5V,MAAMa,MAAQ,SAAS/gB,EAAQnN,GACnCA,EAAIogC,GAAKh+B,EAAEpC,GACX,IAAI8Z,EAAG9e,EAAGgH,EAAGksB,EAAQ,EACrB,IAAKlzB,EAAE,EAAGgH,EAAEmL,EAAOlS,OAAQD,EAAEgH,IAAKhH,EAChC8e,EAAI9Z,EAAIA,EAAEmN,EAAOnS,IAAMmS,EAAOnS,GAC1BolC,GAAKxnB,QAAQkB,KAAIoU,GAAS,GAEhC,OAAOA,GAIT+U,EAAM5V,MAAMI,QAAU,SAAStgB,EAAQnN,GACrCA,EAAIogC,GAAKh+B,EAAEpC,GACX,IAAOhF,EAAGgH,EAAGqrB,EAAQ,EACrB,IAAKryB,EAAE,EAAGgH,EAAEmL,EAAOlS,OAAQD,EAAEgH,IAAKhH,EAEvB,OADLgF,EAAIA,EAAEmN,EAAOnS,IAAMmS,EAAOnS,MACfqyB,GAAS,GAE1B,OAAOA,GAKT4V,EAAM5V,MAAMC,SAAW,SAASngB,EAAQnN,GACtCA,EAAIogC,GAAKh+B,EAAEpC,GACX,IAAY8Z,EAAG9e,EAAGgH,EAAdwV,EAAI,GAAa6V,EAAQ,EAC7B,IAAKryB,EAAE,EAAGgH,EAAEmL,EAAOlS,OAAQD,EAAEgH,IAAKhH,GAChC8e,EAAI9Z,EAAIA,EAAEmN,EAAOnS,IAAMmS,EAAOnS,MACrBwc,IACTA,EAAEsC,GAAK,EACPuT,GAAS,GAEX,OAAOA,GAIT4V,EAAM5V,MAAM/qB,IAAM,SAAS6K,EAAQnN,GACjCA,EAAIogC,GAAKh+B,EAAEpC,GACX,IAAc8Z,EAAG9e,EAAGgH,EAAhBM,EAAM,GACV,IAAKtH,EAAE,EAAGgH,EAAEmL,EAAOlS,OAAQD,EAAEgH,IAAKhH,EAEhCsH,EADAwX,EAAI9Z,EAAIA,EAAEmN,EAAOnS,IAAMmS,EAAOnS,IACpB8e,KAAKxX,EAAOA,EAAIwX,GAAK,EAAI,EAErC,OAAOxX,GAIT2gC,EAAMzV,OAAS,SAASrgB,EAAQnN,GAG9B,OAFIA,IAAGmN,EAASA,EAAO7K,IAAI89B,GAAKh+B,EAAEpC,KAClCmN,EAASA,EAAOsM,OAAO2mB,GAAKxnB,SAASzX,KAAKi/B,GAAKrgC,KACxCkjC,EAAM7uB,SAASjH,EAAQ,KAIhC81B,EAAMe,SAAW,SAAS72B,EAAQnN,GAC5BA,IAAGmN,EAASA,EAAO7K,IAAI89B,GAAKh+B,EAAEpC,KAClCmN,EAASA,EAAOsM,OAAO2mB,GAAKxnB,SAASzX,KAAKi/B,GAAKrgC,KAC/C,IAAIgC,EAAIkhC,EAAM7uB,SACd,MAAO,CAACrS,EAAEoL,EAAQ,KAAOpL,EAAEoL,EAAQ,IAAOpL,EAAEoL,EAAQ,OAKtD81B,EAAM7uB,SAAW,SAASjH,EAAQnN,EAAGvF,QACzBiG,IAANjG,IAAmBA,EAAIuF,EAAGA,EAAIogC,GAAK1oB,UACvC1X,EAAIogC,GAAKh+B,EAAEpC,GACX,IAAIikC,GAAK92B,EAAOlS,OAAS,GAAKR,EAAI,EAC9BypC,EAAIjpB,KAAKC,MAAM+oB,GACfnqB,GAAK9Z,EAAEmN,EAAO+2B,EAAI,IAClB3pC,EAAI0pC,EAAIC,EACZ,OAAO3pC,EAAIuf,EAAIvf,GAAKyF,EAAEmN,EAAO+2B,IAAMpqB,GAAKA,GAI1CmpB,EAAMhV,IAAM,SAAS9gB,EAAQnN,GAC3BA,EAAIogC,GAAKh+B,EAAEpC,GACX,IAAK,IAAiC8Z,EAA7BmU,EAAI,EAAGjzB,EAAE,EAAGgH,EAAEmL,EAAOlS,OAAWD,EAAEgH,IAAKhH,EAC9C8e,EAAI9Z,EAAIA,EAAEmN,EAAOnS,IAAMmS,EAAOnS,GAC1BolC,GAAKxnB,QAAQkB,KAAImU,GAAOnU,GAE9B,OAAOmU,GAITgV,EAAM1V,KAAO,SAASpgB,EAAQnN,GAC5BA,EAAIogC,GAAKh+B,EAAEpC,GACX,IAAqBhF,EAAGgH,EAAGvC,EAAGqa,EAA1ByT,EAAO,EACX,IAAKvyB,EAAE,EAAGyE,EAAE,EAAGuC,EAAEmL,EAAOlS,OAAQD,EAAEgH,IAAKhH,EACrC8e,EAAI9Z,EAAIA,EAAEmN,EAAOnS,IAAMmS,EAAOnS,GAC1BolC,GAAKxnB,QAAQkB,KAEfyT,IADQzT,EAAIyT,KACa9tB,GAG7B,OAAO8tB,GAIT0V,EAAM1V,KAAK4W,UAAY,SAASh3B,EAAQnN,GACtCA,EAAIogC,GAAKh+B,EAAEpC,GACX,IAAcP,EAAGuC,EAAG8X,EAAG9e,EAAnBuyB,EAAO,EACX,IAAKvyB,EAAE,EAAGyE,EAAE,EAAGuC,EAAEmL,EAAOlS,OAAQD,EAAEgH,IAAKhH,EAErC,GADA8e,EAAI9Z,EAAIA,EAAEmN,EAAOnS,IAAMmS,EAAOnS,GAC1BolC,GAAKxnB,QAAQkB,GAAI,CACnB,GAAIA,GAAK,EACP,MAAMpc,MAAM,oDAEd6vB,GAAQzT,IACNra,EAIN,OADA8tB,EAAO9tB,EAAI,EAAIwb,KAAKpH,IAAI0Z,EAAM,EAAE9tB,GAAK,GAKvCwjC,EAAM1V,KAAK6W,SAAW,SAASj3B,EAAQnN,GACrCA,EAAIogC,GAAKh+B,EAAEpC,GACX,IAAcP,EAAGuC,EAAG8X,EAAG9e,EAAnBuyB,EAAO,EACX,IAAKvyB,EAAE,EAAGyE,EAAE,EAAGuC,EAAEmL,EAAOlS,OAAQD,EAAEgH,IAAKhH,EACrC8e,EAAI9Z,EAAIA,EAAEmN,EAAOnS,IAAMmS,EAAOnS,GAC1BolC,GAAKxnB,QAAQkB,KACfyT,GAAQ,EAAEzT,IACRra,GAGN,OAAOA,EAAI8tB,GAIb0V,EAAM9U,SAAW,SAAShhB,EAAQnN,GAEhC,GADAA,EAAIogC,GAAKh+B,EAAEpC,IACNogC,GAAKr/B,QAAQoM,IAAWA,EAAOlS,OAAS,EAAG,OAAO,EACvD,IAAsBopC,EAAOrpC,EAAGyE,EAAGqa,EAA/ByT,EAAO,EAAG+W,EAAK,EACnB,IAAKtpC,EAAE,EAAGyE,EAAE,EAAGzE,EAAEmS,EAAOlS,SAAUD,EAChC8e,EAAI9Z,EAAIA,EAAEmN,EAAOnS,IAAMmS,EAAOnS,GAC1BolC,GAAKxnB,QAAQkB,KAGfwqB,IAFAD,EAAQvqB,EAAIyT,IAEOzT,GADnByT,GAAc8W,IAAW5kC,KAK7B,OADA6kC,GAAW7kC,EAAI,GAKjBwjC,EAAMlV,MAAQ,SAAS5gB,EAAQnN,GAC7B,OAAOib,KAAKnH,KAAKmvB,EAAM9U,SAAShhB,EAAQnN,KAI1CijC,EAAMsB,SAAW,SAASp3B,EAAQnN,GAChC,IAAIwkC,EAAMvB,EAAM1V,KAAKpgB,EAAQnN,GACzBykC,EAAMxB,EAAMzV,OAAOrgB,EAAQnN,GAC3B0kC,EAAMzB,EAAMlV,MAAM5gB,EAAQnN,GAC9B,OAAe,IAAR0kC,EAAY,GAAKF,EAAMC,GAAOC,GAIvCzB,EAAM1a,IAAM,SAASpb,EAAQnN,GAC3B,OAAOijC,EAAM1xB,OAAOpE,EAAQnN,GAAG,IAIjCijC,EAAMrnB,IAAM,SAASzO,EAAQnN,GAC3B,OAAOijC,EAAM1xB,OAAOpE,EAAQnN,GAAG,IAIjCijC,EAAM1xB,OAAS,SAASpE,EAAQnN,GAC9BA,EAAIogC,GAAKh+B,EAAEpC,GACX,IAAIG,EAAGC,EAAG0Z,EAAG9e,EAAGgH,EAAImL,EAAOlS,OAC3B,IAAKD,EAAE,EAAGA,EAAEgH,IAAKhH,EAEf,GADA8e,EAAI9Z,EAAIA,EAAEmN,EAAOnS,IAAMmS,EAAOnS,GAC1BolC,GAAKxnB,QAAQkB,GAAI,CAAE3Z,EAAIC,EAAI0Z,EAAG,MAEpC,KAAO9e,EAAEgH,IAAKhH,EACZ8e,EAAI9Z,EAAIA,EAAEmN,EAAOnS,IAAMmS,EAAOnS,GAC1BolC,GAAKxnB,QAAQkB,KACXA,EAAI3Z,IAAGA,EAAI2Z,GACXA,EAAI1Z,IAAGA,EAAI0Z,IAGnB,MAAO,CAAC3Z,EAAGC,IAIb6iC,EAAM1xB,OAAO1T,MAAQ,SAASsP,EAAQnN,GACpCA,EAAIogC,GAAKh+B,EAAEpC,GACX,IAAoBG,EAAGC,EAAG0Z,EAAG9e,EAAzBqH,GAAK,EAAG4D,GAAK,EAAejE,EAAImL,EAAOlS,OAC3C,IAAKD,EAAE,EAAGA,EAAEgH,IAAKhH,EAEf,GADA8e,EAAI9Z,EAAIA,EAAEmN,EAAOnS,IAAMmS,EAAOnS,GAC1BolC,GAAKxnB,QAAQkB,GAAI,CAAE3Z,EAAIC,EAAI0Z,EAAGzX,EAAI4D,EAAIjL,EAAG,MAE/C,KAAOA,EAAEgH,IAAKhH,EACZ8e,EAAI9Z,EAAIA,EAAEmN,EAAOnS,IAAMmS,EAAOnS,GAC1BolC,GAAKxnB,QAAQkB,KACXA,EAAI3Z,IAAKA,EAAI2Z,EAAGzX,EAAIrH,GACpB8e,EAAI1Z,IAAKA,EAAI0Z,EAAG7T,EAAIjL,IAG5B,MAAO,CAACqH,EAAG4D,IAIbg9B,EAAM0B,IAAM,SAASx3B,EAAQhN,EAAGC,GAC9B,IAAapF,EAAG8e,EAAZmU,EAAM,EACV,GAAK7tB,EAWH,IAFAD,EAAIigC,GAAKh+B,EAAEjC,GACXC,EAAIggC,GAAKh+B,EAAEhC,GACNpF,EAAE,EAAGA,EAAEmS,EAAOlS,SAAUD,GAC3B8e,EAAI3Z,EAAEgN,EAAOnS,IAAMoF,EAAE+M,EAAOnS,MAClB8e,IAAGmU,GAAOnU,OAbhB,CACN,GAAI3M,EAAOlS,SAAWkF,EAAElF,OACtB,MAAMyC,MAAM,6BAEd,IAAK1C,EAAE,EAAGA,EAAEmS,EAAOlS,SAAUD,GAC3B8e,EAAI3M,EAAOnS,GAAKmF,EAAEnF,KACR8e,IAAGmU,GAAOnU,GAUxB,OAAOmU,GAKTgV,EAAM2B,KAAO,SAASz3B,EAAQhN,EAAGC,EAAGoiC,GAClC,IAK8BnxB,EAAGrW,EAL7BgF,EAAIogC,GAAK3nB,WAAWrY,IAAMggC,GAAKj+B,SAAS/B,GACxCoE,EAAI2I,EACJ1I,EAAIzE,EAAImN,EAAShN,EACjB5F,EAAIyF,EAAIwiC,EAAMpiC,EACdykC,EAAW,IAANtqC,GAAgB,MAALA,EAChByH,EAAImL,EAAOlS,OAAQX,EAAI,EAK3B,IAJI0F,IACFG,EAAIigC,GAAKh+B,EAAEjC,GACXC,EAAIggC,GAAKh+B,EAAEhC,IAERpF,EAAE,EAAGA,EAAEgH,IAAKhH,EACfqW,EAAIrR,EAAKG,EAAEqE,EAAExJ,IAAIoF,EAAEqE,EAAEzJ,IAAQwJ,EAAExJ,GAAGyJ,EAAEzJ,GACpCV,GAAKuqC,EAAKxzB,EAAEA,EAAI4J,KAAKpH,IAAIoH,KAAK4nB,IAAIxxB,GAAI9W,GAExC,OAAOsqC,EAAK5pB,KAAKnH,KAAKxZ,GAAK2gB,KAAKpH,IAAIvZ,EAAG,EAAEC,IAI3C0oC,EAAM6B,QAAU,SAAS33B,EAAQhN,EAAGC,GAClC,IAAIoE,EAAIpE,EAAI+M,EAAO7K,IAAI89B,GAAKh+B,EAAEjC,IAAMgN,EAChC1I,EAAIrE,EAAI+M,EAAO7K,IAAI89B,GAAKh+B,EAAEhC,IAAMD,EAChC4kC,EAAK9B,EAAM1V,KAAK/oB,GAChB0B,EAAK+8B,EAAM1V,KAAK9oB,GAChBg/B,EAAKR,EAAM5V,MAAMa,MAAM1pB,GACvBk/B,EAAKT,EAAM5V,MAAMa,MAAMzpB,GAE3B,GAAKg/B,EAAGC,EAAG,GAAM,EAEf,OAAO,EAGT,IAAIsB,EAAK/B,EAAM9U,SAAS3pB,GACpBygC,EAAKhC,EAAM9U,SAAS1pB,GACpBnK,EAAI2gB,KAAKnH,OAAQ2vB,EAAG,GAAGuB,GAAQtB,EAAG,GAAGuB,IAAQxB,EAAGC,EAAG,IAEvD,OAAW,IAAJppC,EAAQ,GAAKyqC,EAAK7+B,GAAM5L,GAIjC2oC,EAAMiC,WAAa,SAAS/3B,EAAQhN,EAAGC,GACrC,IAKoBpF,EAAGqH,EAAG4D,EAAGk/B,EAAIC,EAL7B5gC,EAAIpE,EAAI+M,EAAO7K,IAAI89B,GAAKh+B,EAAEjC,IAAMgN,EAChC1I,EAAIrE,EAAI+M,EAAO7K,IAAI89B,GAAKh+B,EAAEhC,IAAMD,EAChC6B,EAAIwC,EAAEvJ,OACNoqC,EAAKpC,EAAM1V,KAAK/oB,GAChB8gC,EAAKrC,EAAM1V,KAAK9oB,GAChBwpB,EAAM,EAAGxuB,EAAI,EAEjB,GAAIuC,IAAMyC,EAAExJ,OACV,MAAMyC,MAAM,6BAGd,IAAK1C,EAAE,EAAGA,EAAEgH,IAAKhH,EAGf,GAFAqH,EAAImC,EAAExJ,GAAImqC,EAAK/E,GAAKxnB,QAAQvW,GAC5B4D,EAAIxB,EAAEzJ,GAAIoqC,EAAKhF,GAAKxnB,QAAQ3S,GACxBk/B,GAAMC,EACRnX,IAAQ5rB,EAAEgjC,IAAOp/B,EAAEq/B,KACjB7lC,OACG,GAAI0lC,GAAMC,EACf,MAAM1nC,MAAM,4BAGhB,OAAOuwB,GAAOxuB,EAAE,IAKlBwjC,EAAMsC,KAAO,SAASp4B,EAAQnN,GAC5BA,EAAIogC,GAAKh+B,EAAEpC,IAAMogC,GAAK1oB,SACtB,IAOsB1c,EAAG8e,EAAGwpB,EAPxBnjC,EAAIgN,EAAO7K,IAAI,SAASwX,EAAG9e,GAC3B,MAAO,CAAC2f,IAAK3f,EAAGgvB,IAAKhqB,EAAE8Z,MAExB3Y,KAAKi/B,GAAKhmB,WAAW,QAEpBpY,EAAImL,EAAOlS,OACXw5B,EAAI3zB,MAAMkB,GACVwjC,GAAO,EAAG/qC,EAAI,GAElB,IAAKO,EAAE,EAAGA,EAAEgH,IAAKhH,EAAG,CAElB,GADA8e,EAAI3Z,EAAEnF,GAAGgvB,IACLwb,EAAM,GAAK/qC,IAAMqf,EACnB0rB,EAAMxqC,EAAI,OACL,GAAIwqC,GAAO,GAAK/qC,IAAMqf,EAAG,CAE9B,IADAwpB,EAAK,GAAKtoC,EAAE,EAAIwqC,GAAO,EAChBA,EAAIxqC,IAAKwqC,EAAK/Q,EAAEt0B,EAAEqlC,GAAK7qB,KAAO2oB,EACrCkC,GAAO,EAET/Q,EAAEt0B,EAAEnF,GAAG2f,KAAO3f,EAAI,EAClBP,EAAIqf,EAGN,GAAI0rB,GAAO,EAET,IADAlC,EAAK,GAAKthC,EAAE,EAAIwjC,GAAO,EAChBA,EAAIxjC,IAAKwjC,EAAK/Q,EAAEt0B,EAAEqlC,GAAK7qB,KAAO2oB,EAGvC,OAAO7O,GAITwO,EAAMwC,IAAM,SAASt4B,EAAQhN,EAAGC,GAC9B,IAAIkB,EAAKlB,EACTA,EAAIkB,EAAK6L,EAAO7K,IAAI89B,GAAKh+B,EAAEhC,IAAMD,EACjCA,EAAImB,EAAK6L,EAAO7K,IAAI89B,GAAKh+B,EAAEjC,IAAMgN,EAEjC,IAAIw3B,EAAM1B,EAAM0B,IAAIxkC,EAAGC,GACnBslC,EAAMzC,EAAM1V,KAAKptB,GACjBwlC,EAAM1C,EAAM1V,KAAKntB,GACjBwlC,EAAM3C,EAAMlV,MAAM5tB,GAClB0lC,EAAM5C,EAAMlV,MAAM3tB,GAClB4B,EAAImL,EAAOlS,OAEf,OAAQ0pC,EAAM3iC,EAAE0jC,EAAIC,KAAS3jC,EAAE,GAAK4jC,EAAMC,IAI5C5C,EAAMwC,IAAIF,KAAO,SAASp4B,EAAQhN,EAAGC,GACnC,IAEuBpF,EAAGV,EAAG+W,EAFzBy0B,EAAK1lC,EAAI6iC,EAAMsC,KAAKp4B,EAAQhN,GAAK8iC,EAAMsC,KAAKp4B,GAC5C44B,EAAK3lC,EAAI6iC,EAAMsC,KAAKp4B,EAAQ/M,GAAK6iC,EAAMsC,KAAKplC,GAC5C6B,EAAImL,EAAOlS,OAEf,IAAKD,EAAE,EAAGV,EAAE,EAAGU,EAAEgH,IAAKhH,EAEpBV,IADA+W,EAAIy0B,EAAG9qC,GAAK+qC,EAAG/qC,IACNqW,EAGX,OAAO,EAAI,EAAE/W,GAAK0H,GAAKA,EAAEA,EAAE,KAK7BihC,EAAMwC,IAAIb,KAAO,SAASz3B,EAAQhN,EAAGC,GACnC,IAMIpF,EAAGgrC,EAAIC,EAAIC,EANX1hC,EAAIpE,EAAI+M,EAAO7K,IAAI89B,GAAKh+B,EAAEjC,IAAMgN,EAChC1I,EAAIrE,EAAI+M,EAAO7K,IAAI89B,GAAKh+B,EAAEhC,IAAMD,EAEhCgmC,EAAIlD,EAAM2B,KAAKwB,IAAI5hC,GACnB6hC,EAAIpD,EAAM2B,KAAKwB,IAAI3hC,GACnBzC,EAAImkC,EAAElrC,OAGV,IAAKD,EAAE,EAAGgrC,EAAG,EAAGC,EAAG,EAAGC,EAAG,EAAGlrC,EAAEgH,IAAKhH,EACjCgrC,GAAMG,EAAEnrC,GAAGmrC,EAAEnrC,GACbirC,GAAMI,EAAErrC,GAAGqrC,EAAErrC,GACbkrC,GAAMC,EAAEnrC,GAAGqrC,EAAErrC,GAGf,OAAOigB,KAAKnH,KAAKoyB,EAAKjrB,KAAKnH,KAAKkyB,EAAGC,KAMrChD,EAAMqD,iBAAmB,SAASn5B,EAAQhN,EAAGC,GAC3C,IASImmC,EAAKvrC,EATLwJ,EAAIpE,EAAI+M,EAAO7K,IAAI89B,GAAKh+B,EAAEjC,IAAMgN,EAChC1I,EAAIrE,EAAI+M,EAAO7K,IAAI89B,GAAKh+B,EAAEhC,IAAMD,EAChC6B,EAAIwC,EAAEvJ,OACNurC,EAAKvD,EAAMiC,WAAW1gC,EAAGC,GACzBgiC,EAAKxD,EAAMlV,MAAMvpB,GACjBkiC,EAAKzD,EAAMlV,MAAMtpB,GACjBkiC,EAAQH,GAAMC,EAAGA,GACjBG,EAAQ3D,EAAM1V,KAAK9oB,GAAKkiC,EAAQ1D,EAAM1V,KAAK/oB,GAC3CqiC,EAAM,CAACF,MAAOA,EAAOG,UAAWF,EAAOG,EAAGP,GAAMC,EAAGC,GAAKM,IAAK,GAGjE,IAAKhsC,EAAE,EAAGA,EAAEgH,IAAKhH,EACXolC,GAAKxnB,QAAQpU,EAAExJ,KAAOolC,GAAKxnB,QAAQnU,EAAEzJ,MACvCurC,EAAOI,EAAMniC,EAAExJ,GAAK4rC,EAASniC,EAAEzJ,GAC/B6rC,EAAIG,KAAOT,EAAMA,GAIrB,OAAOM,GAIT5D,EAAMF,UAAY,GAKlBE,EAAMF,UAAUkE,GAAK,SAAS95B,EAAQhN,EAAGC,EAAGX,EAAG4R,GAC7C,IAAI7M,EAAG0iC,EAAGC,EAAOnE,EAAQoE,EAAIC,EAAOrsC,EAgBpC,IAfIolC,GAAK3nB,WAAWtY,IAAMigC,GAAKj+B,SAAShC,IACtCqE,EAAI2I,EAAO7K,IAAI89B,GAAKh+B,EAAEjC,IACtB+mC,EAAI9mC,EACJ+mC,EAAQ1nC,EACRujC,EAAS3xB,IAET7M,EAAI2I,EACJ+5B,EAAI/mC,EACJgnC,EAAQ/mC,EACR4iC,EAASvjC,GAEXynC,EAAIA,GAAKA,EAAI,IACbC,EAAQA,GAAS,IAEjBC,EAAKxF,GAAIzmB,OAAO4nB,UAAUv+B,EAAGw+B,GACxBhoC,EAAE,EAAGqsC,EAAQvmC,MAAMomC,GAAIlsC,EAAEksC,IAAKlsC,EACjCqsC,EAAMrsC,GAAKioC,EAAM1V,KAAK6Z,EAAGpF,QAAQx9B,EAAEvJ,SAGrC,OADAosC,EAAMlmC,KAAKi/B,GAAK9lB,QACT,CACL2oB,EAAM7uB,SAASizB,EAAOF,EAAM,GAC5BlE,EAAM7uB,SAASizB,EAAO,EAAGF,EAAM,KAKnClE,EAAMN,EAAI,GAIVM,EAAMN,EAAEsE,GAAK,SAAS95B,EAAQhN,EAAGC,GAC/B,IAAIoE,EAAI2I,EAAQg6B,EAAQhnC,GACpBigC,GAAK3nB,WAAWtY,IAAMigC,GAAKj+B,SAAShC,MACtCqE,EAAI2I,EAAO7K,IAAI89B,GAAKh+B,EAAEjC,IACtBgnC,EAAQ/mC,GAIV,IAAIuiC,EAAY,OAFhBwE,EAAQA,GAAS,KAEM,KAAOvF,GAAIzmB,OAAOknB,OAAO,EAAG,GAAGF,KAAK,EAAGgF,EAAM,GAChE7D,EAAKL,EAAM1V,KAAK/oB,GAChB++B,EAAKN,EAAMlV,MAAMvpB,GAAKyW,KAAKnH,KAAKmvB,EAAM5V,MAAMa,MAAM1pB,IACtD,MAAO,CAAC8+B,EAAMX,EAAEY,EAAKD,EAAMX,EAAEY,IAW/BN,EAAMN,EAAEtJ,KAAO,SAASlsB,EAAQhN,EAAGC,EAAGyP,GACpC,OAAIuwB,GAAK3nB,WAAWrY,IAAMggC,GAAKj+B,SAAS/B,IAC9ByP,GAAOA,EAAIy3B,OAAS9D,EAASI,GAAQ/zB,EAAK1C,EAAQhN,EAAGC,GACpDggC,GAAKr/B,QAAQZ,IACdC,GAAKA,EAAEknC,OAAS9D,EAASI,GAAQxjC,EAAG+M,EAAQhN,GAC3CigC,GAAK3nB,WAAWtY,IAAMigC,GAAKj+B,SAAShC,GACtC+iC,EAAO9iC,EAAG+M,EAAQhN,GAElB+iC,EAAO/iC,EAAGgN,IA8DrB81B,EAAM2B,KAAKwB,IAAM,SAAS5hC,GACxB,IAIWsV,EAAG9e,EAAG6G,EAJbG,EAAIwC,EAAEvJ,OACN+f,EAAIhZ,EAAEA,EACNmkC,EAAIrlC,MAAMka,GACV+rB,EAAInF,GAAIE,MAAM9/B,GACdulC,EAAI,EAER,IAAKvsC,EAAE,EAAGA,EAAEgH,IAAKhH,EAEf,IADAmrC,EAAEnrC,EAAEgH,EAAEhH,GAAK,EACN6G,EAAE7G,EAAE,EAAG6G,EAAEG,IAAKH,EACjBskC,EAAEnrC,EAAEgH,EAAEH,GAAMiY,EAAImB,KAAK4nB,IAAIr+B,EAAExJ,GAAKwJ,EAAE3C,IAClCskC,EAAEtkC,EAAEG,EAAEhH,GAAK8e,EACXitB,EAAE/rC,IAAM8e,EACRitB,EAAEllC,IAAMiY,EAIZ,IAAK9e,EAAE,EAAGA,EAAEgH,IAAKhH,EACfusC,GAAKR,EAAE/rC,GACP+rC,EAAE/rC,IAAMgH,EAIV,IAFAulC,GAAKvsB,EAEAhgB,EAAE,EAAGA,EAAEgH,IAAKhH,EACf,IAAK6G,EAAE7G,EAAG6G,EAAEG,IAAKH,EACfskC,EAAEnrC,EAAEgH,EAAEH,IAAM0lC,EAAIR,EAAE/rC,GAAK+rC,EAAEllC,GACzBskC,EAAEtkC,EAAEG,EAAEhH,GAAKmrC,EAAEnrC,EAAEgH,EAAEH,GAIrB,OAAOskC,GAITlD,EAAMuE,QAAU,SAASC,EAAQznC,GAC/BA,EAAIogC,GAAKh+B,EAAEpC,GACX,IAAIhF,EAAGP,EAAGH,EAAI,EAAG2pC,EAAI,EAAGjiC,EAAIylC,EAAOxsC,OACnC,IAAKD,EAAE,EAAGA,EAAEgH,IAAKhH,EACfV,GAAM0F,EAAIA,EAAEynC,EAAOzsC,IAAMysC,EAAOzsC,GAElC,GAAU,IAANV,EAAS,OAAO,EACpB,IAAKU,EAAE,EAAGA,EAAEgH,IAAKhH,GACfP,GAAKuF,EAAIA,EAAEynC,EAAOzsC,IAAMysC,EAAOzsC,IAAMV,KAC9B2pC,GAAKxpC,EAAIwgB,KAAKnY,IAAIrI,IAE3B,OAAQwpC,EAAIhpB,KAAKysB,KAOnBzE,EAAM0E,OAAS,SAASx6B,EAAQhN,EAAGC,EAAGqnC,GACpC,IAOyBhtC,EAAGD,EAAGQ,EAP3BqH,EAAIolC,EAASt6B,EAAO7K,IAAI89B,GAAKh+B,EAAEjC,IAAMgN,EACrClH,EAAIwhC,EAASt6B,EAAO7K,IAAI89B,GAAKh+B,EAAEhC,IAAMD,EACrCwiC,EAAI8E,EAASt6B,EAAO7K,IAAI89B,GAAKh+B,EAAEqlC,IAAWrnC,EAE1CwnC,EAAK,GACLC,EAAK,GACL7lC,EAAI2gC,EAAE1nC,OACNX,EAAI,EAAGwtC,EAAI,EAAG7D,EAAI,EAEtB,IAAKjpC,EAAE,EAAGA,EAAEgH,IAAKhH,EACf4sC,EAAGvlC,EAAErH,IAAM,EACX6sC,EAAG5hC,EAAEjL,IAAM,EAGb,IAAKA,EAAE,EAAGA,EAAEgH,IAAKhH,EACf4sC,EAAGvlC,EAAErH,KAAO2nC,EAAE3nC,GACd6sC,EAAG5hC,EAAEjL,KAAO2nC,EAAE3nC,GACdV,GAAKqoC,EAAE3nC,GAIT,IADAR,EAAI,GAAKF,EAAI2gB,KAAKysB,KACb1sC,EAAE,EAAGA,EAAEgH,IAAKhH,EACF,IAAT2nC,EAAE3nC,KACNP,EAAKH,EAAIqoC,EAAE3nC,IAAO4sC,EAAGvlC,EAAErH,IAAM6sC,EAAG5hC,EAAEjL,KAClC8sC,GAAKnF,EAAE3nC,GAAKR,EAAIygB,KAAKnY,IAAIrI,GACzBwpC,GAAKtB,EAAE3nC,GAAKR,EAAIygB,KAAKnY,IAAI6/B,EAAE3nC,GAAGV,IAGhC,MAAO,CAACwtC,EAAG,EAAIA,EAAE7D,IAInBhB,EAAM0E,OAAO/1B,KAAO,SAASzE,EAAQhN,EAAGC,EAAGqnC,GACzC,OAAOxE,EAAM0E,OAAOx6B,EAAQhN,EAAGC,EAAGqnC,GAAQ,IAK5CxE,EAAM0E,OAAO/C,KAAO,SAASz3B,EAAQhN,EAAGC,EAAGqnC,GACzC,OAAOxE,EAAM0E,OAAOx6B,EAAQhN,EAAGC,EAAGqnC,GAAQ,IAI5CxE,EAAM8E,QAAU,SAAS56B,EAAQnN,GAC/B,IAQYqkC,EAAO2D,EAAIhtC,EAAG8e,EAAGzX,EARzBkrB,EAAO,EACPW,EAAQ,EACRT,EAAU,EACVH,EAAW,EACX/E,EAAM,KACN3M,EAAM,KACN0oB,EAAK,EACLnsB,EAAO,GACPX,EAAI,GAGR,IAAKxc,EAAE,EAAGA,EAAEmS,EAAOlS,SAAUD,EAI3Bwc,EAHAsC,EAAI9Z,EAAIA,EAAEmN,EAAOnS,IAAMmS,EAAOnS,IAGtB8e,KAAKtC,EAAKA,EAAEsC,GAAK,GAAKwT,GAAY,EAAG,GAEpC,MAALxT,IACA2T,EACO2S,GAAKxnB,QAAQkB,KAEtBzX,EAAkB,iBAANyX,EAAkBA,EAAE7e,OAAS6e,GAC/B,OAANyO,GAAclmB,EAAIkmB,KAAKA,EAAMlmB,IACvB,OAANuZ,GAAcvZ,EAAIuZ,KAAKA,EAAMvZ,GAGjCiiC,IAFAD,EAAQhiC,EAAIkrB,IAEOlrB,GADnBkrB,GAAc8W,IAAWnW,IAEzB/V,EAAKra,KAAKuE,IASd,OANAiiC,GAAWpW,EAAQ,EACnB8Z,EAAK/sB,KAAKnH,KAAKwwB,GAGfnsB,EAAKhX,KAAKi/B,GAAKrgC,KAER,CACL1E,KAAUA,GAAK8R,EAAQnN,GACvB8jC,OAAUtsB,EACV6V,MAAUlgB,EAAOlS,OACjBizB,MAAUA,EACVT,QAAUA,EACVH,SAAUA,EACV/E,IAAUA,EACV3M,IAAUA,EACV2R,KAAUA,EACVQ,MAAUia,EACVxa,OAAW1T,EAAImpB,EAAM7uB,SAAS+D,EAAM,IACpCuV,GAAUuV,EAAM7uB,SAAS+D,EAAM,KAC/BwV,GAAUsV,EAAM7uB,SAAS+D,EAAM,KAC/BosB,SAAiB,IAAPyD,EAAW,GAAKza,EAAOzT,GAAKkuB,IAK1C/E,EAAMgF,QAAU,SAASpoC,EAAM0B,GAE7B,IAAIjH,GADJiH,EAASA,GAAU6+B,GAAKl/B,KAAKrB,EAAK,KACnByC,IAAI,SAAStC,GAC1B,IAAIvF,EAAIwoC,EAAM8E,QAAQloC,EAAMugC,GAAKh+B,EAAEpC,IACnC,OAAQvF,EAAEgI,MAAQzC,EAAGvF,IAEvB,OAAQH,EAAE4tC,aAAc,EAAM5tC,aClsBhC,MAAM6tC,GAAQC,GAwKd,MAAMnhC,GAAQ,CACZmL,QAAS,EACTpU,IAAK,EACLkU,QAAS,EACTC,SAAU,EACVF,aAAc,GAGhB,MAAao2B,GAIXhX,YAAYiX,GACV1kC,KAAK2kC,aAAeD,EAEpBA,EAAY/mC,OAAOJ,KAAK,SAAShB,EAAgBC,GAE/C,OAAI6G,GAAM9G,EAAEqoC,QAAUvhC,GAAM7G,EAAEooC,SACpB,EACCvhC,GAAM9G,EAAEqoC,QAAUvhC,GAAM7G,EAAEooC,QAC5B,EAGAroC,EAAEqB,KAAKo0B,cAAcx1B,EAAEoB,QAKlC8mC,EAAY/mC,OAAOxD,QAAQ,CAACs6B,EAAax6B,IAAWw6B,EAAYx6B,MAAQA,GAExE+F,KAAK6kC,kBAAoBH,EAAY/mC,OAAO+W,OAAO,CAAC0C,EAAGqd,KACrDrd,EAAEqd,EAAY72B,MAAQ62B,EACfrd,GACN,IAIEqW,aACL,OAAOztB,KAAK2kC,aAAahnC,OAAOe,IAAI+1B,GAAeA,EAAY72B,MAIjEknC,mBACE,OAAO9kC,KAAK2kC,aAAahnC,OAGpB8vB,YAAY+P,GACjB,OAAOx9B,KAAK6kC,kBAAkBrH,GAGzB/P,cAIL,MAAMiX,EAAczwB,GAAUjU,KAAK2kC,cAEnC,OADAD,EAAY/mC,OAAOJ,KAAK,CAAChB,EAAGC,IAAMD,EAAEwoC,cAAgBvoC,EAAEuoC,eAC/CL,EAMFjX,cAAc+P,GACnB,OAAOx9B,KAAK6kC,kBAAkBrH,GAAax9B,KAAK6kC,kBAAkBrH,GAAW/lC,KAAO,KAM/Eg2B,OAAO+P,GACZ,OAAOx9B,KAAK6kC,kBAAkBrH,GAAax9B,KAAK6kC,kBAAkBrH,GAAWoH,OAAS,KAMjFnX,YAAYoE,EAAoBmT,GAAiC,EAAMC,GAA0B,GACtG,MAAMxQ,EAAcz0B,KAAK6kC,kBAAkBhT,EAAOhzB,OAClD,GAAIgzB,EAAOvlB,WAAcslB,GAAiBC,IAAWA,EAAOjZ,UAC1D,OAAO,EACF,GAAIiZ,EAAOhZ,IAAK,CAErB,IAAIA,EAaJ,MAAM6L,GAVJ7L,EAFwB,kBAAfgZ,EAAOhZ,IAEV,CACJ6L,QAASqG,GAAY8G,EAAOluB,UAEN,MAAfkuB,EAAOhZ,IACV,CACJ+K,KAAM,EAAC,GAAM,IAGTiO,EAAOhZ,KAEU6L,QAMzB,OALK+P,EAAYyQ,SAASxgB,KAExB+P,EAAYyQ,SAASxgB,GAAWygB,GAAWzgB,EAAS+P,EAAY4K,QAG3D5K,EAAYyQ,SAASxgB,GAASgF,SAChC,GAAImI,EAAO/Y,SAAU,CAC1B,GAAIksB,EACF,OAAQnT,EAAO/Y,UAEb,KAAKwD,GAASO,QAEd,KAAKP,GAASM,QACZ,OAAO,GACT,KAAKN,GAASK,MACZ,OAAO,GACT,KAAKL,GAASG,IACZ,OAAO,EACT,KAAKH,GAASI,KACZ,OAAO,GACT,KAAKJ,GAASE,MACZ,OAAO,GACT,KAAKF,GAASoB,QACZ,OAAO,EACT,KAAKpB,GAASQ,aACZ,OAAO,IAGb,IAAI8F,EAAOiP,EAAO/Y,SACdssB,EAAY3Q,EAAY2Q,UAS5B,OAPKA,GAAcA,EAAUxiB,KAC3BwiB,EAAStuC,OAAAsL,OAAA,GACJgjC,EAAS,CACZ3X,CAAC7K,GAAOyiB,GAAYxT,EAAO/Y,SAAsB2b,EAAY4K,UAI7D4F,EACKG,EAAUxiB,GAAM8G,SAAW4b,GAAaF,EAAUxiB,GAAMsd,OAAQ,CAAC,eAAgB,OAEjFkF,EAAUxiB,GAAM8G,SAGzB,OAAI+K,EACEwQ,EACKxQ,EAAY4K,MAAM3V,SAAW4b,GAAa7Q,EAAY4K,MAAMa,OAAQ,CAAC1B,IAAK,OAE1E/J,EAAY4K,MAAM3V,SAGpB,KAaN+D,qBAAqBoE,GAC1B,IAAKA,EAAO/Y,SACV,OAIF,GAAI+Y,EAAO/Y,WAAawD,GAASG,IAAK,CACpC,MAAM8oB,EAA0BnxB,GAAO,GAAIyd,EAAQ,CAAC/Y,SAAUwD,GAASI,OACvE,GAAI1c,KAAKwlC,YAAYD,GAAU,GAAO,IAAS,EAC7C,OAAO,EAIX,IAAI/3B,EAAeqkB,EAAO/Y,SAC1B,IAAK,IAAIiK,KAAgBjD,GACvB,GAAIkD,GAAiBxV,EAA0BuV,GAAe,CAE5D,MAAM0iB,EAAiBrxB,GAAO,GAAIyd,EAAQ,CAAC/Y,SAAUiK,IACrD,GAAI/iB,KAAKwlC,YAAYC,GAAgB,GAAO,IAAS,EACnD,OAAO,EAIb,OAAO,EAGFhY,OAAOiY,GAEZ,MAAMjR,EAAcz0B,KAAK6kC,kBAAkBa,EAAgB7mC,OAC3D,IAAI4G,EAAgBnI,GAAKm3B,EAAY4K,MAAMa,QAC3C,OAAIzL,EAAYmQ,SAAW5xB,GAElB,EAAEyhB,EAAY4K,MAAM1a,KAAM8P,EAAY4K,MAAMrnB,KAC1Cyc,EAAYh9B,OAASkuC,GAAcC,SAErC,CAACnR,EAAY4K,MAAM1a,IAAK8P,EAAY4K,MAAMrnB,KACxCyc,EAAYh9B,OAASkuC,GAAcE,SAAWpR,EAAYh9B,OAASkuC,GAAcG,QAE1FrgC,EAASA,EAAO/G,IAAID,IAAMA,IACZlB,KAAKpB,IACVs4B,EAAYmQ,SAAW/xB,IAAgB4hB,EAAYD,cACrDC,EAAYD,cAGd/uB,EACJ/G,IAAID,GAGU,SAANA,EAAe,KAAOA,GAE9BlB,KAAKpB,IAMHsxB,MAAMoE,GAEX,MAAM4C,EAAcz0B,KAAK6kC,kBAAkBhT,EAAOhzB,OAClD,OAAO41B,EAAcA,EAAY4K,MAAQ,MAO7C,SAAS8F,GAAWzgB,EAAiB2f,GACnC,MAAMxrB,EAAM0rB,GAAM,CAChB5f,IAAK0f,EAAQ1f,IACb3M,IAAKqsB,EAAQrsB,IACb0M,QAASA,IAIL5B,EAAS1O,GAAO,GAAIiwB,GAM1B,OALAvhB,EAAOod,OAuCT,SAAmBrnB,EAAUktB,GAC3B,MAAMC,EAAY,GAClB,IAAK,IAAIhtC,KAAS+sC,EAAW,CAC3B,IAAIE,EAEFA,EADY,OAAVjtC,EACO,KACAskC,MAAM4I,OAAOltC,IACbwlC,IAEA3lB,EAAI7f,MAAMktC,OAAOltC,IAE5BgtC,EAAUC,IAAWD,EAAUC,IAAW,GAAKF,EAAU/sC,GAE3D,OAAOgtC,EApDSG,CAAUttB,EAAKwrB,EAAQnE,QACvCpd,EAAO4G,UAAY7Q,EAAI2c,KAAO3c,EAAI0c,OAAS1c,EAAI+L,KAC/C9B,EAAO6B,IAAM9L,EAAI0c,MACjBzS,EAAO9K,IAAMa,EAAI2c,KAEV1S,EAMT,SAASuiB,GAAYe,EAAoB/B,GACvC,MAAMvhB,EAAS1O,GAAO,GAAIiwB,GAE1B,IAAInE,EAAoC,GAmBxC,OAlBA5iC,GAAK+mC,EAAQnE,QAAQ/lC,QAAQ,SAASksC,GAEpC,IAEIjsC,EAFA+a,EAA4B,SAAfkxB,EAAwB,KAAO,IAAI5sC,KAAK4sC,GAIvDjsC,EADW,OAAT+a,EACI,KACGmoB,MAAMnoB,EAAKzb,WACd,gBAEC0sC,IAAa9pB,GAASG,IAAMtH,EAAKwhB,SAAWhU,GAAQyjB,EAAUjxB,IAAO7Z,WAE9E4kC,EAAO9lC,IAAQ8lC,EAAO9lC,IAAQ,GAAKiqC,EAAQnE,OAAOmG,KAGpDvjB,EAAOod,OAASA,EAChBpd,EAAO4G,SAAWpsB,GAAK4iC,GAAQ7oC,OAExByrB,EAuBT,SAASwiB,GAAapF,EAAYzrB,GAChC,OAAOA,EAAKC,OAAO,SAAS4xB,EAAMC,GAChC,OAAOrG,EAAOqG,GAAOD,EAAO,EAAIA,GAC/B,GAGL,IAAYX,IAAZ,SAAYA,GACVA,EAAAA,EAAA,OAAS,UAAe,SACxBA,EAAAA,EAAA,OAAS,UAAe,SACxBA,EAAAA,EAAA,QAAU,WAAgB,UAC1BA,EAAAA,EAAA,QAAU,WAAgB,UAC1BA,EAAAA,EAAA,SAAW,YAAiB,WAL9B,CAAYA,KAAAA,GAAa,iCA/YzB,SACE1pC,EACAgQ,EAAmB,GACnBy4B,EAAuD,CAAC/mC,OAAQ,KAEhEsO,EAAMmI,GAAO,GAAIiS,GAAsBpa,GAGvC,IAAIu6B,EAA8BnC,GAAQpoC,GACtCyhC,EAAQG,GAAS5hC,GAEjBwqC,EAAwB/B,EAAY/mC,OAAO+W,OAAO,CAAC0C,EAAGvY,KACxDuY,EAAEvY,EAAMjB,MAAQiB,EACTuY,GACN,IAEC0tB,EAA8B0B,EAAU9nC,IAAI,SAASgoC,EAAczsC,GACrE,MAAM2D,EAAe8oC,EAAa7nC,MAE5BpH,EAAsC,SAAhBimC,EAAM9/B,GAAmB+nC,GAAcC,SAAYlI,EAAM9/B,GACrF,IACIgnC,EADAlb,EAAmBgd,EAAahd,SAGpC,GAAIjyB,IAASkuC,GAAcG,OACzBlB,EAAS5xB,QACJ,GAAIvb,IAASkuC,GAAcE,QAG9BjB,EADElb,EAAWzd,EAAI0a,oBAAsB+C,EAAWgd,EAAajd,MAAQxd,EAAIya,wBAClE5T,GAEAE,QAEN,GAAIvb,IAASkuC,GAAcC,SAAU,CAC1ChB,EAAS7xB,GAGT2zB,EAAa/hB,IAAM,IAAIlrB,KAAKwC,EAAK,GAAG2B,IACpC8oC,EAAa1uB,IAAM,IAAIve,KAAKwC,EAAK,GAAG2B,IACpC,IAAK,MAAM+oC,KAAa1qC,EAAM,CAC5B,MAAMmU,EAAO,IAAI3W,KAAKktC,EAAU/oC,IAAOlE,UACnC0W,EAAQs2B,EAAa/hB,IAAajrB,YACpCgtC,EAAa/hB,IAAM,IAAIlrB,KAAK2W,IAE1BA,EAAQs2B,EAAa1uB,IAAate,YACpCgtC,EAAa1uB,IAAM,IAAIve,KAAK2W,UAIhCw0B,EAAS9xB,GAIT8xB,IAAW9xB,IACX4W,EAAWgd,EAAajd,MAAQxd,EAAIgd,wBACpCyd,EAAajd,MAAQxd,EAAIid,uBAEzB0b,EAAS7X,GAAa/qB,KAGxB,IAAIyyB,EAAc,CAChB72B,KAAMA,EAENmnC,cAAe9qC,EACf2qC,OAAQA,EACRntC,KAAMA,EACN4nC,MAAOqH,EACPtB,UAAW,GACXF,SAAU,IAIZ,MAAM0B,EAAiBH,EAAsBhS,EAAY72B,MAGzD,OAFA62B,EAAcrgB,GAAOqgB,EAAamS,KAMpC,IAAK,IAAInS,KAAeqQ,EACtB,GAAIrQ,EAAYmQ,SAAW5xB,GACzB,IAAK,IAAI0R,KAAWzY,EAAI2X,KAAKa,SAASC,QACpC+P,EAAYyQ,SAASxgB,GAAWygB,GAAWzgB,EAAS+P,EAAY4K,YAE7D,GAAI5K,EAAYmQ,SAAW7xB,GAChC,IAAK,IAAI6P,KAAQ3W,EAAI2X,KAAK9K,cACXhc,IAAT8lB,IACF6R,EAAY2Q,UAAUxiB,GAAQyiB,GAAYziB,EAAM6R,EAAY4K,QAMpE,MAAMwH,EAAkB/vC,OAAAsL,OAAA,GACnBsiC,EAAW,CACd/mC,OAAQmnC,IAGV,OAAO,IAAIL,GAAOoC,+CC/IpB,MAAaC,GAGXrZ,YAAYsZ,GACV/mC,KAAK+mC,WAAaA,EAGbtZ,OACL,OAAOztB,KAAK+mC,WAAWnpC,KAGlB6vB,cACL,OAAOztB,KAAK+mC,WAAWC,YAGlBvZ,aACL,OAAOztB,KAAK+mC,WAAWE,WAGlBxZ,SACL,OAAOztB,KAAK+mC,WAAWG,QAa3B,MAAaC,WAA6DL,GACxErZ,YAAYsZ,GACVK,MAAML,GAGDtZ,iCAAiCiC,GACtC,OAAOvX,GAAMnY,KAAK+mC,WAAWE,WAAaj6B,IAExC,GAAI0L,GAAqB1L,GAAO,CAC9B,IAAI/U,EAAS+U,EAAK/U,OACdU,EAAQqU,EAAKrU,MAEjB,OAAK+2B,EAAKz3B,KAIFwrB,GAAWiM,EAAKz3B,GAAQU,IAGlC,OAAK+2B,EAAK1iB,KAIFyW,GAAWiM,EAAK1iB,MAIrBygB,QAAQiC,EAASxJ,EAAgBmhB,EAA4Cp7B,GAElF,OAAKjM,KAAK+mC,WAAWO,6BAGdtnC,KAAKunC,iCAAiC7X,IAIrC1vB,KAAK+mC,WAAqCS,QAAQ9X,EAAMxJ,EAAQmhB,EAAkBp7B,IC/EvF,MAAMw7B,GAA2D,CACtE,CACE7pC,KAAM,6BACNopC,YAAa,uDACbC,WAAY,CAACzsB,GAASY,KAAMZ,GAASM,WACrCwsB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC3V,EAAoB/5B,EAAW4vC,EAA8BC,KACjE9V,EAAOvlB,YACDggB,GAAWuF,EAAOp6B,OAMhC,CACEmG,KAAM,6BACNopC,YAAa,0DACbC,WAAY,CAACzsB,GAASW,MAAOX,GAASM,WACtCwsB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC3V,EAAoB/5B,EAAW4vC,EAA8BC,IAC5C,MAAjB9V,EAAOhzB,QAAyC,UAArBgzB,EAAOvlB,YAG9C,CACE1O,KAAM,uBACNopC,YAAa,gEACbC,WAAY,CAACzsB,GAASQ,IAAKR,GAASW,MAAOX,GAASY,MACpDksB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC3V,EAAoB3L,EAAgBpuB,EAA6BmU,KACzE,GAAI4lB,EAAOhZ,KAAOgZ,EAAOp6B,OAASub,GAAmB,CAEnD,IAAI40B,EAA+B,CACjCjkC,QAASkuB,EAAOluB,QAChB9E,MAAOgzB,EAAOhzB,MACdpH,KAAMo6B,EAAOp6B,MAEf,OAAOyuB,EAAOsf,YAAYoC,IAAqB37B,EAAIkc,qBAErD,OAAO,IAGX,CACEvqB,KAAM,4BACNopC,YAAa,oDACbC,WAAY,CAACzsB,GAASY,KAAMZ,GAASQ,KACrCssB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC3V,EAAoB/5B,EAAW4vC,EAA8BC,KACjE9V,EAAOhZ,KAEFgZ,EAAOp6B,OAASub,IAK7B,CACEpV,KAAM,yBACNopC,YAAa,iEACbC,WAAY,CAACzsB,GAASK,QAASL,GAASY,KAAMZ,GAASQ,IAAKR,GAASU,UACrEosB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC3V,EAAoB3L,EAAgBmhB,EAA4Cp7B,KACxF,MAAMO,EAAQ1V,OAAAsL,OAAA,CACZvD,MAAO,KACJy1B,GAAWzC,EAAQ,CAAC3L,OAAAA,EAAQ6L,MAAO,CAAC,MAAO,WAAY,YAGtDpF,WAACA,GAAcC,GAAqBpgB,EAAUqlB,EAAOluB,SAE3D,GAAIgpB,EACF,OAAO,EAKP,QAFmC,QAAnBkF,EAAOluB,SAAwC,WAAnBkuB,EAAOluB,UAEnCoc,GAAsBvT,EAASsM,YAAa4H,GAAoBlU,EAASsM,aAO/F,CACElb,KAAM,QACNopC,YAAa,6EACbC,WAAY,CAACzsB,GAASM,UAAWN,GAASQ,IAAKR,GAASU,UACxDosB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC3V,EAAoB/5B,EAAW4vC,EAA8BC,KACjE9V,EAAO9Y,UACA8Y,EAAOvlB,aAAeulB,EAAOhZ,OAASgZ,EAAO/Y,WAK5D,CACElb,KAAM,+BACNopC,YAAa,0CACbC,WAAY,CAACzsB,GAASc,MAAOlB,GAAsB,QAAS,QAASI,GAASQ,KAC9EssB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC3V,EAAoB/5B,EAAW4vC,EAA8BC,KACjE9V,EAAOhZ,MAAOgZ,EAAOhoB,QACmB,IAArCgoB,EAAOhoB,MAAqBkI,MAOvC,CACEnU,KAAM,wBACNopC,YAAa,wFACbC,WAAY,CAACzsB,GAASM,UAAWN,GAASO,UAAWP,GAASU,SAAUV,GAASQ,KACjFssB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC3V,EAAqC/5B,EAAW4vC,EAA8BC,KACtF,GAAIhY,GAAakC,GAAS,CAKxB,QAHIpO,GAAWoO,EAAOvlB,YAAgBulB,EAAOvlB,UAAY,EAAI,KACzDmX,GAAWoO,EAAOhZ,MAAUgZ,EAAOhZ,IAAM,EAAI,KAC7C4K,GAAWoO,EAAO/Y,WAAe+Y,EAAO/Y,SAAW,EAAI,IAC3C,EAGlB,OAAO,IAGX,CACElb,KAAM,6BACNopC,YAAa,sDACbC,WAAY,CAACzsB,GAASY,KAAMZ,GAASU,UACrCosB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC3V,EAAoB/5B,EAAW4vC,EAA8BC,KACjE9V,EAAO/Y,UAAY+Y,EAAOp6B,OAASsb,IAM3C,CACEnV,KAAM,8BACNopC,YAAa,+EACbC,WAAY,CAACzsB,GAASU,SAAUV,GAASY,MACzCksB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC3V,EAAoB3L,EAAgBmhB,EAA4Cp7B,KACpF4lB,EAAO/Y,UAAY+Y,EAAOp6B,OAASsb,MAChCs0B,EAAiBnjB,IAAI,cAAgBjY,EAAI2a,kCAIvCV,EAAO2hB,qBAAqBhW,KAKzC,CACEj0B,KAAM,sCACNopC,YAAa,2DACbC,WAAY,GAAG1nC,OAAOoa,GAAa,CAACa,GAASc,MAAOd,GAASY,OAC7DksB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC3V,EAAoB/5B,EAAW4vC,EAA8BC,KACrE,GAAI9V,EAAOhoB,MAAO,CAChB,MAAMA,EAAoBgoB,EAAOhoB,MAM3Bi+B,EAAQ17B,GAAUylB,GAExB,GAAIiW,MAAAA,EAEF,OAAO,EAGT,IAAK,IAAIC,KAAal+B,EAAO,CAC3B,GAAkB,SAAdk+B,GAAsC,SAAdA,GAAsC,SAAdA,EAElD,SAEF,MAAMC,EAAQD,EACd,GAAc,UAAVD,GAGF,IAAKt1B,GAAyB,QAASw1B,KAAWx1B,GAAyB,OAAQw1B,GACjF,OAAO,OAEJ,IAAKx1B,GAAyBs1B,EAAOE,GAC1C,OAAO,GAIb,OAAO,IAGX,CACEpqC,KAAM,oCACNopC,YAAa,kEACbC,WAAY,GAAG1nC,OAAOoa,GAAa,CAACa,GAASc,MAAOd,GAASK,UAC7DysB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC3V,EAAoB/5B,EAAW4vC,EAA8BC,KACrE,GAAI9V,EAAQ,CACV,IAAIluB,EAAmBkuB,EAAOluB,QAC1BkG,EAAoBgoB,EAAOhoB,MAC/B,GAAIlG,IAAY8f,GAAW9f,IAAYkG,EAAO,CAC5C,GAAgB,QAAZlG,GAAiC,WAAZA,EAEvB,OAAO,EAET,IAAK,IAAIokC,KAAal+B,EAAO,CAC3B,IAAKA,EAAM7S,eAAe+wC,GAAY,SACtC,GAAkB,SAAdA,GAAsC,SAAdA,GAAsC,SAAdA,EAElD,SAGF,UAD6FjrC,IAA3E2V,GAAoC9O,EAASokC,IAE7D,OAAO,IAKf,OAAO,IAGX,CACEnqC,KAAM,2BACNopC,YAAa,2DACbC,WAAY,CAACzsB,GAASW,MAAOX,GAASY,MACtCksB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC3V,EAAoB3L,EAAgBmhB,EAA4Cp7B,KACxF,GAAqB,MAAjB4lB,EAAOhzB,MACT,OAAO,EAGT,MAAMopC,EAAgB/hB,EAAO+hB,cAAcpW,EAAOhzB,OAC5CpH,EAAOo6B,EAAOp6B,KAEpB,IAAK4vC,EAAiBnjB,IAAI,WAAamjB,EAAiBnjB,IAAI,UAAYjY,EAAI2a,iCAE1E,OAAO,EAGT,OAAQqhB,GACN,KAAKtC,GAAcuC,QACnB,KAAKvC,GAAcwC,OACjB,OAAO1wC,IAASub,IAAqBvb,IAASsb,GAChD,KAAK4yB,GAAcG,OACnB,KAAKH,GAAcE,QACjB,OAAOpuC,IAASsb,GAClB,KAAK4yB,GAAcC,SAEjB,OAAOnuC,IAASsb,GAClB,KAAK,KAEH,OAAO,EAEX,MAAM,IAAIjZ,MAAM,qBAGpB,CACE8D,KAAM,wBACNopC,YAAa,+EACbC,WAAY,CAACzsB,GAASW,MAAOX,GAASY,MACtCksB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC3V,EAAoB3L,EAAgBmhB,EAA4Cp7B,MACnFo7B,EAAiBnjB,IAAI,UAAamjB,EAAiBnjB,IAAI,SAAYjY,EAAI2a,oCAKvD,MAAjBiL,EAAOhzB,MACFgzB,EAAOp6B,OAASub,GAGlBkT,EAAO0e,OAAO/S,EAAOhzB,SAAqBgzB,EAAOp6B,OAG5D,CACEmG,KAAM,oCACNopC,YAAa,2DACbC,WAAY,CAACzsB,GAASK,QAASL,GAASW,OACxCmsB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC3V,EAAoB3L,EAAgBpuB,EAA6BmU,IAGrE4lB,EAAOluB,UAAY6P,GAAkBqe,EAAOp6B,OAASqb,IAAgB+e,EAAOp6B,OAASs1B,GAAa/qB,KAC7FkkB,EAAOsf,YAAY3T,IAAW5lB,EAAImc,mCAK/C,CACExqB,KAAM,yBACNopC,YAAa,0DACbC,WAAY,CAACzsB,GAASK,QAASL,GAASW,MAAOX,GAASQ,IAAKR,GAASU,UACtEosB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC3V,EAAoB3L,EAAgBpuB,EAA6BmU,IACrE4lB,EAAOluB,UAAYukB,GAAe2J,EAAOluB,UAAYykC,GAChDliB,EAAOsf,YAAY3T,IAAW5lB,EAAIoc,wBAK/C,CACEzqB,KAAM,yBACNopC,YAAa,qDACbC,WAAY,CAACzsB,GAASK,QAASL,GAASW,MAAOX,GAASQ,IAAKR,GAASU,UACtEosB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC3V,EAAoB3L,EAAgBpuB,EAA6BmU,IACrE4lB,EAAOluB,UAAYgQ,GACduS,EAAOsf,YAAY3T,IAAW5lB,EAAIqc,wBAK/C,CACE1qB,KAAM,oCACNopC,YAAa,kCACbC,WAAY,CACVzsB,GAASY,KACTZ,GAASc,MACTlB,GAAsB,QAAS,QAC/BI,GAASU,SACTV,GAASQ,KAEXssB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC3V,EAAoB/5B,EAAW4vC,EAA8BC,KACrE,GAAI9V,EAAOhoB,MAAO,CAChB,MAAMpS,EAAOo6B,EAAOp6B,KACdqwC,EAAQ17B,GAAUylB,GAExB,GAAIvF,GAAW70B,GACb,YAAiBqF,IAAVgrC,GAAuB92B,GAAkB82B,GAC3C,GAAIrwC,IAASsb,GAClB,OAAK8e,EAAO/Y,SAGH5Y,GAAS,CAAC+O,GAAUM,KAAMN,GAAUO,SAAK1S,GAAYgrC,IAAU92B,GAAkB82B,GAFjF5nC,GAAS,CAAC+O,GAAUM,KAAMN,GAAUO,SAAK1S,GAAYgrC,GAIzD,GAAIrwC,IAASub,GAClB,OAAI6e,EAAOhZ,IACF3Y,GAAS,CAAC+O,GAAUC,YAAQpS,GAAYgrC,GAExC5nC,GACL,CACE+O,GAAUE,IACVF,GAAUG,IACVH,GAAUI,KACVJ,GAAUQ,SACVR,GAAUS,SACVT,GAAUC,YACVpS,GAEFgrC,GAKR,OAAO,IAGX,CACElqC,KAAM,wBACNopC,YAAa,oDACbC,WAAY,CAACzsB,GAASG,MAAOH,GAASK,SACtCysB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC3V,EAAoB/5B,EAAW4vC,EAA8BC,KAC/D9V,EAAO7Y,QACJ6Y,EAAOluB,UAAYsP,GAAa4e,EAAOluB,UAAYuP,KAKhExU,IAAK2pC,GAAuC,IAAIlB,GAAoCkB,IASzEC,IALTb,GAAkB/yB,OAAO,CAAC0C,EAAGixB,KAC/BjxB,EAAEixB,EAAGzqC,QAAUyqC,EACRjxB,GACN,IAE0CqwB,GAAkB/yB,OAAO,CAACza,EAAO4B,KAC5E,IAAK,MAAMmR,KAAQnR,EAAEorC,aAEnBhtC,EAAMM,IAAIyS,EAAM/S,EAAMq3B,IAAItkB,IAAS,IACnC/S,EAAMq3B,IAAItkB,GAAM9S,KAAK2B,GAEvB,OAAO5B,GACN,IAAIuzB,KCjaM+a,GAA2D,CACtE,CACE3qC,KAAM,8BACNopC,YAAa,6EACbC,WAAY,CAACzsB,GAASY,KAAMZ,GAASM,WACrCwsB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACjT,EAAoBz8B,EAAW4vC,EAA8BC,KAE7DznC,GAAS,CAAC,MAAO,SAAU,IAAK,IAAK,SAAU,SAAUq0B,EAAO5wB,WAG5EjF,IAAK2pC,GAAuC,IAAIlB,GAAoCkB,IAQzEG,IALXD,GAAkB7zB,OAAO,CAAC0C,EAAGixB,KAC3BjxB,EAAEixB,EAAGzqC,QAAUyqC,EACRjxB,GACN,IAGHmxB,GAAkB7zB,OAAO,CAACza,EAAO4B,KAC/B,IAAK,MAAMmR,KAAQnR,EAAEorC,aACnBhtC,EAAMM,IAAIyS,EAAM/S,EAAMq3B,IAAItkB,IAAS,IACnC/S,EAAMq3B,IAAItkB,GAAM9S,KAAK2B,GAGvB,OAAO5B,GACN,IAAIuzB,KCzBT,SAAgBib,GAAcz7B,EAAgB07B,EAAyBzuC,EACrE0uC,EAAuBziB,EAAgBja,GAGvC,MAAM28B,EAAsBN,GAA8BhX,IAAItkB,IAAS,GACjE0iB,EAAOiZ,EAAME,wBAAwB5uC,GAE3C,IAAK,MAAM4B,KAAK+sC,EAEd,GAAI/sC,EAAEqrC,UAAcj7B,EAAIpQ,EAAE+B,QAAS,CAIjC,IADgB/B,EAAE2rC,QAAQ9X,EAAMxJ,EAAQyiB,EAAMG,cAAcrZ,UAAUx1B,GAAQgS,GAChE,CACZ,IAAI88B,EAAqB,SAAWltC,EAAE+B,OAKtC,OAHIqO,EAAIqa,SACN7mB,QAAQP,IAAI6pC,EAAqB,gBAAkBJ,EAAMK,cAAgB,QAAUN,EAAS9qC,MAEvFmrC,GAKb,MAAME,EAAkBT,GAA8BlX,IAAItkB,IAAS,GAEnE,IAAK,MAAMnR,KAAKotC,EAEd,IAAKptC,EAAEqrC,UAAcj7B,EAAIpQ,EAAE+B,UAAY+zB,GAAajC,GAAO,CAGzD,IADgB7zB,EAAE2rC,QAAQ9X,EAAMxJ,EAAQyiB,EAAMG,cAAcrZ,UAAUx1B,GAAQgS,GAChE,CACZ,IAAI88B,EAAqB,SAAWltC,EAAE+B,OAKtC,OAHIqO,EAAIqa,SACN7mB,QAAQP,IAAI6pC,EAAqB,gBAAkBJ,EAAMK,cAAgB,QAAUN,EAAS9qC,MAEvFmrC,GAIb,OAAO,8CCxBT,MAAMG,GAA6BhlC,GAAqBwQ,OAAO,CAAC0C,EAAGzT,KACjEyT,EAAEzT,IAAW,EACNyT,GACN,IAMH,MAAa+xB,WAA4BrC,GACvCrZ,YAAY2b,GACVhC,MAAMgC,GAGD3b,iCAAiCkb,GACtC,OAAOxwB,GAAMnY,KAAK+mC,WAAWE,WAAYj6B,IACvC,GAAIA,IAASwN,GAASC,KACpB,OAAQgJ,GAAWklB,EAAMU,WAK3B,GAAI3wB,GAAqB1L,GAAO,CAC9B,IAAI/U,EAAS+U,EAAK/U,OACdU,EAAQqU,EAAKrU,MAEjB,OAAOwf,GAAMwwB,EAAMW,eAAgB5Z,IAC5BA,EAAKz3B,KAIFwrB,GAAWiM,EAAKz3B,GAAQU,KAIpC,IAAK0hB,GAAmBrN,GACtB,MAAM,IAAIlT,MAAM,iBAGlB,OAAOqe,GAAMwwB,EAAMW,eAAgB5Z,IAC5BA,EAAK1iB,KAGFyW,GAAWiM,EAAK1iB,OAKvBygB,QAAQkb,EAAuBziB,EAAgBja,GAEpD,OAAKjM,KAAK+mC,WAAWO,6BACdtnC,KAAKunC,iCAAiCoB,IAKrC3oC,KAAK+mC,WAA8BS,QAAQmB,EAAOziB,EAAQja,IAS/D,MAAMs9B,GAA0C,CACrD,CACE3rC,KAAM,oBACNopC,YAAa,kDACbC,WAAY,CAACzsB,GAASK,SACtBysB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACmB,EAAuB7wC,EAAW4vC,KAC1C,IAAI8B,EAAc,GAGlB,OAAOrxB,GAAMwwB,EAAMW,eAAgB5Z,KAC5BjM,GAAWiM,EAAK/rB,WAEf6lC,EAAY9Z,EAAK/rB,WAGrB6lC,EAAY9Z,EAAK/rB,UAAW,GACrB,MAMf,CACE/F,KAAM,sCACNopC,YAAa,4DACbC,WAAY,CACVzsB,GAASC,KACTD,GAASc,MACTlB,GAAsB,QAAS,QAC/BI,GAASK,QACTL,GAASY,MAEXksB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACmB,EAAuB7wC,EAAW4vC,KAC1C,MAAMljC,EAAOmkC,EAAMU,UACb5Z,EAAYkZ,EAAMW,eAExB,GAAI9kC,IAASuhB,GACX,IAAK,IAAI2J,KAAQD,EACf,GACEE,GAAaD,KACZA,EAAK/rB,UAAYsP,GAAayc,EAAK/rB,UAAYuP,IAChDwc,EAAKj4B,OAASub,IACb0c,EAAK7lB,QAA6C,IAAnC6lB,EAAK7lB,MAAqBkI,KAG1C,OAAO,EAKb,OAAO,IAGX,CACEnU,KAAM,eACNopC,YACE,sHACFC,WAAY,CAACzsB,GAASQ,IAAKR,GAASU,SAAUV,GAASY,KAAMZ,GAASO,WACtEusB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACmB,EAAuB7wC,EAAW4vC,KAG1C,GAFqBpvB,GAAKqwB,EAAMW,eAAiB5Z,GAAwBK,GAAwBL,IAI/F,OAAOvX,GAAMwwB,EAAMW,eAAiB5Z,IAClC,GAAIiC,GAAajC,GACf,OAAO,EAGT,GAAIkC,GAAiBlC,GACnB,OAAO,EAGT,OAAQA,EAAKj4B,MACX,KAAKub,GACH,QAAS0c,EAAK7W,IAChB,KAAK9F,GACH,QAAS2c,EAAK5W,SAChB,KAAKjG,GACL,KAAKka,GAAa/qB,IAClB,KAAK8Q,GACH,OAAO,EAGX,MAAM,IAAIhZ,MAAM,sBAQlB,GAJ2Bqe,GADDwwB,EAAMG,cAAcW,0BAA0BnY,IAAI,cAAgB,GACvCr3B,IACnD,IAAIy1B,EAAOiZ,EAAME,wBAAwB5uC,GACzC,OAAO23B,GAAiBlC,KAAUjM,GAAWiM,EAAK9W,aASlD,OAAON,GAAKqwB,EAAMW,eAAiB5Z,IAC5BC,GAAaD,IAASkC,GAAiBlC,KAAUA,EAAKj4B,OAASub,IAC9Dwd,GAAyBd,KAGpBC,GAAaD,MAAWA,EAAK7W,KAAO4K,GAAWiM,EAAK7W,UAEpD8W,GAAaD,IAASA,EAAKj4B,OAASsb,OACrC2c,EAAK5W,UAAY2K,GAAWiM,EAAK5W,YAOjD,OAAO,IAGX,CACElb,KAAM,6BACNopC,YAAa,6DACbC,WAAY,CAACzsB,GAASK,QAASL,GAASC,MACxC6sB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACmB,EAAuB7wC,EAAW4vC,KAC1C,MAAMljC,EAAOmkC,EAAMU,UAGnB,QAAI5lB,GAAWjf,IAGR2T,GAAMwwB,EAAMW,eAAgB5Z,KAE7BjM,GAAWiM,EAAK/rB,YAEXY,GAAYmrB,EAAK/rB,QAASa,MAIzC,CACE5G,KAAM,gCACNopC,YAAa,mEACbC,WAAY,CAACzsB,GAASK,QAASL,GAASC,MACxC6sB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACmB,EAAuB7wC,EAAW4vC,KAC1C,MAAMljC,EAAOmkC,EAAMU,UAEnB,OAAQ7kC,GACN,KAAKwhB,GACL,I3BlPoB,O2BmPlB,OAAO2iB,EAAMe,YAAYz2B,IAAc01B,EAAMe,YAAYx2B,GAC3D,I3BhPoB,O2BiPlB,OAAOy1B,EAAMe,YAAYC,GAC3B,KAAK5jB,GACL,KAAK6jB,GACL,KAAKC,GACL,I3BpPoB,O2BqPpB,I3BvPoB,O2BwPpB,I3BzPoB,O2B0PlB,OAAOlB,EAAMe,YAAYz2B,IAAc01B,EAAMe,YAAYx2B,GAC3D,KAAK4S,GAEH,OACG6iB,EAAMG,cAAcgB,YAAYtvB,GAASK,UAC1C8tB,EAAMe,YAAYz2B,IAClB01B,EAAMe,YAAYx2B,GAIxB,MAAM,IAAIpZ,MAAM,yDAA2DkD,KAAKJ,UAAU4H,MAG9F,CACE5G,KAAM,gBACNopC,YAAa,wBACbC,WAAY,CAACzsB,GAASM,UAAWN,GAASO,WAC1CusB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACmB,EAAuB7wC,EAAW4vC,KACtCiB,EAAM9Y,eAMd,CACEjyB,KAAM,4CACNopC,YAAa,iGACbC,WAAY,CAACzsB,GAASK,QAASL,GAASM,UAAWN,GAASO,WAC5DusB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACmB,EAAuB7wC,EAAWmU,KAC1C,GAAI08B,EAAM9Y,cAAe,CACvB,IAAIka,GAAiB,EACnBC,GAAS,EACTC,GAAwB,EAiB1B,GAhBAtB,EAAMuB,UAAUza,UAAUt1B,QAAQ,CAACu1B,EAAMz1B,KACnC03B,GAAajC,IAASc,GAAyBd,IAG/CC,GAAaD,KAAUA,EAAKpjB,YAE9B09B,GAAS,EACL9pC,GAAS,CAACgoB,EAAakgB,GAAiB1Y,EAAK/rB,SAC3CglC,EAAMG,cAAcqB,oBAAoBlwC,EAAOugB,GAASK,WAC1DovB,GAAwB,GAG1BF,GAAiB,KAInBC,IAAWD,IACTE,GAAyBh+B,EAAI2a,kCAC/B,OAAO,EAIb,OAAO,IAGX,CACEhpB,KAAM,oCACNopC,YAAa,sDACbC,WAAY,CAACzsB,GAASM,UAAWN,GAASO,UAAWP,GAASQ,IAAKR,GAASU,SAAUV,GAASY,MAC/FksB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACmB,EAAuB7wC,EAAW4vC,KACtCiB,EAAM9Y,eAEDvX,GAAKqwB,EAAMW,eAAiB5Z,MAC7BiF,GAAYjF,IAAUC,GAAaD,IAAuB,aAAdA,EAAKj4B,QAS7D,CAEEmG,KAAM,+BACNopC,YAAa,qFACbC,WAAY,CAACzsB,GAASC,KAAMD,GAASM,UAAWN,GAASO,WACzDusB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACmB,EAAuB7wC,EAAW4vC,KACtCxnC,GAAS,CAAC6lB,G3BrVQ,O2BqVaC,IAAY2iB,EAAMU,YAC5CV,EAAM9Y,eAKnB,CACEjyB,KAAM,sBACNopC,YAAa,0DACbC,WAAY,CAACzsB,GAASK,QAASL,GAASC,MACxC6sB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACmB,EAAuB7wC,EAAWmU,KAC1C,MAAMzH,EAAOmkC,EAAMU,UACnB,GAAInpC,GAAS,C3B9VS,O2B8VG6lB,IAAWvhB,IAC9BmkC,EAAMyB,qBAAqBj3B,GAAe,CAC5C,GAAIlH,EAAI2a,iCAGN,OAAO,EACF,CAEL,MAAM6I,EAAYkZ,EAAMuB,UAAUza,UAClC,IAAK,IAAIr4B,EAAI,EAAGA,EAAIq4B,EAAUp4B,OAAQD,IAAK,CAEzC,GADaq4B,EAAUr4B,GACduM,UAAYwP,EACnB,OAAIw1B,EAAMG,cAAcqB,oBAAoB/yC,EAAGojB,GAASK,WAYlE,OAAO,IAGX,CACEjd,KAAM,yBACNopC,YAAa,uDACbC,WAAY,CACVzsB,GAASC,KACTD,GAASK,QACTL,GAASc,MACTlB,GAAsB,QAAS,QAC/BI,GAASY,MAEXksB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACmB,EAAuB7wC,EAAW4vC,KAC1C,MAAMljC,EAAOmkC,EAAMU,UACb5Z,EAAYkZ,EAAMW,eAGxB,GAAI9kC,IAASwhB,IAAaxhB,IAASuhB,GACjC,IAAK,IAAI2J,KAAQD,EACf,GAAIE,GAAaD,KAAWA,EAAK/rB,UAAYsP,GAAayc,EAAK/rB,UAAYuP,IAAcwc,EAAK7lB,MAAQ,CAGpG,GAFYuC,GAAUsjB,KAERzgB,GAAUE,IACtB,OAAO,EAKf,OAAO,IAGX,CACEvR,KAAM,oCACNopC,YACE,yGACFC,WAAY,CAACzsB,GAASK,SACtBysB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACmB,EAAuB7wC,EAAWmU,KAI1C,MAAMwjB,EAAYkZ,EAAMuB,UAAUza,UAClC,IAAI4a,EAA0B,EAC1BC,GAAkC,EAEtC,IAAK,IAAIlzC,EAAI,EAAGA,EAAIq4B,EAAUp4B,OAAQD,IAAK,CACzC,MAAMs4B,EAAOD,EAAUr4B,GACvB,GAAIu6B,GAAajC,IAASc,GAAyBd,GACjD,SAGF,MAAM/rB,EAAU+rB,EAAK/rB,QACrB,IAAK8f,GAAW9f,IACVulC,GAA2BvlC,EAAU,MACvC0mC,GAA2B,EACvB1B,EAAMG,cAAcqB,oBAAoB/yC,EAAGojB,GAASK,WACtDyvB,GAAkC,GAGlCD,EAA0B,IACzBC,GAAmCr+B,EAAI2a,mCAExC,OAAO,EAKf,OAAO,IAGX,CACEhpB,KAAM,iDACNopC,YAAa,6EACbC,WAAY,CAACzsB,GAASK,SACtBysB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACmB,EAAuB7wC,EAAWmU,KAC1C,MAAMwjB,EAAYkZ,EAAMuB,UAAUza,UAClC,IAAI8a,GAAiC,EACjCC,GAAyC,EACzCC,GAAO,EACTC,GAAO,EACT,IAAK,IAAItzC,EAAI,EAAGA,EAAIq4B,EAAUp4B,OAAQD,IAAK,CACzC,MAAMs4B,EAAOD,EAAUr4B,GACvB,GAAIu6B,GAAajC,IAASc,GAAyBd,GACjD,SAGF,MAAM/rB,EAAU+rB,EAAK/rB,QACjBA,IAAYsP,EACdw3B,GAAO,EACE9mC,IAAYuP,EACrBw3B,GAAO,EACGjnB,GAAW9f,KAErB4mC,GAAiC,EAC7B5B,EAAMG,cAAcqB,oBAAoB/yC,EAAGojB,GAASK,WACtD2vB,GAAyC,IAK/C,QACEA,GACCv+B,EAAI2a,kCAAoC2jB,IAElCE,GAAQC,IAKrB,CACE9sC,KAAM,UACNopC,YAAa,kBACbC,WAAY,CAACzsB,GAASM,UAAWN,GAASO,WAC1CusB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACmB,EAAuB7wC,EAAW4vC,MACrCiB,EAAM9Y,eAMf,CACEjyB,KAAM,yCACNopC,YACE,0IAEFC,WAAY,CAACzsB,GAASM,UAAWN,GAASO,UAAWP,GAASU,SAAUV,GAASQ,IAAKR,GAASY,MAC/FksB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACmB,EAAuB7wC,EAAWmU,KAC1C,GAAI08B,EAAM9Y,cAAe,CACvB,MAAMJ,EAAYkZ,EAAMuB,UAAUza,UAClC,IAAK,IAAIr4B,EAAI,EAAGA,EAAIq4B,EAAUp4B,OAAQD,IAAK,CACzC,MAAMs4B,EAAOD,EAAUr4B,GACvB,IAAIu6B,GAAajC,KAASc,GAAyBd,GAAnD,CAIA,GAAIC,GAAaD,IAASA,EAAKj4B,OAASsb,KAGnC2c,EAAK5W,WACL6vB,EAAMG,cAAcqB,oBAAoB/yC,EAAGojB,GAASU,WAAajP,EAAI2a,kCAEtE,OAAO,EAGX,GAAI8I,EAAKj4B,OAASub,IACZ2c,GAAaD,KAAUA,EAAK7W,MAAQ6W,EAAKpjB,UAAW,CAEtD,GACEq8B,EAAMG,cAAcqB,oBAAoB/yC,EAAGojB,GAASQ,MACpD2tB,EAAMG,cAAcqB,oBAAoB/yC,EAAGojB,GAASM,YACpD6tB,EAAMG,cAAcqB,oBAAoB/yC,EAAGojB,GAASO,WAGpD,OAAO,EAET,GAAI9O,EAAI2a,iCAEN,OAAO,KAMjB,OAAO,IAGX,CACEhpB,KAAM,gBACNopC,YAAa,2CACbC,WAAY,CAACzsB,GAASK,QAASL,GAASM,UAAWN,GAASO,WAC5DusB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACmB,EAAuB7wC,EAAWmU,MACtC08B,EAAM9Y,eAGH1X,GAAMwwB,EAAMuB,UAAUza,UAAW,CAACC,EAAMz1B,OACzC03B,GAAajC,KAASc,GAAyBd,MAE/CA,EAAK/rB,UAAYgnC,IAIjBhC,EAAMG,cAAcqB,oBAAoBlwC,EAAOugB,GAASK,WACxD5O,EAAI2a,oCASd,CACEhpB,KAAM,oBACNopC,YAAa,kDACbC,WAAY,CAACzsB,GAASW,OACtBmsB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACmB,EAAuB7wC,EAAWmU,KAC1C,IAAI2+B,EAAY,GACZC,EAAkB,GAEtB,MAAMpb,EAAYkZ,EAAMuB,UAAUza,UAClC,IAAK,IAAIr4B,EAAI,EAAGA,EAAIq4B,EAAUp4B,OAAQD,IAAK,CACzC,MAAMs4B,EAAOD,EAAUr4B,GAEvB,GAAIu6B,GAAajC,IAASkC,GAAiBlC,GAAO,SAElD,IAAI7wB,EAQJ,GAPI6wB,EAAK7wB,QAAU4kB,GAAWiM,EAAK7wB,SACjCA,EAAQ6wB,EAAK7wB,OAEX+yB,GAAiBlC,KAAUjM,GAAWiM,EAAK9W,aAC7C/Z,EAAQ,WAGNA,EAAO,CAST,GARI8pC,EAAMG,cAAcqB,oBAAoB/yC,EAAGojB,GAASW,SACtD0vB,EAAgBhsC,IAAS,GAOvB+rC,EAAU/rC,KACRgsC,EAAgBhsC,IAAUoN,EAAI2a,kCAChC,OAAO,EAIXgkB,EAAU/rC,IAAS,GAGvB,OAAO,IAIX,CACEjB,KAAM,sBACNopC,YAAa,mCACbC,WAAY,CAACzsB,GAASK,SACtBysB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACmB,EAAuB7wC,EAAW4vC,KAC1C,MAAMjY,EAAYkZ,EAAMW,eACxB,OAAyB,IAArB7Z,EAAUp4B,QAAgBo4B,EAAU,GAAG9rB,UAAYuP,IAO3D,CACEtV,KAAM,mCACNopC,YAAa,wCACbC,WAAY,CACVzsB,GAASK,QACTL,GAASC,KACTD,GAASY,KACTZ,GAASU,SACTV,GAASQ,IACTR,GAASM,UACTN,GAASO,WAEXusB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACmB,EAAuB7wC,EAAW4vC,KAC1C,MAAMljC,EAAOmkC,EAAMU,UAEnB,OAAQ7kC,GACN,KAAKwhB,GACL,I3BtpBoB,O2BupBlB,GAAI2iB,EAAM9Y,cAAe,CAEvB,MAAMib,EAAQnC,EAAMoC,0BAA0B93B,GACxC+3B,EAAQrC,EAAMoC,0BAA0B73B,GACxC+3B,EAAavW,GAAUoW,GACvBI,EAAaxW,GAAUsW,GAG7B,OACEF,GACAE,GACAC,IAAeC,KAIbvb,GAAamb,KAAWG,GAAc/qC,GAAS,CAAC,UAAW,OAAQ4qC,EAAMrzC,UACzEk4B,GAAaqb,KAAWE,GAAchrC,GAAS,CAAC,UAAW,OAAQ8qC,EAAMvzC,OAI/E,OAAO,EACT,I3BxqBoB,O2B0qBlB,OAAO,EACT,KAAKsuB,GACL,I3B3qBoB,O2B6qBlB,GAAI4iB,EAAMyB,qBAAqBj3B,GAC7B,OAAO,EACF,CAEL,MAAM23B,EAAQnC,EAAMoC,0BAA0B93B,GACxC+3B,EAAQrC,EAAMoC,0BAA0B73B,GAG9C,OAFmBwhB,GAAUoW,KACVpW,GAAUsW,GAMjC,I3B7rBoB,O2BksBlB,MAAMF,EAAQnC,EAAMoC,0BAA0B93B,GACxC+3B,EAAQrC,EAAMoC,0BAA0B73B,GACxCi4B,EAAexW,GAAYmW,GAC3BM,EAAezW,GAAYqW,GAE3BK,EAAY1C,EAAMoC,0BAA0Bv3B,GAC5C83B,EAAsB5W,GAAU2W,GAChCE,IAAiB5b,GAAa0b,IAAaA,EAAU5zC,OAASob,GAE9D24B,EACHL,GAAgBC,GAChBD,IAAiBxC,EAAMe,YAAYx2B,IACnCk4B,IAAiBzC,EAAMe,YAAYz2B,GAEhCw4B,GAAgBJ,GAAcA,IAAcC,GAAuBC,GAEzE,OAAOC,GAAmBC,EAC5B,KAAK7B,GACL,KAAK9jB,GACL,KAAK+jB,GACL,I3BrtBoB,O2BstBlB,OAAO,EAGX,MAAM,IAAI/vC,MAAM,yDAA2D0K,KAG/E,CACE5G,KAAM,uBACNopC,YAAa,2DACbC,WAAY,CACVzsB,GAASG,MACTH,GAASW,MACTX,GAASK,QACTL,GAASC,KACTD,GAASM,UACTN,GAASO,UACTP,GAASc,MACTlB,GAAsB,QAAS,QAC/BI,GAASY,MAEXksB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACmB,EAAuB7wC,EAAW4vC,KAC1C,IAAKiB,EAAMG,cAAcgB,YAAYtvB,GAASG,OAC5C,OAAO,EAGT,MAAM+wB,EAAa/C,EAAM3Y,aACzB,OAAmB,OAAf0b,GAAkD,OAA3B/C,EAAMvY,mBAI7Bsb,EAAWxd,eAAiBya,EAAMtY,oBAO1C,CACEzyB,KAAM,kBACNopC,YAAa,gGACbC,WAAY,CACVzsB,GAASK,QACTL,GAASC,KACTD,GAASM,UACTN,GAASO,UACTP,GAASc,MACTlB,GAAsB,QAAS,QAC/BI,GAASY,MAEXksB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACmB,EAAuB7wC,EAAW4vC,KAC1C,MAAMiE,EAAYhD,EAAM3Y,aACxB,GAAiB,MAAb2b,EAAmB,CACrB,MAAMC,EAAkBjD,EAAMoC,0BAA0BY,EAAUzd,cAClE,IAAKhuB,GAAS0qB,GAASghB,EAAgBt/B,WACrC,OAAO,EAGX,OAAO,IAGX,CACE1O,KAAM,uCACNopC,YACE,sJACFC,WAAY,CACVzsB,GAASK,QACTL,GAASY,KACTZ,GAASU,SACTV,GAASQ,IACTR,GAASM,UACTN,GAASO,WAEXusB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACmB,EAAuB7wC,EAAWmU,KAC1C,GAAIA,EAAI4a,aAAc,CACpB,MAAMikB,EAAQnC,EAAMoC,0BAA0B,KACxCC,EAAQrC,EAAMoC,0BAA0B,KAE9C,KAAMpb,GAAamb,IAAUnW,GAAYmW,OAAanb,GAAaqb,IAAUrW,GAAYqW,IACvF,QAAKrC,EAAM9Y,eAGF1X,GAAMwwB,EAAMW,eAAgB5Z,IACjC,IAAI/rB,EAAU+rB,EAAK/rB,QAEnB,QACEA,IAAYsP,GACZtP,IAAYuP,GACZvP,IAAYukB,GACZvkB,IAAYykC,GAGRzY,GAAaD,KAAUA,EAAKpjB,aAS1C,OAAO,KAGX5N,IAAIkwB,GAAM,IAAIua,GAAoBva,IAGvBid,GAA+DtC,GAAiB70B,OAC3F,CAAC0C,EAAQvb,KACPub,EAAEvb,EAAE+B,QAAU/B,EACPub,GAET,IAGI00B,GAA+BvC,GAAiB70B,OAAO,CAACza,EAAO4B,KACnE,IAAK,MAAMmR,KAAQnR,EAAEorC,aAEnBhtC,EAAMM,IAAIyS,EAAM/S,EAAMq3B,IAAItkB,IAAS,IACnC/S,EAAMq3B,IAAItkB,GAAM9S,KAAK2B,GAEvB,OAAO5B,GACN,IAAIuzB,IAKP,SAAgBue,GACd/+B,EACA07B,EACAC,EACAziB,EACAja,GAGA,MAAM+/B,EAAkBF,GAA6Bxa,IAAItkB,IAAS,GAElE,IAAK,MAAMnR,KAAKmwC,EAEd,GAAInwC,EAAEqrC,UAAcj7B,EAAIpQ,EAAE+B,QAAS,CAIjC,IADgB/B,EAAE2rC,QAAQmB,EAAOziB,EAAQja,GAC3B,CACZ,IAAI88B,EAAqB,UAAYltC,EAAE+B,OAKvC,OAHIqO,EAAIqa,SACN7mB,QAAQP,IAAI6pC,EAAqB,gBAAkBJ,EAAMK,cAAgB,QAAUN,EAAS9qC,MAEvFmrC,GAIb,OAAO,sJCj3BT,MAAMkD,GAAmB,IAAIze,GAM7B,SAAgB0e,GAAcl/B,GAC5B,OAAOi/B,GAAiB3a,IAAItkB,GAyC9B,SAAgBm/B,GAAiCn/B,GAI/C,MAAO,CAAC87B,EAA8B5iB,EAAgBja,IAE7C,CAACmgC,EAA6BzD,KAEnC,MAAM7xB,EAAUgyB,EAAcW,0BAA0BnY,IAAItkB,GAwD5D,OAtDA,SAASq/B,EAAUC,GACjB,GAAIA,IAAax1B,EAAQzf,OAGvB,YADA+0C,EAAUlyC,KAAKyuC,EAAM10B,aAGvB,MAAMha,EAAQ6c,EAAQw1B,GAChB5D,EAA0BI,EAAcrZ,UAAUx1B,GAAOq3B,IAAItkB,GAC7D0iB,EAAOiZ,EAAME,wBAAwB5uC,GACrCsyC,EAAe5D,EAAM6D,oBAAoBvyC,EAAO+S,GAElD2kB,GAAajC,IAKVc,GAAyBd,KAGzB6c,EAGLF,EAAUC,EAAW,IAErB5D,EAAS9kB,KAAKzpB,QAASsyC,IACL,OAAZA,IAGFA,OAAU3vC,GAEZ6rC,EAAM+D,oBAAoBzyC,EAAO+S,EAAMy/B,EAAS/D,GAGbD,GAAcz7B,EAAM07B,EAAUzuC,EAAO0uC,EAAOziB,EAAQja,IAKxD8/B,GAAU/+B,EAAM07B,EAAUC,EAAOziB,EAAQja,IAKxEogC,EAAUC,EAAW,KAIvB3D,EAAMgE,sBAAsB1yC,EAAO+S,EAAM07B,IAK7C2D,CAAU,GAEHD,GAlGbH,GAAiB1xC,IAAI,OAAQ,CAACuuC,EAA8B5iB,EAAgBja,IACnE,CAACmgC,EAAWzD,KAiBjB,OAhBqBA,EAAMU,UAGdzlB,KAAKzpB,QAASqK,IACzBmkC,EAAMiE,QAAQpoC,GAEiBunC,GAAU,OAAQjD,EAActkC,KAAMmkC,EAAOziB,EAAQja,IAGlFmgC,EAAUlyC,KAAKyuC,EAAM10B,eAKzB00B,EAAMkE,YAECT,IAIXjzB,GAAwBhf,QAAS6S,IAC/Bi/B,GAAiB1xC,IAAIyS,EAAMm/B,GAAiCn/B,MAG9D8M,GAAsB3f,QAASg4B,IAC7B8Z,GAAiB1xC,IAAI43B,EAAYga,GAAiCha,mFCpCpE,SAAgB2a,GAAkBC,GAChC,OAAOzuC,GAASyuC,MAAQA,EAAY,SAWtC,SAAgBC,GAAaC,EACzB7b,EACAR,GAeF,OAZAQ,EAAUA,GAAW,IAAI5D,GACzBoD,EAAeA,GAAgB,IAAIpD,GAEnCyf,EAAQ9yC,QAAS+yC,IACXJ,GAAkBI,IACpB9b,EAAQ+b,SAASD,EAAM//B,UAAU,GACjCyjB,EAAauc,SAASD,EAAM//B,SAAU+/B,EAAMvuC,UAE5CyyB,EAAQ+b,SAASD,GAAO,KAIrB,CACL9b,QAASA,EACTR,aAAcA,EACdG,SAAUJ,GAAiBC,IA6BxB,MAAMwc,GAA2B,CACtC5yB,GAASW,MAAOX,GAASY,KACzBZ,GAASM,UAAWN,GAASQ,IAAKR,GAASU,SAAUV,GAASG,OAGnD0yB,GAAqBD,GAA6D7tC,OAAO,CACpG,CACE4N,SAAUqN,GAASK,QACnBlc,QAAS,CACPF,EAAK,KAAM4D,EAAK,KAChBO,MAAS,QAASO,KAAQ,QAASC,MAAS,QAASL,QAAW,QAChEc,IAAO,QAASC,OAAU,uDA7EkB,CAACwpC,IAAK,wBACP,CAAC7uC,EAAG,KAAM4D,EAAG,6BACV,CAACwB,IAAK,QAASC,OAAQ,qCAClB,CAAClB,MAAO,QAASG,QAAS,QAASK,MAAO,QAASD,KAAM,uDAsClH,SAAyB8pC,GACvB,OAAI9vC,GAAQ8vC,GACHA,EAAQvuC,IAAKquC,IAClB,GAAID,GAAkBC,GAAI,CACxB,GAAIA,EAAEpuC,QAAS,CACb,IAAIiyB,EAAetzB,GAAKyvC,EAAEpuC,SAAS+V,OAAO,CAACza,EAAOszC,KAClD,MAAMC,EAAQT,EAAEpuC,QAAQ4uC,GAEtB,OADCtzC,EAAMuzC,GAASvzC,EAAMuzC,IAAU,IAAItzC,KAAKqzC,GAClCtzC,GACN,IAEH,OAAO8yC,EAAE5/B,SAAW,IAAM7P,GAAKszB,GAAclyB,IAAK8uC,GAC/B5c,EAAa4c,GAAOjwC,OACrByB,KAAK,KAAO,KAAOwuC,GAClCxuC,KAAK,KAAO,IAEjB,OAAO+tC,EAAE5/B,SAEX,OAAO4/B,IACN/tC,KAAK,KAEDiuC,sDC/DX,IAAIQ,GAAoD,GAKxD,SAAgBC,GAAc9vC,EAAciZ,GAC1C42B,GAAc7vC,GAAQiZ,EAYxB,SAAgB82B,GAAKC,EAA8BC,GACjD,GAAIA,EAAW,CACb,MAAMC,EAAiC,CACrClwC,KAAM,GACNM,KAAM,GACN6vC,MAAO,IAET,IAAIC,EAAwC,GAKxCC,EAAsC,GACtCC,EAA2C,GAC3CC,EAAwC,GAE5C,IAAK,IAAIp2B,EAAI,EAAGA,EAAI81B,EAAUx2C,OAAQ0gB,IAAK,CACzCk2B,EAAS/zC,KAAK6d,EAAI,EAAIk2B,EAASl2B,EAAI,GAAG9D,YAAc,IAAIuZ,IACxD0gB,EAASh0C,KAAK6d,EAAI,EAAIm2B,EAASn2B,EAAI,GAAG9D,YAAc,IAAIuZ,IAExD,MAAMyf,EAAUY,EAAU91B,GAAGk1B,QAC7B,GAAI9vC,GAAQ8vC,GAAU,CAEpB,IAAImB,EAAgBpB,GAAaC,EAASgB,EAASl2B,GAAIm2B,EAASn2B,IAChEo2B,EAAUj0C,KAAKk0C,EAAcrd,WAgCjC,OA1BA6c,EAAWzzC,QAAQwuC,IACjB,IAAIzqC,EAAO,GACPmwC,EAA6BP,EACjC,IAAK,IAAI/1B,EAAI,EAAGA,EAAI81B,EAAUx2C,OAAQ0gB,IAAK,CACzC,MAAMk1B,EAAWoB,EAAMpB,QAAUY,EAAU91B,GAAGk1B,QAC9CoB,EAAMC,aAAeT,EAAU91B,GAAGu2B,aAElC,MAAMl0C,EAAM+C,GAAQ8vC,GAChBsB,GAAc5F,EAAMuB,UAAW+D,EAASl2B,GAAIo2B,EAAUp2B,IACtD01B,GAAcR,GAAStE,EAAMuB,WAG5B8D,EADL9vC,GAAQ,IAAM9D,KAGZ4zC,EAAW9vC,GAAQ,CACjBN,KAAMxD,EACN8D,KAAMA,EACN6vC,MAAO,IAGTM,EAAMN,MAAM7zC,KAAK8zC,EAAW9vC,KAE9BmwC,EAAQL,EAAW9vC,GAErBmwC,EAAMN,MAAM7zC,KAAKyuC,KAEZmF,EAGP,MAAO,CACLlwC,KAAM,GACNM,KAAM,GACN6vC,MAAOH,GAMb,MACMY,GAAwBxB,GADP,CAACxyB,GAASW,QAGjC,SAAgBszB,GAAc9F,EAAkBsE,GAC9C,OAAOQ,GAAcR,GAAStE,GAGhC+E,GApFqB,QAoFC5d,GACbye,GAAcze,EAAO0e,GAAsBpd,QAASod,GAAsBzd,WAG5E,MAAM2d,GAAkC1B,GAAaI,IAE5DM,GAzF+B,iBAyFC5d,GACvBye,GAAcze,EAAO4e,GAAgCtd,QAASsd,GAAgC3d,WAGhG,MAAM4d,GAA2B3B,GAAaK,IAErDK,GA9FwB,WA8FC5d,GAChBye,GAAcze,EAAO6e,GAAyBvd,QAASud,GAAyB5d,WAGzF2c,GAjGoB,OAiGC5d,GAAqB9yB,KAAKJ,UAAUkzB,iDApGpC,wBACU,0BACP,gBACJ,uGCbP8e,GAWXnhB,cACEztB,KAAK6uC,WAAQ/xC,EACbkD,KAAK8uC,WAAa,GAClB9uC,KAAK+uC,2BAA6B,IAAIvhB,GAGjCC,oBAAoBxzB,EAAe+S,EAAgB07B,GACxD,MAAMsG,EAAiBhvC,KAAK8uC,YAGXE,EAAe/0C,GAAS+0C,EAAe/0C,IAAU,IAAIuzB,IAC7DjzB,IAAIyS,EAAM07B,GAGnB,MAAMuG,EAAgBjvC,KAAK+uC,2BAI3B,OAHAE,EAAc10C,IAAIyS,EAAOiiC,EAAc3d,IAAItkB,IAAS,IACpDiiC,EAAc3d,IAAItkB,GAAM9S,KAAKD,GAEtB+F,KAGFytB,oBAAoBxzB,EAAe+S,GACxC,QAAShN,KAAK8uC,WAAW70C,IAAU+F,KAAK8uC,WAAW70C,GAAOiqB,IAAIlX,GAGzDygB,YAAYzgB,GACjB,GAAIqN,GAAmBrN,GACrB,OAAOhN,KAAKypC,0BAA0BvlB,IAAIlX,GACrC,GAAa,SAATA,EACT,QAAShN,KAAKwE,KAGhB,MAAM,IAAI1K,MAAM,8BAAgCkT,GAG3CygB,UACL,OAAQztB,KAAKwE,MAAkD,IAA1CxE,KAAKypC,0BAA0BtmC,OAG/CsqB,QAAQjpB,GAEb,OADAxE,KAAK6uC,MAAQrqC,EACNxE,KAGTwE,WACE,OAAOxE,KAAK6uC,MAGdpf,gBACE,OAAOzvB,KAAK8uC,WAGdrF,gCACE,OAAOzpC,KAAK+uC,4BCtChB,MAAaG,GAuGXzhB,YACE4B,EACAyZ,EACA5iB,EACAja,EACAkjC,GAlGMnvC,KAAAovC,cAAoC,GAoG1CpvC,KAAKqvC,MAAQhgB,EACbrvB,KAAKsvC,mBAAqBjgB,EAAKI,UAAU/a,OACvC,CAAC0C,EAAGsY,KACGjM,GAAWiM,EAAK/rB,UAAciuB,GAAiBlC,KAA4B,IAAnBA,EAAK9W,YAChExB,EAAEsY,EAAK/rB,QAAU,IAAM,GAElByT,GAET,IAGFpX,KAAKuvC,eAAiBzG,EACtB9oC,KAAKwvC,uBAAyBL,EAC9BnvC,KAAKyvC,KAAOxjC,EACZjM,KAAK0vC,QAAUxpB,EAzGVuH,aAAaqC,EAAkB5J,EAAgBja,GACpD,IAAI68B,EAA+B,IAAI8F,GAEvC,GAAInrB,GAAWqM,EAAMtrB,MAAO,CAC1B,MAAM5G,EAAOwnB,GAAe5K,GAASC,MACrCqV,EAAMtrB,KAAOqf,GAAaiM,EAAMtrB,KAAM5G,EAAMqO,EAAI2X,KAAKpf,MACrDskC,EAAc8D,QAAQ9c,EAAMtrB,MAoD9B,GA9CAsrB,EAAML,UAAUt1B,QAAQ,CAACu1B,EAAMz1B,KACzB23B,GAAiBlC,KAEnBjwB,QAAQsO,KAAK,8FAEb2hB,EAAKj4B,KAAOub,IAGV2c,GAAaD,SAAuB5yB,IAAd4yB,EAAKj4B,OAE7Bi4B,EAAKj4B,KAAO+rB,IAIdrK,GAAwBhf,QAAQ6S,IAC9B,GAAIyW,GAAWiM,EAAK1iB,IAAQ,CAE1B,MAAM2iC,EAAsBvqB,GAAepY,GAAQ/S,EAC7C8pB,EAAoBkC,GAAqBjZ,EAAMkZ,EAAQja,GACvDy8B,EAAYhZ,EAAK1iB,GAAQ6W,GAAa6L,EAAK1iB,GAAO2iC,EAAqB5rB,GAG7E+kB,EAAc4D,oBAAoBzyC,EAAO+S,EAAM07B,MAKnD5uB,GAAsB3f,QAAQ6S,IAC5B,MAAM4iC,EAAUlgB,EAAK1iB,EAAK/U,QAC1B,GAAI23C,EAAS,CACX,MAAMj3C,EAAQqU,EAAKrU,MACnB,GAAI8qB,GAAWmsB,EAAQj3C,IAAS,CAE9B,MAAMg3C,EAAsBvqB,GAAepY,GAAQ/S,EAC7C8pB,EAAoBkC,GAAqBjZ,EAAMkZ,EAAQja,GACvDy8B,EAAYkH,EAAQj3C,GAASkrB,GAAa+rB,EAAQj3C,GAAQg3C,EAAqB5rB,GAGrF+kB,EAAc4D,oBAAoBzyC,EAAO+S,EAAM07B,SAQnDz8B,EAAI4a,aAAc,CACpB,MAAMljB,EAA6B,CACjC/F,KAAMwnB,GAAe5K,GAASK,SAAWiV,EAAML,UAAUp4B,OACzDusB,KAAMqC,GAAqBzL,GAASK,QAASqL,EAAQja,IAEjD2M,EAA+B,CACnChb,KAAMwnB,GAAe5K,GAASO,WAAa+U,EAAML,UAAUp4B,OAC3DusB,KAAM,EAAC,GAAO,IAEVisB,EAA4B,CAChClsC,QAAAA,EACAiV,UAAAA,EACAnhB,KAAMub,IAER8c,EAAML,UAAUv1B,KAAK21C,GAErB,MAAM51C,EAAQ61B,EAAML,UAAUp4B,OAAS,EAGvCyxC,EAAc4D,oBAAoBzyC,EAAOugB,GAASK,QAASlX,GAC3DmlC,EAAc4D,oBAAoBzyC,EAAOugB,GAASO,UAAWnC,GAG/D,OAAO,IAAIs2B,GAAepf,EAAOgZ,EAAe5iB,EAAQja,EAAK,IA2B/D68B,oBACE,OAAO9oC,KAAKuvC,eAGdrpB,aACE,OAAOlmB,KAAK0vC,QAGdxF,gBACE,OAAOlqC,KAAKqvC,MAGP5hB,YACL,OAAO,IAAIyhB,GACTj7B,GAAUjU,KAAKqvC,OACfrvC,KAAKuvC,eACLvvC,KAAK0vC,QACL1vC,KAAKyvC,KACLx7B,GAAUjU,KAAKwvC,yBAIZ/hB,QAAQjpB,GACb,MAAM5G,EAAOoC,KAAKuvC,eAAe/qC,KAAK5G,KACtCoC,KAAKwvC,uBAAuB5xC,GAAQoC,KAAKqvC,MAAM7qC,KAAOA,EAGjDipB,YACL,MAAMib,EAAY1oC,KAAKqvC,MAAM7qC,KAAOxE,KAAKuvC,eAAe/qC,YACjDxE,KAAKwvC,uBAAuB9G,EAAS9qC,MAGvC6vB,UACL,OAAOztB,KAAKqvC,MAAM7qC,KAGbipB,oBAAoBxzB,EAAe+S,GACxC,MAAM0iB,EAAO1vB,KAAKqvC,MAAM5f,UAAUx1B,GAClC,OAAIye,GAAqB1L,GAEhB0iB,EAAK1iB,EAAK/U,QAAQ+U,EAAKrU,OAEzB+2B,EAAK1iB,GAGPygB,oBAAoBxzB,EAAe+S,EAAgBhU,EAAY0vC,GACpE,MAAMhZ,EAAO1vB,KAAKqvC,MAAM5f,UAAUx1B,GAE9B+S,IAASwN,GAASK,SAAW6U,EAAK/rB,UAAY8f,GAAWiM,EAAK/rB,UAEhE3D,KAAKsvC,mBAAmB5f,EAAK/rB,WAG3B+U,GAAqB1L,GAEvB0iB,EAAK1iB,EAAK/U,QAAQ+U,EAAKrU,OAASK,EACvBsgB,GAAuBtM,KAAmB,IAAVhU,EACzC02B,EAAK1iB,GAAQoH,GACX,GACAsb,EAAK1iB,GACL,CAAC4W,UAAM9mB,EAAWc,UAAMd,IAI1B4yB,EAAK1iB,GAAQhU,EAGfgH,KAAKwvC,uBAAuB9G,EAAS9qC,MAAQ5E,EAEzCgU,IAASwN,GAASK,UAEpB7a,KAAKsvC,mBAAmBt2C,IAAUgH,KAAKsvC,mBAAmBt2C,IAAU,GAAK,GAItEy0B,sBAAsBxzB,EAAe+S,EAAgB07B,GAC1D,MAAMhZ,EAAO1vB,KAAKqvC,MAAM5f,UAAUx1B,GAC9B+S,IAASwN,GAASK,SACpB7a,KAAKsvC,mBAAmB5f,EAAK/rB,WAI3B+U,GAAqB1L,GAEvB0iB,EAAK1iB,EAAK/U,QAAQ+U,EAAKrU,OAAS+vC,EAGhChZ,EAAK1iB,GAAQ07B,SAIR1oC,KAAKwvC,uBAAuB9G,EAAS9qC,MAGvC6vB,YAAY9pB,GAEjB,OAAO3D,KAAKsvC,mBAAmB3rC,GAAW,EAGrC8pB,qBAAqB9pB,GAE1B,OAAOgsB,GADe3vB,KAAK+qC,0BAA0BpnC,IAIhD8pB,eAEL,OAAOztB,KAAKqvC,MAAM5f,UAAU5Z,OAAO6Z,IAASc,GAAyBd,IAGhEjC,0BAA0B9pB,GAC/B,IAAK,IAAImsC,KAAgB9vC,KAAKqvC,MAAM5f,UAClC,GAAIqgB,EAAansC,UAAYA,EAC3B,OAAOmsC,EAMNriB,wBAAwBr2B,GAC7B,OAAO4I,KAAKqvC,MAAM5f,UAAUr4B,GAGvBq2B,cACL,OAAOoC,GAAY7vB,KAAKqvC,OAOnB5hB,aACL,OAAOuC,GAAWhwB,KAAKqvC,OAOlB5hB,iBACL,OAAO2C,GAAepwB,KAAKqvC,OAOtB5hB,kBACL,OAAO4C,GAAgBrwB,KAAKqvC,OAGvB5hB,YAAYwf,GACjB,GAAIA,EAAS,CACX,GAAI1uC,GAAS0uC,GACX,OAAOwB,GAAczuC,KAAKkqC,UAAW+C,GAEvC,MAAMmB,EAAgBpB,GAAaC,GACnC,OAAOsB,GAAcvuC,KAAKqvC,MAAOjB,EAAchd,QAASgd,EAAcrd,UAExE,OAAOwd,GAAcvuC,KAAKqvC,OAOrB5hB,OAAOxxB,GACZ,GAAIwnB,GAAWzjB,KAAKqvC,MAAM7qC,MAAO,OAAO,KAExC,IAAI6qB,EAAY,GA6BhB,OA5BApzB,EAAOA,GAAQ+D,KAAKqvC,MAAMpzC,QAExBozB,EAAKpzB,KAAOA,GAGV+D,KAAKqvC,MAAMtjC,YACbsjB,EAAKtjB,UAAY/L,KAAKqvC,MAAMtjC,WAG9BsjB,EAAK7qB,KAAOxE,KAAKqvC,MAAM7qC,KACvB6qB,EAAK3lB,SAAWwmB,GAAWlwB,KAAKkqC,UAAUza,UAAW,CAACvJ,OAAQlmB,KAAK0vC,QAASvf,aAAc,SAEtFnwB,KAAKqvC,MAAM/f,QACbD,EAAKC,MAAQtvB,KAAKqvC,MAAM/f,OAEtBtvB,KAAKqvC,MAAM9f,SACbF,EAAKE,OAASvvB,KAAKqvC,MAAM9f,QAEvBvvB,KAAKqvC,MAAM7f,aACbH,EAAKG,WAAaxvB,KAAKqvC,MAAM7f,YAE3BxvB,KAAKqvC,MAAMtkC,UACbskB,EAAKtkB,QAAU/K,KAAKqvC,MAAMtkC,SAExB/K,KAAKqvC,MAAM7mC,QACb6mB,EAAK7mB,MAAQxI,KAAKqvC,MAAM7mC,OAGJ,OAAlB6mB,EAAK3lB,SACA,OAEL1J,KAAKqvC,MAAMzf,QAAU5vB,KAAKyvC,KAAKlpB,qBACjC8I,EAAKO,OAASxb,GAAO,GAAIpU,KAAKyvC,KAAKlpB,kBAAmBvmB,KAAKqvC,MAAMzf,SAE5DP,GAGF5B,gBAAgBsiB,GACrB,OAAO/vC,KAAKovC,cAAcW,GAGrBtiB,gBAAgBsiB,EAAqBC,GAC1ChwC,KAAKovC,cAAcW,GAAeC,kEC9WtC,SAAgBniB,GAAU1vB,GACxB,GAAIA,EAAE8uC,QAAS,CACb,IAAIU,EAAa,CACfV,QAAS9uC,EAAE8uC,SAGT9uC,EAAE8xC,UACJtC,EAAKW,aAAenwC,EAAE8xC,SAGxB,IAAIC,EAAqB,CACvB7gB,KAAMpb,GAAU9V,EAAEkxB,MAClBse,KAAM,CAACA,IAWT,OARIxvC,EAAEgyC,WACJD,EAAYC,SAAWhyC,EAAEgyC,UAGvBhyC,EAAEyxB,SACJsgB,EAAYtgB,OAASzxB,EAAEyxB,QAGlBsgB,EAET,OAAOj8B,GAAU9V,0GCrBHiyC,GAAgBhwC,GAC9B,YAAuCtD,IAAhBsD,EAAM2tC,MAG/B,SAAgBsC,GAAwBnG,GACtC,IAAIoG,EAAUpG,EAAU6D,MAAM,GAC9B,KAAOuC,GAAWF,GAAaE,IAC7BA,EAAUA,EAAQvC,MAAM,GAE1B,OAAUuC,MCdAC,uEDiBZ,SAAgBC,EAAgBnC,EAAsBjyC,GACpD,OAAAtF,OAAAsL,OAAA,GACKisC,EAAK,CACRN,MAAOM,EAAMN,MAAMrvC,IAAI0B,GAASgwC,GAAahwC,GAAQowC,EAAUpwC,EAAMhE,GAAKA,EAAEgE,eErB1DqwC,GAGpBhjB,YAAYh2B,GACVuI,KAAKvI,KAAOA,EACZuI,KAAK0wC,WAAa1wC,KAAK2wC,YAKfljB,gBAAgBmjB,GACxB,MAAMn5C,EAAOuI,KAAKvI,KACZu4C,EAAQhwC,KAAK0wC,WAAWE,GAC9B,QAAc9zC,IAAVkzC,EACF,MAAO,CAACv4C,KAAAA,EAAMm5C,QAAAA,EAASZ,MAAAA,KDb7B,SAAYO,GACVA,EAAAA,EAAA,EAAIv9B,IAAwB,IAC5Bu9B,EAAAA,EAAA,MAAS,OAASv9B,IAAyB,QAC3Cu9B,EAAAA,EAAA,EAAIx9B,IAAoB,IAKxBw9B,EAAAA,EAAA,WAAa,iBAAsB,aAInCA,EAAAA,EAAA,WAAc,YAAc19B,IAAoB,aAChD09B,EAAAA,EAAA,EAAI19B,IAAmB,IACvB09B,EAAAA,EAAA,EAAIz9B,IAAmB,IACvBy9B,EAAAA,EAAA,EAAIxjB,GAAa/qB,KAAU,IAC3BuuC,EAAAA,EAAA,KAAO,KAAU,OAhBnB,CAAYA,KAAAA,GAAY,KAmBjB,MAAMM,GAAIN,GAAaM,EACjBC,GAAQP,GAAaO,MACrBC,GAAIR,GAAaQ,EACjBC,GAAaT,GAAaS,WAC1BC,GAAaV,GAAaU,WAC1BC,GAAIX,GAAaW,EACjB5N,GAAIiN,GAAajN,EACjB6N,GAAIZ,GAAaY,EACjBC,GAAOb,GAAaa,KAEjC,SAAgBC,GAAgBxf,GAC9B,GAAIA,EAAOhZ,IACT,OAAO03B,GAAaO,MACf,GAAIjf,EAAO/Y,SAAU,CAE1B,OAAO9H,GADO5E,GAAUylB,IACU0e,GAAaU,WAAaV,GAAaS,WAE3E,OAAOnf,EAAOp6B,KEzBT,MAAM65C,IAAY,GCyBzB,SAAgBC,GAAUC,EAAqBC,EAAqBC,EAAuBltC,GACzF,OAAOgtC,EAAQ,IAAMC,EAAQ,IAAMC,EAAe,IAAMltC,EClC1D,MAAMmtC,GAAU,CACd,ICMF,cAAgClB,GAC9BhjB,cACE2Z,MAAM,QAEE3Z,UAAUxhB,EAAmB,IACrCA,EAAGnV,OAAAsL,OAAA,GAAOikB,GAAyBpa,GACnC,IAAI+jC,EAAsB,GAuC1B,MArCsB,CACpB,CACEY,QAASE,GACT7kC,IAAK,oBAEP,CACE2kC,QAASG,GACT9kC,IAAK,yBAEP,CACE2kC,QAASI,GACT/kC,IAAK,yBAEP,CACE2kC,QAASK,GACThlC,IAAK,yBAEP,CACE2kC,QAASM,GACTjlC,IAAK,wBAEP,CACE2kC,QAAStN,GACTr3B,IAAK,yBAIK9R,QAAQy3C,IAChB3lC,EAAI2lC,EAAM3lC,OAASgH,EAErB+8B,EAAM4B,EAAMhB,QAAU,IAAM19B,IAAc,IACjCjH,EAAI2lC,EAAM3lC,OAASiH,IAE5B88B,EAAM4B,EAAMhB,QAAU,IAAM39B,IAAc,OAIvC+8B,EAGFviB,UAAUh2B,EAAoBkM,GACnC,OAAOlM,EAAO,IAAMkM,EAGf8pB,SAASkb,EAAuB7wC,EAAW4vC,GAChD,OAAOiB,EAAMW,eAAe50B,OAAO,CAACm9B,EAAUniB,KAC5C,GAAIC,GAAaD,IAASkC,GAAiBlC,GAAO,CAChD,MAAMj4B,EAAO45C,GAAgB3hB,GACvBkhB,EAAU5wC,KAAKuxC,UAAU95C,EAAMi4B,EAAK/rB,SACpCmuC,EAAe9xC,KAAK+xC,gBAAgBnB,GAEtCkB,GACFD,EAAS33C,KAAK43C,GAGlB,OAAOD,GACN,MDrEL,IEFF,cAAqCpB,GACnChjB,cACE2Z,MAAM,aAGE3Z,YACR,MAAO,CACL5pB,KAAM,EACNC,QAAS,EACTlB,MAAO,EACPG,QAAS,EACTI,KAAM,EACNC,MAAO,GAIJqqB,SAASkb,EAAuB7wC,EAAW4vC,GAYhD,OAXIiB,EAAM9Y,eACR8Y,EAAMW,eAAe50B,OAAO,CAACs9B,EAAWtiB,KACtC,GAAIkC,GAAiBlC,IAAUC,GAAaD,KAAUA,EAAKpjB,UAAY,CACrE,MAAMwlC,EAAe9xC,KAAK+xC,gBAAgBriB,EAAK/rB,QAAU,IACzD,GAAImuC,GAAgBA,EAAa9B,MAAQgC,EAAUhC,MACjD,OAAO8B,EAGX,OAAOE,GACN,CAACv6C,KAAM,YAAam5C,QAAS,eAAgBZ,OAAQ,IAEnD,KFzBT,IGFF,cAAiCS,GAC/BhjB,cACE2Z,MAAM,SAEE3Z,UAAUxhB,GAElB,IAAI+jC,EAAsB,GAU1B,OAXA/jC,EAAGnV,OAAAsL,OAAA,GAAOikB,GAAyBpa,IAG3Bgc,iBAAmBC,EAEzB8nB,EAAM5H,IAAmB,IAChBn8B,EAAIgc,iBAAmBmgB,IAEhC4H,EAAM9nB,IAAgB,KAGjB8nB,EAEFviB,SAASkb,EAAuB7wC,EAAW4vC,GAChD,OAAOiB,EAAMW,eAAe50B,OAAO,CAACm9B,EAAUniB,KAC5C,GAAIC,GAAaD,IAASkC,GAAiBlC,GAAO,CAChD,MAAMoiB,EAAe9xC,KAAK+xC,gBAAgBriB,EAAK/rB,SAC3CmuC,GACFD,EAAS33C,KAAK43C,GAGlB,OAAOD,GACN,MHxBL,kBDJ8BpB,GAC9BhjB,cACE2Z,MAAM,QAGE3Z,YACR,OA+BJ,WACE,MAAMwkB,EAAW,CAACpB,GAAGE,IAEfmB,EADW,CAACpB,GAAOG,GAAYC,GAAG5N,GAAG6N,IACT5xC,OAAO,CAAC6xC,KAE1C,IAAIe,EAAQ,GAEZF,EAAS93C,QAAQq3C,IACfS,EAAS93C,QAAQs3C,IAYft3C,GAVuB,CACrBsK,MAAO,EACPnB,MAAO,GACPoB,MAAO,GACPK,MAAO,EACPD,KAAM,EACNE,MAAO,EACPE,MAAO,EACPP,MAAO,KAEe,CAACqrC,EAAOxrC,KAC9B,MAAMosC,EAAUW,GAAUC,EAAOC,GAAO,EAAMjtC,GAC9C2tC,EAAMvB,GAAWZ,IAcnB71C,GATyB,CACvBsK,MAAO,EACPnB,MAAO,GACPoB,MAAO,GACPI,KAAM,EACNE,MAAO,EACPE,MAAO,EACPP,MAAO,KAEiB,CAACqrC,EAAOxrC,KAChC,MAAMosC,EAAUW,GAAUC,EAAOC,GAAO,EAAOjtC,GAC/C2tC,EAAMvB,GAAWZ,QAMvBiC,EAAS93C,QAAQq3C,IAEfU,EAAiB/3C,QAAQs3C,IAUvBt3C,GATqC,CACnCuK,KAAM,EACND,OAAQ,GACRnB,MAAO,GACPwB,KAAM,EACNE,MAAO,EACPE,MAAO,EACPP,MAAO,KAE6B,CAACqrC,EAAOxrC,KAC5C,MAAMosC,EAAUW,GAAUC,EAAOC,GAAO,EAAMjtC,GAC9C2tC,EAAMvB,GAAWZ,EAEjB,MAAMoC,EAAWb,GAAUE,EAAOD,GAAO,EAAMhtC,GAC/C2tC,EAAMC,GAAYpC,MAItB,CAACgB,IAAY72C,QAAQs3C,IAWnBt3C,GAVqC,CAEnCsK,MAAO,EACPnB,MAAO,GACPoB,MAAO,EACPI,KAAM,EACNE,MAAO,EACPE,MAAO,EACPP,MAAO,KAE6B,CAACqrC,EAAOxrC,KAC5C,MAAMosC,EAAUW,GAAUC,EAAOC,GAAO,EAAMjtC,GAC9C2tC,EAAMvB,GAAWZ,EAEjB,MAAMoC,EAAWb,GAAUE,EAAOD,GAAO,EAAMhtC,GAC/C2tC,EAAMC,GAAYpC,MAKtB,CAACoB,GAAM9N,GAAG4N,GAAGC,IAAGh3C,QAAQs3C,IAYtBt3C,GAXsB,CACpB2K,IAAK,EACLL,OAAQ,GACRC,MAAO,IACPpB,MAAO,GAEP0B,MAAO,EACPE,MAAO,EAEPP,MAAO,KAEc,CAACqrC,EAAOxrC,KAC7B,MAAMosC,EAAUW,GAAUC,EAAOC,GAAO,EAAOjtC,GAC/C2tC,EAAMvB,GAAWZ,EAGjB,MAAMoC,EAAWb,GAAUE,EAAOD,GAAO,EAAOhtC,GAChD2tC,EAAMC,GAAYpC,MAItB,CAACc,IAAO32C,QAAQs3C,IAYdt3C,GAXyB,CACvB2K,IAAK,EACLL,OAAQ,GACRC,MAAO,IACPpB,MAAO,GAEP0B,MAAO,GACPE,MAAO,GAEPP,MAAO,KAEiB,CAACqrC,EAAOxrC,KAChC,MAAMosC,EAAUW,GAAUC,EAAOC,GAAO,EAAOjtC,GAC/C2tC,EAAMvB,GAAWZ,EAGjB,MAAMoC,EAAWb,GAAUE,EAAOD,GAAO,EAAOhtC,GAChD2tC,EAAMC,GAAYpC,MAItB,CAACgB,GAAYC,IAAY92C,QAAQs3C,IAa/Bt3C,GAVyB,CACvB6K,KAAM,EACNE,MAAO,GACPJ,KAAM,GACNL,OAAQ,GACRC,MAAO,IACPpB,MAAO,GAEPqB,MAAO,KAEiB,CAACqrC,EAAOxrC,KAChC,MAAMosC,EAAUW,GAAUC,EAAOC,GAAO,EAAOjtC,GAC/C2tC,EAAMvB,GAAWZ,EAGjB,MAAMoC,EAAWb,GAAUE,EAAOD,GAAO,EAAOhtC,GAChD2tC,EAAMC,GAAYpC,QAKxB,CAACgB,IAAY72C,QAAQq3C,IACnB,CAACR,IAAY72C,QAAQs3C,IAEnB,MAAMY,EAAS,CACb5tC,MAAO,EACPM,MAAO,GACPzB,MAAO,GACPoB,MAAO,EACPI,KAAM,EACNE,MAAO,EACPE,MAAO,EACPP,MAAO,KAITxK,GAAQk4C,EAAQ,CAACrC,EAAOxrC,KACtB,MAAMosC,EAAUW,GAAUC,EAAOC,GAAO,EAAMjtC,GAC9C2tC,EAAMvB,GAAWZ,IAEnB71C,GAAQk4C,EAAQ,CAACrC,EAAOxrC,KACtB,MAAMosC,EAAUW,GAAUC,EAAOC,GAAO,EAAOjtC,GAC/C2tC,EAAMvB,GAAWZ,MAIrBkC,EAAiB/3C,QAAQs3C,IAEvB,MAAMa,EAAS,CACb5tC,KAAM,EACND,OAAQ,GACRnB,MAAO,GACPyB,MAAO,EACPD,KAAM,EACNE,MAAO,EACPE,MAAO,EACPP,MAAO,KAITxK,GAAQm4C,EAAQ,CAACtC,EAAOxrC,KACtB,MAAMosC,EAAUW,GAAUC,EAAOC,GAAO,EAAMjtC,GAC9C2tC,EAAMvB,GAAWZ,IAEnB71C,GAAQm4C,EAAQ,CAACtC,EAAOxrC,KACtB,MAAMosC,EAAUW,GAAUE,EAAOD,GAAO,EAAMhtC,GAC9C2tC,EAAMvB,GAAWZ,IAEnB71C,GAAQm4C,EAAQ,CAACtC,EAAOxrC,KACtB,MAAMosC,EAAUW,GAAUC,EAAOC,GAAO,EAAOjtC,GAC/C2tC,EAAMvB,GAAWZ,IAEnB71C,GAAQm4C,EAAQ,CAACtC,EAAOxrC,KACtB,MAAMosC,EAAUW,GAAUE,EAAOD,GAAO,EAAOhtC,GAC/C2tC,EAAMvB,GAAWZ,QAOvB,IAAK,MAAMwB,KAASU,EAClB,IAAK,MAAMT,KAASS,EAAkB,CAEpC,MAAMK,EAAS,CACb9tC,MAAO,EACPM,KAAM,EACNzB,MAAO,GACPoB,MAAO,EACPI,KAAM,EACNE,MAAO,EACPE,MAAO,EACPP,MAAO,KAGTxK,GAAQo4C,EAAQ,CAACvC,EAAOxrC,KACtB,MAAMosC,EAAUW,GAAUC,EAAOC,GAAO,EAAMjtC,GAC9C2tC,EAAMvB,GAAWZ,IAInB71C,GAAQo4C,EAAQ,CAACvC,EAAOxrC,KACtB,MAAMosC,EAAUW,GAAUC,EAAOC,GAAO,EAAOjtC,GAC/C2tC,EAAMvB,GAAWZ,IAKvB,OAAOmC,EAhREK,GAGF/kB,SAASkb,EAAuB7wC,EAAW4vC,GAChD,IAAIljC,EAAOmkC,EAAMU,UACb7kC,IAASolC,IAAeplC,IAASqlC,KACnCrlC,EAAOshB,IAET,MAAMglB,EAAQnC,EAAMoC,0BAA0B93B,GACxCu+B,EAAQ1G,EAAQuG,GAAgBvG,GAASsG,GAEzCpG,EAAQrC,EAAMoC,0BAA0B73B,GAKxC09B,EAAUY,EAAQ,KAJVxG,EAAQqG,GAAgBrG,GAASoG,IAIT,KAFlBzI,EAAM9Y,cAE+B,IAAMrrB,EACzDstC,EAAe9xC,KAAK+xC,gBAAgBnB,GAE1C,OAAIkB,EACK,CAACA,IAEVryC,QAAQ3B,MAAM,4BAA6B8yC,GACpC,MCxBT,IILF,cAAuCH,GACrChjB,cACE2Z,MAAM,eAGE3Z,YACR,MAAO,CACLglB,UAAW,EACXC,WAAY,GAITjlB,SAASkb,EAAuB7wC,EAAW4vC,GAChD,MAAMljC,EAAOmkC,EAAMU,UACnB,OAAOV,EAAMW,eAAe50B,OAAO,CAACi+B,EAAejjB,KACjD,GAAIC,GAAaD,IAASkC,GAAiBlC,GAAO,CAChD,MAAMkhB,EAAUpsC,EAAO,IAAMkrB,EAAK/rB,QAC5BmuC,EAAe9xC,KAAK+xC,gBAAgBnB,GACtCkB,GACFa,EAAcz4C,KAAK43C,GAGvB,OAAOa,GACN,MJjBL,IFQF,cAAuClC,GACrChjB,cACE2Z,MAAM,eAEE3Z,YACR,IAAI0kB,EAAQ,GAGZ,MAAMS,EAAgC,CACpCn0C,EAAG,EACH4D,EAAG,EACHc,MAAO,KACPP,OAAQ,KACRU,MAAO,EACPP,SAAU,EAEVK,MAAOkuC,GACPztC,IAAKytC,GACLxtC,OAAQwtC,GACR/tC,OAAQ,EAAI+tC,IAGd,CAACT,GAAGE,GAAGC,IAAY72C,QAAS1C,IAC1B6F,GAAKs1C,GAA+Bz4C,QAASwJ,IAC3CwuC,EAAMnyC,KAAKuxC,UAAU95C,EAAMkM,IAAYivC,EAA8BjvC,OAMzE,MAAMkvC,EAA6Bz+B,GAAO,GAAIw+B,EAA+B,CAC3E/uC,KAAM,IACNC,QAAS,IAETV,OAAQ,IACRE,MAAO,IACPC,QAAS,IAGX,CAACutC,GAAOG,GAAYC,IAAG/2C,QAAS1C,IAC9B6F,GAAKu1C,GAA4B14C,QAASwJ,IACxCwuC,EAAMnyC,KAAKuxC,UAAU95C,EAAMkM,IAAYkvC,EAA2BlvC,OAItE,MAAMmvC,EAA6B,CACjCr0C,EAAG,EACH4D,EAAG,EACHO,OAAQ,GACRQ,OAAQ,IACRS,KAAM,GACNC,QAAS,GACTR,MAAO,GAEPC,QAAS,EACTJ,MAAO,EACPJ,SAAU,KAWZ,OARAzF,GAAKw1C,GAA4B34C,QAASwJ,IACxCwuC,EAAMnyC,KAAKuxC,UAAUjO,GAAG3/B,IAAYmvC,EAA2BnvC,GAC/DwuC,EAAMnyC,KAAKuxC,UAAUJ,GAAGxtC,IAEtBzD,GAAS,CAAC,IAAK,IAAK,UAAWyD,IAAY,EACzCmvC,EAA2BnvC,GAAW,IAGrCwuC,EAGF1kB,UAAUh2B,EAAoBkM,GACnC,OAAOlM,EAAO,IAAMkM,EAGf8pB,SAASkb,EAAuBziB,EAAgBja,GACrD,MAAM8mC,EAAuBpK,EAAMW,eAAe50B,OAAO,CAAC0C,EAAGsY,KAC3D,GAAIC,GAAaD,IAASkC,GAAiBlC,GAAO,CAChD,MAAMsjB,EAAWxf,GAAkB9D,IAClCtY,EAAE47B,GAAY57B,EAAE47B,IAAa,IAAI94C,KAAKw1B,GAEzC,OAAOtY,GACN,IAEGy6B,EAA2B,GAoBjC,OAlBA13C,GAAQ44C,EAAuBxhB,IAC7B,MAAM0hB,EAAmB1hB,EAAM7c,OAAO,CAACw+B,EAAoBxjB,KACzD,GAAIC,GAAaD,IAASkC,GAAiBlC,GAAO,CAChD,MAAMj4B,EAAO45C,GAAgB3hB,GACvBkhB,EAAU5wC,KAAKuxC,UAAU95C,EAAMi4B,EAAK/rB,SACpCmuC,EAAe9xC,KAAK+xC,gBAAgBnB,GAE1C,GAAa,OAATsC,GAAiBpB,EAAa9B,MAAQkD,EAAKlD,MAC7C,OAAO8B,EAGX,OAAOoB,GACN,MAEHrB,EAAS33C,KAAK+4C,KAITpB,KExGX,SAAgBsB,GAAcxK,EAAuBziB,EAAgBja,GACnE,MAAM4lC,EAAWF,GAAQj9B,OAAO,CAACtY,EAAGg3C,KAClC,MAAMC,EAASD,EAAOE,SAAS3K,EAAOziB,EAAQja,GAC9C,OAAO7P,EAAEmD,OAAO8zC,IACf,IAEH,MAAO,CACLrD,MAAO6B,EAASn9B,OAAO,CAAChe,EAAG0F,IAClB1F,EAAI0F,EAAE4zC,MACZ,GACH6B,SAAUA,GK1BP,MAAMj0C,GAAO,qBAEpB,SAAgBoyC,GAAMrH,EAAuBziB,EAAgBja,GAC3D,MAAM2kC,EAOR,SAAmCjI,EAAuB7wC,EAAW4vC,GACnE,MAAMjY,EAAYkZ,EAAMW,eACxB,GAAIX,EAAM9Y,cAAe,CACvB,MAAM0jB,EAAmB7jB,GAErBC,GAAaD,KACXA,EAAKj4B,OAASub,KAAsB0c,EAAK7W,MAAQ6W,EAAKpjB,WACrDojB,EAAKj4B,OAASsb,KAAkB2c,EAAK5W,UAI5C,GAAIR,GAAKmX,EAAW8jB,GAGlB,MAAO,CACL97C,KAAMmG,GACNoyC,MAAO,GACPY,QAAS,iCAIb,GAAIt4B,GAAKmX,EAAWC,GAAQC,GAAaD,IAASiF,GAAYjF,IAAQ,CACpE,IAAI8jB,EAAWl7B,GAAKmX,EAAYC,GACtBC,GAAaD,IAA4B,UAAnBA,EAAKpjB,WAA0ByjB,GAAwBL,IAEnF+jB,EAASn7B,GAAKmX,EAAYC,GACrBC,GAAaD,MAAWA,EAAK7W,KAGtC,OAAI26B,EAGK,CACL/7C,KAAMmG,GACNoyC,MAAO,GACPY,QAAS,wBAEF6C,EAEF,CACLh8C,KAAMmG,GACNoyC,MAAO,GACPY,QAAS,wCAGJ,CACLn5C,KAAMmG,GACNoyC,MAAO,GACPY,QAAS,2CAKf,MAAO,CACLn5C,KAAMmG,GACNoyC,MAAO,GACPY,QAAS,+BAGX,OAAIt4B,GAAKmX,EAAWC,GAAQC,GAAaD,KAAUiF,GAAYjF,IAEtD,CACLj4B,KAAMmG,GACNoyC,MAAO,EACPY,QAAS,oBAIN,CACLn5C,KAAMmG,GACNoyC,MAAO,GACPY,QAAS,uBA9EG8C,CAA0B/K,GAC1C,MAAO,CACLqH,MAAOY,EAAQZ,MACf6B,SAAU,CAACjB,6CCGf,SAAgBZ,GAAMrH,EAAuBziB,EAAgBpuB,GAC3D,MAAM67C,EAAuBhL,EAAMG,cAAcW,0BAA0BnY,IAAI,SAC/E,IAAKqiB,EACH,MAAO,CACL3D,MAAO,EACP6B,SAAU,IAId,MAAMpiB,EAAYkZ,EAAMuB,UAAUza,UAC5BmkB,EAAY1tB,EAAO4e,aAAaztC,OAEhCw6C,EAA2B,GACjC,IAAIgC,EAAa,EAAGliC,EAAO,EAE3B,IAAK,IAAIva,EAAIu8C,EAAqBt8C,OAAS,EAAGD,GAAK,EAAGA,IAAK,CACzD,MAAM6C,EAAQ05C,EAAqBv8C,GAC7BsS,EAAW+lB,EAAUx1B,GAG3B,IAAI4E,EAEJ,IAAI8wB,GAAajmB,GAGf,SAFA7K,EAAQ6K,EAAS7K,MAKnB,MAAMi1C,EAAgBnL,EAAMG,cAAcrZ,UAAUx1B,GAAOq3B,IAAI,SACzDyiB,EAAa7tB,EAAOuO,YAAY51B,GAAO5E,MAEvC+1C,GAAU+D,EAAapiC,EAC7BkiC,GAAc7D,EAEd6B,EAAS33C,KAAK,CACZ81C,MAAOA,EACPv4C,KAAM,aACNm5C,iBAAkBkD,EAAcl2C,WAAWiB,OAAWk1C,qBAGxDpiC,GAAQiiC,EAGV,MAAO,CACL5D,MAAO6D,EACPhC,SAAUA,8BAvDM,wBCuCpB,IAAImC,GAA0C,GAK9C,SAAgBC,GAASr2C,EAAciZ,GACrCm9B,GAAgBp2C,GAAQiZ,EAG1B,SAAgBya,GAAI1zB,GAClB,OAAOo2C,GAAgBp2C,GAGzB,SAAgB+jC,GAAK0M,EAA4B6F,EAAchuB,EAAgB9mB,GAoB7E,OAnBK80C,EAAMvG,MAAQvuC,IAAU80C,EAAMvG,KAAKt2C,QAYtCg3C,EAAMN,MAAM5zC,QAASg6C,IACnBxS,GAAKwS,EAAiCD,EAAOhuB,EAAQ9mB,EAAQ,KAE3D80C,EAAMvG,KAAKvuC,GAAOkvC,cACpBD,EAAMN,MAAMxwC,KAAK62C,GAAuBF,EAAMvG,KAAKvuC,GAAOkvC,aAAcpoB,EAAQguB,EAAMtkB,WAfpFskB,EAAMjE,SAAWiE,EAAM/D,YACzB9B,EAAMN,MAAMxwC,KAAK82C,GAAkBH,EAAMjE,SAAWiE,EAAM/D,SAAUjqB,EAAQguB,EAAMtkB,SAC9EskB,EAAM/D,UACJ9B,EAAMN,MAAM12C,OAAS,GAEvBg3C,EAAMN,MAAMvwC,OAAO,IAapB6wC,EAGT,SAAgBgG,GAAkBz2C,EAAyBsoB,EAAgBja,GACzE,MAAO,CAACqoC,EAAoBC,IACtB32C,aAAgBV,MACXs3C,GAAmB52C,EAAM02C,EAAIC,EAAIruB,EAAQja,GAEzCuoC,GAAmB,CAAC52C,GAAO02C,EAAIC,EAAIruB,EAAQja,GAKxD,SAAgBmoC,GAAuBx2C,EAAyBsoB,EAAgBja,GAC9E,MAAO,CAACwoC,EAAyBC,KAC/B,MAAMJ,EAAKjE,GAAqBoE,GAC1BF,EAAKlE,GAAqBqE,GAChC,OAAI92C,aAAgBV,MACXs3C,GAAmB52C,EAAM02C,EAAIC,EAAIruB,EAAQja,GAEzCuoC,GAAmB,CAAC52C,GAAO02C,EAAIC,EAAIruB,EAAQja,IAKxD,SAASuoC,GAAmB52C,EAAgB02C,EAAoBC,EAAoBruB,EAAgBja,GAClG,IAAK,IAAI8jC,KAAenyC,EAAM,CAC5B,IAAI+2C,EAAkBrB,GAASiB,EAAIxE,EAAa7pB,EAAQja,GAAK+jC,MAAQsD,GAASgB,EAAIvE,EAAa7pB,EAAQja,GAAK+jC,MAC5G,GAAwB,IAApB2E,EACF,OAAOA,EAGX,OAAO,EAGT,SAAgBrB,GAASsB,EAAuB7E,EAAqB7pB,EAAgBja,GACnF,QAA2CnP,IAAvC83C,EAAMC,gBAAgB9E,GACxB,OAAO6E,EAAMC,gBAAgB9E,GAE/B,MACMC,EADK1e,GAAIye,EACDryC,CAAGk3C,EAAO1uB,EAAQja,GAEhC,OADA2oC,EAAME,gBAAgB/E,EAAaC,GAC5BA,EAITiE,GAD6B,gBACLd,IAExBc,GAASc,GAAkBC,IAC3Bf,GDzHoB,aCyHMgB,2JAJG,4CClHbxsB,GAAQ2jB,EAA6BlmB,EAAgBja,GACnE,IAAIipC,EAAiC,GAgBrC,OAfA9I,EAAYA,EAAU1tC,IAAI,SAASiqC,GAYjC,OAXI18B,EAAIyc,0CACNigB,EAgBN,SACEA,EACAziB,EACAgvB,EACAjpC,GAEA,CAACic,EAAahV,EAAWk1B,EAAgBn1B,GAAW9Y,QAAQwJ,IAC1DuxC,EAAUvxC,GAAWglC,EAAMoC,0BAA0BpnC,KAGvD,MAAMqnC,EAAQkK,EAAUhiC,GACxB,QAAcpW,IAAVkuC,GAAuBrb,GAAaqb,KAEpCkK,EAAUhtB,IACVhC,EAAOsf,YAAYwF,GAAS/+B,EAAIyc,wCAAwCC,gBACxE,MAMoB7rB,IAAhBkuC,EAAMnhC,QACRmhC,EAAMnhC,MAAQ,IAKhB,MAAMsrC,EAAa/oC,GAAU4+B,GACzBA,EAAMnhC,aAAyB/M,IAAfq4C,GAA4BnkC,GAAkBmkC,MAC1DnK,EAAMnhC,MAAqBuH,YAC9B45B,EAAMnhC,MAAqBuH,UAAY,KAMhD,MAAM05B,EAAQoK,EAAUjiC,GACxB,GAAI0c,GAAamb,KAEboK,EAAU9M,IACVliB,EAAOsf,YAAYsF,GAAS7+B,EAAIyc,wCAAwCC,gBACxE,MAEoB7rB,IAAhBguC,EAAMjhC,QACRihC,EAAMjhC,MAAQ,IAKhB,MAAMurC,EAAahpC,GAAU0+B,GACzBA,EAAMjhC,aAAyB/M,IAAfs4C,GAA4BpkC,GAAkBokC,MAC1DtK,EAAMjhC,MAAqBuH,YAC9B05B,EAAMjhC,MAAqBuH,UAAY,KAMhD,OAAOu3B,EA1EKjgB,CAAwCigB,EAAOziB,EAAQgvB,EAAWjpC,IAGxEA,EAAI2c,sCACN+f,EAyEN,SACEA,EACAziB,EACAgvB,EACAjpC,GAEAipC,EAAU1hC,GAAiBm1B,EAAMoC,0BAA0Bv3B,GAE3D,MAAM63B,EAAY6J,EAAU1hC,GAE1Bmc,GAAa0b,SACCvuC,IAAduuC,IACCA,EAAU5zC,OAASqb,IAAgBu4B,EAAU5zC,OAASs1B,GAAa/qB,MACpEkkB,EAAOsf,YAAY6F,GAAap/B,EAAI2c,oCAAoCD,sBAEhD7rB,IAApBuuC,EAAUxhC,QACZwhC,EAAUxhC,MAAQ,IAGhBwhC,EAAUxhC,QACNwhC,EAAUxhC,MAAqBsH,QAClCk6B,EAAUxhC,MAAqBwH,OAASpF,EAAI2c,oCAAoCC,WAKvF,OAAO8f,EAnGK/f,CAAoC+f,EAAOziB,EAAQgvB,EAAWjpC,IAGpEA,EAAI6c,6CACN6f,EAkGN,SACEA,EACAziB,EACAgvB,EACAjpC,GAMA,GAJA,CAACm8B,EAAgBn1B,EAAWC,GAAW/Y,QAAQwJ,IAC7CuxC,EAAUvxC,GAAWglC,EAAMoC,0BAA0BpnC,UAGrB7G,IAA9Bo4C,EAAU9M,GAA+B,CAC3C,MAAM0C,EAAQoK,EAAUjiC,GAClB+3B,EAAQkK,EAAUhiC,GAEtByc,GAAamb,IACbnb,GAAaqb,SACHluC,IAAVkuC,GACAA,EAAMnsC,OACNmS,GAAkB5E,GAAU4+B,UAEdluC,IAAVguC,GACE5kB,EAAOsf,YAAYwF,GAAS/+B,EAAI6c,2CAA2CH,sBAC1D7rB,IAAfguC,EAAM7xB,OACR6xB,EAAM7xB,KAAO,IAGX6xB,EAAM7xB,OAAU6xB,EAAM7xB,KAAmB1T,SAC1CulC,EAAM7xB,KAAmB1T,OAAS,QAO7C,OAAOojC,EApIK7f,CAA2C6f,EAAOziB,EAAQgvB,EAAWjpC,IAExE08B,aCfK0M,GAASvlB,EAAkB5J,EAAgBja,EAAmBoa,IAE5E,MAAMsiB,EAAQuG,GAAeoG,MAAMxlB,EAAO5J,EAAQja,GAC5C68B,EAAgBH,EAAMG,cAI5B,IAAIsD,EAAY,CAACzD,GAYjB,OAXA18B,EAAIwa,mBAAmBtsB,QAASo7C,IAC9B,MAAMvoC,EAAOkN,GAAQq7B,GAErB,GAAIzM,EAAcgB,YAAY98B,GAAO,CAEnC,MACMwoC,EADatJ,GAAcl/B,EACjByoC,CAAW3M,EAAe5iB,EAAQja,GAClDmgC,EAAYA,EAAU13B,OAAO8gC,EAAS,QAItCvpC,EAAIwc,SAC2C,OAA5Cxc,EAAI2c,qCAC4C,OAAhD3c,EAAIyc,yCAC+C,OAAnDzc,EAAI6c,2CAKJsjB,EAJI3jB,GAAQ2jB,EAAWlmB,EAAQja,4ICvBd9N,EAAU+nB,EAAgB0J,GAiBlD,MAAO,CACLskB,MAdF/1C,EAACrH,OAAAsL,OAAA,GACIyrB,GAAU1vB,GAAE,CACfyxB,OAAM94B,OAAAsL,OAAA,GACDikB,GACAuJ,EACAzxB,EAAEyxB,UAUP9M,OAJa6e,GADSgM,GADN0H,GAASl3C,EAAEkxB,KAAMnJ,EAAQ/nB,EAAEyxB,QACLzxB,EAAEwvC,MACLxvC,EAAG+nB,EAAQ","file":"build/compassql.min.js.map","sourcesContent":["/*! *****************************************************************************\r\nCopyright (c) Microsoft Corporation. All rights reserved.\r\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use\r\nthis file except in compliance with the License. You may obtain a copy of the\r\nLicense at http://www.apache.org/licenses/LICENSE-2.0\r\n\r\nTHIS CODE IS PROVIDED ON AN *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\r\nKIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED\r\nWARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,\r\nMERCHANTABLITY OR NON-INFRINGEMENT.\r\n\r\nSee the Apache Version 2.0 License for specific language governing permissions\r\nand limitations under the License.\r\n***************************************************************************** */\r\n/* global Reflect, Promise */\r\n\r\nvar extendStatics = function(d, b) {\r\n    extendStatics = Object.setPrototypeOf ||\r\n        ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\r\n        function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\r\n    return extendStatics(d, b);\r\n};\r\n\r\nexport function __extends(d, b) {\r\n    extendStatics(d, b);\r\n    function __() { this.constructor = d; }\r\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\r\n}\r\n\r\nexport var __assign = function() {\r\n    __assign = Object.assign || function __assign(t) {\r\n        for (var s, i = 1, n = arguments.length; i < n; i++) {\r\n            s = arguments[i];\r\n            for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];\r\n        }\r\n        return t;\r\n    }\r\n    return __assign.apply(this, arguments);\r\n}\r\n\r\nexport function __rest(s, e) {\r\n    var t = {};\r\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\r\n        t[p] = s[p];\r\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\r\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) if (e.indexOf(p[i]) < 0)\r\n            t[p[i]] = s[p[i]];\r\n    return t;\r\n}\r\n\r\nexport function __decorate(decorators, target, key, desc) {\r\n    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\r\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\r\n    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\r\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\r\n}\r\n\r\nexport function __param(paramIndex, decorator) {\r\n    return function (target, key) { decorator(target, key, paramIndex); }\r\n}\r\n\r\nexport function __metadata(metadataKey, metadataValue) {\r\n    if (typeof Reflect === \"object\" && typeof Reflect.metadata === \"function\") return Reflect.metadata(metadataKey, metadataValue);\r\n}\r\n\r\nexport function __awaiter(thisArg, _arguments, P, generator) {\r\n    return new (P || (P = Promise))(function (resolve, reject) {\r\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\r\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\r\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\r\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\r\n    });\r\n}\r\n\r\nexport function __generator(thisArg, body) {\r\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\r\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\r\n    function verb(n) { return function (v) { return step([n, v]); }; }\r\n    function step(op) {\r\n        if (f) throw new TypeError(\"Generator is already executing.\");\r\n        while (_) try {\r\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\r\n            if (y = 0, t) op = [op[0] & 2, t.value];\r\n            switch (op[0]) {\r\n                case 0: case 1: t = op; break;\r\n                case 4: _.label++; return { value: op[1], done: false };\r\n                case 5: _.label++; y = op[1]; op = [0]; continue;\r\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\r\n                default:\r\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\r\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\r\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\r\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\r\n                    if (t[2]) _.ops.pop();\r\n                    _.trys.pop(); continue;\r\n            }\r\n            op = body.call(thisArg, _);\r\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\r\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\r\n    }\r\n}\r\n\r\nexport function __exportStar(m, exports) {\r\n    for (var p in m) if (!exports.hasOwnProperty(p)) exports[p] = m[p];\r\n}\r\n\r\nexport function __values(o) {\r\n    var m = typeof Symbol === \"function\" && o[Symbol.iterator], i = 0;\r\n    if (m) return m.call(o);\r\n    return {\r\n        next: function () {\r\n            if (o && i >= o.length) o = void 0;\r\n            return { value: o && o[i++], done: !o };\r\n        }\r\n    };\r\n}\r\n\r\nexport function __read(o, n) {\r\n    var m = typeof Symbol === \"function\" && o[Symbol.iterator];\r\n    if (!m) return o;\r\n    var i = m.call(o), r, ar = [], e;\r\n    try {\r\n        while ((n === void 0 || n-- > 0) && !(r = i.next()).done) ar.push(r.value);\r\n    }\r\n    catch (error) { e = { error: error }; }\r\n    finally {\r\n        try {\r\n            if (r && !r.done && (m = i[\"return\"])) m.call(i);\r\n        }\r\n        finally { if (e) throw e.error; }\r\n    }\r\n    return ar;\r\n}\r\n\r\nexport function __spread() {\r\n    for (var ar = [], i = 0; i < arguments.length; i++)\r\n        ar = ar.concat(__read(arguments[i]));\r\n    return ar;\r\n}\r\n\r\nexport function __await(v) {\r\n    return this instanceof __await ? (this.v = v, this) : new __await(v);\r\n}\r\n\r\nexport function __asyncGenerator(thisArg, _arguments, generator) {\r\n    if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\r\n    var g = generator.apply(thisArg, _arguments || []), i, q = [];\r\n    return i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i;\r\n    function verb(n) { if (g[n]) i[n] = function (v) { return new Promise(function (a, b) { q.push([n, v, a, b]) > 1 || resume(n, v); }); }; }\r\n    function resume(n, v) { try { step(g[n](v)); } catch (e) { settle(q[0][3], e); } }\r\n    function step(r) { r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r); }\r\n    function fulfill(value) { resume(\"next\", value); }\r\n    function reject(value) { resume(\"throw\", value); }\r\n    function settle(f, v) { if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]); }\r\n}\r\n\r\nexport function __asyncDelegator(o) {\r\n    var i, p;\r\n    return i = {}, verb(\"next\"), verb(\"throw\", function (e) { throw e; }), verb(\"return\"), i[Symbol.iterator] = function () { return this; }, i;\r\n    function verb(n, f) { i[n] = o[n] ? function (v) { return (p = !p) ? { value: __await(o[n](v)), done: n === \"return\" } : f ? f(v) : v; } : f; }\r\n}\r\n\r\nexport function __asyncValues(o) {\r\n    if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\r\n    var m = o[Symbol.asyncIterator], i;\r\n    return m ? m.call(o) : (o = typeof __values === \"function\" ? __values(o) : o[Symbol.iterator](), i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i);\r\n    function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }\r\n    function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }\r\n}\r\n\r\nexport function __makeTemplateObject(cooked, raw) {\r\n    if (Object.defineProperty) { Object.defineProperty(cooked, \"raw\", { value: raw }); } else { cooked.raw = raw; }\r\n    return cooked;\r\n};\r\n\r\nexport function __importStar(mod) {\r\n    if (mod && mod.__esModule) return mod;\r\n    var result = {};\r\n    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) result[k] = mod[k];\r\n    result.default = mod;\r\n    return result;\r\n}\r\n\r\nexport function __importDefault(mod) {\r\n    return (mod && mod.__esModule) ? mod : { default: mod };\r\n}\r\n","var clone = (function() {\n'use strict';\n\nfunction _instanceof(obj, type) {\n  return type != null && obj instanceof type;\n}\n\nvar nativeMap;\ntry {\n  nativeMap = Map;\n} catch(_) {\n  // maybe a reference error because no `Map`. Give it a dummy value that no\n  // value will ever be an instanceof.\n  nativeMap = function() {};\n}\n\nvar nativeSet;\ntry {\n  nativeSet = Set;\n} catch(_) {\n  nativeSet = function() {};\n}\n\nvar nativePromise;\ntry {\n  nativePromise = Promise;\n} catch(_) {\n  nativePromise = function() {};\n}\n\n/**\n * Clones (copies) an Object using deep copying.\n *\n * This function supports circular references by default, but if you are certain\n * there are no circular references in your object, you can save some CPU time\n * by calling clone(obj, false).\n *\n * Caution: if `circular` is false and `parent` contains circular references,\n * your program may enter an infinite loop and crash.\n *\n * @param `parent` - the object to be cloned\n * @param `circular` - set to true if the object to be cloned may contain\n *    circular references. (optional - true by default)\n * @param `depth` - set to a number if the object is only to be cloned to\n *    a particular depth. (optional - defaults to Infinity)\n * @param `prototype` - sets the prototype to be used when cloning an object.\n *    (optional - defaults to parent prototype).\n * @param `includeNonEnumerable` - set to true if the non-enumerable properties\n *    should be cloned as well. Non-enumerable properties on the prototype\n *    chain will be ignored. (optional - false by default)\n*/\nfunction clone(parent, circular, depth, prototype, includeNonEnumerable) {\n  if (typeof circular === 'object') {\n    depth = circular.depth;\n    prototype = circular.prototype;\n    includeNonEnumerable = circular.includeNonEnumerable;\n    circular = circular.circular;\n  }\n  // maintain two arrays for circular references, where corresponding parents\n  // and children have the same index\n  var allParents = [];\n  var allChildren = [];\n\n  var useBuffer = typeof Buffer != 'undefined';\n\n  if (typeof circular == 'undefined')\n    circular = true;\n\n  if (typeof depth == 'undefined')\n    depth = Infinity;\n\n  // recurse this function so we don't reset allParents and allChildren\n  function _clone(parent, depth) {\n    // cloning null always returns null\n    if (parent === null)\n      return null;\n\n    if (depth === 0)\n      return parent;\n\n    var child;\n    var proto;\n    if (typeof parent != 'object') {\n      return parent;\n    }\n\n    if (_instanceof(parent, nativeMap)) {\n      child = new nativeMap();\n    } else if (_instanceof(parent, nativeSet)) {\n      child = new nativeSet();\n    } else if (_instanceof(parent, nativePromise)) {\n      child = new nativePromise(function (resolve, reject) {\n        parent.then(function(value) {\n          resolve(_clone(value, depth - 1));\n        }, function(err) {\n          reject(_clone(err, depth - 1));\n        });\n      });\n    } else if (clone.__isArray(parent)) {\n      child = [];\n    } else if (clone.__isRegExp(parent)) {\n      child = new RegExp(parent.source, __getRegExpFlags(parent));\n      if (parent.lastIndex) child.lastIndex = parent.lastIndex;\n    } else if (clone.__isDate(parent)) {\n      child = new Date(parent.getTime());\n    } else if (useBuffer && Buffer.isBuffer(parent)) {\n      if (Buffer.allocUnsafe) {\n        // Node.js >= 4.5.0\n        child = Buffer.allocUnsafe(parent.length);\n      } else {\n        // Older Node.js versions\n        child = new Buffer(parent.length);\n      }\n      parent.copy(child);\n      return child;\n    } else if (_instanceof(parent, Error)) {\n      child = Object.create(parent);\n    } else {\n      if (typeof prototype == 'undefined') {\n        proto = Object.getPrototypeOf(parent);\n        child = Object.create(proto);\n      }\n      else {\n        child = Object.create(prototype);\n        proto = prototype;\n      }\n    }\n\n    if (circular) {\n      var index = allParents.indexOf(parent);\n\n      if (index != -1) {\n        return allChildren[index];\n      }\n      allParents.push(parent);\n      allChildren.push(child);\n    }\n\n    if (_instanceof(parent, nativeMap)) {\n      parent.forEach(function(value, key) {\n        var keyChild = _clone(key, depth - 1);\n        var valueChild = _clone(value, depth - 1);\n        child.set(keyChild, valueChild);\n      });\n    }\n    if (_instanceof(parent, nativeSet)) {\n      parent.forEach(function(value) {\n        var entryChild = _clone(value, depth - 1);\n        child.add(entryChild);\n      });\n    }\n\n    for (var i in parent) {\n      var attrs;\n      if (proto) {\n        attrs = Object.getOwnPropertyDescriptor(proto, i);\n      }\n\n      if (attrs && attrs.set == null) {\n        continue;\n      }\n      child[i] = _clone(parent[i], depth - 1);\n    }\n\n    if (Object.getOwnPropertySymbols) {\n      var symbols = Object.getOwnPropertySymbols(parent);\n      for (var i = 0; i < symbols.length; i++) {\n        // Don't need to worry about cloning a symbol because it is a primitive,\n        // like a number or string.\n        var symbol = symbols[i];\n        var descriptor = Object.getOwnPropertyDescriptor(parent, symbol);\n        if (descriptor && !descriptor.enumerable && !includeNonEnumerable) {\n          continue;\n        }\n        child[symbol] = _clone(parent[symbol], depth - 1);\n        if (!descriptor.enumerable) {\n          Object.defineProperty(child, symbol, {\n            enumerable: false\n          });\n        }\n      }\n    }\n\n    if (includeNonEnumerable) {\n      var allPropertyNames = Object.getOwnPropertyNames(parent);\n      for (var i = 0; i < allPropertyNames.length; i++) {\n        var propertyName = allPropertyNames[i];\n        var descriptor = Object.getOwnPropertyDescriptor(parent, propertyName);\n        if (descriptor && descriptor.enumerable) {\n          continue;\n        }\n        child[propertyName] = _clone(parent[propertyName], depth - 1);\n        Object.defineProperty(child, propertyName, {\n          enumerable: false\n        });\n      }\n    }\n\n    return child;\n  }\n\n  return _clone(parent, depth);\n}\n\n/**\n * Simple flat clone using prototype, accepts only objects, usefull for property\n * override on FLAT configuration object (no nested props).\n *\n * USE WITH CAUTION! This may not behave as you wish if you do not know how this\n * works.\n */\nclone.clonePrototype = function clonePrototype(parent) {\n  if (parent === null)\n    return null;\n\n  var c = function () {};\n  c.prototype = parent;\n  return new c();\n};\n\n// private utility functions\n\nfunction __objToStr(o) {\n  return Object.prototype.toString.call(o);\n}\nclone.__objToStr = __objToStr;\n\nfunction __isDate(o) {\n  return typeof o === 'object' && __objToStr(o) === '[object Date]';\n}\nclone.__isDate = __isDate;\n\nfunction __isArray(o) {\n  return typeof o === 'object' && __objToStr(o) === '[object Array]';\n}\nclone.__isArray = __isArray;\n\nfunction __isRegExp(o) {\n  return typeof o === 'object' && __objToStr(o) === '[object RegExp]';\n}\nclone.__isRegExp = __isRegExp;\n\nfunction __getRegExpFlags(re) {\n  var flags = '';\n  if (re.global) flags += 'g';\n  if (re.ignoreCase) flags += 'i';\n  if (re.multiline) flags += 'm';\n  return flags;\n}\nclone.__getRegExpFlags = __getRegExpFlags;\n\nreturn clone;\n})();\n\nif (typeof module === 'object' && module.exports) {\n  module.exports = clone;\n}\n","'use strict';\n\nmodule.exports = function (data, opts) {\n    if (!opts) opts = {};\n    if (typeof opts === 'function') opts = { cmp: opts };\n    var cycles = (typeof opts.cycles === 'boolean') ? opts.cycles : false;\n\n    var cmp = opts.cmp && (function (f) {\n        return function (node) {\n            return function (a, b) {\n                var aobj = { key: a, value: node[a] };\n                var bobj = { key: b, value: node[b] };\n                return f(aobj, bobj);\n            };\n        };\n    })(opts.cmp);\n\n    var seen = [];\n    return (function stringify (node) {\n        if (node && node.toJSON && typeof node.toJSON === 'function') {\n            node = node.toJSON();\n        }\n\n        if (node === undefined) return;\n        if (typeof node == 'number') return isFinite(node) ? '' + node : 'null';\n        if (typeof node !== 'object') return JSON.stringify(node);\n\n        var i, out;\n        if (Array.isArray(node)) {\n            out = '[';\n            for (i = 0; i < node.length; i++) {\n                if (i) out += ',';\n                out += stringify(node[i]) || 'null';\n            }\n            return out + ']';\n        }\n\n        if (node === null) return 'null';\n\n        if (seen.indexOf(node) !== -1) {\n            if (cycles) return JSON.stringify('__cycle__');\n            throw new TypeError('Converting circular structure to JSON');\n        }\n\n        var seenIndex = seen.push(node) - 1;\n        var keys = Object.keys(node).sort(cmp && cmp(node));\n        out = '';\n        for (i = 0; i < keys.length; i++) {\n            var key = keys[i];\n            var value = stringify(node[key]);\n\n            if (!value) continue;\n            if (out) out += ',';\n            out += JSON.stringify(key) + ':' + value;\n        }\n        seen.splice(seenIndex, 1);\n        return '{' + out + '}';\n    })(data);\n};\n","export default function(fn, fields, name) {\n  fn.fields = fields || [];\n  fn.fname = name;\n  return fn;\n}\n\nexport function accessorName(fn) {\n  return fn == null ? null : fn.fname;\n}\n\nexport function accessorFields(fn) {\n  return fn == null ? null : fn.fields;\n}\n","export default function(message) {\n  throw Error(message);\n}\n","import error from './error';\n\nexport default function(p) {\n  var path = [],\n      q = null,\n      b = 0,\n      n = p.length,\n      s = '',\n      i, j, c;\n\n  p = p + '';\n\n  function push() {\n    path.push(s + p.substring(i, j));\n    s = '';\n    i = j + 1;\n  }\n\n  for (i=j=0; j<n; ++j) {\n    c = p[j];\n    if (c === '\\\\') {\n      s += p.substring(i, j);\n      i = ++j;\n    } else if (c === q) {\n      push();\n      q = null;\n      b = -1;\n    } else if (q) {\n      continue;\n    } else if (i === b && c === '\"') {\n      i = j + 1;\n      q = c;\n    } else if (i === b && c === \"'\") {\n      i = j + 1;\n      q = c;\n    } else if (c === '.' && !b) {\n      if (j > i) {\n        push();\n      } else {\n        i = j + 1;\n      }\n    } else if (c === '[') {\n      if (j > i) push();\n      b = i = j + 1;\n    } else if (c === ']') {\n      if (!b) error('Access path missing open bracket: ' + p);\n      if (b > 0) push();\n      b = 0;\n      i = j + 1;\n    }\n  }\n\n  if (b) error('Access path missing closing bracket: ' + p);\n  if (q) error('Access path missing closing quote: ' + p);\n\n  if (j > i) {\n    j++;\n    push();\n  }\n\n  return path;\n}\n","export default Array.isArray;\n","export default function(_) {\n  return _ === Object(_);\n}\n","export default function(_) {\n  return typeof _ === 'string';\n}\n","import isArray from './isArray';\nimport isObject from './isObject';\nimport isString from './isString';\n\nexport default function $(x) {\n  return isArray(x) ? '[' + x.map($) + ']'\n    : isObject(x) || isString(x) ?\n      // Output valid JSON and JS source strings.\n      // See http://timelessrepo.com/json-isnt-a-javascript-subset\n      JSON.stringify(x).replace('\\u2028','\\\\u2028').replace('\\u2029', '\\\\u2029')\n    : x;\n}\n","import accessor from './accessor';\nimport field from './field';\n\nvar empty = [];\n\nexport var id = field('id');\n\nexport var identity = accessor(function(_) { return _; }, empty, 'identity');\n\nexport var zero = accessor(function() { return 0; }, empty, 'zero');\n\nexport var one = accessor(function() { return 1; }, empty, 'one');\n\nexport var truthy = accessor(function() { return true; }, empty, 'true');\n\nexport var falsy = accessor(function() { return false; }, empty, 'false');\n","import accessor from './accessor';\nimport splitAccessPath from './splitAccessPath';\nimport stringValue from './stringValue';\n\nexport default function(field, name) {\n  var path = splitAccessPath(field),\n      code = 'return _[' + path.map(stringValue).join('][') + '];';\n\n  return accessor(\n    Function('_', code),\n    [(field = path.length===1 ? path[0] : field)],\n    name || field\n  );\n}\n","function log(method, level, input) {\n  var msg = [level].concat([].slice.call(input));\n  console[method](...msg); // eslint-disable-line no-console\n}\n\nexport var None  = 0;\nexport var Error = 1;\nexport var Warn  = 2;\nexport var Info  = 3;\nexport var Debug = 4;\n\nexport default function(_, method) {\n  var level = _ || None;\n  return {\n    level: function(_) {\n      if (arguments.length) {\n        level = +_;\n        return this;\n      } else {\n        return level;\n      }\n    },\n    error: function() {\n      if (level >= Error) log(method || 'error', 'ERROR', arguments);\n      return this;\n    },\n    warn: function() {\n      if (level >= Warn) log(method || 'warn', 'WARN', arguments);\n      return this;\n    },\n    info: function() {\n      if (level >= Info) log(method || 'log', 'INFO', arguments);\n      return this;\n    },\n    debug: function() {\n      if (level >= Debug) log(method || 'log', 'DEBUG', arguments);\n      return this;\n    }\n  }\n}\n","export default function(_) {\n  return typeof _ === 'boolean';\n}\n","export default function(_) {\n  for (var s={}, i=0, n=_.length; i<n; ++i) s[_[i]] = true;\n  return s;\n}\n","import {default as clone_} from 'clone';\nimport deepEqual_ from 'fast-deep-equal';\nimport stableStringify from 'fast-json-stable-stringify';\nimport {isArray, isNumber, isString, splitAccessPath, stringValue} from 'vega-util';\nimport {isLogicalAnd, isLogicalNot, isLogicalOr, LogicalOperand} from './logical';\n\nexport const deepEqual = deepEqual_;\nexport const duplicate = clone_;\n\n/**\n * Creates an object composed of the picked object properties.\n *\n * var object = {'a': 1, 'b': '2', 'c': 3};\n * pick(object, ['a', 'c']);\n * // → {'a': 1, 'c': 3}\n *\n */\nexport function pick<T extends object, K extends keyof T>(obj: T, props: K[]): Pick<T, K> {\n  const copy: any = {};\n  for (const prop of props) {\n    if (obj.hasOwnProperty(prop)) {\n      copy[prop] = obj[prop];\n    }\n  }\n  return copy;\n}\n\n/**\n * The opposite of _.pick; this method creates an object composed of the own\n * and inherited enumerable string keyed properties of object that are not omitted.\n */\nexport function omit<T extends object, K extends keyof T>(obj: T, props: K[]): Omit<T, K> {\n  const copy = {...(obj as any)};\n  for (const prop of props) {\n    delete copy[prop];\n  }\n  return copy;\n}\n\n/**\n * Monkey patch Set so that `stringify` produces a string representation of sets.\n */\nSet.prototype['toJSON'] = function() {\n  return `Set(${[...this].map(x => stableStringify(x)).join(',')})`;\n};\n\n/**\n * Converts any object to a string representation that can be consumed by humans.\n */\nexport const stringify = stableStringify;\n\n/**\n * Converts any object to a string of limited size, or a number.\n */\nexport function hash(a: any): string | number {\n  if (isNumber(a)) {\n    return a;\n  }\n\n  const str = isString(a) ? a : stableStringify(a);\n\n  // short strings can be used as hash directly, longer strings are hashed to reduce memory usage\n  if (str.length < 250) {\n    return str;\n  }\n\n  // from http://werxltd.com/wp/2010/05/13/javascript-implementation-of-javas-string-hashcode-method/\n  let h = 0;\n  for (let i = 0; i < str.length; i++) {\n    const char = str.charCodeAt(i);\n    h = (h << 5) - h + char;\n    h = h & h; // Convert to 32bit integer\n  }\n  return h;\n}\n\nexport function isNullOrFalse(x: any): x is false | null {\n  return x === false || x === null;\n}\n\nexport function contains<T>(array: T[], item: T) {\n  return array.indexOf(item) > -1;\n}\n\n/** Returns the array without the elements in item */\nexport function without<T>(array: T[], excludedItems: T[]) {\n  return array.filter(item => !contains(excludedItems, item));\n}\n\nexport function union<T>(array: T[], other: T[]) {\n  return array.concat(without(other, array));\n}\n\n/**\n * Returns true if any item returns true.\n */\nexport function some<T>(arr: T[], f: (d: T, k?: any, i?: any) => boolean) {\n  let i = 0;\n  for (const [k, a] of arr.entries()) {\n    if (f(a, k, i++)) {\n      return true;\n    }\n  }\n  return false;\n}\n\n/**\n * Returns true if all items return true.\n */\nexport function every<T>(arr: T[], f: (d: T, k?: any, i?: any) => boolean) {\n  let i = 0;\n  for (const [k, a] of arr.entries()) {\n    if (!f(a, k, i++)) {\n      return false;\n    }\n  }\n  return true;\n}\n\nexport function flatten<T>(arrays: T[][]): T[] {\n  return ([] as T[]).concat(...arrays);\n}\n\nexport function fill<T>(val: T, len: number) {\n  const arr = new Array<T>(len);\n  for (let i = 0; i < len; ++i) {\n    arr[i] = val;\n  }\n  return arr;\n}\n\n/**\n * Like TS Partial but applies recursively to all properties.\n */\nexport type DeepPartial<T> = {[P in keyof T]?: DeepPartial<T[P]>};\n\n/**\n * recursively merges src into dest\n */\nexport function mergeDeep<T>(dest: T, ...src: DeepPartial<T>[]): T {\n  for (const s of src) {\n    dest = deepMerge_(dest, s);\n  }\n  return dest;\n}\n\n// recursively merges src into dest\nfunction deepMerge_(dest: any, src: any) {\n  if (typeof src !== 'object' || src === null) {\n    return dest;\n  }\n\n  for (const p in src) {\n    if (!src.hasOwnProperty(p)) {\n      continue;\n    }\n    if (src[p] === undefined) {\n      continue;\n    }\n    if (typeof src[p] !== 'object' || isArray(src[p]) || src[p] === null) {\n      dest[p] = src[p];\n    } else if (typeof dest[p] !== 'object' || dest[p] === null) {\n      dest[p] = mergeDeep(isArray(src[p].constructor) ? [] : {}, src[p]);\n    } else {\n      mergeDeep(dest[p], src[p]);\n    }\n  }\n  return dest;\n}\n\nexport function unique<T>(values: T[], f: (item: T) => string | number): T[] {\n  const results: T[] = [];\n  const u = {};\n  let v: string | number;\n  for (const val of values) {\n    v = f(val);\n    if (v in u) {\n      continue;\n    }\n    u[v] = 1;\n    results.push(val);\n  }\n  return results;\n}\n\nexport interface Dict<T> {\n  [key: string]: T;\n}\n\n/**\n * Returns true if the two dictionaries disagree. Applies only to defined values.\n */\nexport function isEqual<T>(dict: Dict<T>, other: Dict<T>) {\n  const dictKeys = keys(dict);\n  const otherKeys = keys(other);\n  if (dictKeys.length !== otherKeys.length) {\n    return false;\n  }\n  for (const key of dictKeys) {\n    if (dict[key] !== other[key]) {\n      return false;\n    }\n  }\n  return true;\n}\n\nexport function setEqual<T>(a: Set<T>, b: Set<T>) {\n  if (a.size !== b.size) {\n    return false;\n  }\n  for (const e of a) {\n    if (!b.has(e)) {\n      return false;\n    }\n  }\n  return true;\n}\n\nexport function hasIntersection<T>(a: Set<T>, b: Set<T>) {\n  for (const key of a) {\n    if (b.has(key)) {\n      return true;\n    }\n  }\n  return false;\n}\n\nexport function prefixGenerator(a: Set<string>): Set<string> {\n  const prefixes = new Set<string>();\n  for (const x of a) {\n    const splitField = splitAccessPath(x);\n    // Wrap every element other than the first in `[]`\n    const wrappedWithAccessors = splitField.map((y, i) => (i === 0 ? y : `[${y}]`));\n    const computedPrefixes = wrappedWithAccessors.map((_, i) => wrappedWithAccessors.slice(0, i + 1).join(''));\n    computedPrefixes.forEach(y => prefixes.add(y));\n  }\n  return prefixes;\n}\n\nexport function fieldIntersection(a: Set<string>, b: Set<string>): boolean {\n  return hasIntersection(prefixGenerator(a), prefixGenerator(b));\n}\n\nexport function isNumeric(num: string | number) {\n  return !isNaN(num as any);\n}\n\nexport function differArray<T>(array: T[], other: T[]) {\n  if (array.length !== other.length) {\n    return true;\n  }\n\n  array.sort();\n  other.sort();\n\n  for (let i = 0; i < array.length; i++) {\n    if (other[i] !== array[i]) {\n      return true;\n    }\n  }\n\n  return false;\n}\n\n// This is a stricter version of Object.keys but with better types. See https://github.com/Microsoft/TypeScript/pull/12253#issuecomment-263132208\nexport const keys = Object.keys as <T>(o: T) => (Extract<keyof T, string>)[];\n\nexport function vals<T>(x: {[key: string]: T}): T[] {\n  const _vals: T[] = [];\n  for (const k in x) {\n    if (x.hasOwnProperty(k)) {\n      _vals.push(x[k]);\n    }\n  }\n  return _vals;\n}\n\nexport function entries<T>(x: {[key: string]: T}): {key: string; value: T}[] {\n  const _entries: {key: string; value: T}[] = [];\n  for (const k in x) {\n    if (x.hasOwnProperty(k)) {\n      _entries.push({\n        key: k,\n        value: x[k]\n      });\n    }\n  }\n  return _entries;\n}\n\n// Using mapped type to declare a collect of flags for a string literal type S\n// https://www.typescriptlang.org/docs/handbook/advanced-types.html#mapped-types\nexport type Flag<S extends string> = {[K in S]: 1};\n\nexport function flagKeys<S extends string>(f: Flag<S>): S[] {\n  return keys(f) as S[];\n}\n\nexport function isBoolean(b: any): b is boolean {\n  return b === true || b === false;\n}\n\n/**\n * Convert a string into a valid variable name\n */\nexport function varName(s: string): string {\n  // Replace non-alphanumeric characters (anything besides a-zA-Z0-9_) with _\n  const alphanumericS = s.replace(/\\W/g, '_');\n\n  // Add _ if the string has leading numbers.\n  return (s.match(/^\\d+/) ? '_' : '') + alphanumericS;\n}\n\nexport function logicalExpr<T>(op: LogicalOperand<T>, cb: (...args: any[]) => string): string {\n  if (isLogicalNot(op)) {\n    return '!(' + logicalExpr(op.not, cb) + ')';\n  } else if (isLogicalAnd(op)) {\n    return '(' + op.and.map((and: LogicalOperand<T>) => logicalExpr(and, cb)).join(') && (') + ')';\n  } else if (isLogicalOr(op)) {\n    return '(' + op.or.map((or: LogicalOperand<T>) => logicalExpr(or, cb)).join(') || (') + ')';\n  } else {\n    return cb(op);\n  }\n}\n\nexport type Omit<T, K extends keyof T> = Pick<T, Exclude<keyof T, K>>;\n\n/**\n * Delete nested property of an object, and delete the ancestors of the property if they become empty.\n */\nexport function deleteNestedProperty(obj: any, orderedProps: string[]) {\n  if (orderedProps.length === 0) {\n    return true;\n  }\n  const prop = orderedProps.shift();\n  if (deleteNestedProperty(obj[prop], orderedProps)) {\n    delete obj[prop];\n  }\n  return keys(obj).length === 0;\n}\n\nexport function titlecase(s: string) {\n  return s.charAt(0).toUpperCase() + s.substr(1);\n}\n\n/**\n * Converts a path to an access path with datum.\n * @param path The field name.\n * @param datum The string to use for `datum`.\n */\nexport function accessPathWithDatum(path: string, datum = 'datum') {\n  const pieces = splitAccessPath(path);\n  const prefixes = [];\n  for (let i = 1; i <= pieces.length; i++) {\n    const prefix = `[${pieces\n      .slice(0, i)\n      .map(stringValue)\n      .join('][')}]`;\n    prefixes.push(`${datum}${prefix}`);\n  }\n  return prefixes.join(' && ');\n}\n\n/**\n * Return access with datum to the flattened field.\n *\n * @param path The field name.\n * @param datum The string to use for `datum`.\n */\nexport function flatAccessWithDatum(path: string, datum: 'datum' | 'parent' | 'datum.datum' = 'datum') {\n  return `${datum}[${stringValue(splitAccessPath(path).join('.'))}]`;\n}\n\n/**\n * Replaces path accesses with access to non-nested field.\n * For example, `foo[\"bar\"].baz` becomes `foo\\\\.bar\\\\.baz`.\n */\nexport function replacePathInField(path: string) {\n  return `${splitAccessPath(path)\n    .map(p => p.replace('.', '\\\\.'))\n    .join('\\\\.')}`;\n}\n\n/**\n * Remove path accesses with access from field.\n * For example, `foo[\"bar\"].baz` becomes `foo.bar.baz`.\n */\nexport function removePathFromField(path: string) {\n  return `${splitAccessPath(path).join('.')}`;\n}\n\n/**\n * Count the depth of the path. Returns 1 for fields that are not nested.\n */\nexport function accessPathDepth(path: string) {\n  if (!path) {\n    return 0;\n  }\n  return splitAccessPath(path).length;\n}\n\n/**\n * This is a replacement for chained || for numeric properties or properties that respect null so that 0 will be included.\n */\nexport function getFirstDefined<T>(...args: T[]): T {\n  for (const arg of args) {\n    if (arg !== undefined) {\n      return arg;\n    }\n  }\n  return undefined;\n}\n\n// variable used to generate id\nlet idCounter = 42;\n\n/**\n * Returns a new random id every time it gets called.\n *\n * Has side effect!\n */\nexport function uniqueId(prefix?: string) {\n  const id = ++idCounter;\n  return prefix ? String(prefix) + id : id;\n}\n\n/**\n * Resets the id counter used in uniqueId. This can be useful for testing.\n */\nexport function resetIdCounter() {\n  idCounter = 42;\n}\n\nexport function internalField(name: string) {\n  return isInternalField(name) ? name : `__${name}`;\n}\n\nexport function isInternalField(name: string) {\n  return name.indexOf('__') === 0;\n}\n\n/**\n * Normalize angle to be within [0,360).\n */\nexport function normalizeAngle(angle: number) {\n  return ((angle % 360) + 360) % 360;\n}\n","/*\n * Constants and utilities for encoding channels (Visual variables)\n * such as 'x', 'y', 'color'.\n */\n\nimport {RangeType} from './compile/scale/type';\nimport {Encoding} from './encoding';\nimport {Mark} from './mark';\nimport {EncodingFacetMapping, EncodingFacetMapping as ExtendedFacetMapping} from './spec/facet';\nimport {Flag, flagKeys} from './util';\n\nexport type Channel = keyof Encoding<any> | keyof ExtendedFacetMapping<any>;\n\n// Facet\nexport const ROW: 'row' = 'row';\nexport const COLUMN: 'column' = 'column';\n\nexport const FACET: 'facet' = 'facet';\n\n// Position\nexport const X: 'x' = 'x';\nexport const Y: 'y' = 'y';\nexport const X2: 'x2' = 'x2';\nexport const Y2: 'y2' = 'y2';\n// Geo Position\nexport const LATITUDE: 'latitude' = 'latitude';\nexport const LONGITUDE: 'longitude' = 'longitude';\nexport const LATITUDE2: 'latitude2' = 'latitude2';\nexport const LONGITUDE2: 'longitude2' = 'longitude2';\n\n// Mark property with scale\nexport const COLOR: 'color' = 'color';\n\nexport const FILL: 'fill' = 'fill';\n\nexport const STROKE: 'stroke' = 'stroke';\n\nexport const SHAPE: 'shape' = 'shape';\nexport const SIZE: 'size' = 'size';\nexport const OPACITY: 'opacity' = 'opacity';\nexport const FILLOPACITY: 'fillOpacity' = 'fillOpacity';\n\nexport const STROKEOPACITY: 'strokeOpacity' = 'strokeOpacity';\n\nexport const STROKEWIDTH: 'strokeWidth' = 'strokeWidth';\n\n// Non-scale channel\nexport const TEXT: 'text' = 'text';\nexport const ORDER: 'order' = 'order';\nexport const DETAIL: 'detail' = 'detail';\nexport const KEY: 'key' = 'key';\n\nexport const TOOLTIP: 'tooltip' = 'tooltip';\nexport const HREF: 'href' = 'href';\n\nexport type PositionChannel = 'x' | 'y' | 'x2' | 'y2';\n\nexport type GeoPositionChannel = 'longitude' | 'latitude' | 'longitude2' | 'latitude2';\n\nexport function isGeoPositionChannel(c: Channel): c is GeoPositionChannel {\n  switch (c) {\n    case LATITUDE:\n    case LATITUDE2:\n    case LONGITUDE:\n    case LONGITUDE2:\n      return true;\n  }\n  return false;\n}\n\nexport function getPositionChannelFromLatLong(channel: GeoPositionChannel): PositionChannel {\n  switch (channel) {\n    case LATITUDE:\n      return 'y';\n    case LATITUDE2:\n      return 'y2';\n    case LONGITUDE:\n      return 'x';\n    case LONGITUDE2:\n      return 'x2';\n  }\n}\n\nexport const GEOPOSITION_CHANNEL_INDEX: Flag<GeoPositionChannel> = {\n  longitude: 1,\n  longitude2: 1,\n  latitude: 1,\n  latitude2: 1\n};\n\nexport const GEOPOSITION_CHANNELS = flagKeys(GEOPOSITION_CHANNEL_INDEX);\n\nconst UNIT_CHANNEL_INDEX: Flag<keyof Encoding<any>> = {\n  // position\n  x: 1,\n  y: 1,\n  x2: 1,\n  y2: 1,\n\n  ...GEOPOSITION_CHANNEL_INDEX,\n\n  // color\n  color: 1,\n  fill: 1,\n  stroke: 1,\n\n  // other non-position with scale\n  opacity: 1,\n  fillOpacity: 1,\n  strokeOpacity: 1,\n\n  strokeWidth: 1,\n  size: 1,\n  shape: 1,\n\n  // channels without scales\n  order: 1,\n  text: 1,\n  detail: 1,\n  key: 1,\n  tooltip: 1,\n  href: 1\n};\n\nexport type ColorChannel = 'color' | 'fill' | 'stroke';\n\nexport function isColorChannel(channel: Channel): channel is ColorChannel {\n  return channel === 'color' || channel === 'fill' || channel === 'stroke';\n}\n\nexport type FacetChannel = keyof EncodingFacetMapping<any>;\n\nconst FACET_CHANNEL_INDEX: Flag<keyof EncodingFacetMapping<any>> = {\n  row: 1,\n  column: 1,\n  facet: 1\n};\n\nexport const FACET_CHANNELS = flagKeys(FACET_CHANNEL_INDEX);\n\nconst CHANNEL_INDEX = {\n  ...UNIT_CHANNEL_INDEX,\n  ...FACET_CHANNEL_INDEX\n};\n\nexport const CHANNELS = flagKeys(CHANNEL_INDEX);\n\nconst {order: _o, detail: _d, ...SINGLE_DEF_CHANNEL_INDEX} = CHANNEL_INDEX;\nconst {order: _o1, detail: _d1, row: _r, column: _c, facet: _f, ...SINGLE_DEF_UNIT_CHANNEL_INDEX} = CHANNEL_INDEX;\n/**\n * Channels that cannot have an array of channelDef.\n * model.fieldDef, getFieldDef only work for these channels.\n *\n * (The only two channels that can have an array of channelDefs are \"detail\" and \"order\".\n * Since there can be multiple fieldDefs for detail and order, getFieldDef/model.fieldDef\n * are not applicable for them.  Similarly, selection projection won't work with \"detail\" and \"order\".)\n */\n\nexport const SINGLE_DEF_CHANNELS: SingleDefChannel[] = flagKeys(SINGLE_DEF_CHANNEL_INDEX);\n\nexport const SINGLE_DEF_UNIT_CHANNELS: SingleDefUnitChannel[] = flagKeys(SINGLE_DEF_UNIT_CHANNEL_INDEX);\n\n// Using the following line leads to TypeError: Cannot read property 'elementTypes' of undefined\n// when running the schema generator\n// export type SingleDefChannel = typeof SINGLE_DEF_CHANNELS[0];\n\nexport type SingleDefUnitChannel =\n  | 'x'\n  | 'y'\n  | 'x2'\n  | 'y2'\n  | 'longitude'\n  | 'latitude'\n  | 'longitude2'\n  | 'latitude2'\n  | 'color'\n  | 'fill'\n  | 'stroke'\n  | 'strokeWidth'\n  | 'size'\n  | 'shape'\n  | 'fillOpacity'\n  | 'strokeOpacity'\n  | 'opacity'\n  | 'text'\n  | 'tooltip'\n  | 'href'\n  | 'key';\n\nexport type SingleDefChannel = SingleDefUnitChannel | 'row' | 'column' | 'facet';\n\nexport function isSingleDefUnitChannel(str: string): str is SingleDefUnitChannel {\n  return !!SINGLE_DEF_UNIT_CHANNEL_INDEX[str];\n}\n\nexport function isChannel(str: string): str is Channel {\n  return !!CHANNEL_INDEX[str];\n}\n\nexport type SecondaryRangeChannel = 'x2' | 'y2' | 'latitude2' | 'longitude2';\n\nexport const SECONDARY_RANGE_CHANNEL: SecondaryRangeChannel[] = ['x2', 'y2', 'latitude2', 'longitude2'];\n\nexport function isSecondaryRangeChannel(c: Channel): c is SecondaryRangeChannel {\n  const main = getMainRangeChannel(c);\n  return main !== c;\n}\n\nexport function getMainRangeChannel(channel: Channel): Channel {\n  switch (channel) {\n    case 'x2':\n      return 'x';\n    case 'y2':\n      return 'y';\n    case 'latitude2':\n      return 'latitude';\n    case 'longitude2':\n      return 'longitude';\n  }\n  return channel;\n}\n\n// CHANNELS without COLUMN, ROW\nexport const UNIT_CHANNELS = flagKeys(UNIT_CHANNEL_INDEX);\n\n// NONPOSITION_CHANNELS = UNIT_CHANNELS without X, Y, X2, Y2;\nconst {\n  x: _x,\n  y: _y,\n  // x2 and y2 share the same scale as x and y\n  x2: _x2,\n  y2: _y2,\n  latitude: _latitude,\n  longitude: _longitude,\n  latitude2: _latitude2,\n  longitude2: _longitude2,\n  // The rest of unit channels then have scale\n  ...NONPOSITION_CHANNEL_INDEX\n} = UNIT_CHANNEL_INDEX;\n\nexport const NONPOSITION_CHANNELS = flagKeys(NONPOSITION_CHANNEL_INDEX);\nexport type NonPositionChannel = typeof NONPOSITION_CHANNELS[0];\n\n// POSITION_SCALE_CHANNELS = X and Y;\nconst POSITION_SCALE_CHANNEL_INDEX: {x: 1; y: 1} = {x: 1, y: 1};\nexport const POSITION_SCALE_CHANNELS = flagKeys(POSITION_SCALE_CHANNEL_INDEX);\nexport type PositionScaleChannel = typeof POSITION_SCALE_CHANNELS[0];\n\n// NON_POSITION_SCALE_CHANNEL = SCALE_CHANNELS without X, Y\nconst {\n  // x2 and y2 share the same scale as x and y\n  // text and tooltip have format instead of scale,\n  // href has neither format, nor scale\n  text: _t,\n  tooltip: _tt,\n  href: _hr,\n  // detail and order have no scale\n  detail: _dd,\n  key: _k,\n  order: _oo,\n  ...NONPOSITION_SCALE_CHANNEL_INDEX\n} = NONPOSITION_CHANNEL_INDEX;\nexport const NONPOSITION_SCALE_CHANNELS = flagKeys(NONPOSITION_SCALE_CHANNEL_INDEX);\nexport type NonPositionScaleChannel = typeof NONPOSITION_SCALE_CHANNELS[0];\n\nexport function isNonPositionScaleChannel(channel: Channel): channel is NonPositionScaleChannel {\n  return !!NONPOSITION_CHANNEL_INDEX[channel];\n}\n\n/**\n * @returns whether Vega supports legends for a particular channel\n */\nexport function supportLegend(channel: NonPositionScaleChannel) {\n  switch (channel) {\n    case COLOR:\n    case FILL:\n    case STROKE:\n    case SIZE:\n    case SHAPE:\n    case OPACITY:\n      return true;\n\n    case FILLOPACITY:\n    case STROKEOPACITY:\n    case STROKEWIDTH:\n      return false;\n  }\n}\n\n// Declare SCALE_CHANNEL_INDEX\nconst SCALE_CHANNEL_INDEX = {\n  ...POSITION_SCALE_CHANNEL_INDEX,\n  ...NONPOSITION_SCALE_CHANNEL_INDEX\n};\n\n/** List of channels with scales */\nexport const SCALE_CHANNELS = flagKeys(SCALE_CHANNEL_INDEX);\nexport type ScaleChannel = typeof SCALE_CHANNELS[0];\n\nexport function isScaleChannel(channel: Channel): channel is ScaleChannel {\n  return !!SCALE_CHANNEL_INDEX[channel];\n}\n\nexport type SupportedMark = {[mark in Mark]?: 'always' | 'binned'};\n\n/**\n * Return whether a channel supports a particular mark type.\n * @param channel  channel name\n * @param mark the mark type\n * @return whether the mark supports the channel\n */\nexport function supportMark(channel: Channel, mark: Mark) {\n  return getSupportedMark(channel)[mark];\n}\n\n/**\n * Return a dictionary showing whether a channel supports mark type.\n * @param channel\n * @return A dictionary mapping mark types to 'always', 'binned', or undefined\n */\nfunction getSupportedMark(channel: Channel): SupportedMark {\n  switch (channel) {\n    case COLOR:\n    case FILL:\n    case STROKE:\n    // falls through\n\n    case DETAIL:\n    case KEY:\n    case TOOLTIP:\n    case HREF:\n    case ORDER: // TODO: revise (order might not support rect, which is not stackable?)\n    case OPACITY:\n    case FILLOPACITY:\n    case STROKEOPACITY:\n    case STROKEWIDTH:\n    // falls through\n\n    case FACET:\n    case ROW: // falls through\n    case COLUMN:\n      return {\n        // all marks\n        point: 'always',\n        tick: 'always',\n        rule: 'always',\n        circle: 'always',\n        square: 'always',\n        bar: 'always',\n        rect: 'always',\n        line: 'always',\n        trail: 'always',\n        area: 'always',\n        text: 'always',\n        geoshape: 'always'\n      };\n    case X:\n    case Y:\n    case LATITUDE:\n    case LONGITUDE:\n      return {\n        // all marks except geoshape. geoshape does not use X, Y -- it uses a projection\n        point: 'always',\n        tick: 'always',\n        rule: 'always',\n        circle: 'always',\n        square: 'always',\n        bar: 'always',\n        rect: 'always',\n        line: 'always',\n        trail: 'always',\n        area: 'always',\n        text: 'always'\n      };\n    case X2:\n    case Y2:\n    case LATITUDE2:\n    case LONGITUDE2:\n      return {\n        rule: 'always',\n        bar: 'always',\n        rect: 'always',\n        area: 'always',\n        circle: 'binned',\n        point: 'binned',\n        square: 'binned',\n        tick: 'binned'\n      };\n    case SIZE:\n      return {\n        point: 'always',\n        tick: 'always',\n        rule: 'always',\n        circle: 'always',\n        square: 'always',\n        bar: 'always',\n        text: 'always',\n        line: 'always',\n        trail: 'always'\n      };\n    case SHAPE:\n      return {point: 'always', geoshape: 'always'};\n    case TEXT:\n      return {text: 'always'};\n  }\n}\n\nexport function rangeType(channel: Channel): RangeType {\n  switch (channel) {\n    case X:\n    case Y:\n    case SIZE:\n    case STROKEWIDTH:\n    case OPACITY:\n    case FILLOPACITY:\n    case STROKEOPACITY:\n\n    // X2 and Y2 use X and Y scales, so they similarly have continuous range. [falls through]\n    case X2:\n    case Y2:\n      return undefined;\n\n    case FACET:\n    case ROW:\n    case COLUMN:\n    case SHAPE:\n    // TEXT, TOOLTIP, and HREF have no scale but have discrete output [falls through]\n    case TEXT:\n    case TOOLTIP:\n    case HREF:\n      return 'discrete';\n\n    // Color can be either continuous or discrete, depending on scale type.\n    case COLOR:\n    case FILL:\n    case STROKE:\n      return 'flexible';\n\n    // No scale, no range type.\n\n    case LATITUDE:\n    case LONGITUDE:\n    case LATITUDE2:\n    case LONGITUDE2:\n    case DETAIL:\n    case KEY:\n    case ORDER:\n      return undefined;\n  }\n  /* istanbul ignore next: should never reach here. */\n  throw new Error('rangeType not implemented for ' + channel);\n}\n","import {\n  Align,\n  Axis as VgAxis,\n  AxisOrient,\n  BaseAxis,\n  FontStyle,\n  FontWeight,\n  LabelOverlap,\n  TextBaseline,\n  TitleAnchor\n} from 'vega';\nimport {DateTime} from './datetime';\nimport {Guide, GuideEncodingEntry, VlOnlyGuideConfig} from './guide';\nimport {Flag, flagKeys} from './util';\nimport {Color, LayoutAlign} from './vega.schema';\n\ntype BaseAxisNoSignals = AxisMixins &\n  BaseAxis<\n    number,\n    number,\n    boolean,\n    number | boolean,\n    string,\n    Color,\n    FontWeight,\n    FontStyle,\n    Align,\n    TextBaseline,\n    LayoutAlign,\n    LabelOverlap,\n    number[],\n    TitleAnchor\n  >;\n\n// Vega axis config is the same as vega axis base. If this is not the case, add specific type.\ntype VgAxisConfigNoSignals = BaseAxisNoSignals;\n\n// Change comments to be Vega-Lite specific\ninterface AxisMixins {\n  /**\n   * A boolean flag indicating if grid lines should be included as part of the axis\n   *\n   * __Default value:__ `true` for [continuous scales](https://vega.github.io/vega-lite/docs/scale.html#continuous) that are not binned; otherwise, `false`.\n   */\n  grid?: boolean;\n\n  /**\n   * Indicates if the first and last axis labels should be aligned flush with the scale range. Flush alignment for a horizontal axis will left-align the first label and right-align the last label. For vertical axes, bottom and top text baselines are applied instead. If this property is a number, it also indicates the number of pixels by which to offset the first and last labels; for example, a value of 2 will flush-align the first and last labels and also push them 2 pixels outward from the center of the axis. The additional adjustment can sometimes help the labels better visually group with corresponding axis ticks.\n   *\n   * __Default value:__ `true` for axis of a continuous x-scale. Otherwise, `false`.\n   */\n  labelFlush?: boolean | number;\n\n  /**\n   * The strategy to use for resolving overlap of axis labels. If `false` (the default), no overlap reduction is attempted. If set to `true` or `\"parity\"`, a strategy of removing every other label is used (this works well for standard linear axes). If set to `\"greedy\"`, a linear scan of the labels is performed, removing any labels that overlaps with the last visible label (this often works better for log-scaled axes).\n   *\n   * __Default value:__ `true` for non-nominal fields with non-log scales; `\"greedy\"` for log scales; otherwise `false`.\n   */\n  labelOverlap?: LabelOverlap;\n}\n\nexport interface AxisOrientMixins {\n  /**\n   * The orientation of the axis. One of `\"top\"`, `\"bottom\"`, `\"left\"` or `\"right\"`. The orientation can be used to further specialize the axis type (e.g., a y-axis oriented towards the right edge of the chart).\n   *\n   * __Default value:__ `\"bottom\"` for x-axes and `\"left\"` for y-axes.\n   */\n  orient?: AxisOrient;\n}\n\nexport type AxisConfig = VgAxisConfigNoSignals & VlOnlyGuideConfig & AxisOrientMixins;\n\nexport interface Axis extends AxisOrientMixins, BaseAxisNoSignals, Guide {\n  /**\n   * The offset, in pixels, by which to displace the axis from the edge of the enclosing group or data rectangle.\n   *\n   * __Default value:__ derived from the [axis config](https://vega.github.io/vega-lite/docs/config.html#facet-scale-config)'s `offset` (`0` by default)\n   */\n  offset?: number;\n\n  /**\n   * The anchor position of the axis in pixels. For x-axes with top or bottom orientation, this sets the axis group x coordinate. For y-axes with left or right orientation, this sets the axis group y coordinate.\n   *\n   * __Default value__: `0`\n   */\n  position?: number;\n\n  /**\n   * A desired number of ticks, for axes visualizing quantitative scales. The resulting number may be different so that values are \"nice\" (multiples of 2, 5, 10) and lie within the underlying scale's range.\n   * @minimum 0\n   *\n   * __Default value__: Determine using a formula `ceil(width/40)` for x and `ceil(height/40)` for y.\n   */\n  tickCount?: number;\n\n  /**\n   * The minimum desired step between axis ticks, in terms of scale domain values. For example, a value of `1` indicates that ticks should not be less than 1 unit apart. If `tickMinStep` is specified, the `tickCount` value will be adjusted, if necessary, to enforce the minimum step value.\n   *\n   * __Default value__: `undefined`\n   */\n  tickMinStep?: number;\n\n  /**\n   * Explicitly set the visible axis tick values.\n   */\n  values?: number[] | string[] | boolean[] | DateTime[];\n\n  /**\n   * A non-positive integer indicating z-index of the axis.\n   * If zindex is 0, axes should be drawn behind all chart elements.\n   * To put them in front, use `\"zindex = 1\"`.\n   *\n   * __Default value:__ `1` (in front of the marks) for actual axis and `0` (behind the marks) for grids.\n   *\n   * @TJS-type integer\n   * @minimum 0\n   */\n  zindex?: number;\n\n  /**\n   * Mark definitions for custom axis encoding.\n   *\n   * @hide\n   */\n  encoding?: AxisEncoding;\n}\n\nexport type AxisPart = keyof AxisEncoding;\nexport const AXIS_PARTS: AxisPart[] = ['domain', 'grid', 'labels', 'ticks', 'title'];\n\n/**\n * A dictionary listing whether a certain axis property is applicable for only main axes or only grid axes.\n * (Properties not listed are applicable for both)\n */\nexport const AXIS_PROPERTY_TYPE: {\n  // Using Mapped Type to declare type (https://www.typescriptlang.org/docs/handbook/advanced-types.html#mapped-types)\n  [k in keyof VgAxis]: 'main' | 'grid' | 'both'\n} = {\n  grid: 'grid',\n  gridColor: 'grid',\n  gridDash: 'grid',\n  gridOpacity: 'grid',\n  gridScale: 'grid',\n  gridWidth: 'grid',\n\n  orient: 'main',\n\n  bandPosition: 'both', // Need to be applied to grid axis too, so the grid will align with ticks.\n  domain: 'main',\n  domainColor: 'main',\n  domainOpacity: 'main',\n  domainWidth: 'main',\n  format: 'main',\n  formatType: 'main',\n  labelAlign: 'main',\n  labelAngle: 'main',\n  labelBaseline: 'main',\n  labelBound: 'main',\n  labelColor: 'main',\n  labelFlush: 'main',\n  labelFlushOffset: 'main',\n  labelFont: 'main',\n  labelFontSize: 'main',\n  labelFontWeight: 'main',\n  labelLimit: 'main',\n  labelOpacity: 'main',\n  labelOverlap: 'main',\n  labelPadding: 'main',\n  labels: 'main',\n  maxExtent: 'main',\n  minExtent: 'main',\n  offset: 'main',\n  position: 'main',\n  tickColor: 'main',\n  tickExtra: 'main',\n  tickOffset: 'both', // Need to be applied to grid axis too, so the grid will align with ticks.\n  tickOpacity: 'main',\n  tickRound: 'main',\n  ticks: 'main',\n  tickSize: 'main',\n  title: 'main',\n  titleAlign: 'main',\n  titleAngle: 'main',\n  titleBaseline: 'main',\n  titleColor: 'main',\n  titleFont: 'main',\n  titleFontSize: 'main',\n  titleFontWeight: 'main',\n  titleLimit: 'main',\n  titleOpacity: 'main',\n  titlePadding: 'main',\n  titleX: 'main',\n  titleY: 'main',\n\n  tickWidth: 'both',\n  tickCount: 'both',\n  values: 'both',\n  scale: 'both',\n  zindex: 'both' // this is actually set afterward, so it doesn't matter\n};\n\nexport interface AxisEncoding {\n  /**\n   * Custom encoding for the axis container.\n   */\n  axis?: GuideEncodingEntry;\n\n  /**\n   * Custom encoding for the axis domain rule mark.\n   */\n  domain?: GuideEncodingEntry;\n\n  /**\n   * Custom encoding for axis gridline rule marks.\n   */\n  grid?: GuideEncodingEntry;\n\n  /**\n   * Custom encoding for axis label text marks.\n   */\n  labels?: GuideEncodingEntry;\n\n  /**\n   * Custom encoding for axis tick rule marks.\n   */\n  ticks?: GuideEncodingEntry;\n\n  /**\n   * Custom encoding for the axis title text mark.\n   */\n  title?: GuideEncodingEntry;\n}\n\nconst COMMON_AXIS_PROPERTIES_INDEX: Flag<keyof (VgAxis | Axis)> = {\n  orient: 1, // other things can depend on orient\n\n  bandPosition: 1,\n  domain: 1,\n  domainColor: 1,\n  domainDash: 1,\n  domainDashOffset: 1,\n  domainOpacity: 1,\n  domainWidth: 1,\n  format: 1,\n  formatType: 1,\n  grid: 1,\n  gridColor: 1,\n  gridDash: 1,\n  gridDashOffset: 1,\n  gridOpacity: 1,\n  gridWidth: 1,\n  labelAlign: 1,\n  labelAngle: 1,\n  labelBaseline: 1,\n  labelBound: 1,\n  labelColor: 1,\n  labelFlush: 1,\n  labelFlushOffset: 1,\n  labelFont: 1,\n  labelFontSize: 1,\n  labelFontStyle: 1,\n  labelFontWeight: 1,\n  labelLimit: 1,\n  labelOpacity: 1,\n  labelOverlap: 1,\n  labelPadding: 1,\n  labels: 1,\n  labelSeparation: 1,\n  maxExtent: 1,\n  minExtent: 1,\n  offset: 1,\n  position: 1,\n  tickColor: 1,\n  tickCount: 1,\n  tickDash: 1,\n  tickDashOffset: 1,\n  tickExtra: 1,\n  tickMinStep: 1,\n  tickOffset: 1,\n  tickOpacity: 1,\n  tickRound: 1,\n  ticks: 1,\n  tickSize: 1,\n  tickWidth: 1,\n  title: 1,\n  titleAlign: 1,\n  titleAnchor: 1,\n  titleAngle: 1,\n  titleBaseline: 1,\n  titleColor: 1,\n  titleFont: 1,\n  titleFontSize: 1,\n  titleFontStyle: 1,\n  titleFontWeight: 1,\n  titleLimit: 1,\n  titleOpacity: 1,\n  titlePadding: 1,\n  titleX: 1,\n  titleY: 1,\n  values: 1,\n  zindex: 1\n};\n\nconst AXIS_PROPERTIES_INDEX: Flag<keyof Axis> = {\n  ...COMMON_AXIS_PROPERTIES_INDEX,\n  encoding: 1\n};\n\nconst VG_AXIS_PROPERTIES_INDEX: Flag<keyof VgAxis> = {\n  gridScale: 1,\n  scale: 1,\n  ...COMMON_AXIS_PROPERTIES_INDEX,\n  encode: 1\n};\n\nexport function isAxisProperty(prop: string): prop is keyof Axis {\n  return !!AXIS_PROPERTIES_INDEX[prop];\n}\n\nexport const VG_AXIS_PROPERTIES = flagKeys(VG_AXIS_PROPERTIES_INDEX);\n\n// Export for dependent projects\nexport const AXIS_PROPERTIES = flagKeys(AXIS_PROPERTIES_INDEX);\n\nexport interface AxisConfigMixins {\n  /**\n   * Axis configuration, which determines default properties for all `x` and `y` [axes](https://vega.github.io/vega-lite/docs/axis.html). For a full list of axis configuration options, please see the [corresponding section of the axis documentation](https://vega.github.io/vega-lite/docs/axis.html#config).\n   */\n  axis?: AxisConfig;\n\n  /**\n   * X-axis specific config.\n   */\n  axisX?: AxisConfig;\n\n  /**\n   * Y-axis specific config.\n   */\n  axisY?: AxisConfig;\n\n  /**\n   * Specific axis config for y-axis along the left edge of the chart.\n   */\n  axisLeft?: AxisConfig;\n\n  /**\n   * Specific axis config for y-axis along the right edge of the chart.\n   */\n  axisRight?: AxisConfig;\n\n  /**\n   * Specific axis config for x-axis along the top edge of the chart.\n   */\n  axisTop?: AxisConfig;\n\n  /**\n   * Specific axis config for x-axis along the bottom edge of the chart.\n   */\n  axisBottom?: AxisConfig;\n\n  /**\n   * Specific axis config for axes with \"band\" scales.\n   */\n  axisBand?: AxisConfig;\n}\n","import {\n  Align,\n  BaseLegend,\n  FontStyle,\n  FontWeight,\n  LabelOverlap,\n  Legend as VgLegend,\n  LegendConfig as VgLegendConfig,\n  LegendOrient,\n  Orient,\n  Orientation,\n  SymbolShape,\n  TextBaseline,\n  TitleAnchor\n} from 'vega';\nimport {DateTime} from './datetime';\nimport {Guide, GuideEncodingEntry, VlOnlyGuideConfig} from './guide';\nimport {Flag, flagKeys} from './util';\nimport {Color, LayoutAlign} from './vega.schema';\n\nexport type LegendConfig = LegendMixins &\n  VlOnlyGuideConfig &\n  VgLegendConfig<\n    number,\n    number,\n    string,\n    Color,\n    FontWeight,\n    FontStyle,\n    Align,\n    TextBaseline,\n    LayoutAlign,\n    LabelOverlap,\n    SymbolShape,\n    number[],\n    Orient,\n    TitleAnchor,\n    LegendOrient\n  > & {\n    /**\n     * Max legend length for a vertical gradient when `config.legend.gradientLength` is undefined.\n     *\n     * __Default value:__ `200`\n     */\n    gradientVerticalMaxLength?: number;\n\n    /**\n     * Min legend length for a vertical gradient when `config.legend.gradientLength` is undefined.\n     *\n     * __Default value:__ `100`\n     */\n    gradientVerticalMinLength?: number;\n\n    /**\n     * Max legend length for a horizontal gradient when `config.legend.gradientLength` is undefined.\n     *\n     * __Default value:__ `200`\n     */\n    gradientHorizontalMaxLength?: number;\n\n    /**\n     * Min legend length for a horizontal gradient when `config.legend.gradientLength` is undefined.\n     *\n     * __Default value:__ `100`\n     */\n    gradientHorizontalMinLength?: number;\n\n    /**\n     * The length in pixels of the primary axis of a color gradient. This value corresponds to the height of a vertical gradient or the width of a horizontal gradient.\n     *\n     * __Default value:__ `undefined`.  If `undefined`, the default gradient will be determined based on the following rules:\n     * - For vertical gradients, `clamp(plot_height, gradientVerticalMinLength, gradientVerticalMaxLength)`\n     * - For top-`orient`ed or bottom-`orient`ed horizontal gradients, `clamp(plot_width, gradientHorizontalMinLength, gradientHorizontalMaxLength)`\n     * - For other horizontal gradients, `gradientHorizontalMinLength`\n     *\n     * where `clamp(value, min, max)` restricts _value_ to be between the specified _min_ and _max_.\n     * @minimum 0\n     */\n    gradientLength?: number;\n  };\n\n/**\n * Properties of a legend or boolean flag for determining whether to show it.\n */\nexport interface Legend\n  extends BaseLegend<\n      number,\n      number,\n      string,\n      Color,\n      FontWeight,\n      FontStyle,\n      Align,\n      TextBaseline,\n      LayoutAlign,\n      LabelOverlap,\n      SymbolShape,\n      number[],\n      Orient,\n      TitleAnchor,\n      LegendOrient\n    >,\n    LegendMixins,\n    Guide {\n  /**\n   * Mark definitions for custom legend encoding.\n   *\n   * @hide\n   */\n  encoding?: LegendEncoding;\n\n  /**\n   * The desired number of tick values for quantitative legends.\n   */\n  tickCount?: number;\n\n  /**\n   * The minimum desired step between legend ticks, in terms of scale domain values. For example, a value of `1` indicates that ticks should not be less than 1 unit apart. If `tickMinStep` is specified, the `tickCount` value will be adjusted, if necessary, to enforce the minimum step value.\n   *\n   * __Default value__: `undefined`\n   */\n  tickMinStep?: number;\n\n  /**\n   * Explicitly set the visible legend values.\n   */\n  values?: (number | string | boolean | DateTime)[];\n\n  /**\n   * The type of the legend. Use `\"symbol\"` to create a discrete legend and `\"gradient\"` for a continuous color gradient.\n   *\n   * __Default value:__ `\"gradient\"` for non-binned quantitative fields and temporal fields; `\"symbol\"` otherwise.\n   */\n  type?: 'symbol' | 'gradient';\n\n  /**\n   * A non-positive integer indicating z-index of the legend.\n   * If zindex is 0, legend should be drawn behind all chart elements.\n   * To put them in front, use zindex = 1.\n   *\n   * @TJS-type integer\n   * @minimum 0\n   */\n  zindex?: number;\n\n  /**\n   * The direction of the legend, one of `\"vertical\"` or `\"horizontal\"`.\n   *\n   * __Default value:__\n   * - For top-/bottom-`orient`ed legends, `\"horizontal\"`\n   * - For left-/right-`orient`ed legends, `\"vertical\"`\n   * - For top/bottom-left/right-`orient`ed legends, `\"horizontal\"` for gradient legends and `\"vertical\"` for symbol legends.\n   */\n  direction?: Orientation;\n\n  /**\n   * The orientation of the legend, which determines how the legend is positioned within the scene. One of `\"left\"`, `\"right\"`, `\"top-left\"`, `\"top-right\"`, `\"bottom-left\"`, `\"bottom-right\"`, `\"none\"`.\n   *\n   * __Default value:__ `\"right\"`\n   */\n  orient?: LegendOrient;\n}\n\n// Change comments to be Vega-Lite specific\ninterface LegendMixins {\n  /**\n   * The strategy to use for resolving overlap of labels in gradient legends. If `false`, no overlap reduction is attempted. If set to `true` or `\"parity\"`, a strategy of removing every other label is used. If set to `\"greedy\"`, a linear scan of the labels is performed, removing any label that overlaps with the last visible label (this often works better for log-scaled axes).\n   *\n   * __Default value:__ `\"greedy\"` for `log scales otherwise `true`.\n   */\n  labelOverlap?: LabelOverlap;\n}\n\nexport interface LegendEncoding {\n  /**\n   * Custom encoding for the legend container.\n   * This can be useful for creating legend with custom x, y position.\n   */\n  legend?: GuideEncodingEntry;\n\n  /**\n   * Custom encoding for the legend title text mark.\n   */\n  title?: GuideEncodingEntry;\n\n  /**\n   * Custom encoding for legend label text marks.\n   */\n  labels?: GuideEncodingEntry;\n\n  /**\n   * Custom encoding for legend symbol marks.\n   */\n  symbols?: GuideEncodingEntry;\n\n  /**\n   * Custom encoding for legend gradient filled rect marks.\n   */\n  gradient?: GuideEncodingEntry;\n}\n\nexport const defaultLegendConfig: LegendConfig = {\n  gradientHorizontalMaxLength: 200,\n  gradientHorizontalMinLength: 100,\n  gradientVerticalMaxLength: 200,\n  gradientVerticalMinLength: 64 // This is the Vega's minimum.\n};\n\nconst COMMON_LEGEND_PROPERTY_INDEX: Flag<keyof (VgLegend | Legend)> = {\n  clipHeight: 1,\n  columnPadding: 1,\n  columns: 1,\n  cornerRadius: 1,\n  direction: 1,\n  fillColor: 1,\n  format: 1,\n  formatType: 1,\n  gradientLength: 1,\n  gradientOpacity: 1,\n  gradientStrokeColor: 1,\n  gradientStrokeWidth: 1,\n  gradientThickness: 1,\n  gridAlign: 1,\n  labelAlign: 1,\n  labelBaseline: 1,\n  labelColor: 1,\n  labelFont: 1,\n  labelFontSize: 1,\n  labelFontStyle: 1,\n  labelFontWeight: 1,\n  labelLimit: 1,\n  labelOffset: 1,\n  labelOpacity: 1,\n  labelOverlap: 1,\n  labelPadding: 1,\n  labelSeparation: 1,\n  legendX: 1,\n  legendY: 1,\n  offset: 1,\n  orient: 1,\n  padding: 1,\n  rowPadding: 1,\n  strokeColor: 1,\n  symbolDash: 1,\n  symbolDashOffset: 1,\n  symbolFillColor: 1,\n  symbolOffset: 1,\n  symbolOpacity: 1,\n  symbolSize: 1,\n  symbolStrokeColor: 1,\n  symbolStrokeWidth: 1,\n  symbolType: 1,\n  tickCount: 1,\n  tickMinStep: 1,\n  title: 1,\n  titleAlign: 1,\n  titleAnchor: 1,\n  titleBaseline: 1,\n  titleColor: 1,\n  titleFont: 1,\n  titleFontSize: 1,\n  titleFontStyle: 1,\n  titleFontWeight: 1,\n  titleLimit: 1,\n  titleOpacity: 1,\n  titleOrient: 1,\n  titlePadding: 1,\n  type: 1,\n  values: 1,\n  zindex: 1\n};\n\nconst VG_LEGEND_PROPERTY_INDEX: Flag<Exclude<keyof VgLegend, 'strokeDash'>> = {\n  ...COMMON_LEGEND_PROPERTY_INDEX,\n  // channel scales\n  opacity: 1,\n  shape: 1,\n  stroke: 1,\n  fill: 1,\n  size: 1,\n  strokeWidth: 1,\n  // encode\n  encode: 1\n};\n\nexport const LEGEND_PROPERTIES = flagKeys(COMMON_LEGEND_PROPERTY_INDEX);\n\nexport const VG_LEGEND_PROPERTIES = flagKeys(VG_LEGEND_PROPERTY_INDEX);\n","/**\n * Vega-Lite's singleton logger utility.\n */\n\nimport {logger, LoggerInterface, Warn} from 'vega-util';\nimport * as message_ from './message';\n\nexport const message = message_;\n\n/**\n * Main (default) Vega Logger instance for Vega-Lite\n */\nconst main = logger(Warn);\nlet current: LoggerInterface = main;\n\n/**\n * Logger tool for checking if the code throws correct warning\n */\nexport class LocalLogger implements LoggerInterface {\n  public warns: any[] = [];\n  public infos: any[] = [];\n  public debugs: any[] = [];\n\n  public level() {\n    return this;\n  }\n\n  public warn(...args: any[]) {\n    this.warns.push(...args);\n    return this;\n  }\n\n  public info(...args: any[]) {\n    this.infos.push(...args);\n    return this;\n  }\n\n  public debug(...args: any[]) {\n    this.debugs.push(...args);\n    return this;\n  }\n\n  public error(...args: any[]) {\n    throw Error(...args);\n    return this; // @ts-ignore\n  }\n}\n\nexport function wrap(f: (logger: LocalLogger) => void) {\n  return () => {\n    current = new LocalLogger();\n    f(current as LocalLogger);\n    reset();\n  };\n}\n\n/**\n * Set the singleton logger to be a custom logger\n */\nexport function set(newLogger: LoggerInterface) {\n  current = newLogger;\n  return current;\n}\n\n/**\n * Reset the main logger to use the default Vega Logger\n */\nexport function reset() {\n  current = main;\n  return current;\n}\n\n// eslint-disable-next-line @typescript-eslint/no-unused-vars\nexport function warn(..._: any[]) {\n  current.warn.apply(current, arguments);\n}\n\n// eslint-disable-next-line @typescript-eslint/no-unused-vars\nexport function info(..._: any[]) {\n  current.info.apply(current, arguments);\n}\n\n// eslint-disable-next-line @typescript-eslint/no-unused-vars\nexport function debug(..._: any[]) {\n  current.debug.apply(current, arguments);\n}\n","import {AggregateOp} from 'vega';\nimport {CompositeMark} from '../compositemark';\nimport {Aggregate} from '../aggregate';\nimport {Channel, FacetChannel, GeoPositionChannel} from '../channel';\nimport {TypedFieldDef} from '../channeldef';\nimport {ErrorBarCenter, ErrorBarExtent} from '../compositemark/errorbar';\nimport {DateTime, DateTimeExpr} from '../datetime';\nimport {Mark} from '../mark';\nimport {Projection} from '../projection';\nimport {ScaleType} from '../scale';\nimport {Type} from '../type';\nimport {stringify} from '../util';\nimport {VgSortField} from '../vega.schema';\n\n/**\n * Collection of all Vega-Lite Error Messages\n */\n\nexport const INVALID_SPEC = 'Invalid spec';\n\n// FIT\nexport const FIT_NON_SINGLE = 'Autosize \"fit\" only works for single views and layered views.';\n\nexport const CANNOT_FIX_RANGE_STEP_WITH_FIT = 'Cannot use a fixed value of \"rangeStep\" when \"autosize\" is \"fit\".';\n\n// SELECTION\nexport function cannotProjectOnChannelWithoutField(channel: Channel) {\n  return `Cannot project a selection on encoding channel \"${channel}\", which has no field.`;\n}\n\nexport function nearestNotSupportForContinuous(mark: string) {\n  return `The \"nearest\" transform is not supported for ${mark} marks.`;\n}\n\nexport function selectionNotSupported(mark: CompositeMark) {\n  return `Selection not supported for ${mark} yet`;\n}\n\nexport function selectionNotFound(name: string) {\n  return `Cannot find a selection named \"${name}\"`;\n}\n\nexport const SCALE_BINDINGS_CONTINUOUS =\n  'Scale bindings are currently only supported for scales with unbinned, continuous domains.';\n\nexport const NO_INIT_SCALE_BINDINGS = 'Selections bound to scales cannot be separately initialized.';\n\n// REPEAT\nexport function noSuchRepeatedValue(field: string) {\n  return `Unknown repeated value \"${field}\".`;\n}\n\nexport function columnsNotSupportByRowCol(type: 'facet' | 'repeat') {\n  return `The \"columns\" property cannot be used when \"${type}\" has nested row/column.`;\n}\n\n// CONCAT\nexport const CONCAT_CANNOT_SHARE_AXIS =\n  'Axes cannot be shared in concatenated views yet (https://github.com/vega/vega-lite/issues/2415).';\n\n// REPEAT\nexport const REPEAT_CANNOT_SHARE_AXIS =\n  'Axes cannot be shared in repeated views yet (https://github.com/vega/vega-lite/issues/2415).';\n\n// DATA\nexport function unrecognizedParse(p: string) {\n  return `Unrecognized parse \"${p}\".`;\n}\n\nexport function differentParse(field: string, local: string, ancestor: string) {\n  return `An ancestor parsed field \"${field}\" as ${ancestor} but a child wants to parse the field as ${local}.`;\n}\n\n// TRANSFORMS\nexport function invalidTransformIgnored(transform: any) {\n  return `Ignoring an invalid transform: ${stringify(transform)}.`;\n}\n\nexport const NO_FIELDS_NEEDS_AS =\n  'If \"from.fields\" is not specified, \"as\" has to be a string that specifies the key to be used for the data from the secondary source.';\n\n// ENCODING & FACET\n\nexport function encodingOverridden(channels: Channel[]) {\n  return `Layer's shared ${channels.join(',')} channel ${channels.length === 1 ? 'is' : 'are'} overriden`;\n}\nexport function projectionOverridden(opt: {parentProjection: Projection; projection: Projection}) {\n  const {parentProjection, projection} = opt;\n  return `Layer's shared projection ${stringify(parentProjection)} is overridden by a child projection ${stringify(\n    projection\n  )}.`;\n}\n\nexport function primitiveChannelDef(\n  channel: Channel,\n  type: 'string' | 'number' | 'boolean',\n  value: string | number | boolean\n) {\n  return `Channel ${channel} is a ${type}. Converted to {value: ${stringify(value)}}.`;\n}\n\nexport function invalidFieldType(type: Type) {\n  return `Invalid field type \"${type}\"`;\n}\n\nexport function nonZeroScaleUsedWithLengthMark(\n  mark: 'bar' | 'area',\n  channel: Channel,\n  opt: {scaleType?: ScaleType; zeroFalse?: boolean}\n) {\n  const scaleText = opt.scaleType\n    ? `${opt.scaleType} scale`\n    : opt.zeroFalse\n    ? 'scale with zero=false'\n    : 'scale with custom domain that excludes zero';\n\n  return `A ${scaleText} is used to encode ${mark}'s ${channel}. This can be misleading as the ${\n    channel === 'x' ? 'width' : 'height'\n  } of the ${mark} can be arbitrary based on the scale domain. You may want to use point mark instead.`;\n}\n\nexport function invalidFieldTypeForCountAggregate(type: Type, aggregate: Aggregate | string) {\n  return `Invalid field type \"${type}\" for aggregate: \"${aggregate}\", using \"quantitative\" instead.`;\n}\n\nexport function invalidAggregate(aggregate: AggregateOp | string) {\n  return `Invalid aggregation operator \"${aggregate}\"`;\n}\n\nexport function missingFieldType(channel: Channel, newType: Type) {\n  return `Missing type for channel \"${channel}\", using \"${newType}\" instead.`;\n}\nexport function droppingColor(type: 'encoding' | 'property', opt: {fill?: boolean; stroke?: boolean}) {\n  const {fill, stroke} = opt;\n  return (\n    `Dropping color ${type} as the plot also has ` + (fill && stroke ? 'fill and stroke' : fill ? 'fill' : 'stroke')\n  );\n}\n\nexport function emptyFieldDef(fieldDef: TypedFieldDef<string>, channel: Channel) {\n  return `Dropping ${stringify(fieldDef)} from channel \"${channel}\" since it does not contain data field or value.`;\n}\nexport function latLongDeprecated(channel: Channel, type: Type, newChannel: GeoPositionChannel) {\n  return `${channel}-encoding with type ${type} is deprecated. Replacing with ${newChannel}-encoding.`;\n}\n\nexport const LINE_WITH_VARYING_SIZE =\n  'Line marks cannot encode size with a non-groupby field. You may want to use trail marks instead.';\n\nexport function incompatibleChannel(channel: Channel, markOrFacet: Mark | 'facet' | CompositeMark, when?: string) {\n  return `${channel} dropped as it is incompatible with \"${markOrFacet}\"${when ? ` when ${when}` : ''}.`;\n}\n\nexport function invalidEncodingChannel(channel: string) {\n  return `${channel}-encoding is dropped as ${channel} is not a valid encoding channel.`;\n}\n\nexport function facetChannelShouldBeDiscrete(channel: string) {\n  return `${channel} encoding should be discrete (ordinal / nominal / binned).`;\n}\n\nexport function facetChannelDropped(channels: FacetChannel[]) {\n  return `Facet encoding dropped as ${channels.join(' and ')} ${channels.length > 1 ? 'are' : 'is'} also specified.`;\n}\n\nexport function discreteChannelCannotEncode(channel: Channel, type: Type) {\n  return `Using discrete channel \"${channel}\" to encode \"${type}\" field can be misleading as it does not encode ${\n    type === 'ordinal' ? 'order' : 'magnitude'\n  }.`;\n}\n\n// Mark\nexport const BAR_WITH_POINT_SCALE_AND_RANGESTEP_NULL =\n  'Bar mark should not be used with point scale when rangeStep is null. Please use band scale instead.';\n\nexport function lineWithRange(hasX2: boolean, hasY2: boolean) {\n  const channels = hasX2 && hasY2 ? 'x2 and y2' : hasX2 ? 'x2' : 'y2';\n  return `Line mark is for continuous lines and thus cannot be used with ${channels}. We will use the rule mark (line segments) instead.`;\n}\n\nexport function orientOverridden(original: string, actual: string) {\n  return `Specified orient \"${original}\" overridden with \"${actual}\"`;\n}\n\n// SCALE\nexport const CANNOT_UNION_CUSTOM_DOMAIN_WITH_FIELD_DOMAIN =\n  'custom domain scale cannot be unioned with default field-based domain';\n\nexport function cannotUseScalePropertyWithNonColor(prop: string) {\n  return `Cannot use the scale property \"${prop}\" with non-color channel.`;\n}\n\nexport function unaggregateDomainHasNoEffectForRawField(fieldDef: TypedFieldDef<string>) {\n  return `Using unaggregated domain with raw field has no effect (${stringify(fieldDef)}).`;\n}\n\nexport function unaggregateDomainWithNonSharedDomainOp(aggregate: Aggregate | string) {\n  return `Unaggregated domain not applicable for \"${aggregate}\" since it produces values outside the origin domain of the source data.`;\n}\n\nexport function unaggregatedDomainWithLogScale(fieldDef: TypedFieldDef<string>) {\n  return `Unaggregated domain is currently unsupported for log scale (${stringify(fieldDef)}).`;\n}\n\nexport function cannotApplySizeToNonOrientedMark(mark: Mark) {\n  return `Cannot apply size to non-oriented mark \"${mark}\".`;\n}\n\nexport function rangeStepDropped(channel: Channel) {\n  return `rangeStep for \"${channel}\" is dropped as top-level ${channel === 'x' ? 'width' : 'height'} is provided.`;\n}\n\nexport function scaleTypeNotWorkWithChannel(channel: Channel, scaleType: ScaleType, defaultScaleType: ScaleType) {\n  return `Channel \"${channel}\" does not work with \"${scaleType}\" scale. We are using \"${defaultScaleType}\" scale instead.`;\n}\n\nexport function scaleTypeNotWorkWithFieldDef(scaleType: ScaleType, defaultScaleType: ScaleType) {\n  return `FieldDef does not work with \"${scaleType}\" scale. We are using \"${defaultScaleType}\" scale instead.`;\n}\n\nexport function scalePropertyNotWorkWithScaleType(scaleType: ScaleType, propName: string, channel: Channel) {\n  return `${channel}-scale's \"${propName}\" is dropped as it does not work with ${scaleType} scale.`;\n}\n\nexport function scaleTypeNotWorkWithMark(mark: Mark, scaleType: ScaleType) {\n  return `Scale type \"${scaleType}\" does not work with mark \"${mark}\".`;\n}\n\nexport function mergeConflictingProperty<T>(\n  property: string | number | symbol,\n  propertyOf: string | number | symbol,\n  v1: T,\n  v2: T\n) {\n  return `Conflicting ${propertyOf.toString()} property \"${property.toString()}\" (${stringify(v1)} and ${stringify(\n    v2\n  )}).  Using ${stringify(v1)}.`;\n}\n\nexport function independentScaleMeansIndependentGuide(channel: Channel) {\n  return `Setting the scale to be independent for \"${channel}\" means we also have to set the guide (axis or legend) to be independent.`;\n}\n\nexport function domainSortDropped(sort: VgSortField) {\n  return `Dropping sort property ${stringify(sort)} as unioned domains only support boolean or op 'count'.`;\n}\n\nexport const UNABLE_TO_MERGE_DOMAINS = 'Unable to merge domains';\n\nexport const MORE_THAN_ONE_SORT =\n  'Domains that should be unioned has conflicting sort properties. Sort will be set to true.';\n\n// AXIS\nexport const INVALID_CHANNEL_FOR_AXIS = 'Invalid channel for axis.';\n\n// STACK\nexport function cannotStackRangedMark(channel: Channel) {\n  return `Cannot stack \"${channel}\" if there is already \"${channel}2\"`;\n}\n\nexport function cannotStackNonLinearScale(scaleType: ScaleType) {\n  return `Cannot stack non-linear scale (${scaleType})`;\n}\n\nexport function stackNonSummativeAggregate(aggregate: Aggregate | string) {\n  return `Stacking is applied even though the aggregate function is non-summative (\"${aggregate}\")`;\n}\n\n// TIMEUNIT\nexport function invalidTimeUnit(unitName: string, value: string | number) {\n  return `Invalid ${unitName}: ${stringify(value)}`;\n}\n\nexport function dayReplacedWithDate(fullTimeUnit: string) {\n  return `Time unit \"${fullTimeUnit}\" is not supported. We are replacing it with ${fullTimeUnit.replace(\n    'day',\n    'date'\n  )}.`;\n}\n\nexport function droppedDay(d: DateTime | DateTimeExpr) {\n  return `Dropping day from datetime ${stringify(d)} as day cannot be combined with other units.`;\n}\n\nexport function errorBarCenterAndExtentAreNotNeeded(center: ErrorBarCenter, extent: ErrorBarExtent) {\n  return `${extent ? 'extent ' : ''}${extent && center ? 'and ' : ''}${center ? 'center ' : ''}${\n    extent && center ? 'are ' : 'is '\n  }not needed when data are aggregated.`;\n}\n\nexport function errorBarCenterIsUsedWithWrongExtent(\n  center: ErrorBarCenter,\n  extent: ErrorBarExtent,\n  mark: 'errorbar' | 'errorband'\n) {\n  return `${center} is not usually used with ${extent} for ${mark}.`;\n}\n\nexport function errorBarContinuousAxisHasCustomizedAggregate(\n  aggregate: Aggregate | string,\n  compositeMark: CompositeMark\n) {\n  return `Continuous axis should not have customized aggregation function ${aggregate}; ${compositeMark} already agregates the axis.`;\n}\n\nexport function errorBarCenterIsNotNeeded(extent: ErrorBarExtent, mark: 'errorbar' | 'errorband') {\n  return `Center is not needed to be specified in ${mark} when extent is ${extent}.`;\n}\n\nexport function errorBand1DNotSupport(property: 'interpolate' | 'tension') {\n  return `1D error band does not support ${property}`;\n}\n\n// CHANNEL\nexport function channelRequiredForBinned(channel: Channel) {\n  return `Channel ${channel} is required for \"binned\" bin`;\n}\n\nexport function domainRequiredForThresholdScale(channel: Channel) {\n  return `Domain for ${channel} is required for threshold scale`;\n}\n","import {Flag} from './util';\n/** Constants and utilities for data type */\n/** Data type based on level of measurement */\n\nexport const TYPE_INDEX: Flag<Type> = {\n  quantitative: 1,\n  ordinal: 1,\n  temporal: 1,\n  nominal: 1,\n  geojson: 1\n};\n\nexport function isType(t: any): t is Type {\n  return !!TYPE_INDEX[t];\n}\n\nexport const QUANTITATIVE: 'quantitative' = 'quantitative';\nexport const ORDINAL: 'ordinal' = 'ordinal';\nexport const TEMPORAL: 'temporal' = 'temporal';\nexport const NOMINAL: 'nominal' = 'nominal';\n\nexport const GEOJSON: 'geojson' = 'geojson';\n\nexport type StandardType = typeof QUANTITATIVE | typeof ORDINAL | typeof TEMPORAL | typeof NOMINAL;\n\nexport type Type = StandardType | typeof GEOJSON;\n\n/**\n * Get full, lowercase type name for a given type.\n * @param  type\n * @return Full type name.\n */\nexport function getFullName(type: Type | string): Type {\n  if (type) {\n    type = type.toLowerCase();\n    switch (type) {\n      case 'q':\n      case QUANTITATIVE:\n        return 'quantitative';\n      case 't':\n      case TEMPORAL:\n        return 'temporal';\n      case 'o':\n      case ORDINAL:\n        return 'ordinal';\n      case 'n':\n      case NOMINAL:\n        return 'nominal';\n      case GEOJSON:\n        return 'geojson';\n    }\n  }\n  // If we get invalid input, return undefined type.\n  return undefined;\n}\n","import {toSet} from 'vega-util';\nimport * as CHANNEL from './channel';\nimport {Channel, CHANNELS, isColorChannel} from './channel';\nimport {FieldName} from './channeldef';\nimport {DateTime} from './datetime';\nimport * as log from './log';\nimport * as TYPE from './type';\nimport {Type, TYPE_INDEX} from './type';\nimport {contains, Flag, flagKeys, keys} from './util';\nimport {ScaleInterpolate, ScaleInterpolateParams} from './vega.schema';\n\nexport namespace ScaleType {\n  // Continuous - Quantitative\n  export const LINEAR: 'linear' = 'linear';\n  export const LOG: 'log' = 'log';\n  export const POW: 'pow' = 'pow';\n  export const SQRT: 'sqrt' = 'sqrt';\n  export const SYMLOG: 'symlog' = 'symlog';\n  // Continuous - Time\n  export const TIME: 'time' = 'time';\n  export const UTC: 'utc' = 'utc';\n\n  // Discretizing scales\n  export const QUANTILE: 'quantile' = 'quantile';\n  export const QUANTIZE: 'quantize' = 'quantize';\n  export const THRESHOLD: 'threshold' = 'threshold';\n  export const BIN_ORDINAL: 'bin-ordinal' = 'bin-ordinal';\n\n  // Discrete scales\n  export const ORDINAL: 'ordinal' = 'ordinal';\n  export const POINT: 'point' = 'point';\n  export const BAND: 'band' = 'band';\n}\n\nexport type ScaleType =\n  | typeof ScaleType.LINEAR\n  | typeof ScaleType.LOG\n  | typeof ScaleType.POW\n  | typeof ScaleType.SQRT\n  | typeof ScaleType.SYMLOG\n  | typeof ScaleType.TIME\n  | typeof ScaleType.UTC\n  | typeof ScaleType.QUANTILE\n  | typeof ScaleType.QUANTIZE\n  | typeof ScaleType.THRESHOLD\n  | typeof ScaleType.BIN_ORDINAL\n  | typeof ScaleType.ORDINAL\n  | typeof ScaleType.POINT\n  | typeof ScaleType.BAND;\n\n/**\n * Index for scale categories -- only scale of the same categories can be merged together.\n * Current implementation is trying to be conservative and avoid merging scale type that might not work together\n */\nconst SCALE_CATEGORY_INDEX: {\n  // Using Mapped Type to declare type (https://www.typescriptlang.org/docs/handbook/advanced-types.html#mapped-types)\n  [k in ScaleType]: ScaleType | 'numeric' | 'ordinal-position' | 'discretizing'\n} = {\n  linear: 'numeric',\n  log: 'numeric',\n  pow: 'numeric',\n  sqrt: 'numeric',\n  symlog: 'numeric',\n  time: 'time',\n  utc: 'time',\n  ordinal: 'ordinal',\n  'bin-ordinal': 'bin-ordinal', // TODO: should bin-ordinal support merging with other\n  point: 'ordinal-position',\n  band: 'ordinal-position',\n  quantile: 'discretizing',\n  quantize: 'discretizing',\n  threshold: 'discretizing'\n};\n\nexport const SCALE_TYPES = keys(SCALE_CATEGORY_INDEX) as ScaleType[];\n\n/**\n * Whether the two given scale types can be merged together.\n */\nexport function scaleCompatible(scaleType1: ScaleType, scaleType2: ScaleType) {\n  const scaleCategory1 = SCALE_CATEGORY_INDEX[scaleType1];\n  const scaleCategory2 = SCALE_CATEGORY_INDEX[scaleType2];\n  return (\n    scaleCategory1 === scaleCategory2 ||\n    (scaleCategory1 === 'ordinal-position' && scaleCategory2 === 'time') ||\n    (scaleCategory2 === 'ordinal-position' && scaleCategory1 === 'time')\n  );\n}\n\n/**\n * Index for scale precedence -- high score = higher priority for merging.\n */\nconst SCALE_PRECEDENCE_INDEX: {\n  // Using Mapped Type to declare type (https://www.typescriptlang.org/docs/handbook/advanced-types.html#mapped-types)\n  [k in ScaleType]: number\n} = {\n  // numeric\n  linear: 0,\n  log: 1,\n  pow: 1,\n  sqrt: 1,\n  symlog: 1,\n  // time\n  time: 0,\n  utc: 0,\n  // ordinal-position -- these have higher precedence than continuous scales as they support more types of data\n  point: 10,\n  band: 11, // band has higher precedence as it is better for interaction\n  // non grouped types\n  ordinal: 0,\n  'bin-ordinal': 0,\n  quantile: 0,\n  quantize: 0,\n  threshold: 0\n};\n\n/**\n * Return scale categories -- only scale of the same categories can be merged together.\n */\nexport function scaleTypePrecedence(scaleType: ScaleType): number {\n  return SCALE_PRECEDENCE_INDEX[scaleType];\n}\n\nexport const CONTINUOUS_TO_CONTINUOUS_SCALES: ScaleType[] = ['linear', 'log', 'pow', 'sqrt', 'symlog', 'time', 'utc'];\nconst CONTINUOUS_TO_CONTINUOUS_INDEX = toSet(CONTINUOUS_TO_CONTINUOUS_SCALES);\n\nexport const CONTINUOUS_TO_DISCRETE_SCALES: ScaleType[] = ['quantile', 'quantize', 'threshold'];\nconst CONTINUOUS_TO_DISCRETE_INDEX = toSet(CONTINUOUS_TO_DISCRETE_SCALES);\n\nexport const CONTINUOUS_DOMAIN_SCALES: ScaleType[] = CONTINUOUS_TO_CONTINUOUS_SCALES.concat([\n  'quantile',\n  'quantize',\n  'threshold'\n]);\nconst CONTINUOUS_DOMAIN_INDEX = toSet(CONTINUOUS_DOMAIN_SCALES);\n\nexport const DISCRETE_DOMAIN_SCALES: ScaleType[] = ['ordinal', 'bin-ordinal', 'point', 'band'];\nconst DISCRETE_DOMAIN_INDEX = toSet(DISCRETE_DOMAIN_SCALES);\n\nexport const TIME_SCALE_TYPES: ScaleType[] = ['time', 'utc'];\n\nexport function hasDiscreteDomain(type: ScaleType): type is 'ordinal' | 'bin-ordinal' | 'point' | 'band' {\n  return type in DISCRETE_DOMAIN_INDEX;\n}\n\nexport function hasContinuousDomain(\n  type: ScaleType\n): type is 'linear' | 'log' | 'pow' | 'sqrt' | 'symlog' | 'time' | 'utc' | 'quantile' | 'quantize' | 'threshold' {\n  return type in CONTINUOUS_DOMAIN_INDEX;\n}\n\nexport function isContinuousToContinuous(\n  type: ScaleType\n): type is 'linear' | 'log' | 'pow' | 'sqrt' | 'symlog' | 'time' | 'utc' {\n  return type in CONTINUOUS_TO_CONTINUOUS_INDEX;\n}\n\nexport function isContinuousToDiscrete(type: ScaleType): type is 'quantile' | 'quantize' | 'threshold' {\n  return type in CONTINUOUS_TO_DISCRETE_INDEX;\n}\n\nexport type NiceTime = 'second' | 'minute' | 'hour' | 'day' | 'week' | 'month' | 'year';\n\nexport interface ScaleConfig {\n  /**\n   * If true, rounds numeric output values to integers.\n   * This can be helpful for snapping to the pixel grid.\n   * (Only available for `x`, `y`, and `size` scales.)\n   */\n  round?: boolean;\n\n  /**\n   * If true, values that exceed the data domain are clamped to either the minimum or maximum range value\n   */\n  clamp?: boolean;\n  /**\n   *  Default range step for `x` band and point scales of text marks.\n   *\n   * __Default value:__ `90`\n   *\n   *  @minimum 0\n   */\n  textXRangeStep?: number; // FIXME: consider if we will rename this \"tableColumnWidth\"\n\n  /**\n   * Default range step for band and point scales of (1) the `y` channel\n   * and (2) the `x` channel when the mark is not `text`.\n   *\n   * __Default value:__ `20`\n   *\n   * @minimum 0\n   */\n  rangeStep?: number | null;\n\n  /**\n   * Default inner padding for `x` and `y` band-ordinal scales.\n   *\n   * __Default value:__\n   * - `barBandPaddingInner` for bar marks (`0.1` by default)\n   * - `rectBandPaddingInner` for rect and other marks (`0` by default)\n   *\n   * @minimum 0\n   * @maximum 1\n   */\n  bandPaddingInner?: number;\n\n  /**\n   * Default outer padding for `x` and `y` band-ordinal scales.\n   *\n   * If not specified, by default, band scale's paddingOuter is paddingInner/2.\n   * @minimum 0\n   * @maximum 1\n   */\n  bandPaddingOuter?: number;\n\n  /**\n   * Default inner padding for `x` and `y` band-ordinal scales of `\"bar\"` marks.\n   *\n   * __Default value:__ `0.1`\n   *\n   * @minimum 0\n   * @maximum 1\n   */\n  barBandPaddingInner?: number;\n\n  /**\n   * Default outer padding for `x` and `y` band-ordinal scales of `\"bar\"` marks.\n   * If not specified, by default, band scale's paddingOuter is paddingInner/2.\n   * @minimum 0\n   * @maximum 1\n   */\n  barBandPaddingOuter?: number;\n\n  /**\n   * Default inner padding for `x` and `y` band-ordinal scales of `\"rect\"` marks.\n   *\n   * __Default value:__ `0`\n   *\n   * @minimum 0\n   * @maximum 1\n   */\n  rectBandPaddingInner?: number;\n\n  /**\n   * Default outer padding for `x` and `y` band-ordinal scales of `\"rect\"` marks.\n   * If not specified, by default, band scale's paddingOuter is paddingInner/2.\n   * @minimum 0\n   * @maximum 1\n   */\n  rectBandPaddingOuter?: number;\n\n  /**\n   * Default padding for continuous scales.\n   *\n   * __Default:__ `5` for continuous x-scale of a vertical bar and continuous y-scale of a horizontal bar.; `0` otherwise.\n   *\n   * @minimum 0\n   */\n  continuousPadding?: number;\n\n  /**\n   * Default outer padding for `x` and `y` point-ordinal scales.\n   *\n   * __Default value:__ `0.5`\n   *\n   * @minimum 0\n   * @maximum 1\n   */\n  pointPadding?: number;\n\n  /**\n   * Use the source data range before aggregation as scale domain instead of aggregated data for aggregate axis.\n   *\n   * This is equivalent to setting `domain` to `\"unaggregate\"` for aggregated _quantitative_ fields by default.\n   *\n   * This property only works with aggregate functions that produce values within the raw data domain (`\"mean\"`, `\"average\"`, `\"median\"`, `\"q1\"`, `\"q3\"`, `\"min\"`, `\"max\"`). For other aggregations that produce values outside of the raw data domain (e.g. `\"count\"`, `\"sum\"`), this property is ignored.\n   *\n   * __Default value:__ `false`\n   */\n  useUnaggregatedDomain?: boolean;\n\n  // nice should depends on type (quantitative or temporal), so\n  // let's not make a config.\n\n  // Configs for Range\n\n  /**\n   * The default max value for mapping quantitative fields to bar's size/bandSize.\n   *\n   * If undefined (default), we will use the scale's `rangeStep` - 1.\n   * @minimum 0\n   */\n  maxBandSize?: number;\n\n  /**\n   * The default min value for mapping quantitative fields to bar and tick's size/bandSize scale with zero=false.\n   *\n   * __Default value:__ `2`\n   *\n   * @minimum 0\n   */\n  minBandSize?: number;\n\n  /**\n   * The default max value for mapping quantitative fields to text's size/fontSize.\n   *\n   * __Default value:__ `40`\n   *\n   * @minimum 0\n   */\n  maxFontSize?: number;\n\n  /**\n   * The default min value for mapping quantitative fields to tick's size/fontSize scale with zero=false\n   *\n   * __Default value:__ `8`\n   *\n   * @minimum 0\n   */\n  minFontSize?: number;\n\n  /**\n   * Default minimum opacity for mapping a field to opacity.\n   *\n   * __Default value:__ `0.3`\n   *\n   * @minimum 0\n   * @maximum 1\n   */\n  minOpacity?: number;\n\n  /**\n   * Default max opacity for mapping a field to opacity.\n   *\n   * __Default value:__ `0.8`\n   *\n   * @minimum 0\n   * @maximum 1\n   */\n  maxOpacity?: number;\n\n  /**\n   * Default minimum value for point size scale with zero=false.\n   *\n   * __Default value:__ `9`\n   *\n   * @minimum 0\n   */\n  minSize?: number;\n\n  /**\n   * Default max value for point size scale.\n   * @minimum 0\n   */\n  maxSize?: number;\n\n  /**\n   * Default minimum strokeWidth for the scale of strokeWidth for rule and line marks and of size for trail marks with zero=false.\n   *\n   * __Default value:__ `1`\n   *\n   * @minimum 0\n   */\n  minStrokeWidth?: number;\n\n  /**\n   * Default max strokeWidth for the scale of strokeWidth for rule and line marks and of size for trail marks.\n   *\n   * __Default value:__ `4`\n   *\n   * @minimum 0\n   */\n  maxStrokeWidth?: number;\n\n  /**\n   * Default range cardinality for [`quantile`](https://vega.github.io/vega-lite/docs/scale.html#quantile) scale.\n   *\n   * __Default value:__ `4`\n   *\n   * @minimum 0\n   */\n  quantileCount?: number;\n\n  /**\n   * Default range cardinality for [`quantize`](https://vega.github.io/vega-lite/docs/scale.html#quantize) scale.\n   *\n   * __Default value:__ `4`\n   *\n   * @minimum 0\n   */\n  quantizeCount?: number;\n}\n\nexport const defaultScaleConfig: ScaleConfig = {\n  textXRangeStep: 90,\n  rangeStep: 20,\n  pointPadding: 0.5,\n\n  barBandPaddingInner: 0.1,\n  rectBandPaddingInner: 0,\n\n  minBandSize: 2,\n\n  minFontSize: 8,\n  maxFontSize: 40,\n\n  minOpacity: 0.3,\n  maxOpacity: 0.8,\n\n  // FIXME: revise if these *can* become ratios of rangeStep\n  minSize: 9, // Point size is area. For square point, 9 = 3 pixel ^ 2, not too small!\n\n  minStrokeWidth: 1,\n  maxStrokeWidth: 4,\n  quantileCount: 4,\n  quantizeCount: 4\n};\n\nexport interface SchemeParams {\n  /**\n   * A color scheme name for ordinal scales (e.g., `\"category10\"` or `\"blues\"`).\n   *\n   * For the full list of supported schemes, please refer to the [Vega Scheme](https://vega.github.io/vega/docs/schemes/#reference) reference.\n   */\n  name: string;\n\n  /**\n   * The extent of the color range to use. For example `[0.2, 1]` will rescale the color scheme such that color values in the range _[0, 0.2)_ are excluded from the scheme.\n   */\n  extent?: number[];\n\n  /**\n   * The number of colors to use in the scheme. This can be useful for scale types such as `\"quantize\"`, which use the length of the scale range to determine the number of discrete bins for the scale domain.\n   */\n  count?: number;\n}\n\nexport type SelectionDomain =\n  | {\n      /**\n       * The name of a selection.\n       */\n      selection: string;\n      /**\n       * The field name to extract selected values for, when a selection is [projected](https://vega.github.io/vega-lite/docs/project.html)\n       * over multiple fields or encodings.\n       */\n      field?: FieldName;\n    }\n  | {\n      /**\n       * The name of a selection.\n       */\n      selection: string;\n      /**\n       * The encoding channel to extract selected values for, when a selection is [projected](https://vega.github.io/vega-lite/docs/project.html)\n       * over multiple fields or encodings.\n       */\n      encoding?: string;\n    };\n\nexport type Domain = number[] | string[] | boolean[] | DateTime[] | 'unaggregated' | SelectionDomain;\nexport type Scheme = string | SchemeParams;\n\nexport function isExtendedScheme(scheme: string | SchemeParams): scheme is SchemeParams {\n  return scheme && !!scheme['name'];\n}\n\nexport function isSelectionDomain(domain: Domain): domain is SelectionDomain {\n  return domain && domain['selection'];\n}\n\nexport interface Scale {\n  /**\n   * The type of scale.  Vega-Lite supports the following categories of scale types:\n   *\n   * 1) [**Continuous Scales**](https://vega.github.io/vega-lite/docs/scale.html#continuous) -- mapping continuous domains to continuous output ranges ([`\"linear\"`](https://vega.github.io/vega-lite/docs/scale.html#linear), [`\"pow\"`](https://vega.github.io/vega-lite/docs/scale.html#pow), [`\"sqrt\"`](https://vega.github.io/vega-lite/docs/scale.html#sqrt), [`\"symlog\"`](https://vega.github.io/vega-lite/docs/scale.html#symlog), [`\"log\"`](https://vega.github.io/vega-lite/docs/scale.html#log), [`\"time\"`](https://vega.github.io/vega-lite/docs/scale.html#time), [`\"utc\"`](https://vega.github.io/vega-lite/docs/scale.html#utc).\n   *\n   * 2) [**Discrete Scales**](https://vega.github.io/vega-lite/docs/scale.html#discrete) -- mapping discrete domains to discrete ([`\"ordinal\"`](https://vega.github.io/vega-lite/docs/scale.html#ordinal)) or continuous ([`\"band\"`](https://vega.github.io/vega-lite/docs/scale.html#band) and [`\"point\"`](https://vega.github.io/vega-lite/docs/scale.html#point)) output ranges.\n   *\n   * 3) [**Discretizing Scales**](https://vega.github.io/vega-lite/docs/scale.html#discretizing) -- mapping continuous domains to discrete output ranges [`\"bin-ordinal\"`](https://vega.github.io/vega-lite/docs/scale.html#bin-ordinal), [`\"quantile\"`](https://vega.github.io/vega-lite/docs/scale.html#quantile), [`\"quantize\"`](https://vega.github.io/vega-lite/docs/scale.html#quantize) and [`\"threshold\"`](https://vega.github.io/vega-lite/docs/scale.html#threshold).\n   *\n   * __Default value:__ please see the [scale type table](https://vega.github.io/vega-lite/docs/scale.html#type).\n   */\n  type?: ScaleType;\n\n  /**\n   * Customized domain values.\n   *\n   * For _quantitative_ fields, `domain` can take the form of a two-element array with minimum and maximum values.  [Piecewise scales](https://vega.github.io/vega-lite/docs/scale.html#piecewise) can be created by providing a `domain` with more than two entries.\n   * If the input field is aggregated, `domain` can also be a string value `\"unaggregated\"`, indicating that the domain should include the raw data values prior to the aggregation.\n   *\n   * For _temporal_ fields, `domain` can be a two-element array minimum and maximum values, in the form of either timestamps or the [DateTime definition objects](https://vega.github.io/vega-lite/docs/types.html#datetime).\n   *\n   * For _ordinal_ and _nominal_ fields, `domain` can be an array that lists valid input values.\n   *\n   * The `selection` property can be used to [interactively determine](https://vega.github.io/vega-lite/docs/selection.html#scale-domains) the scale domain.\n   */\n  domain?: number[] | string[] | boolean[] | DateTime[] | 'unaggregated' | SelectionDomain;\n\n  // Hide because we might not really need this.\n  /**\n   * If true, reverses the order of the scale range.\n   * __Default value:__ `false`.\n   *\n   * @hide\n   */\n  reverse?: boolean;\n\n  /**\n   * The range of the scale. One of:\n   *\n   * - A string indicating a [pre-defined named scale range](https://vega.github.io/vega-lite/docs/scale.html#range-config) (e.g., example, `\"symbol\"`, or `\"diverging\"`).\n   *\n   * - For [continuous scales](https://vega.github.io/vega-lite/docs/scale.html#continuous), two-element array indicating  minimum and maximum values, or an array with more than two entries for specifying a [piecewise scale](https://vega.github.io/vega-lite/docs/scale.html#piecewise).\n   *\n   * - For [discrete](https://vega.github.io/vega-lite/docs/scale.html#discrete) and [discretizing](https://vega.github.io/vega-lite/docs/scale.html#discretizing) scales, an array of desired output values.\n   *\n   * __Notes:__\n   *\n   * 1) For color scales you can also specify a color [`scheme`](https://vega.github.io/vega-lite/docs/scale.html#scheme) instead of `range`.\n   *\n   * 2) Any directly specified `range` for `x` and `y` channels will be ignored. Range can be customized via the view's corresponding [size](https://vega.github.io/vega-lite/docs/size.html) (`width` and `height`) or via [range steps and paddings properties](#range-step) for [band](#band) and [point](#point) scales.\n   */\n  range?: number[] | string[] | string;\n\n  // ordinal\n  /**\n   * The distance between the starts of adjacent bands or points in [band](https://vega.github.io/vega-lite/docs/scale.html#band) and [point](https://vega.github.io/vega-lite/docs/scale.html#point) scales.\n   *\n   * If `rangeStep` is `null` or if the view contains the scale's corresponding [size](https://vega.github.io/vega-lite/docs/size.html) (`width` for `x` scales and `height` for `y` scales), `rangeStep` will be automatically determined to fit the size of the view.\n   *\n   * __Default value:__  derived the [scale config](https://vega.github.io/vega-lite/docs/config.html#scale-config)'s `textXRangeStep` (`90` by default) for x-scales of `text` marks and `rangeStep` (`21` by default) for x-scales of other marks and y-scales.\n   *\n   * __Warning__: If `rangeStep` is `null` and the cardinality of the scale's domain is higher than `width` or `height`, the rangeStep might become less than one pixel and the mark might not appear correctly.\n   *\n   * @minimum 0\n   */\n  rangeStep?: number | null;\n\n  /**\n   * A string indicating a color [scheme](https://vega.github.io/vega-lite/docs/scale.html#scheme) name (e.g., `\"category10\"` or `\"blues\"`) or a [scheme parameter object](https://vega.github.io/vega-lite/docs/scale.html#scheme-params).\n   *\n   * Discrete color schemes may be used with [discrete](https://vega.github.io/vega-lite/docs/scale.html#discrete) or [discretizing](https://vega.github.io/vega-lite/docs/scale.html#discretizing) scales. Continuous color schemes are intended for use with color scales.\n   *\n   * For the full list of supported schemes, please refer to the [Vega Scheme](https://vega.github.io/vega/docs/schemes/#reference) reference.\n   */\n  scheme?: string | SchemeParams;\n\n  /**\n   * An array of bin boundaries over the scale domain. If provided, axes and legends will use the bin boundaries to inform the choice of tick marks and text labels.\n   */\n  bins?: number[];\n\n  /**\n   * If `true`, rounds numeric output values to integers. This can be helpful for snapping to the pixel grid.\n   *\n   * __Default value:__ `false`.\n   */\n  round?: boolean;\n\n  /**\n   * For _[continuous](https://vega.github.io/vega-lite/docs/scale.html#continuous)_ scales, expands the scale domain to accommodate the specified number of pixels on each of the scale range. The scale range must represent pixels for this parameter to function as intended. Padding adjustment is performed prior to all other adjustments, including the effects of the `zero`, `nice`, `domainMin`, and `domainMax` properties.\n   *\n   * For _[band](https://vega.github.io/vega-lite/docs/scale.html#band)_ scales, shortcut for setting `paddingInner` and `paddingOuter` to the same value.\n   *\n   * For _[point](https://vega.github.io/vega-lite/docs/scale.html#point)_ scales, alias for `paddingOuter`.\n   *\n   * __Default value:__ For _continuous_ scales, derived from the [scale config](https://vega.github.io/vega-lite/docs/scale.html#config)'s `continuousPadding`.\n   * For _band and point_ scales, see `paddingInner` and `paddingOuter`.\n   *\n   * @minimum 0\n   */\n  padding?: number;\n\n  /**\n   * The inner padding (spacing) within each band step of band scales, as a fraction of the step size. This value must lie in the range [0,1].\n   *\n   * For point scale, this property is invalid as point scales do not have internal band widths (only step sizes between bands).\n   *\n   * __Default value:__ derived from the [scale config](https://vega.github.io/vega-lite/docs/scale.html#config)'s `bandPaddingInner`.\n   *\n   * @minimum 0\n   * @maximum 1\n   */\n  paddingInner?: number;\n\n  /**\n   * The outer padding (spacing) at the ends of the range of band and point scales,\n   * as a fraction of the step size. This value must lie in the range [0,1].\n   *\n   * __Default value:__ derived from the [scale config](https://vega.github.io/vega-lite/docs/scale.html#config)'s `bandPaddingOuter` for band scales and `pointPadding` for point scales.\n   *\n   * @minimum 0\n   * @maximum 1\n   */\n  paddingOuter?: number;\n\n  // typical\n  /**\n   * If `true`, values that exceed the data domain are clamped to either the minimum or maximum range value\n   *\n   * __Default value:__ derived from the [scale config](https://vega.github.io/vega-lite/docs/config.html#scale-config)'s `clamp` (`true` by default).\n   */\n  clamp?: boolean;\n\n  /**\n   * Extending the domain so that it starts and ends on nice round values. This method typically modifies the scale’s domain, and may only extend the bounds to the nearest round value. Nicing is useful if the domain is computed from data and may be irregular. For example, for a domain of _[0.201479…, 0.996679…]_, a nice domain might be _[0.2, 1.0]_.\n   *\n   * For quantitative scales such as linear, `nice` can be either a boolean flag or a number. If `nice` is a number, it will represent a desired tick count. This allows greater control over the step size used to extend the bounds, guaranteeing that the returned ticks will exactly cover the domain.\n   *\n   * For temporal fields with time and utc scales, the `nice` value can be a string indicating the desired time interval. Legal values are `\"millisecond\"`, `\"second\"`, `\"minute\"`, `\"hour\"`, `\"day\"`, `\"week\"`, `\"month\"`, and `\"year\"`. Alternatively, `time` and `utc` scales can accept an object-valued interval specifier of the form `{\"interval\": \"month\", \"step\": 3}`, which includes a desired number of interval steps. Here, the domain would snap to quarter (Jan, Apr, Jul, Oct) boundaries.\n   *\n   * __Default value:__ `true` for unbinned _quantitative_ fields; `false` otherwise.\n   *\n   */\n  nice?: boolean | number | NiceTime | {interval: string; step: number};\n\n  /**\n   * The logarithm base of the `log` scale (default `10`).\n   */\n  base?: number;\n\n  /**\n   * The exponent of the `pow` scale.\n   */\n  exponent?: number;\n\n  /**\n   * A constant determining the slope of the symlog function around zero. Only used for `symlog` scales.\n   *\n   * __Default value:__ `1`\n   */\n  constant?: number;\n\n  /**\n   * If `true`, ensures that a zero baseline value is included in the scale domain.\n   *\n   * __Default value:__ `true` for x and y channels if the quantitative field is not binned and no custom `domain` is provided; `false` otherwise.\n   *\n   * __Note:__ Log, time, and utc scales do not support `zero`.\n   */\n  zero?: boolean;\n\n  /**\n   * The interpolation method for range values. By default, a general interpolator for numbers, dates, strings and colors (in HCL space) is used. For color ranges, this property allows interpolation in alternative color spaces. Legal values include `rgb`, `hsl`, `hsl-long`, `lab`, `hcl`, `hcl-long`, `cubehelix` and `cubehelix-long` ('-long' variants use longer paths in polar coordinate spaces). If object-valued, this property accepts an object with a string-valued _type_ property and an optional numeric _gamma_ property applicable to rgb and cubehelix interpolators. For more, see the [d3-interpolate documentation](https://github.com/d3/d3-interpolate).\n   *\n   * * __Default value:__ `hcl`\n   */\n  interpolate?: ScaleInterpolate | ScaleInterpolateParams;\n}\n\nconst SCALE_PROPERTY_INDEX: Flag<keyof Scale> = {\n  type: 1,\n  domain: 1,\n  range: 1,\n  rangeStep: 1,\n  scheme: 1,\n  bins: 1,\n  // Other properties\n  reverse: 1,\n  round: 1,\n  // quantitative / time\n  clamp: 1,\n  nice: 1,\n  // quantitative\n  base: 1,\n  exponent: 1,\n  constant: 1,\n  interpolate: 1,\n  zero: 1, // zero depends on domain\n  // band/point\n  padding: 1,\n  paddingInner: 1,\n  paddingOuter: 1\n};\n\nexport const SCALE_PROPERTIES = flagKeys(SCALE_PROPERTY_INDEX);\n\nconst {\n  type,\n  domain,\n  range,\n  rangeStep,\n  scheme,\n  ...NON_TYPE_DOMAIN_RANGE_VEGA_SCALE_PROPERTY_INDEX\n} = SCALE_PROPERTY_INDEX;\n\nexport const NON_TYPE_DOMAIN_RANGE_VEGA_SCALE_PROPERTIES = flagKeys(NON_TYPE_DOMAIN_RANGE_VEGA_SCALE_PROPERTY_INDEX);\n\nexport const SCALE_TYPE_INDEX = generateScaleTypeIndex();\n\nexport function scaleTypeSupportProperty(scaleType: ScaleType, propName: keyof Scale) {\n  switch (propName) {\n    case 'type':\n    case 'domain':\n    case 'reverse':\n    case 'range':\n      return true;\n    case 'scheme':\n    case 'interpolate':\n      return !contains(['point', 'band', 'identity'], scaleType);\n    case 'bins':\n      return !contains(['point', 'band', 'identity', 'ordinal'], scaleType);\n    case 'round':\n      return isContinuousToContinuous(scaleType) || scaleType === 'band' || scaleType === 'point';\n    case 'padding':\n      return isContinuousToContinuous(scaleType) || contains(['point', 'band'], scaleType);\n    case 'paddingOuter':\n    case 'rangeStep':\n      return contains(['point', 'band'], scaleType);\n    case 'paddingInner':\n      return scaleType === 'band';\n    case 'clamp':\n      return isContinuousToContinuous(scaleType);\n    case 'nice':\n      return isContinuousToContinuous(scaleType) || scaleType === 'quantize' || scaleType === 'threshold';\n    case 'exponent':\n      return scaleType === 'pow';\n    case 'base':\n      return scaleType === 'log';\n    case 'constant':\n      return scaleType === 'symlog';\n    case 'zero':\n      return (\n        hasContinuousDomain(scaleType) &&\n        !contains(\n          [\n            'log', // log scale cannot have zero value\n            'time',\n            'utc', // zero is not meaningful for time\n            'threshold', // threshold requires custom domain so zero does not matter\n            'quantile' // quantile depends on distribution so zero does not matter\n          ],\n          scaleType\n        )\n      );\n  }\n  /* istanbul ignore next: should never reach here*/\n  throw new Error(`Invalid scale property ${propName}.`);\n}\n\n/**\n * Returns undefined if the input channel supports the input scale property name\n */\nexport function channelScalePropertyIncompatability(channel: Channel, propName: keyof Scale): string {\n  switch (propName) {\n    case 'interpolate':\n    case 'scheme':\n      if (!isColorChannel(channel)) {\n        return log.message.cannotUseScalePropertyWithNonColor(channel);\n      }\n      return undefined;\n    case 'type':\n    case 'bins':\n    case 'domain':\n    case 'range':\n    case 'base':\n    case 'exponent':\n    case 'constant':\n    case 'nice':\n    case 'padding':\n    case 'paddingInner':\n    case 'paddingOuter':\n    case 'rangeStep':\n    case 'reverse':\n    case 'round':\n    case 'clamp':\n    case 'zero':\n      return undefined; // GOOD!\n  }\n  /* istanbul ignore next: it should never reach here */\n  throw new Error(`Invalid scale property \"${propName}\".`);\n}\n\nexport function scaleTypeSupportDataType(specifiedType: ScaleType, fieldDefType: Type): boolean {\n  if (contains([TYPE.ORDINAL, TYPE.NOMINAL], fieldDefType)) {\n    return specifiedType === undefined || hasDiscreteDomain(specifiedType);\n  } else if (fieldDefType === TYPE.TEMPORAL) {\n    return contains([ScaleType.TIME, ScaleType.UTC, undefined], specifiedType);\n  } else if (fieldDefType === TYPE.QUANTITATIVE) {\n    return contains(\n      [\n        ScaleType.LOG,\n        ScaleType.POW,\n        ScaleType.SQRT,\n        ScaleType.SYMLOG,\n        ScaleType.QUANTILE,\n        ScaleType.QUANTIZE,\n        ScaleType.THRESHOLD,\n        ScaleType.LINEAR,\n        undefined\n      ],\n      specifiedType\n    );\n  }\n\n  return true;\n}\n\nexport function channelSupportScaleType(channel: Channel, scaleType: ScaleType): boolean {\n  switch (channel) {\n    case CHANNEL.X:\n    case CHANNEL.Y:\n      return isContinuousToContinuous(scaleType) || contains(['band', 'point'], scaleType);\n    case CHANNEL.SIZE: // TODO: size and opacity can support ordinal with more modification\n    case CHANNEL.STROKEWIDTH:\n    case CHANNEL.OPACITY:\n    case CHANNEL.FILLOPACITY:\n    case CHANNEL.STROKEOPACITY:\n      // Although it generally doesn't make sense to use band with size and opacity,\n      // it can also work since we use band: 0.5 to get midpoint.\n      return (\n        isContinuousToContinuous(scaleType) ||\n        isContinuousToDiscrete(scaleType) ||\n        contains(['band', 'point'], scaleType)\n      );\n    case CHANNEL.COLOR:\n    case CHANNEL.FILL:\n    case CHANNEL.STROKE:\n      return scaleType !== 'band'; // band does not make sense with color\n    case CHANNEL.SHAPE:\n      return scaleType === 'ordinal'; // shape = lookup only\n  }\n  /* istanbul ignore next: it should never reach here */\n  return false;\n}\n\nexport function getSupportedScaleType(channel: Channel, fieldDefType: Type) {\n  return SCALE_TYPE_INDEX[generateScaleTypeIndexKey(channel, fieldDefType)];\n}\n\nexport interface ScaleTypeIndex {\n  [channel: string]: ScaleType[];\n}\n\n// generates ScaleTypeIndex where keys are encoding channels and values are list of valid ScaleTypes\nfunction generateScaleTypeIndex() {\n  const index: ScaleTypeIndex = {};\n  for (const channel of CHANNELS) {\n    for (const fieldDefType of keys(TYPE_INDEX)) {\n      for (const scaleType of SCALE_TYPES) {\n        const key = generateScaleTypeIndexKey(channel, fieldDefType);\n        if (channelSupportScaleType(channel, scaleType) && scaleTypeSupportDataType(scaleType, fieldDefType)) {\n          index[key] = index[key] || [];\n          index[key].push(scaleType);\n        }\n      }\n    }\n  }\n  return index;\n}\n\nfunction generateScaleTypeIndexKey(channel: Channel, fieldDefType: Type) {\n  return channel + '_' + fieldDefType;\n}\n","var u = module.exports;\n\n// utility functions\n\nvar FNAME = '__name__';\n\nu.namedfunc = function(name, f) { return (f[FNAME] = name, f); };\n\nu.name = function(f) { return f==null ? null : f[FNAME]; };\n\nu.identity = function(x) { return x; };\n\nu.true = u.namedfunc('true', function() { return true; });\n\nu.false = u.namedfunc('false', function() { return false; });\n\nu.duplicate = function(obj) {\n  return JSON.parse(JSON.stringify(obj));\n};\n\nu.equal = function(a, b) {\n  return JSON.stringify(a) === JSON.stringify(b);\n};\n\nu.extend = function(obj) {\n  for (var x, name, i=1, len=arguments.length; i<len; ++i) {\n    x = arguments[i];\n    for (name in x) { obj[name] = x[name]; }\n  }\n  return obj;\n};\n\nu.length = function(x) {\n  return x != null && x.length != null ? x.length : null;\n};\n\nu.keys = function(x) {\n  var keys = [], k;\n  for (k in x) keys.push(k);\n  return keys;\n};\n\nu.vals = function(x) {\n  var vals = [], k;\n  for (k in x) vals.push(x[k]);\n  return vals;\n};\n\nu.toMap = function(list, f) {\n  return (f = u.$(f)) ?\n    list.reduce(function(obj, x) { return (obj[f(x)] = 1, obj); }, {}) :\n    list.reduce(function(obj, x) { return (obj[x] = 1, obj); }, {});\n};\n\nu.keystr = function(values) {\n  // use to ensure consistent key generation across modules\n  var n = values.length;\n  if (!n) return '';\n  for (var s=String(values[0]), i=1; i<n; ++i) {\n    s += '|' + String(values[i]);\n  }\n  return s;\n};\n\n// type checking functions\n\nvar toString = Object.prototype.toString;\n\nu.isObject = function(obj) {\n  return obj === Object(obj);\n};\n\nu.isFunction = function(obj) {\n  return toString.call(obj) === '[object Function]';\n};\n\nu.isString = function(obj) {\n  return typeof value === 'string' || toString.call(obj) === '[object String]';\n};\n\nu.isArray = Array.isArray || function(obj) {\n  return toString.call(obj) === '[object Array]';\n};\n\nu.isNumber = function(obj) {\n  return typeof obj === 'number' || toString.call(obj) === '[object Number]';\n};\n\nu.isBoolean = function(obj) {\n  return obj === true || obj === false || toString.call(obj) == '[object Boolean]';\n};\n\nu.isDate = function(obj) {\n  return toString.call(obj) === '[object Date]';\n};\n\nu.isValid = function(obj) {\n  return obj != null && obj === obj;\n};\n\nu.isBuffer = (typeof Buffer === 'function' && Buffer.isBuffer) || u.false;\n\n// type coercion functions\n\nu.number = function(s) {\n  return s == null || s === '' ? null : +s;\n};\n\nu.boolean = function(s) {\n  return s == null || s === '' ? null : s==='false' ? false : !!s;\n};\n\n// parse a date with optional d3.time-format format\nu.date = function(s, format) {\n  var d = format ? format : Date;\n  return s == null || s === '' ? null : d.parse(s);\n};\n\nu.array = function(x) {\n  return x != null ? (u.isArray(x) ? x : [x]) : [];\n};\n\nu.str = function(x) {\n  return u.isArray(x) ? '[' + x.map(u.str) + ']'\n    : u.isObject(x) || u.isString(x) ?\n      // Output valid JSON and JS source strings.\n      // See http://timelessrepo.com/json-isnt-a-javascript-subset\n      JSON.stringify(x).replace('\\u2028','\\\\u2028').replace('\\u2029', '\\\\u2029')\n    : x;\n};\n\n// data access functions\n\nvar field_re = /\\[(.*?)\\]|[^.\\[]+/g;\n\nu.field = function(f) {\n  return String(f).match(field_re).map(function(d) {\n    return d[0] !== '[' ? d :\n      d[1] !== \"'\" && d[1] !== '\"' ? d.slice(1, -1) :\n      d.slice(2, -2).replace(/\\\\([\"'])/g, '$1');\n  });\n};\n\nu.accessor = function(f) {\n  /* jshint evil: true */\n  return f==null || u.isFunction(f) ? f :\n    u.namedfunc(f, Function('x', 'return x[' + u.field(f).map(u.str).join('][') + '];'));\n};\n\n// short-cut for accessor\nu.$ = u.accessor;\n\nu.mutator = function(f) {\n  var s;\n  return u.isString(f) && (s=u.field(f)).length > 1 ?\n    function(x, v) {\n      for (var i=0; i<s.length-1; ++i) x = x[s[i]];\n      x[s[i]] = v;\n    } :\n    function(x, v) { x[f] = v; };\n};\n\n\nu.$func = function(name, op) {\n  return function(f) {\n    f = u.$(f) || u.identity;\n    var n = name + (u.name(f) ? '_'+u.name(f) : '');\n    return u.namedfunc(n, function(d) { return op(f(d)); });\n  };\n};\n\nu.$valid  = u.$func('valid', u.isValid);\nu.$length = u.$func('length', u.length);\n\nu.$in = function(f, values) {\n  f = u.$(f);\n  var map = u.isArray(values) ? u.toMap(values) : values;\n  return function(d) { return !!map[f(d)]; };\n};\n\n// comparison / sorting functions\n\nu.comparator = function(sort) {\n  var sign = [];\n  if (sort === undefined) sort = [];\n  sort = u.array(sort).map(function(f) {\n    var s = 1;\n    if      (f[0] === '-') { s = -1; f = f.slice(1); }\n    else if (f[0] === '+') { s = +1; f = f.slice(1); }\n    sign.push(s);\n    return u.accessor(f);\n  });\n  return function(a, b) {\n    var i, n, f, c;\n    for (i=0, n=sort.length; i<n; ++i) {\n      f = sort[i];\n      c = u.cmp(f(a), f(b));\n      if (c) return c * sign[i];\n    }\n    return 0;\n  };\n};\n\nu.cmp = function(a, b) {\n  return (a < b || a == null) && b != null ? -1 :\n    (a > b || b == null) && a != null ? 1 :\n    ((b = b instanceof Date ? +b : b),\n     (a = a instanceof Date ? +a : a)) !== a && b === b ? -1 :\n    b !== b && a === a ? 1 : 0;\n};\n\nu.numcmp = function(a, b) { return a - b; };\n\nu.stablesort = function(array, sortBy, keyFn) {\n  var indices = array.reduce(function(idx, v, i) {\n    return (idx[keyFn(v)] = i, idx);\n  }, {});\n\n  array.sort(function(a, b) {\n    var sa = sortBy(a),\n        sb = sortBy(b);\n    return sa < sb ? -1 : sa > sb ? 1\n         : (indices[keyFn(a)] - indices[keyFn(b)]);\n  });\n\n  return array;\n};\n\n// permutes an array using a Knuth shuffle\nu.permute = function(a) {\n  var m = a.length,\n      swap,\n      i;\n\n  while (m) {\n    i = Math.floor(Math.random() * m--);\n    swap = a[m];\n    a[m] = a[i];\n    a[i] = swap;\n  }\n};\n\n// string functions\n\nu.pad = function(s, length, pos, padchar) {\n  padchar = padchar || \" \";\n  var d = length - s.length;\n  if (d <= 0) return s;\n  switch (pos) {\n    case 'left':\n      return strrep(d, padchar) + s;\n    case 'middle':\n    case 'center':\n      return strrep(Math.floor(d/2), padchar) +\n         s + strrep(Math.ceil(d/2), padchar);\n    default:\n      return s + strrep(d, padchar);\n  }\n};\n\nfunction strrep(n, str) {\n  var s = \"\", i;\n  for (i=0; i<n; ++i) s += str;\n  return s;\n}\n\nu.truncate = function(s, length, pos, word, ellipsis) {\n  var len = s.length;\n  if (len <= length) return s;\n  ellipsis = ellipsis !== undefined ? String(ellipsis) : '\\u2026';\n  var l = Math.max(0, length - ellipsis.length);\n\n  switch (pos) {\n    case 'left':\n      return ellipsis + (word ? truncateOnWord(s,l,1) : s.slice(len-l));\n    case 'middle':\n    case 'center':\n      var l1 = Math.ceil(l/2), l2 = Math.floor(l/2);\n      return (word ? truncateOnWord(s,l1) : s.slice(0,l1)) +\n        ellipsis + (word ? truncateOnWord(s,l2,1) : s.slice(len-l2));\n    default:\n      return (word ? truncateOnWord(s,l) : s.slice(0,l)) + ellipsis;\n  }\n};\n\nfunction truncateOnWord(s, len, rev) {\n  var cnt = 0, tok = s.split(truncate_word_re);\n  if (rev) {\n    s = (tok = tok.reverse())\n      .filter(function(w) { cnt += w.length; return cnt <= len; })\n      .reverse();\n  } else {\n    s = tok.filter(function(w) { cnt += w.length; return cnt <= len; });\n  }\n  return s.length ? s.join('').trim() : tok[0].slice(0, len);\n}\n\nvar truncate_word_re = /([\\u0009\\u000A\\u000B\\u000C\\u000D\\u0020\\u00A0\\u1680\\u180E\\u2000\\u2001\\u2002\\u2003\\u2004\\u2005\\u2006\\u2007\\u2008\\u2009\\u200A\\u202F\\u205F\\u2028\\u2029\\u3000\\uFEFF])/;\n","import {isArray} from 'datalib/src/util';\nimport {Flag} from 'vega-lite/build/src/util';\n\nexport {cmp, keys, duplicate, extend, isObject, isBoolean, toMap} from 'datalib/src/util';\n\nexport {isArray};\n\nexport interface Dict<T> {\n  [key: string]: T;\n}\n\nexport function contains(array: any[], item: any) {\n  return array.indexOf(item) !== -1;\n};\n\nexport function every<T>(arr: T[], f: (item: T, key: number) => boolean) {\n  for (let i = 0; i < arr.length; i++) {\n    if (!f(arr[i], i)) {\n      return false;\n    }\n  }\n  return true;\n};\n\nexport function forEach(obj: any, f: (item: any, key: number|string, i: number)=>void, thisArg?: any) {\n  if (obj.forEach) {\n    obj.forEach.call(thisArg, f);\n  } else {\n    for (let k in obj) {\n      f.call(thisArg, obj[k], k, obj);\n    }\n  }\n};\n\nexport function some<T>(arr: T[], f: (item: T, key: number|string, i: number)=>boolean) {\n  let i = 0, k;\n  for (k in arr) {\n    if (f(arr[k], k, i++)) {\n      return true;\n    }\n  }\n  return false;\n};\n\nexport function nestedMap(array: any[], f: (item: any)=>any): any[] {\n  return array.map((a) => {\n    if (isArray(a)) {\n      return nestedMap(a, f);\n    }\n    return f(a);\n  });\n}\n\n/** Returns the array without the elements in item */\nexport function without<T>(array: Array<T>, excludedItems: Array<T>) {\n  return array.filter(function(item) {\n    return !contains(excludedItems, item);\n  });\n}\n\nexport function flagKeys<S extends string>(f: Flag<S>): S[] {\n  return Object.keys(f) as S[];\n}\n\nexport type Diff<T extends string, U extends string> = ({ [P in T]: P } & { [P in U]: never } & { [x: string]: never })[T];\n","import {Axis, AXIS_PROPERTIES} from 'vega-lite/build/src/axis';\nimport {BinParams} from 'vega-lite/build/src/bin';\nimport {Legend, LEGEND_PROPERTIES} from 'vega-lite/build/src/legend';\nimport {Scale, SCALE_PROPERTIES} from 'vega-lite/build/src/scale';\nimport {EncodingSortField} from 'vega-lite/build/src/sort';\nimport {Flag} from 'vega-lite/build/src/util';\nimport {AutoCountQuery, FieldQuery, ValueQuery} from './query/encoding';\nimport {TransformQuery} from './query/transform';\nimport {Diff, flagKeys} from './util';\n\n/**\n * There are two types of `Property`'s.\n * One is just flat property names.\n * (Try to hover `FlatProp` to see all of them.)\n * Another is an object that describes a parent property (e.g., `scale`) and the child property (e.g., `type`)\n */\nexport type Property = FlatProp | EncodingNestedProp;\nexport type FlatProp = MarkProp | TransformProp | ViewProp | EncodingTopLevelProp;\n\nexport type MarkProp = 'mark' | 'stack'; // FIXME: determine how 'stack' works;\nexport type TransformProp = keyof TransformQuery;\nexport type ViewProp = 'width' | 'height' | 'background' | 'padding' | 'title';\nexport type EncodingTopLevelProp = Diff<keyof (FieldQuery & ValueQuery & AutoCountQuery), 'description'>; // Do not include description since description is simply a metadata\n\nexport type EncodingNestedProp = BinProp | SortProp | ScaleProp | AxisProp | LegendProp;\n\nexport type EncodingNestedChildProp =\n  | keyof BinParams\n  | keyof EncodingSortField<string>\n  | keyof Scale\n  | keyof Axis\n  | keyof Legend;\n\n/**\n * An object that describes a parent property (e.g., `scale`) and the child property (e.g., `type`)\n */\nexport type BaseEncodingNestedProp<P, T> = {\n  parent: P;\n  child: keyof T;\n};\n\nexport type BinProp = BaseEncodingNestedProp<'bin', BinParams>;\nexport type SortProp = BaseEncodingNestedProp<'sort', EncodingSortField<string>>;\nexport type ScaleProp = BaseEncodingNestedProp<'scale', Scale>;\nexport type AxisProp = BaseEncodingNestedProp<'axis', Axis>;\nexport type LegendProp = BaseEncodingNestedProp<'legend', Legend>;\n\nexport function isEncodingNestedProp(p: Property): p is EncodingNestedProp {\n  return !!p['parent'];\n}\n\nconst ENCODING_TOPLEVEL_PROP_INDEX: Flag<EncodingTopLevelProp> = {\n  channel: 1,\n  aggregate: 1,\n  autoCount: 1,\n  bin: 1,\n  timeUnit: 1,\n  hasFn: 1,\n  sort: 1,\n  stack: 1,\n  field: 1,\n  type: 1,\n  format: 1,\n  scale: 1,\n  axis: 1,\n  legend: 1,\n  value: 1\n};\n\nexport const ENCODING_TOPLEVEL_PROPS = flagKeys(ENCODING_TOPLEVEL_PROP_INDEX);\n\nexport function isEncodingTopLevelProperty(p: Property): p is EncodingTopLevelProp {\n  return p in ENCODING_TOPLEVEL_PROP_INDEX;\n}\n\nexport type EncodingNestedPropParent = 'bin' | 'scale' | 'sort' | 'axis' | 'legend';\n\nconst ENCODING_NESTED_PROP_PARENT_INDEX: Flag<EncodingNestedPropParent> = {\n  bin: 1,\n  scale: 1,\n  sort: 1,\n  axis: 1,\n  legend: 1\n};\n\nexport function isEncodingNestedParent(prop: string): prop is EncodingNestedPropParent {\n  return ENCODING_NESTED_PROP_PARENT_INDEX[prop as string];\n}\n\n// FIXME -- we should not have to manually specify these\nexport const BIN_CHILD_PROPS: (keyof BinParams)[] = ['maxbins', 'divide', 'extent', 'base', 'step', 'steps', 'minstep'];\nexport const SORT_CHILD_PROPS: (keyof EncodingSortField<string>)[] = ['field', 'op', 'order'];\n\nconst BIN_PROPS = BIN_CHILD_PROPS.map(\n  (c): BinProp => {\n    return {parent: 'bin', child: c};\n  }\n);\n\nexport const SORT_PROPS = SORT_CHILD_PROPS.map(\n  (c): SortProp => {\n    return {parent: 'sort', child: c};\n  }\n);\n\nexport const SCALE_PROPS = SCALE_PROPERTIES.map(\n  (c): ScaleProp => {\n    return {parent: 'scale', child: c};\n  }\n);\n\nconst AXIS_PROPS = AXIS_PROPERTIES.map(\n  (c): AxisProp => {\n    return {parent: 'axis', child: c};\n  }\n);\n\nconst LEGEND_PROPS = LEGEND_PROPERTIES.map(\n  (c): LegendProp => {\n    return {parent: 'legend', child: c};\n  }\n);\n\nexport const ENCODING_NESTED_PROPS = ([] as EncodingNestedProp[]).concat(\n  BIN_PROPS,\n  SORT_PROPS,\n  SCALE_PROPS,\n  AXIS_PROPS,\n  LEGEND_PROPS\n);\n\nexport const VIEW_PROPS: Property[] = ['width', 'height', 'background', 'padding', 'title'] as Property[];\n\nconst PROP_KEY_DELIMITER = '.';\n\nexport function toKey(p: Property): string {\n  if (isEncodingNestedProp(p)) {\n    return p.parent + PROP_KEY_DELIMITER + p.child;\n  }\n  return p;\n}\n\nexport function fromKey(k: string): Property {\n  const split = k.split(PROP_KEY_DELIMITER);\n  /* istanbul ignore else */\n  if (split.length === 1) {\n    return k as Property;\n  } else if (split.length === 2) {\n    return {\n      parent: split[0],\n      child: split[1]\n    } as EncodingNestedProp;\n  } else {\n    throw 'Invalid property key with ' + split.length + ' dots: ' + k;\n  }\n}\n\nconst ENCODING_NESTED_PROP_INDEX = ENCODING_NESTED_PROPS.reduce((i, prop: EncodingNestedProp) => {\n  i[prop.parent] = i[prop.parent] || [];\n  i[prop.parent][prop.child] = prop;\n  return i;\n}, {});\n\n// FIXME consider using a more general method\nexport function getEncodingNestedProp(parent: EncodingTopLevelProp, child: EncodingNestedChildProp) {\n  return (ENCODING_NESTED_PROP_INDEX[parent] || {})[child];\n}\n\nexport function isEncodingProperty(p: Property): p is EncodingTopLevelProp | EncodingNestedProp {\n  return isEncodingTopLevelProperty(p) || isEncodingNestedProp(p);\n}\n\nexport const ALL_ENCODING_PROPS = ([] as Property[]).concat(ENCODING_TOPLEVEL_PROPS, ENCODING_NESTED_PROPS);\n\nexport const DEFAULT_PROP_PRECEDENCE: Property[] = ([\n  'type', // type is a constraint for field\n  'field',\n\n  // Field Transform\n  'bin',\n  'timeUnit',\n  'aggregate',\n  'autoCount',\n\n  // Encoding\n  'channel',\n\n  // Mark\n  'mark',\n  'stack',\n\n  'scale',\n  'sort',\n  'axis',\n  'legend'\n] as Property[]).concat(BIN_PROPS, SCALE_PROPS, AXIS_PROPS, LEGEND_PROPS, SORT_PROPS);\n\nexport namespace Property {\n  export const MARK: 'mark' = 'mark';\n\n  export const TRANSFORM: 'transform' = 'transform';\n  // Layout\n  export const STACK: 'stack' = 'stack';\n\n  export const FORMAT: 'format' = 'format';\n\n  // TODO: sub parts of stack\n\n  // Encoding Properties\n  export const CHANNEL: 'channel' = 'channel';\n  export const AGGREGATE: 'aggregate' = 'aggregate';\n  export const AUTOCOUNT: 'autoCount' = 'autoCount';\n  export const BIN: 'bin' = 'bin';\n\n  export const HAS_FN: 'hasFn' = 'hasFn';\n  export const TIMEUNIT: 'timeUnit' = 'timeUnit';\n  export const FIELD: 'field' = 'field';\n  export const TYPE: 'type' = 'type';\n\n  export const SORT: 'sort' = 'sort';\n\n  export const SCALE: 'scale' = 'scale';\n  export const AXIS: 'axis' = 'axis';\n\n  export const LEGEND: 'legend' = 'legend';\n\n  export const WIDTH: 'width' = 'width';\n  export const HEIGHT: 'height' = 'height';\n  export const BACKGROUND: 'background' = 'background';\n  export const PADDING: 'padding' = 'padding';\n  export const TITLE: 'title' = 'title';\n}\n","import {toSet} from 'vega-util';\nimport {CompositeMark, CompositeMarkDef} from './compositemark/index';\nimport {contains, flagKeys} from './util';\nimport {BaseMarkConfig} from './vega.schema';\n\nexport const AREA: 'area' = 'area';\nexport const BAR: 'bar' = 'bar';\nexport const LINE: 'line' = 'line';\nexport const POINT: 'point' = 'point';\nexport const RECT: 'rect' = 'rect';\nexport const RULE: 'rule' = 'rule';\nexport const TEXT: 'text' = 'text';\nexport const TICK: 'tick' = 'tick';\nexport const TRAIL: 'trail' = 'trail';\nexport const CIRCLE: 'circle' = 'circle';\nexport const SQUARE: 'square' = 'square';\nexport const GEOSHAPE: 'geoshape' = 'geoshape';\n\n/**\n * All types of primitive marks.\n */\nexport type Mark =\n  | typeof AREA\n  | typeof BAR\n  | typeof LINE\n  | typeof TRAIL\n  | typeof POINT\n  | typeof TEXT\n  | typeof TICK\n  | typeof RECT\n  | typeof RULE\n  | typeof CIRCLE\n  | typeof SQUARE\n  | typeof GEOSHAPE;\n\n// Using mapped type to declare index, ensuring we always have all marks when we add more.\nconst MARK_INDEX: {[M in Mark]: 1} = {\n  area: 1,\n  bar: 1,\n  line: 1,\n  point: 1,\n  text: 1,\n  tick: 1,\n  trail: 1,\n  rect: 1,\n  geoshape: 1,\n  rule: 1,\n  circle: 1,\n  square: 1\n};\n\nexport function isMark(m: string): m is Mark {\n  return !!MARK_INDEX[m];\n}\n\nexport function isPathMark(m: Mark | CompositeMark): m is 'line' | 'area' | 'trail' {\n  return contains(['line', 'area', 'trail'], m);\n}\n\nexport const PRIMITIVE_MARKS = flagKeys(MARK_INDEX);\n\nexport interface ColorMixins {\n  /**\n   * Default color.  Note that `fill` and `stroke` have higher precedence than `color` and will override `color`.\n   *\n   * __Default value:__ <span style=\"color: #4682b4;\">&#9632;</span> `\"#4682b4\"`\n   *\n   * __Note:__ This property cannot be used in a [style config](https://vega.github.io/vega-lite/docs/mark.html#style-config).\n   */\n  color?: string;\n}\n\nexport interface TooltipContent {\n  content: 'encoding' | 'data';\n}\n\nexport interface MarkConfig extends ColorMixins, BaseMarkConfig {\n  // ========== VL-Specific ==========\n\n  /**\n   * Whether the mark's color should be used as fill color instead of stroke color.\n   *\n   * __Default value:__ `false` for `point`, `line` and `rule`; otherwise, `true`.\n   *\n   * __Note:__ This property cannot be used in a [style config](https://vega.github.io/vega-lite/docs/mark.html#style-config).\n   *\n   */\n  filled?: boolean;\n\n  // ========== Overriding Vega ==========\n\n  /**\n   * The tooltip text string to show upon mouse hover or an object defining which fields should the tooltip be derived from.\n   *\n   * - If `tooltip` is `{\"content\": \"encoding\"}`, then all fields from `encoding` will be used.\n   * - If `tooltip` is `{\"content\": \"data\"}`, then all fields that appear in the highlighted data point will be used.\n   * - If set to `null`, then no tooltip will be used.\n   */\n  tooltip?: string | TooltipContent | null;\n\n  /**\n   * Default size for marks.\n   * - For `point`/`circle`/`square`, this represents the pixel area of the marks. For example: in the case of circles, the radius is determined in part by the square root of the size value.\n   * - For `bar`, this represents the band size of the bar, in pixels.\n   * - For `text`, this represents the font size, in pixels.\n   *\n   * __Default value:__ `30` for point, circle, square marks; `rangeStep` - 1 for bar marks with discrete dimensions; `5` for bar marks with continuous dimensions; `11` for text marks.\n   *\n   * @minimum 0\n   */\n  size?: number;\n\n  /**\n   * For line and trail marks, this `order` property can be set to `null` or `false` to make the lines use the original order in the data sources.\n   */\n  order?: null | boolean;\n}\n\nexport interface BarBinSpacingMixins {\n  /**\n   * Offset between bars for binned field.  Ideal value for this is either 0 (Preferred by statisticians) or 1 (Vega-Lite Default, D3 example style).\n   *\n   * __Default value:__ `1`\n   *\n   * @minimum 0\n   */\n  binSpacing?: number;\n}\n\nexport type AnyMark = CompositeMark | CompositeMarkDef | Mark | MarkDef;\n\nexport function isMarkDef(mark: string | GenericMarkDef<any>): mark is GenericMarkDef<any> {\n  return mark['type'];\n}\n\nconst PRIMITIVE_MARK_INDEX = toSet(PRIMITIVE_MARKS);\n\nexport function isPrimitiveMark(mark: AnyMark): mark is Mark {\n  const markType = isMarkDef(mark) ? mark.type : mark;\n  return markType in PRIMITIVE_MARK_INDEX;\n}\n\nexport const STROKE_CONFIG = [\n  'stroke',\n  'strokeWidth',\n  'strokeDash',\n  'strokeDashOffset',\n  'strokeOpacity',\n  'strokeJoin',\n  'strokeMiterLimit'\n];\n\nexport const FILL_CONFIG = ['fill', 'fillOpacity'];\n\nexport const FILL_STROKE_CONFIG = [].concat(STROKE_CONFIG, FILL_CONFIG);\n\nexport const VL_ONLY_MARK_CONFIG_PROPERTIES: (keyof MarkConfig)[] = ['filled', 'color', 'tooltip'];\n\nexport const VL_ONLY_MARK_SPECIFIC_CONFIG_PROPERTY_INDEX: {\n  [k in typeof PRIMITIVE_MARKS[0]]?: (keyof MarkConfigMixins[k])[]\n} = {\n  area: ['line', 'point'],\n  bar: ['binSpacing', 'continuousBandSize', 'discreteBandSize'],\n  line: ['point'],\n  text: ['shortTimeLabels'],\n  tick: ['bandSize', 'thickness']\n};\n\nexport const defaultMarkConfig: MarkConfig = {\n  color: '#4c78a8',\n  tooltip: {content: 'encoding'}\n};\n\nexport interface MarkConfigMixins {\n  /** Mark Config */\n  mark?: MarkConfig;\n\n  // MARK-SPECIFIC CONFIGS\n  /** Area-Specific Config */\n  area?: AreaConfig;\n\n  /** Bar-Specific Config */\n  bar?: BarConfig;\n\n  /** Circle-Specific Config */\n  circle?: MarkConfig;\n\n  /** Line-Specific Config */\n  line?: LineConfig;\n\n  /** Point-Specific Config */\n  point?: MarkConfig;\n\n  /** Rect-Specific Config */\n  rect?: MarkConfig;\n\n  /** Rule-Specific Config */\n  rule?: MarkConfig;\n\n  /** Square-Specific Config */\n  square?: MarkConfig;\n\n  /** Text-Specific Config */\n  text?: TextConfig;\n\n  /** Tick-Specific Config */\n  tick?: TickConfig;\n\n  /** Trail-Specific Config */\n  trail?: LineConfig;\n\n  /** Geoshape-Specific Config */\n  geoshape?: MarkConfig;\n}\n\nexport interface BarConfig extends BarBinSpacingMixins, MarkConfig {\n  /**\n   * The default size of the bars on continuous scales.\n   *\n   * __Default value:__ `5`\n   *\n   * @minimum 0\n   */\n  continuousBandSize?: number;\n\n  /**\n   * The default size of the bars with discrete dimensions.  If unspecified, the default size is  `bandSize-1`,\n   * which provides 1 pixel offset between bars.\n   * @minimum 0\n   */\n  discreteBandSize?: number;\n}\n\nexport type OverlayMarkDef = MarkConfig & MarkDefMixins;\n\nexport interface PointOverlayMixins {\n  /**\n   * A flag for overlaying points on top of line or area marks, or an object defining the properties of the overlayed points.\n   *\n   * - If this property is `\"transparent\"`, transparent points will be used (for enhancing tooltips and selections).\n   *\n   * - If this property is an empty object (`{}`) or `true`, filled points with default properties will be used.\n   *\n   * - If this property is `false`, no points would be automatically added to line or area marks.\n   *\n   * __Default value:__ `false`.\n   */\n  point?: boolean | OverlayMarkDef | 'transparent';\n}\n\nexport interface LineConfig extends MarkConfig, PointOverlayMixins {}\n\nexport interface LineOverlayMixins {\n  /**\n   * A flag for overlaying line on top of area marks, or an object defining the properties of the overlayed lines.\n   *\n   * - If this value is an empty object (`{}`) or `true`, lines with default properties will be used.\n   *\n   * - If this value is `false`, no lines would be automatically added to area marks.\n   *\n   * __Default value:__ `false`.\n   */\n  line?: boolean | OverlayMarkDef;\n}\n\nexport interface AreaConfig extends MarkConfig, PointOverlayMixins, LineOverlayMixins {}\n\nexport interface TickThicknessMixins {\n  /**\n   * Thickness of the tick mark.\n   *\n   * __Default value:__  `1`\n   *\n   * @minimum 0\n   */\n  thickness?: number;\n}\n\nexport interface GenericMarkDef<M> {\n  /**\n   * The mark type. This could a primitive mark type\n   * (one of `\"bar\"`, `\"circle\"`, `\"square\"`, `\"tick\"`, `\"line\"`,\n   * `\"area\"`, `\"point\"`, `\"geoshape\"`, `\"rule\"`, and `\"text\"`)\n   * or a composite mark type (`\"boxplot\"`, `\"errorband\"`, `\"errorbar\"`).\n   */\n  type: M;\n}\n\nexport interface MarkDefMixins {\n  /**\n   * A string or array of strings indicating the name of custom styles to apply to the mark. A style is a named collection of mark property defaults defined within the [style configuration](https://vega.github.io/vega-lite/docs/mark.html#style-config). If style is an array, later styles will override earlier styles. Any [mark properties](https://vega.github.io/vega-lite/docs/encoding.html#mark-prop) explicitly defined within the `encoding` will override a style default.\n   *\n   * __Default value:__ The mark's name.  For example, a bar mark will have style `\"bar\"` by default.\n   * __Note:__ Any specified style will augment the default style. For example, a bar mark with `\"style\": \"foo\"` will receive from `config.style.bar` and `config.style.foo` (the specified style `\"foo\"` has higher precedence).\n   */\n  style?: string | string[];\n\n  /**\n   * Whether a mark be clipped to the enclosing group’s width and height.\n   */\n  clip?: boolean;\n\n  // Offset properties should not be a part of config\n\n  /**\n   * Offset for x-position.\n   */\n  xOffset?: number;\n\n  /**\n   * Offset for y-position.\n   */\n  yOffset?: number;\n\n  /**\n   * Offset for x2-position.\n   */\n  x2Offset?: number;\n\n  /**\n   * Offset for y2-position.\n   */\n  y2Offset?: number;\n}\n\n// Point/Line OverlayMixins are only for area, line, and trail but we don't want to declare multiple types of MarkDef\n\n// Point/Line OverlayMixins are only for area, line, and trail but we don't want to declare multiple types of MarkDef\nexport interface MarkDef<M extends string | Mark = Mark>\n  extends GenericMarkDef<M>,\n    BarBinSpacingMixins,\n    MarkConfig,\n    PointOverlayMixins,\n    LineOverlayMixins,\n    TickThicknessMixins,\n    MarkDefMixins {}\n\nexport const defaultBarConfig: BarConfig = {\n  binSpacing: 1,\n  continuousBandSize: 5\n};\n\nexport interface TextConfig extends MarkConfig {\n  /**\n   * Whether month names and weekday names should be abbreviated.\n   */\n  shortTimeLabels?: boolean;\n}\n\nexport interface TickConfig extends MarkConfig, TickThicknessMixins {\n  /**\n   * The width of the ticks.\n   *\n   * __Default value:__  3/4 of rangeStep.\n   * @minimum 0\n   */\n  bandSize?: number;\n}\n\nexport const defaultTickConfig: TickConfig = {\n  thickness: 1\n};\n\nexport function getMarkType(m: string | GenericMarkDef<any>) {\n  return isMarkDef(m) ? m.type : m;\n}\n","// DateTime definition object\n\nimport {isNumber} from 'vega-util';\nimport * as log from './log';\nimport {duplicate, keys} from './util';\n\n/*\n * A designated year that starts on Sunday.\n */\nconst SUNDAY_YEAR = 2006;\n\n/**\n * @minimum 1\n * @maximum 12\n * @TJS-type integer\n */\nexport type Month = number;\n\n/**\n * @minimum 1\n * @maximum 7\n */\nexport type Day = number;\n\n/**\n * Object for defining datetime in Vega-Lite Filter.\n * If both month and quarter are provided, month has higher precedence.\n * `day` cannot be combined with other date.\n * We accept string for month and day names.\n */\nexport interface DateTime {\n  /**\n   * Integer value representing the year.\n   * @TJS-type integer\n   */\n  year?: number;\n\n  /**\n   * Integer value representing the quarter of the year (from 1-4).\n   * @minimum 1\n   * @maximum 4\n   * @TJS-type integer\n   */\n  quarter?: number;\n\n  /** One of: (1) integer value representing the month from `1`-`12`. `1` represents January;  (2) case-insensitive month name (e.g., `\"January\"`);  (3) case-insensitive, 3-character short month name (e.g., `\"Jan\"`). */\n  month?: Month | string;\n\n  /**\n   * Integer value representing the date from 1-31.\n   * @minimum 1\n   * @maximum 31\n   * @TJS-type integer\n   */\n  date?: number;\n\n  /**\n   * Value representing the day of a week.  This can be one of: (1) integer value -- `1` represents Monday; (2) case-insensitive day name (e.g., `\"Monday\"`);  (3) case-insensitive, 3-character short day name (e.g., `\"Mon\"`).   <br/> **Warning:** A DateTime definition object with `day`** should not be combined with `year`, `quarter`, `month`, or `date`.\n   */\n  day?: Day | string;\n\n  /**\n   * Integer value representing the hour of a day from 0-23.\n   * @minimum 0\n   * @maximum 23\n   * @TJS-type integer\n   */\n  hours?: number;\n\n  /**\n   * Integer value representing the minute segment of time from 0-59.\n   * @minimum 0\n   * @maximum 59\n   * @TJS-type integer\n   */\n  minutes?: number;\n\n  /**\n   * Integer value representing the second segment (0-59) of a time value\n   * @minimum 0\n   * @maximum 59\n   * @TJS-type integer\n   */\n  seconds?: number;\n\n  /**\n   * Integer value representing the millisecond segment of time.\n   * @minimum 0\n   * @maximum 999\n   * @TJS-type integer\n   */\n  milliseconds?: number;\n\n  /**\n   * A boolean flag indicating if date time is in utc time. If false, the date time is in local time\n   */\n  utc?: boolean;\n}\n\n/**\n * Internal Object for defining datetime expressions.\n * This is an expression version of DateTime.\n * If both month and quarter are provided, month has higher precedence.\n * `day` cannot be combined with other date.\n */\nexport interface DateTimeExpr {\n  year?: string;\n  quarter?: string;\n  month?: string;\n  date?: string;\n  day?: string;\n  hours?: string;\n  minutes?: string;\n  seconds?: string;\n  milliseconds?: string;\n  utc?: boolean;\n}\n\nexport function isDateTime(o: any): o is DateTime {\n  return (\n    !!o &&\n    (!!o.year ||\n      !!o.quarter ||\n      !!o.month ||\n      !!o.date ||\n      !!o.day ||\n      !!o.hours ||\n      !!o.minutes ||\n      !!o.seconds ||\n      !!o.milliseconds)\n  );\n}\n\nexport const MONTHS = [\n  'january',\n  'february',\n  'march',\n  'april',\n  'may',\n  'june',\n  'july',\n  'august',\n  'september',\n  'october',\n  'november',\n  'december'\n];\nexport const SHORT_MONTHS = MONTHS.map(m => m.substr(0, 3));\n\nexport const DAYS = ['sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday'];\nexport const SHORT_DAYS = DAYS.map(d => d.substr(0, 3));\n\nfunction normalizeQuarter(q: number | string) {\n  if (isNumber(q)) {\n    if (q > 4) {\n      log.warn(log.message.invalidTimeUnit('quarter', q));\n    }\n    // We accept 1-based quarter, so need to readjust to 0-based quarter\n    return (q - 1).toString();\n  } else {\n    // Invalid quarter\n    throw new Error(log.message.invalidTimeUnit('quarter', q));\n  }\n}\n\nfunction normalizeMonth(m: string | number) {\n  if (isNumber(m)) {\n    // We accept 1-based month, so need to readjust to 0-based month\n    return (m - 1).toString();\n  } else {\n    const lowerM = m.toLowerCase();\n    const monthIndex = MONTHS.indexOf(lowerM);\n    if (monthIndex !== -1) {\n      return monthIndex + ''; // 0 for january, ...\n    }\n    const shortM = lowerM.substr(0, 3);\n    const shortMonthIndex = SHORT_MONTHS.indexOf(shortM);\n    if (shortMonthIndex !== -1) {\n      return shortMonthIndex + '';\n    }\n    // Invalid month\n    throw new Error(log.message.invalidTimeUnit('month', m));\n  }\n}\n\nfunction normalizeDay(d: string | number) {\n  if (isNumber(d)) {\n    // mod so that this can be both 0-based where 0 = sunday\n    // and 1-based where 7=sunday\n    return (d % 7) + '';\n  } else {\n    const lowerD = d.toLowerCase();\n    const dayIndex = DAYS.indexOf(lowerD);\n    if (dayIndex !== -1) {\n      return dayIndex + ''; // 0 for january, ...\n    }\n    const shortD = lowerD.substr(0, 3);\n    const shortDayIndex = SHORT_DAYS.indexOf(shortD);\n    if (shortDayIndex !== -1) {\n      return shortDayIndex + '';\n    }\n    // Invalid day\n    throw new Error(log.message.invalidTimeUnit('day', d));\n  }\n}\n\n/**\n * Return Vega Expression for a particular date time.\n * @param d\n * @param normalize whether to normalize quarter, month, day.\n */\nexport function dateTimeExpr(d: DateTime | DateTimeExpr, normalize = false) {\n  const units: (string | number)[] = [];\n\n  if (normalize && d.day !== undefined) {\n    if (keys(d).length > 1) {\n      log.warn(log.message.droppedDay(d));\n      d = duplicate(d);\n      delete d.day;\n    }\n  }\n\n  if (d.year !== undefined) {\n    units.push(d.year);\n  } else if (d.day !== undefined) {\n    // Set year to 2006 for working with day since January 1 2006 is a Sunday\n    units.push(SUNDAY_YEAR);\n  } else {\n    units.push(0);\n  }\n\n  if (d.month !== undefined) {\n    const month = normalize ? normalizeMonth(d.month) : d.month;\n    units.push(month);\n  } else if (d.quarter !== undefined) {\n    const quarter = normalize ? normalizeQuarter(d.quarter) : d.quarter;\n    units.push(quarter + '*3');\n  } else {\n    units.push(0); // months start at zero in JS\n  }\n\n  if (d.date !== undefined) {\n    units.push(d.date);\n  } else if (d.day !== undefined) {\n    // HACK: Day only works as a standalone unit\n    // This is only correct because we always set year to 2006 for day\n    const day = normalize ? normalizeDay(d.day) : d.day;\n    units.push(day + '+1');\n  } else {\n    units.push(1); // Date starts at 1 in JS\n  }\n\n  // Note: can't use TimeUnit enum here as importing it will create\n  // circular dependency problem!\n  for (const timeUnit of ['hours', 'minutes', 'seconds', 'milliseconds']) {\n    if (d[timeUnit] !== undefined) {\n      units.push(d[timeUnit]);\n    } else {\n      units.push(0);\n    }\n  }\n\n  if (d.utc) {\n    return `utc(${units.join(', ')})`;\n  } else {\n    return `datetime(${units.join(', ')})`;\n  }\n}\n","import {DateTimeExpr, dateTimeExpr} from './datetime';\nimport * as log from './log';\nimport {accessPathWithDatum, Flag, flagKeys} from './util';\n\nexport namespace TimeUnit {\n  export const YEAR: 'year' = 'year';\n  export const MONTH: 'month' = 'month';\n  export const DAY: 'day' = 'day';\n  export const DATE: 'date' = 'date';\n  export const HOURS: 'hours' = 'hours';\n  export const MINUTES: 'minutes' = 'minutes';\n  export const SECONDS: 'seconds' = 'seconds';\n  export const MILLISECONDS: 'milliseconds' = 'milliseconds';\n  export const YEARMONTH: 'yearmonth' = 'yearmonth';\n  export const YEARMONTHDATE: 'yearmonthdate' = 'yearmonthdate';\n  export const YEARMONTHDATEHOURS: 'yearmonthdatehours' = 'yearmonthdatehours';\n  export const YEARMONTHDATEHOURSMINUTES: 'yearmonthdatehoursminutes' = 'yearmonthdatehoursminutes';\n  export const YEARMONTHDATEHOURSMINUTESSECONDS: 'yearmonthdatehoursminutesseconds' =\n    'yearmonthdatehoursminutesseconds';\n\n  // MONTHDATE and MONTHDATEHOURS always include 29 February since we use year 0th (which is a leap year);\n  export const MONTHDATE: 'monthdate' = 'monthdate';\n  export const MONTHDATEHOURS: 'monthdatehours' = 'monthdatehours';\n  export const HOURSMINUTES: 'hoursminutes' = 'hoursminutes';\n  export const HOURSMINUTESSECONDS: 'hoursminutesseconds' = 'hoursminutesseconds';\n  export const MINUTESSECONDS: 'minutesseconds' = 'minutesseconds';\n  export const SECONDSMILLISECONDS: 'secondsmilliseconds' = 'secondsmilliseconds';\n  export const QUARTER: 'quarter' = 'quarter';\n  export const YEARQUARTER: 'yearquarter' = 'yearquarter';\n  export const QUARTERMONTH: 'quartermonth' = 'quartermonth';\n  export const YEARQUARTERMONTH: 'yearquartermonth' = 'yearquartermonth';\n  export const UTCYEAR: 'utcyear' = 'utcyear';\n  export const UTCMONTH: 'utcmonth' = 'utcmonth';\n  export const UTCDAY: 'utcday' = 'utcday';\n  export const UTCDATE: 'utcdate' = 'utcdate';\n  export const UTCHOURS: 'utchours' = 'utchours';\n  export const UTCMINUTES: 'utcminutes' = 'utcminutes';\n  export const UTCSECONDS: 'utcseconds' = 'utcseconds';\n  export const UTCMILLISECONDS: 'utcmilliseconds' = 'utcmilliseconds';\n  export const UTCYEARMONTH: 'utcyearmonth' = 'utcyearmonth';\n  export const UTCYEARMONTHDATE: 'utcyearmonthdate' = 'utcyearmonthdate';\n  export const UTCYEARMONTHDATEHOURS: 'utcyearmonthdatehours' = 'utcyearmonthdatehours';\n  export const UTCYEARMONTHDATEHOURSMINUTES: 'utcyearmonthdatehoursminutes' = 'utcyearmonthdatehoursminutes';\n  export const UTCYEARMONTHDATEHOURSMINUTESSECONDS: 'utcyearmonthdatehoursminutesseconds' =\n    'utcyearmonthdatehoursminutesseconds';\n\n  // UTCMONTHDATE and UTCMONTHDATEHOURS always include 29 February since we use year 0th (which is a leap year);\n  export const UTCMONTHDATE: 'utcmonthdate' = 'utcmonthdate';\n  export const UTCMONTHDATEHOURS: 'utcmonthdatehours' = 'utcmonthdatehours';\n  export const UTCHOURSMINUTES: 'utchoursminutes' = 'utchoursminutes';\n  export const UTCHOURSMINUTESSECONDS: 'utchoursminutesseconds' = 'utchoursminutesseconds';\n  export const UTCMINUTESSECONDS: 'utcminutesseconds' = 'utcminutesseconds';\n  export const UTCSECONDSMILLISECONDS: 'utcsecondsmilliseconds' = 'utcsecondsmilliseconds';\n  export const UTCQUARTER: 'utcquarter' = 'utcquarter';\n  export const UTCYEARQUARTER: 'utcyearquarter' = 'utcyearquarter';\n  export const UTCQUARTERMONTH: 'utcquartermonth' = 'utcquartermonth';\n  export const UTCYEARQUARTERMONTH: 'utcyearquartermonth' = 'utcyearquartermonth';\n}\n\nexport type LocalSingleTimeUnit =\n  | typeof TimeUnit.YEAR\n  | typeof TimeUnit.QUARTER\n  | typeof TimeUnit.MONTH\n  | typeof TimeUnit.DAY\n  | typeof TimeUnit.DATE\n  | typeof TimeUnit.HOURS\n  | typeof TimeUnit.MINUTES\n  | typeof TimeUnit.SECONDS\n  | typeof TimeUnit.MILLISECONDS;\n\n/** Time Unit that only corresponds to only one part of Date objects. */\nconst LOCAL_SINGLE_TIMEUNIT_INDEX: Flag<LocalSingleTimeUnit> = {\n  year: 1,\n  quarter: 1,\n  month: 1,\n  day: 1,\n  date: 1,\n  hours: 1,\n  minutes: 1,\n  seconds: 1,\n  milliseconds: 1\n};\n\nexport const TIMEUNIT_PARTS = flagKeys(LOCAL_SINGLE_TIMEUNIT_INDEX);\n\nexport function isLocalSingleTimeUnit(timeUnit: string): timeUnit is LocalSingleTimeUnit {\n  return !!LOCAL_SINGLE_TIMEUNIT_INDEX[timeUnit];\n}\n\nexport type UtcSingleTimeUnit =\n  | typeof TimeUnit.UTCYEAR\n  | typeof TimeUnit.UTCQUARTER\n  | typeof TimeUnit.UTCMONTH\n  | typeof TimeUnit.UTCDAY\n  | typeof TimeUnit.UTCDATE\n  | typeof TimeUnit.UTCHOURS\n  | typeof TimeUnit.UTCMINUTES\n  | typeof TimeUnit.UTCSECONDS\n  | typeof TimeUnit.UTCMILLISECONDS;\n\nconst UTC_SINGLE_TIMEUNIT_INDEX: Flag<UtcSingleTimeUnit> = {\n  utcyear: 1,\n  utcquarter: 1,\n  utcmonth: 1,\n  utcday: 1,\n  utcdate: 1,\n  utchours: 1,\n  utcminutes: 1,\n  utcseconds: 1,\n  utcmilliseconds: 1\n};\n\nexport function isUtcSingleTimeUnit(timeUnit: string): timeUnit is UtcSingleTimeUnit {\n  return !!UTC_SINGLE_TIMEUNIT_INDEX[timeUnit];\n}\n\nexport type SingleTimeUnit = LocalSingleTimeUnit | UtcSingleTimeUnit;\n\nexport type LocalMultiTimeUnit =\n  // Local Time\n  | typeof TimeUnit.YEARQUARTER\n  | typeof TimeUnit.YEARQUARTERMONTH\n  | typeof TimeUnit.YEARMONTH\n  | typeof TimeUnit.YEARMONTHDATE\n  | typeof TimeUnit.YEARMONTHDATEHOURS\n  | typeof TimeUnit.YEARMONTHDATEHOURSMINUTES\n  | typeof TimeUnit.YEARMONTHDATEHOURSMINUTESSECONDS\n  | typeof TimeUnit.QUARTERMONTH\n  | typeof TimeUnit.MONTHDATE\n  | typeof TimeUnit.MONTHDATEHOURS\n  | typeof TimeUnit.HOURSMINUTES\n  | typeof TimeUnit.HOURSMINUTESSECONDS\n  | typeof TimeUnit.MINUTESSECONDS\n  | typeof TimeUnit.SECONDSMILLISECONDS;\n\nconst LOCAL_MULTI_TIMEUNIT_INDEX: Flag<LocalMultiTimeUnit> = {\n  yearquarter: 1,\n  yearquartermonth: 1,\n\n  yearmonth: 1,\n  yearmonthdate: 1,\n  yearmonthdatehours: 1,\n  yearmonthdatehoursminutes: 1,\n  yearmonthdatehoursminutesseconds: 1,\n\n  quartermonth: 1,\n\n  monthdate: 1,\n  monthdatehours: 1,\n\n  hoursminutes: 1,\n  hoursminutesseconds: 1,\n\n  minutesseconds: 1,\n\n  secondsmilliseconds: 1\n};\n\nexport type UtcMultiTimeUnit =\n  | typeof TimeUnit.UTCYEARQUARTER\n  | typeof TimeUnit.UTCYEARQUARTERMONTH\n  | typeof TimeUnit.UTCYEARMONTH\n  | typeof TimeUnit.UTCYEARMONTHDATE\n  | typeof TimeUnit.UTCYEARMONTHDATEHOURS\n  | typeof TimeUnit.UTCYEARMONTHDATEHOURSMINUTES\n  | typeof TimeUnit.UTCYEARMONTHDATEHOURSMINUTESSECONDS\n  | typeof TimeUnit.UTCQUARTERMONTH\n  | typeof TimeUnit.UTCMONTHDATE\n  | typeof TimeUnit.UTCMONTHDATEHOURS\n  | typeof TimeUnit.UTCHOURSMINUTES\n  | typeof TimeUnit.UTCHOURSMINUTESSECONDS\n  | typeof TimeUnit.UTCMINUTESSECONDS\n  | typeof TimeUnit.UTCSECONDSMILLISECONDS;\n\nconst UTC_MULTI_TIMEUNIT_INDEX: Flag<UtcMultiTimeUnit> = {\n  utcyearquarter: 1,\n  utcyearquartermonth: 1,\n\n  utcyearmonth: 1,\n  utcyearmonthdate: 1,\n  utcyearmonthdatehours: 1,\n  utcyearmonthdatehoursminutes: 1,\n  utcyearmonthdatehoursminutesseconds: 1,\n\n  utcquartermonth: 1,\n\n  utcmonthdate: 1,\n  utcmonthdatehours: 1,\n\n  utchoursminutes: 1,\n  utchoursminutesseconds: 1,\n\n  utcminutesseconds: 1,\n\n  utcsecondsmilliseconds: 1\n};\n\nexport type MultiTimeUnit = LocalMultiTimeUnit | UtcMultiTimeUnit;\n\nexport type LocalTimeUnit = LocalSingleTimeUnit | LocalMultiTimeUnit;\nexport type UtcTimeUnit = UtcSingleTimeUnit | UtcMultiTimeUnit;\n\nconst UTC_TIMEUNIT_INDEX: Flag<UtcTimeUnit> = {\n  ...UTC_SINGLE_TIMEUNIT_INDEX,\n  ...UTC_MULTI_TIMEUNIT_INDEX\n};\n\nexport function isUTCTimeUnit(t: string): t is UtcTimeUnit {\n  return !!UTC_TIMEUNIT_INDEX[t];\n}\n\nexport function getLocalTimeUnit(t: UtcTimeUnit): LocalTimeUnit {\n  return t.substr(3) as LocalTimeUnit;\n}\n\nexport type TimeUnit = SingleTimeUnit | MultiTimeUnit;\n\nconst TIMEUNIT_INDEX: Flag<TimeUnit> = {\n  ...LOCAL_SINGLE_TIMEUNIT_INDEX,\n  ...UTC_SINGLE_TIMEUNIT_INDEX,\n  ...LOCAL_MULTI_TIMEUNIT_INDEX,\n  ...UTC_MULTI_TIMEUNIT_INDEX\n};\n\nexport const TIMEUNITS = flagKeys(TIMEUNIT_INDEX);\n\nexport function isTimeUnit(t: string): t is TimeUnit {\n  return !!TIMEUNIT_INDEX[t];\n}\n\ntype DateMethodName = keyof Date;\n\nconst SET_DATE_METHOD: Record<LocalSingleTimeUnit, DateMethodName> = {\n  year: 'setFullYear',\n  month: 'setMonth',\n  date: 'setDate',\n  hours: 'setHours',\n  minutes: 'setMinutes',\n  seconds: 'setSeconds',\n  milliseconds: 'setMilliseconds',\n  // Day and quarter have their own special cases\n  quarter: null,\n  day: null\n};\n\n/**\n * Converts a date to only have the measurements relevant to the specified unit\n * i.e. ('yearmonth', '2000-12-04 07:58:14') -> '2000-12-01 00:00:00'\n * Note: the base date is Jan 01 1900 00:00:00\n */\nexport function convert(unit: TimeUnit, date: Date): Date {\n  const isUTC = isUTCTimeUnit(unit);\n  const result: Date = isUTC\n    ? // start with uniform date\n      new Date(Date.UTC(1972, 0, 1, 0, 0, 0, 0)) // 1972 is the first leap year after 1970, the start of unix time\n    : new Date(1972, 0, 1, 0, 0, 0, 0);\n  for (const timeUnitPart of TIMEUNIT_PARTS) {\n    if (containsTimeUnit(unit, timeUnitPart)) {\n      switch (timeUnitPart) {\n        case TimeUnit.DAY:\n          throw new Error(\"Cannot convert to TimeUnits containing 'day'\");\n        case TimeUnit.QUARTER: {\n          const {getDateMethod, setDateMethod} = dateMethods('month', isUTC);\n          // indicate quarter by setting month to be the first of the quarter i.e. may (4) -> april (3)\n          result[setDateMethod](Math.floor(date[getDateMethod]() / 3) * 3);\n          break;\n        }\n        default: {\n          const {getDateMethod, setDateMethod} = dateMethods(timeUnitPart, isUTC);\n          result[setDateMethod](date[getDateMethod]());\n        }\n      }\n    }\n  }\n  return result;\n}\n\nfunction dateMethods(singleUnit: SingleTimeUnit, isUtc: boolean) {\n  const rawSetDateMethod = SET_DATE_METHOD[singleUnit];\n  const setDateMethod = isUtc ? 'setUTC' + rawSetDateMethod.substr(3) : rawSetDateMethod;\n  const getDateMethod = 'get' + (isUtc ? 'UTC' : '') + rawSetDateMethod.substr(3);\n  return {setDateMethod, getDateMethod};\n}\n\nexport function getTimeUnitParts(timeUnit: TimeUnit) {\n  return TIMEUNIT_PARTS.reduce((parts, part) => {\n    if (containsTimeUnit(timeUnit, part)) {\n      return [...parts, part];\n    }\n    return parts;\n  }, []);\n}\n\n/** Returns true if fullTimeUnit contains the timeUnit, false otherwise. */\nexport function containsTimeUnit(fullTimeUnit: TimeUnit, timeUnit: TimeUnit) {\n  const index = fullTimeUnit.indexOf(timeUnit);\n  return (\n    index > -1 && (timeUnit !== TimeUnit.SECONDS || index === 0 || fullTimeUnit.charAt(index - 1) !== 'i') // exclude milliseconds\n  );\n}\n\n/**\n * Returns Vega expresssion for a given timeUnit and fieldRef\n */\nexport function fieldExpr(fullTimeUnit: TimeUnit, field: string): string {\n  const fieldRef = accessPathWithDatum(field);\n\n  const utc = isUTCTimeUnit(fullTimeUnit) ? 'utc' : '';\n  function func(timeUnit: TimeUnit) {\n    if (timeUnit === TimeUnit.QUARTER) {\n      // quarter starting at 0 (0,3,6,9).\n      return `(${utc}quarter(${fieldRef})-1)`;\n    } else {\n      return `${utc}${timeUnit}(${fieldRef})`;\n    }\n  }\n\n  const d = TIMEUNIT_PARTS.reduce(\n    (dateExpr: DateTimeExpr, tu: TimeUnit) => {\n      if (containsTimeUnit(fullTimeUnit, tu)) {\n        dateExpr[tu] = func(tu);\n      }\n      return dateExpr;\n    },\n    {} as {[key in SingleTimeUnit]: string}\n  );\n\n  return dateTimeExpr(d);\n}\n\nexport function getDateTimeComponents(timeUnit: TimeUnit, shortTimeLabels: boolean) {\n  if (!timeUnit) {\n    return undefined;\n  }\n\n  const dateComponents: string[] = [];\n  const hasYear = containsTimeUnit(timeUnit, TimeUnit.YEAR);\n\n  if (containsTimeUnit(timeUnit, TimeUnit.MONTH)) {\n    // By default use short month name\n    dateComponents.push(shortTimeLabels !== false ? '%b' : '%B');\n  }\n\n  if (containsTimeUnit(timeUnit, TimeUnit.DAY)) {\n    dateComponents.push(shortTimeLabels ? '%a' : '%A');\n  } else if (containsTimeUnit(timeUnit, TimeUnit.DATE)) {\n    dateComponents.push('%d' + (hasYear ? ',' : '')); // add comma if there is year\n  }\n\n  if (hasYear) {\n    dateComponents.push(shortTimeLabels ? '%y' : '%Y');\n  }\n\n  const timeComponents: string[] = [];\n\n  if (containsTimeUnit(timeUnit, TimeUnit.HOURS)) {\n    timeComponents.push('%H');\n  }\n  if (containsTimeUnit(timeUnit, TimeUnit.MINUTES)) {\n    timeComponents.push('%M');\n  }\n  if (containsTimeUnit(timeUnit, TimeUnit.SECONDS)) {\n    timeComponents.push('%S');\n  }\n  if (containsTimeUnit(timeUnit, TimeUnit.MILLISECONDS)) {\n    timeComponents.push('%L');\n  }\n\n  const dateTimeComponents: string[] = [];\n  if (dateComponents.length > 0) {\n    dateTimeComponents.push(dateComponents.join(' '));\n  }\n  if (timeComponents.length > 0) {\n    dateTimeComponents.push(timeComponents.join(':'));\n  }\n\n  return dateTimeComponents;\n}\n\n/**\n * returns the signal expression used for axis labels for a time unit\n */\nexport function formatExpression(\n  timeUnit: TimeUnit,\n  field: string,\n  shortTimeLabels: boolean,\n  isUTCScale: boolean\n): string {\n  if (!timeUnit) {\n    return undefined;\n  }\n\n  const dateTimeComponents: string[] = getDateTimeComponents(timeUnit, shortTimeLabels);\n  let expression = '';\n\n  if (containsTimeUnit(timeUnit, TimeUnit.QUARTER)) {\n    // special expression for quarter as prefix\n    expression = `'Q' + quarter(${field})`;\n  }\n\n  if (dateTimeComponents.length > 0) {\n    if (expression) {\n      // Add space between quarter and main time format\n      expression += ` + ' ' + `;\n    }\n\n    // We only use utcFormat for utc scale\n    // For utc time units, the data is already converted as a part of timeUnit transform.\n    // Thus, utc time units should use timeFormat to avoid shifting the time twice.\n    if (isUTCScale) {\n      expression += `utcFormat(${field}, '${dateTimeComponents.join(' ')}')`;\n    } else {\n      expression += `timeFormat(${field}, '${dateTimeComponents.join(' ')}')`;\n    }\n  }\n\n  // If expression is still an empty string, return undefined instead.\n  return expression || undefined;\n}\n\nexport function normalizeTimeUnit(timeUnit: TimeUnit): TimeUnit {\n  if (timeUnit !== 'day' && timeUnit.indexOf('day') >= 0) {\n    log.warn(log.message.dayReplacedWithDate(timeUnit));\n    return timeUnit.replace('day', 'date') as TimeUnit;\n  }\n  return timeUnit;\n}\n","import {Axis, AXIS_PROPERTIES} from 'vega-lite/build/src/axis';\nimport {BinParams} from 'vega-lite/build/src/bin';\nimport {Channel, COLOR, COLUMN, ROW, SIZE, X, Y} from 'vega-lite/build/src/channel';\nimport {TypedFieldDef} from 'vega-lite/build/src/channeldef';\nimport {Legend, LEGEND_PROPERTIES} from 'vega-lite/build/src/legend';\nimport * as MARK from 'vega-lite/build/src/mark';\nimport {Mark} from 'vega-lite/build/src/mark';\nimport {Scale, ScaleType, SCALE_PROPERTIES} from 'vega-lite/build/src/scale';\nimport {EncodingSortField, SortOrder} from 'vega-lite/build/src/sort';\nimport {StackOffset} from 'vega-lite/build/src/stack';\nimport {TimeUnit} from 'vega-lite/build/src/timeunit';\nimport * as TYPE from 'vega-lite/build/src/type';\nimport {QueryConfig} from './config';\nimport {isEncodingNestedProp, Property} from './property';\nimport {Schema} from './schema';\nimport {extend, isArray} from './util';\n\nexport const SHORT_WILDCARD: SHORT_WILDCARD = '?';\nexport type SHORT_WILDCARD = '?';\n\nexport interface Wildcard<T> {\n  name?: string;\n\n  /**\n   * List of values to enumerate\n   */\n  enum?: T[];\n}\n\nexport type WildcardProperty<T> = T | Wildcard<T> | SHORT_WILDCARD;\n\nexport interface ExtendedWildcard<T> extends Wildcard<T> {\n  [prop: string]: any;\n}\n\nexport function isWildcard(prop: any): prop is Wildcard<any> | SHORT_WILDCARD {\n  return isShortWildcard(prop) || isWildcardDef(prop);\n}\n\nexport function isShortWildcard(prop: any): prop is SHORT_WILDCARD {\n  return prop === SHORT_WILDCARD;\n}\n\nexport function isWildcardDef(prop: any): prop is Wildcard<any> {\n  return prop !== undefined && prop != null && (!!prop.enum || !!prop.name) && !isArray(prop);\n}\n\nexport function initWildcard(\n  prop: SHORT_WILDCARD | ExtendedWildcard<any>,\n  defaultName: string,\n  defaultEnumValues: any[]\n): ExtendedWildcard<any> {\n  return extend(\n    {},\n    {\n      name: defaultName,\n      enum: defaultEnumValues\n    },\n    prop === SHORT_WILDCARD ? {} : prop\n  );\n}\n\n/**\n * Initial short names from list of full camelCaseNames.\n * For each camelCaseNames, return unique short names based on initial (e.g., `ccn`)\n */\nfunction initNestedPropName(fullNames: string[]) {\n  let index = {};\n  let has = {};\n  for (const fullName of fullNames) {\n    const initialIndices = [0];\n    for (let i = 0; i < fullName.length; i++) {\n      if (fullName.charAt(i).toUpperCase() === fullName.charAt(i)) {\n        initialIndices.push(i);\n      }\n    }\n    let shortName = initialIndices\n      .map(i => fullName.charAt(i))\n      .join('')\n      .toLowerCase();\n    if (!has[shortName]) {\n      index[fullName] = shortName;\n      has[shortName] = true;\n      continue;\n    }\n    // If duplicate, add last character and try again!\n    if (initialIndices[initialIndices.length - 1] !== fullName.length - 1) {\n      shortName = initialIndices\n        .concat([fullName.length - 1])\n        .map(i => fullName.charAt(i))\n        .join('')\n        .toLowerCase();\n      if (!has[shortName]) {\n        index[fullName] = shortName;\n        has[shortName] = true;\n        continue;\n      }\n    }\n    for (let i = 1; !index[fullName]; i++) {\n      let shortNameWithNo = shortName + '_' + i;\n      if (!has[shortNameWithNo]) {\n        index[fullName] = shortNameWithNo;\n        has[shortNameWithNo] = true;\n        break;\n      }\n    }\n  }\n  return index;\n}\n\nexport const DEFAULT_NAME = {\n  mark: 'm',\n  channel: 'c',\n  aggregate: 'a',\n  autoCount: '#',\n  hasFn: 'h',\n  bin: 'b',\n  sort: 'so',\n  stack: 'st',\n  scale: 's',\n  format: 'f',\n  axis: 'ax',\n  legend: 'l',\n  value: 'v',\n\n  timeUnit: 'tu',\n  field: 'f',\n  type: 't',\n\n  binProps: {\n    maxbins: 'mb',\n    min: 'mi',\n    max: 'ma',\n    base: 'b',\n    step: 's',\n    steps: 'ss',\n    minstep: 'ms',\n    divide: 'd'\n  },\n  sortProps: {\n    field: 'f',\n    op: 'o',\n    order: 'or'\n  },\n  scaleProps: initNestedPropName(SCALE_PROPERTIES),\n  axisProps: initNestedPropName(AXIS_PROPERTIES),\n  legendProps: initNestedPropName(LEGEND_PROPERTIES)\n};\n\nexport function getDefaultName(prop: Property) {\n  if (isEncodingNestedProp(prop)) {\n    return DEFAULT_NAME[prop.parent] + '-' + DEFAULT_NAME[prop.parent + 'Props'][prop.child];\n  }\n  if (DEFAULT_NAME[prop]) {\n    return DEFAULT_NAME[prop];\n  }\n  /* istanbul ignore next */\n  throw new Error('Default name undefined for ' + prop);\n}\n\n/**\n * Generic index for default enum (values to enumerate) of a particular definition type.\n */\nexport type DefEnumIndex<T> = {[P in keyof T]-?: T[P][]};\n\nconst DEFAULT_BOOLEAN_ENUM = [false, true];\n\nexport type EnumIndex = {\n  mark: Mark[];\n  channel: Channel[];\n  autoCount: boolean[];\n  hasFn: boolean[];\n} & DefEnumIndex<TypedFieldDef<string>> & {\n    sort: (EncodingSortField<string> | SortOrder)[];\n    stack: StackOffset[];\n    format: string[];\n    scale: boolean[];\n    axis: boolean[];\n    legend: boolean[];\n    value: any[];\n\n    binProps: Partial<DefEnumIndex<BinParams>>;\n    sortProps: Partial<DefEnumIndex<EncodingSortField<string>>>;\n    scaleProps: Partial<DefEnumIndex<Scale>>;\n    axisProps: Partial<DefEnumIndex<Axis>>;\n    legendProps: Partial<DefEnumIndex<Legend>>;\n  };\n\nconst DEFAULT_BIN_PROPS_ENUM: DefEnumIndex<BinParams> = {\n  maxbins: [5, 10, 20],\n  extent: [undefined],\n  base: [10],\n  step: [undefined],\n  steps: [undefined],\n  minstep: [undefined],\n  divide: [[5, 2]],\n  binned: [false],\n  anchor: [undefined],\n  nice: [true]\n};\n\nconst DEFAULT_SORT_PROPS: DefEnumIndex<EncodingSortField<string>> = {\n  field: [undefined], // This should be never call and instead read from the schema\n  op: ['min', 'mean'],\n  order: ['ascending', 'descending']\n};\n\nconst DEFAULT_SCALE_PROPS_ENUM: DefEnumIndex<Scale> = {\n  type: [undefined, ScaleType.LOG],\n  domain: [undefined],\n  base: [undefined],\n  exponent: [1, 2],\n  constant: [undefined],\n\n  bins: [undefined],\n\n  clamp: DEFAULT_BOOLEAN_ENUM,\n  nice: DEFAULT_BOOLEAN_ENUM,\n  reverse: DEFAULT_BOOLEAN_ENUM,\n  round: DEFAULT_BOOLEAN_ENUM,\n  zero: DEFAULT_BOOLEAN_ENUM,\n\n  padding: [undefined],\n  paddingInner: [undefined],\n  paddingOuter: [undefined],\n\n  interpolate: [undefined],\n\n  range: [undefined],\n  rangeStep: [17, 21],\n  scheme: [undefined]\n};\n\nconst DEFAULT_AXIS_PROPS_ENUM: DefEnumIndex<Axis> = {\n  zindex: [1, 0],\n  offset: [undefined],\n  orient: [undefined],\n  values: [undefined],\n\n  bandPosition: [undefined],\n  encoding: [undefined],\n\n  domain: DEFAULT_BOOLEAN_ENUM,\n  domainColor: [undefined],\n  domainDash: [undefined],\n  domainDashOffset: [undefined],\n  domainOpacity: [undefined],\n  domainWidth: [undefined],\n\n  formatType: [undefined],\n\n  grid: DEFAULT_BOOLEAN_ENUM,\n  gridColor: [undefined],\n  gridDash: [undefined],\n  gridDashOffset: [undefined],\n  gridOpacity: [undefined],\n  gridWidth: [undefined],\n\n  format: [undefined],\n  labels: DEFAULT_BOOLEAN_ENUM,\n  labelAlign: [undefined],\n  labelAngle: [undefined],\n  labelBaseline: [undefined],\n  labelColor: [undefined],\n  labelFlushOffset: [undefined],\n  labelFont: [undefined],\n  labelFontSize: [undefined],\n  labelFontStyle: [undefined],\n  labelFontWeight: [undefined],\n  labelLimit: [undefined],\n  labelOpacity: [undefined],\n  labelSeparation: [undefined],\n  labelOverlap: [undefined],\n  labelPadding: [undefined],\n  labelBound: [undefined],\n  labelFlush: [undefined],\n\n  maxExtent: [undefined],\n  minExtent: [undefined],\n  position: [undefined],\n\n  ticks: DEFAULT_BOOLEAN_ENUM,\n  tickColor: [undefined],\n  tickCount: [undefined],\n  tickDash: [undefined],\n  tickExtra: [undefined],\n  tickDashOffset: [undefined],\n  tickMinStep: [undefined],\n  tickOffset: [undefined],\n  tickOpacity: [undefined],\n  tickRound: [undefined],\n  tickSize: [undefined],\n  tickWidth: [undefined],\n\n  title: [undefined],\n  titleAlign: [undefined],\n  titleAnchor: [undefined],\n  titleAngle: [undefined],\n  titleBaseline: [undefined],\n  titleColor: [undefined],\n  titleFont: [undefined],\n  titleFontSize: [undefined],\n  titleFontStyle: [undefined],\n  titleFontWeight: [undefined],\n  titleLimit: [undefined],\n  titleOpacity: [undefined],\n  titlePadding: [undefined],\n  titleX: [undefined],\n  titleY: [undefined]\n};\n\nconst DEFAULT_LEGEND_PROPS_ENUM: DefEnumIndex<Legend> = {\n  orient: ['left', 'right'],\n  format: [undefined],\n  type: [undefined],\n  values: [undefined],\n  zindex: [undefined],\n\n  clipHeight: [undefined],\n  columnPadding: [undefined],\n  columns: [undefined],\n  cornerRadius: [undefined],\n  direction: [undefined],\n  encoding: [undefined],\n  fillColor: [undefined],\n  formatType: [undefined],\n  gridAlign: [undefined],\n  offset: [undefined],\n  padding: [undefined],\n  rowPadding: [undefined],\n  strokeColor: [undefined],\n\n  labelAlign: [undefined],\n  labelBaseline: [undefined],\n  labelColor: [undefined],\n  labelFont: [undefined],\n  labelFontSize: [undefined],\n  labelFontStyle: [undefined],\n  labelFontWeight: [undefined],\n  labelLimit: [undefined],\n  labelOffset: [undefined],\n  labelOpacity: [undefined],\n  labelOverlap: [undefined],\n  labelPadding: [undefined],\n  labelSeparation: [undefined],\n\n  legendX: [undefined],\n  legendY: [undefined],\n\n  gradientLength: [undefined],\n  gradientOpacity: [undefined],\n  gradientStrokeColor: [undefined],\n  gradientStrokeWidth: [undefined],\n  gradientThickness: [undefined],\n\n  symbolDash: [undefined],\n  symbolDashOffset: [undefined],\n  symbolFillColor: [undefined],\n  symbolOffset: [undefined],\n  symbolOpacity: [undefined],\n  symbolSize: [undefined],\n  symbolStrokeColor: [undefined],\n  symbolStrokeWidth: [undefined],\n  symbolType: [undefined],\n\n  tickCount: [undefined],\n  tickMinStep: [undefined],\n\n  title: [undefined],\n  titleAnchor: [undefined],\n  titleAlign: [undefined],\n  titleBaseline: [undefined],\n  titleColor: [undefined],\n  titleFont: [undefined],\n  titleFontSize: [undefined],\n  titleFontStyle: [undefined],\n  titleFontWeight: [undefined],\n  titleLimit: [undefined],\n  titleOpacity: [undefined],\n  titleOrient: [undefined],\n  titlePadding: [undefined]\n};\n\n// Use FullEnumIndex to make sure we have all properties specified here!\nexport const DEFAULT_ENUM_INDEX: EnumIndex = {\n  mark: [MARK.POINT, MARK.BAR, MARK.LINE, MARK.AREA, MARK.RECT, MARK.TICK, MARK.TEXT],\n  channel: [X, Y, ROW, COLUMN, SIZE, COLOR], // TODO: TEXT\n\n  aggregate: [undefined, 'mean'],\n  autoCount: DEFAULT_BOOLEAN_ENUM,\n  bin: DEFAULT_BOOLEAN_ENUM,\n  hasFn: DEFAULT_BOOLEAN_ENUM,\n  timeUnit: [undefined, TimeUnit.YEAR, TimeUnit.MONTH, TimeUnit.MINUTES, TimeUnit.SECONDS],\n\n  field: [undefined], // This is not used as field should be read from schema\n  type: [TYPE.NOMINAL, TYPE.ORDINAL, TYPE.QUANTITATIVE, TYPE.TEMPORAL],\n\n  sort: ['ascending', 'descending'],\n  stack: ['zero', 'normalize', 'center', null],\n  value: [undefined],\n\n  format: [undefined],\n  title: [undefined],\n  scale: [true],\n  axis: DEFAULT_BOOLEAN_ENUM,\n  legend: DEFAULT_BOOLEAN_ENUM,\n\n  binProps: DEFAULT_BIN_PROPS_ENUM,\n  sortProps: DEFAULT_SORT_PROPS,\n  scaleProps: DEFAULT_SCALE_PROPS_ENUM,\n  axisProps: DEFAULT_AXIS_PROPS_ENUM,\n  legendProps: DEFAULT_LEGEND_PROPS_ENUM\n};\n\n// TODO: rename this to getDefaultEnum\nexport function getDefaultEnumValues(prop: Property, schema: Schema, opt: QueryConfig): any[] {\n  if (prop === 'field' || (isEncodingNestedProp(prop) && prop.parent === 'sort' && prop.child === 'field')) {\n    // For field, by default enumerate all fields\n    return schema.fieldNames();\n  }\n\n  let val;\n  if (isEncodingNestedProp(prop)) {\n    val = opt.enum[prop.parent + 'Props'][prop.child];\n  } else {\n    val = opt.enum[prop];\n  }\n\n  if (val !== undefined) {\n    return val;\n  }\n\n  /* istanbul ignore next */\n  throw new Error('No default enumValues for ' + JSON.stringify(prop));\n}\n","import * as CHANNEL from 'vega-lite/build/src/channel';\nimport {Channel} from 'vega-lite/build/src/channel';\nimport {Config} from 'vega-lite/build/src/config';\nimport {DEFAULT_PROP_PRECEDENCE, toKey} from './property';\nimport {DEFAULT_ENUM_INDEX, EnumIndex} from './wildcard';\n\n// We name this QueryConfig to avoid confusion with Vega-Lite's Config\nexport interface QueryConfig {\n  verbose?: boolean;\n\n  defaultSpecConfig?: Config;\n\n  propertyPrecedence?: string[];\n\n  enum?: Partial<EnumIndex>;\n\n  /** Default ratio for number fields to be considered ordinal */\n  numberNominalProportion?: number;\n\n  /** Default cutoff for not applying the numberOrdinalProportion inference */\n  numberNominalLimit?: number;\n\n  // SPECIAL MODE\n  /**\n   * Allow automatically adding a special count (autoCount) field for plots\n   * that contain only discrete fields. In such cases, adding count make the\n   * output plots way more meaningful.\n   */\n  autoAddCount?: boolean;\n\n  // CONSTRAINTS\n  constraintManuallySpecifiedValue?: boolean;\n  // Spec Constraints\n\n  hasAppropriateGraphicTypeForMark?: boolean;\n  omitAggregate?: boolean;\n  omitAggregatePlotWithDimensionOnlyOnFacet?: boolean;\n  omitAggregatePlotWithoutDimension?: boolean;\n  omitBarLineAreaWithOcclusion?: boolean;\n  omitBarTickWithSize?: boolean;\n  omitMultipleNonPositionalChannels?: boolean;\n  omitRaw?: boolean;\n  omitRawContinuousFieldForAggregatePlot?: boolean;\n  omitRawWithXYBothOrdinalScaleOrBin?: boolean;\n  omitRepeatedField?: boolean;\n  omitNonPositionalOrFacetOverPositionalChannels?: boolean;\n  omitTableWithOcclusionIfAutoAddCount?: boolean;\n  omitVerticalDotPlot?: boolean;\n  omitInvalidStackSpec?: boolean;\n  omitNonSumStack?: boolean;\n\n  preferredBinAxis?: Channel;\n  preferredTemporalAxis?: Channel;\n  preferredOrdinalAxis?: Channel;\n  preferredNominalAxis?: Channel;\n  preferredFacet?: Channel;\n\n  // Field Encoding Constraints\n  minCardinalityForBin?: number;\n  maxCardinalityForCategoricalColor?: number;\n  maxCardinalityForFacet?: number;\n  maxCardinalityForShape?: number;\n  timeUnitShouldHaveVariation?: boolean;\n  typeMatchesSchemaType?: boolean;\n\n  // STYLIZE\n  stylize?: boolean;\n  smallRangeStepForHighCardinalityOrFacet?: {maxCardinality: number; rangeStep: number};\n  nominalColorScaleForHighCardinality?: {maxCardinality: number; palette: string};\n  xAxisOnTopForHighYCardinalityWithoutColumn?: {maxCardinality: number};\n\n  // EFFECTIVENESS PREFERENCE\n  maxGoodCardinalityForColor?: number; // FIXME: revise\n  maxGoodCardinalityForFacet?: number; // FIXME: revise\n  // HIGH CARDINALITY STRINGS\n  minPercentUniqueForKey?: number;\n  minCardinalityForKey?: number;\n}\n\nexport const DEFAULT_QUERY_CONFIG: QueryConfig = {\n  verbose: false,\n  defaultSpecConfig: {\n    line: {point: true},\n    scale: {useUnaggregatedDomain: true}\n  },\n  propertyPrecedence: DEFAULT_PROP_PRECEDENCE.map(toKey),\n  enum: DEFAULT_ENUM_INDEX,\n\n  numberNominalProportion: 0.05,\n  numberNominalLimit: 40,\n\n  // CONSTRAINTS\n  constraintManuallySpecifiedValue: false,\n  // Spec Constraints -- See description inside src/constraints/spec.ts\n  autoAddCount: false,\n\n  hasAppropriateGraphicTypeForMark: true,\n  omitAggregate: false,\n  omitAggregatePlotWithDimensionOnlyOnFacet: true,\n  omitAggregatePlotWithoutDimension: false,\n  omitBarLineAreaWithOcclusion: true,\n  omitBarTickWithSize: true,\n  omitMultipleNonPositionalChannels: true,\n  omitRaw: false,\n  omitRawContinuousFieldForAggregatePlot: true,\n  omitRepeatedField: true,\n  omitNonPositionalOrFacetOverPositionalChannels: true,\n  omitTableWithOcclusionIfAutoAddCount: true,\n  omitVerticalDotPlot: false,\n  omitInvalidStackSpec: true,\n  omitNonSumStack: true,\n\n  preferredBinAxis: CHANNEL.X,\n  preferredTemporalAxis: CHANNEL.X,\n  preferredOrdinalAxis: CHANNEL.Y, // ordinal on y makes it easier to read.\n  preferredNominalAxis: CHANNEL.Y, // nominal on y makes it easier to read.\n  preferredFacet: CHANNEL.ROW, // row make it easier to scroll than column\n\n  // Field Encoding Constraints -- See description inside src/constraint/field.ts\n  minCardinalityForBin: 15,\n  maxCardinalityForCategoricalColor: 20,\n  maxCardinalityForFacet: 20,\n  maxCardinalityForShape: 6,\n  timeUnitShouldHaveVariation: true,\n  typeMatchesSchemaType: true,\n\n  // STYLIZE\n  stylize: true,\n  smallRangeStepForHighCardinalityOrFacet: {maxCardinality: 10, rangeStep: 12},\n  nominalColorScaleForHighCardinality: {maxCardinality: 10, palette: 'category20'},\n  xAxisOnTopForHighYCardinalityWithoutColumn: {maxCardinality: 30},\n\n  // RANKING PREFERENCE\n  maxGoodCardinalityForFacet: 5, // FIXME: revise\n  maxGoodCardinalityForColor: 7, // FIXME: revise\n\n  // HIGH CARDINALITY STRINGS\n  minPercentUniqueForKey: 0.8,\n  minCardinalityForKey: 50\n};\n\nexport function extendConfig(opt: QueryConfig) {\n  return {\n    ...DEFAULT_QUERY_CONFIG,\n    ...opt,\n    enum: extendEnumIndex(opt.enum)\n  };\n}\n\nfunction extendEnumIndex(enumIndex: Partial<EnumIndex>) {\n  const enumOpt: EnumIndex = {\n    ...DEFAULT_ENUM_INDEX,\n    ...enumIndex,\n    binProps: extendNestedEnumIndex(enumIndex, 'bin'),\n    scaleProps: extendNestedEnumIndex(enumIndex, 'scale'),\n    axisProps: extendNestedEnumIndex(enumIndex, 'axis'),\n    legendProps: extendNestedEnumIndex(enumIndex, 'legend')\n  };\n  return enumOpt;\n}\n\nfunction extendNestedEnumIndex(enumIndex: Partial<EnumIndex>, prop: 'bin' | 'scale' | 'axis' | 'legend') {\n  return {\n    ...DEFAULT_ENUM_INDEX[prop + 'Props'],\n    ...enumIndex[prop + 'Props']\n  };\n}\n","import {AggregateOp} from 'vega';\nimport {isString, toSet} from 'vega-util';\nimport {contains, Flag, flagKeys} from './util';\n\nconst AGGREGATE_OP_INDEX: Flag<AggregateOp> = {\n  argmax: 1,\n  argmin: 1,\n  average: 1,\n  count: 1,\n  distinct: 1,\n  max: 1,\n  mean: 1,\n  median: 1,\n  min: 1,\n  missing: 1,\n  q1: 1,\n  q3: 1,\n  ci0: 1,\n  ci1: 1,\n  stderr: 1,\n  stdev: 1,\n  stdevp: 1,\n  sum: 1,\n  valid: 1,\n  values: 1,\n  variance: 1,\n  variancep: 1\n};\n\nexport interface ArgminDef {\n  argmin: string;\n}\n\nexport interface ArgmaxDef {\n  argmax: string;\n}\n\nexport type Aggregate = AggregateOp | ArgmaxDef | ArgminDef;\n\nexport function isArgminDef(a: Aggregate | string): a is ArgminDef {\n  return !!a && !!a['argmin'];\n}\n\nexport function isArgmaxDef(a: Aggregate | string): a is ArgmaxDef {\n  return !!a && !!a['argmax'];\n}\n\nexport const AGGREGATE_OPS = flagKeys(AGGREGATE_OP_INDEX);\n\nexport function isAggregateOp(a: string | ArgminDef | ArgmaxDef): a is AggregateOp {\n  return isString(a) && !!AGGREGATE_OP_INDEX[a];\n}\n\nexport const COUNTING_OPS: AggregateOp[] = ['count', 'valid', 'missing', 'distinct'];\n\nexport function isCountingAggregateOp(aggregate: string | Aggregate): boolean {\n  return aggregate && isString(aggregate) && contains(COUNTING_OPS, aggregate);\n}\n\nexport function isMinMaxOp(aggregate: Aggregate | string): boolean {\n  return aggregate && isString(aggregate) && contains(['min', 'max'], aggregate);\n}\n\n/** Additive-based aggregation operations.  These can be applied to stack. */\nexport const SUM_OPS: AggregateOp[] = ['count', 'sum', 'distinct', 'valid', 'missing'];\n\n/**\n * Aggregation operators that always produce values within the range [domainMin, domainMax].\n */\nexport const SHARED_DOMAIN_OPS: AggregateOp[] = ['mean', 'average', 'median', 'q1', 'q3', 'min', 'max'];\n\nexport const SHARED_DOMAIN_OP_INDEX = toSet(SHARED_DOMAIN_OPS);\n","import {isBoolean, isObject} from 'vega-util';\nimport {BinParams} from './bin';\nimport {\n  Channel,\n  COLOR,\n  COLUMN,\n  FILL,\n  FILLOPACITY,\n  OPACITY,\n  ROW,\n  SHAPE,\n  SIZE,\n  STROKE,\n  STROKEOPACITY,\n  STROKEWIDTH\n} from './channel';\nimport {normalizeBin} from './channeldef';\nimport {keys, varName} from './util';\n\nexport interface BaseBin {\n  /**\n   * The number base to use for automatic bin determination (default is base 10).\n   *\n   * __Default value:__ `10`\n   *\n   */\n  base?: number;\n  /**\n   * An exact step size to use between bins.\n   *\n   * __Note:__ If provided, options such as maxbins will be ignored.\n   */\n  step?: number;\n  /**\n   * An array of allowable step sizes to choose from.\n   * @minItems 1\n   */\n  steps?: number[];\n  /**\n   * A minimum allowable step size (particularly useful for integer values).\n   */\n  minstep?: number;\n  /**\n   * Scale factors indicating allowable subdivisions. The default value is [5, 2], which indicates that for base 10 numbers (the default base), the method may consider dividing bin sizes by 5 and/or 2. For example, for an initial step size of 10, the method can check if bin sizes of 2 (= 10/5), 5 (= 10/2), or 1 (= 10/(5*2)) might also satisfy the given constraints.\n   *\n   * __Default value:__ `[5, 2]`\n   *\n   * @minItems 1\n   */\n  divide?: number[];\n  /**\n   * Maximum number of bins.\n   *\n   * __Default value:__ `6` for `row`, `column` and `shape` channels; `10` for other channels\n   *\n   * @minimum 2\n   */\n  maxbins?: number;\n  /**\n   * A value in the binned domain at which to anchor the bins, shifting the bin boundaries if necessary to ensure that a boundary aligns with the anchor value.\n   *\n   * __Default Value:__ the minimum bin extent value\n   */\n  anchor?: number;\n  /**\n   * If true (the default), attempts to make the bin boundaries use human-friendly boundaries, such as multiples of ten.\n   */\n  nice?: boolean;\n}\n\n/**\n * Binning properties or boolean flag for determining whether to bin data or not.\n */\nexport interface BinParams extends BaseBin {\n  /**\n   * A two-element (`[min, max]`) array indicating the range of desired bin values.\n   * @minItems 2\n   * @maxItems 2\n   */\n  extent?: number[]; // VgBinTransform uses a different extent so we need to pull this out.\n\n  /**\n   * When set to true, Vega-Lite treats the input data as already binned.\n   */\n  binned?: boolean;\n}\n\nexport type Bin = boolean | BinParams | 'binned' | null;\n\n/**\n * Create a key for the bin configuration. Not for prebinned bin.\n */\nexport function binToString(bin: BinParams | true) {\n  if (isBoolean(bin)) {\n    bin = normalizeBin(bin, undefined);\n  }\n  return (\n    'bin' +\n    keys(bin)\n      .map(p => varName(`_${p}_${bin[p]}`))\n      .join('')\n  );\n}\n\n/**\n * Vega-Lite should bin the data.\n */\nexport function isBinning(bin: BinParams | boolean | 'binned'): bin is BinParams | true {\n  return bin === true || (isBinParams(bin) && !bin.binned);\n}\n\n/**\n * The data is already binned and so Vega-Lite should not bin it again.\n */\nexport function isBinned(bin: BinParams | boolean | 'binned'): bin is 'binned' {\n  return bin === 'binned' || (isBinParams(bin) && bin.binned);\n}\n\nexport function isBinParams(bin: BinParams | boolean | 'binned'): bin is BinParams {\n  return isObject(bin);\n}\n\nexport function autoMaxBins(channel: Channel): number {\n  switch (channel) {\n    case ROW:\n    case COLUMN:\n    case SIZE:\n    case COLOR:\n    case FILL:\n    case STROKE:\n    case STROKEWIDTH:\n    case OPACITY:\n    case FILLOPACITY:\n    case STROKEOPACITY:\n    // Facets and Size shouldn't have too many bins\n    // We choose 6 like shape to simplify the rule [falls through]\n    case SHAPE:\n      return 6; // Vega's \"shape\" has 6 distinct values\n    default:\n      return 10;\n  }\n}\n","// Declaration and utility for variants of a field definition object\nimport {isArray, isBoolean, isNumber, isString} from 'vega-util';\nimport {Aggregate, isAggregateOp, isArgmaxDef, isArgminDef, isCountingAggregateOp} from './aggregate';\nimport {Axis} from './axis';\nimport {autoMaxBins, Bin, BinParams, binToString, isBinned, isBinning} from './bin';\nimport {Channel, isScaleChannel, isSecondaryRangeChannel, POSITION_SCALE_CHANNELS, rangeType} from './channel';\nimport {CompositeAggregate} from './compositemark';\nimport {Config} from './config';\nimport {DateTime, dateTimeExpr, isDateTime} from './datetime';\nimport {FormatMixins, Guide, TitleMixins} from './guide';\nimport {ImputeParams} from './impute';\nimport {Legend} from './legend';\nimport * as log from './log';\nimport {LogicalOperand} from './logical';\nimport {Predicate} from './predicate';\nimport {Scale} from './scale';\nimport {Sort, SortOrder} from './sort';\nimport {isFacetFieldDef} from './spec/facet';\nimport {StackOffset} from './stack';\nimport {\n  getLocalTimeUnit,\n  getTimeUnitParts,\n  isLocalSingleTimeUnit,\n  isUtcSingleTimeUnit,\n  normalizeTimeUnit,\n  TimeUnit\n} from './timeunit';\nimport {AggregatedFieldDef, WindowFieldDef} from './transform';\nimport {getFullName, QUANTITATIVE, StandardType, Type} from './type';\nimport {contains, flatAccessWithDatum, getFirstDefined, internalField, replacePathInField, titlecase} from './util';\n\nexport type Value = number | string | boolean | null;\n\n/**\n * Definition object for a constant value of an encoding channel.\n */\nexport interface ValueDef<V extends Value = Value> {\n  /**\n   * A constant value in visual domain (e.g., `\"red\"` / \"#0099ff\" for color, values between `0` to `1` for opacity).\n   */\n  value: V;\n}\n\n/**\n * Generic type for conditional channelDef.\n * F defines the underlying FieldDef type.\n */\n\nexport type ChannelDefWithCondition<F extends FieldDef<any>, V extends Value> =\n  | FieldDefWithCondition<F, V>\n  | ValueDefWithCondition<F, V>;\n\n/**\n * A ValueDef with Condition<ValueDef | FieldDef> where either the conition or the value are optional.\n * {\n *   condition: {field: ...} | {value: ...},\n *   value: ...,\n * }\n */\n\nexport type ValueDefWithCondition<F extends FieldDef<any>, V extends Value = Value> =\n  | ValueDefWithOptionalCondition<F, V>\n  | ConditionOnlyDef<F>;\n\nexport type StringValueDefWithCondition<F extends Field, T extends Type = StandardType> = ValueDefWithCondition<\n  MarkPropFieldDef<F, T>,\n  string | null\n>;\n\nexport type NumericValueDefWithCondition<F extends Field> = ValueDefWithCondition<\n  MarkPropFieldDef<F, StandardType>,\n  number\n>;\n\nexport type TypeForShape = 'nominal' | 'ordinal' | 'geojson';\n\nexport type ShapeValueDefWithCondition<F extends Field> = StringValueDefWithCondition<F, TypeForShape>;\n\nexport type TextValueDefWithCondition<F extends Field> = ValueDefWithCondition<TextFieldDef<F>, Value>;\n\nexport type Conditional<CD extends FieldDef<any> | ValueDef<any>> = ConditionalPredicate<CD> | ConditionalSelection<CD>;\n\nexport type ConditionalPredicate<CD extends FieldDef<any> | ValueDef<any>> = {\n  /**\n   * Predicate for triggering the condition\n   */\n  test: LogicalOperand<Predicate>;\n} & CD;\n\nexport type ConditionalSelection<CD extends FieldDef<any> | ValueDef<any>> = {\n  /**\n   * A [selection name](https://vega.github.io/vega-lite/docs/selection.html), or a series of [composed selections](https://vega.github.io/vega-lite/docs/selection.html#compose).\n   */\n  selection: LogicalOperand<string>;\n} & CD;\n\nexport function isConditionalSelection<T>(c: Conditional<T>): c is ConditionalSelection<T> {\n  return c['selection'];\n}\n\nexport interface ConditionValueDefMixins<V extends Value = Value> {\n  /**\n   * One or more value definition(s) with [a selection or a test predicate](https://vega.github.io/vega-lite/docs/condition.html).\n   *\n   * __Note:__ A field definition's `condition` property can only contain [conditional value definitions](https://vega.github.io/vega-lite/docs/condition.html#value)\n   * since Vega-Lite only allows at most one encoded field per encoding channel.\n   */\n  condition?: Conditional<ValueDef<V>> | Conditional<ValueDef<V>>[];\n}\n\n/**\n * A FieldDef with Condition<ValueDef>\n * {\n *   condition: {value: ...},\n *   field: ...,\n *   ...\n * }\n */\n\nexport type FieldDefWithCondition<F extends FieldDef<any>, V extends Value = Value> = F & ConditionValueDefMixins<V>;\n\nexport type StringFieldDefWithCondition<F extends Field, T extends Type = StandardType> = FieldDefWithCondition<\n  MarkPropFieldDef<F, T>,\n  string | null\n>;\n\nexport type NumericFieldDefWithCondition<F extends Field> = FieldDefWithCondition<\n  MarkPropFieldDef<F, StandardType>,\n  number\n>;\n\nexport type ShapeFieldDefWithCondition<F extends Field> = StringFieldDefWithCondition<F, TypeForShape>;\n\nexport type TextFieldDefWithCondition<F extends Field> = FieldDefWithCondition<TextFieldDef<F>, Value>;\n\n/**\n * A ValueDef with optional Condition<ValueDef | FieldDef>\n * {\n *   condition: {field: ...} | {value: ...},\n *   value: ...,\n * }\n */\n\nexport interface ValueDefWithOptionalCondition<FD extends FieldDef<any>, V extends Value> extends ValueDef<V> {\n  /**\n   * A field definition or one or more value definition(s) with a selection predicate.\n   */\n  condition?: Conditional<FD> | Conditional<ValueDef<V>> | Conditional<ValueDef<V>>[];\n}\n\n/**\n * A Condition<ValueDef | FieldDef> only definition.\n * {\n *   condition: {field: ...} | {value: ...}\n * }\n */\nexport interface ConditionOnlyDef<F extends FieldDef<any>, V extends Value = Value> {\n  /**\n   * A field definition or one or more value definition(s) with a selection predicate.\n   */\n  condition: Conditional<F> | Conditional<ValueDef<V>> | Conditional<ValueDef<V>>[];\n}\n\n/**\n * Reference to a repeated value.\n */\nexport interface RepeatRef {\n  repeat: 'row' | 'column' | 'repeat';\n}\n\nexport type FieldName = string;\nexport type Field = FieldName | RepeatRef;\n\nexport function isRepeatRef(field: Field): field is RepeatRef {\n  return field && !isString(field) && 'repeat' in field;\n}\n\n/** @hide */\nexport type HiddenCompositeAggregate = CompositeAggregate;\n\nexport interface FieldDefBase<F, B extends Bin = Bin> {\n  /**\n   * __Required.__ A string defining the name of the field from which to pull a data value\n   * or an object defining iterated values from the [`repeat`](https://vega.github.io/vega-lite/docs/repeat.html) operator.\n   *\n   * __Note:__ Dots (`.`) and brackets (`[` and `]`) can be used to access nested objects (e.g., `\"field\": \"foo.bar\"` and `\"field\": \"foo['bar']\"`).\n   * If field names contain dots or brackets but are not nested, you can use `\\\\` to escape dots and brackets (e.g., `\"a\\\\.b\"` and `\"a\\\\[0\\\\]\"`).\n   * See more details about escaping in the [field documentation](https://vega.github.io/vega-lite/docs/field.html).\n   *\n   * __Note:__ `field` is not required if `aggregate` is `count`.\n   */\n  field?: F;\n\n  // function\n\n  /**\n   * Time unit (e.g., `year`, `yearmonth`, `month`, `hours`) for a temporal field.\n   * or [a temporal field that gets casted as ordinal](https://vega.github.io/vega-lite/docs/type.html#cast).\n   *\n   * __Default value:__ `undefined` (None)\n   */\n  timeUnit?: TimeUnit;\n\n  /**\n   * Aggregation function for the field\n   * (e.g., `mean`, `sum`, `median`, `min`, `max`, `count`).\n   *\n   * __Default value:__ `undefined` (None)\n   */\n  aggregate?: Aggregate | HiddenCompositeAggregate;\n\n  /**\n   * A flag for binning a `quantitative` field, [an object defining binning parameters](https://vega.github.io/vega-lite/docs/bin.html#params), or indicating that the data for `x` or `y` channel are binned before they are imported into Vega-Lite (`\"binned\"`).\n   *\n   * - If `true`, default [binning parameters](https://vega.github.io/vega-lite/docs/bin.html) will be applied.\n   *\n   * - If `\"binned\"`, this indicates that the data for the `x` (or `y`) channel are already binned. You can map the bin-start field to `x` (or `y`) and the bin-end field to `x2` (or `y2`). The scale and axis will be formatted similar to binning in Vega-lite.  To adjust the axis ticks based on the bin step, you can also set the axis's [`tickMinStep`](https://vega.github.io/vega-lite/docs/axis.html#ticks) property.\n   *\n   * __Default value:__ `false`\n   */\n  bin?: B;\n}\n\nexport function toFieldDefBase(fieldDef: TypedFieldDef<string>): FieldDefBase<string> {\n  const {field, timeUnit, bin, aggregate} = fieldDef;\n  return {\n    ...(timeUnit ? {timeUnit} : {}),\n    ...(bin ? {bin} : {}),\n    ...(aggregate ? {aggregate} : {}),\n    field\n  };\n}\n\nexport interface TypeMixins<T extends Type> {\n  /**\n   * The encoded field's type of measurement (`\"quantitative\"`, `\"temporal\"`, `\"ordinal\"`, or `\"nominal\"`).\n   * It can also be a `\"geojson\"` type for encoding ['geoshape'](https://vega.github.io/vega-lite/docs/geoshape.html).\n   *\n   *\n   * __Note:__\n   *\n   * - Data values for a temporal field can be either a date-time string (e.g., `\"2015-03-07 12:32:17\"`, `\"17:01\"`, `\"2015-03-16\"`. `\"2015\"`) or a timestamp number (e.g., `1552199579097`).\n   * - Data `type` describes the semantics of the data rather than the primitive data types (`number`, `string`, etc.). The same primitive data type can have different types of measurement. For example, numeric data can represent quantitative, ordinal, or nominal data.\n   * - When using with [`bin`](https://vega.github.io/vega-lite/docs/bin.html), the `type` property can be either `\"quantitative\"` (for using a linear bin scale) or [`\"ordinal\"` (for using an ordinal bin scale)](https://vega.github.io/vega-lite/docs/type.html#cast-bin).\n   * - When using with [`timeUnit`](https://vega.github.io/vega-lite/docs/timeunit.html), the `type` property can be either `\"temporal\"` (for using a temporal scale) or [`\"ordinal\"` (for using an ordinal scale)](https://vega.github.io/vega-lite/docs/type.html#cast-bin).\n   * - When using with [`aggregate`](https://vega.github.io/vega-lite/docs/aggregate.html), the `type` property refers to the post-aggregation data type. For example, we can calculate count `distinct` of a categorical field `\"cat\"` using `{\"aggregate\": \"distinct\", \"field\": \"cat\", \"type\": \"quantitative\"}`. The `\"type\"` of the aggregate output is `\"quantitative\"`.\n   * - Secondary channels (e.g., `x2`, `y2`, `xError`, `yError`) do not have `type` as they have exactly the same type as their primary channels (e.g., `x`, `y`).\n   */\n  type: T;\n}\n\n/**\n *  Definition object for a data field, its type and transformation of an encoding channel.\n */\nexport type TypedFieldDef<\n  F extends Field,\n  T extends Type = Type,\n  B extends Bin = boolean | BinParams | 'binned' | null // This is equivalent to Bin but we use the full form so the docs has detailed types\n> = FieldDefBase<F, B> & TitleMixins & TypeMixins<T>;\n\nexport interface SortableFieldDef<\n  F extends Field,\n  T extends Type = StandardType,\n  B extends Bin = boolean | BinParams | null\n> extends TypedFieldDef<F, T, B> {\n  /**\n   * Sort order for the encoded field.\n   *\n   * For continuous fields (quantitative or temporal), `sort` can be either `\"ascending\"` or `\"descending\"`.\n   *\n   * For discrete fields, `sort` can be one of the following:\n   * - `\"ascending\"` or `\"descending\"` -- for sorting by the values' natural order in Javascript.\n   * - [A sort-by-encoding definition](https://vega.github.io/vega-lite/docs/sort.html#sort-by-encoding) for sorting by another encoding channel. (This type of sort definition is not available for `row` and `column` channels.)\n   * - [A sort field definition](https://vega.github.io/vega-lite/docs/sort.html#sort-field) for sorting by another field.\n   * - [An array specifying the field values in preferred order](https://vega.github.io/vega-lite/docs/sort.html#sort-array). In this case, the sort order will obey the values in the array, followed by any unspecified values in their original order.  For discrete time field, values in the sort array can be [date-time definition objects](types#datetime). In addition, for time units `\"month\"` and `\"day\"`, the values can be the month or day names (case insensitive) or their 3-letter initials (e.g., `\"Mon\"`, `\"Tue\"`).\n   * - `null` indicating no sort.\n   *\n   * __Default value:__ `\"ascending\"`\n   *\n   * __Note:__ `null` is not supported for `row` and `column`.\n   */\n  sort?: Sort<F>;\n}\n\nexport function isSortableFieldDef<F extends Field>(fieldDef: FieldDef<F>): fieldDef is SortableFieldDef<F> {\n  return isTypedFieldDef(fieldDef) && !!fieldDef['sort'];\n}\n\nexport interface ScaleFieldDef<\n  F extends Field,\n  T extends Type = StandardType,\n  B extends Bin = boolean | BinParams | null\n> extends SortableFieldDef<F, T, B> {\n  /**\n   * An object defining properties of the channel's scale, which is the function that transforms values in the data domain (numbers, dates, strings, etc) to visual values (pixels, colors, sizes) of the encoding channels.\n   *\n   * If `null`, the scale will be [disabled and the data value will be directly encoded](https://vega.github.io/vega-lite/docs/scale.html#disable).\n   *\n   * __Default value:__ If undefined, default [scale properties](https://vega.github.io/vega-lite/docs/scale.html) are applied.\n   */\n  scale?: Scale | null;\n}\n\n/**\n * A field definition of a secondary channel that shares a scale with another primary channel.  For example, `x2`, `xError` and `xError2` share the same scale with `x`.\n */\nexport type SecondaryFieldDef<F extends Field> = FieldDefBase<F, null> & TitleMixins; // x2/y2 shouldn't have bin, but we keep bin property for simplicity of the codebase.\n\n/**\n * Field Def without scale (and without bin: \"binned\" support).\n */\nexport type FieldDefWithoutScale<F extends Field, T extends Type = StandardType> = TypedFieldDef<F, T>;\n\nexport type LatLongFieldDef<F extends Field> = FieldDefBase<F, null> &\n  TitleMixins &\n  Partial<TypeMixins<'quantitative'>>; // Lat long shouldn't have bin, but we keep bin property for simplicity of the codebase.\n\nexport interface PositionFieldDef<F extends Field>\n  extends ScaleFieldDef<\n    F,\n    StandardType,\n    boolean | BinParams | 'binned' | null // This is equivalent to Bin but we use the full form so the docs has detailed types\n  > {\n  /**\n   * An object defining properties of axis's gridlines, ticks and labels.\n   * If `null`, the axis for the encoding channel will be removed.\n   *\n   * __Default value:__ If undefined, default [axis properties](https://vega.github.io/vega-lite/docs/axis.html) are applied.\n   */\n  axis?: Axis | null;\n\n  /**\n   * Type of stacking offset if the field should be stacked.\n   * `stack` is only applicable for `x` and `y` channels with continuous domains.\n   * For example, `stack` of `y` can be used to customize stacking for a vertical bar chart.\n   *\n   * `stack` can be one of the following values:\n   * - `\"zero\"` or `true`: stacking with baseline offset at zero value of the scale (for creating typical stacked [bar](https://vega.github.io/vega-lite/docs/stack.html#bar) and [area](https://vega.github.io/vega-lite/docs/stack.html#area) chart).\n   * - `\"normalize\"` - stacking with normalized domain (for creating [normalized stacked bar and area charts](https://vega.github.io/vega-lite/docs/stack.html#normalized). <br/>\n   * -`\"center\"` - stacking with center baseline (for [streamgraph](https://vega.github.io/vega-lite/docs/stack.html#streamgraph)).\n   * - `null` or `false` - No-stacking. This will produce layered [bar](https://vega.github.io/vega-lite/docs/stack.html#layered-bar-chart) and area chart.\n   *\n   * __Default value:__ `zero` for plots with all of the following conditions are true:\n   * (1) the mark is `bar` or `area`;\n   * (2) the stacked measure channel (x or y) has a linear scale;\n   * (3) At least one of non-position channels mapped to an unaggregated field that is different from x and y.  Otherwise, `null` by default.\n   */\n  stack?: StackOffset | null | boolean;\n\n  /**\n   * An object defining the properties of the Impute Operation to be applied.\n   * The field value of the other positional channel is taken as `key` of the `Impute` Operation.\n   * The field of the `color` channel if specified is used as `groupby` of the `Impute` Operation.\n   */\n  impute?: ImputeParams;\n}\n\n/**\n * Field definition of a mark property, which can contain a legend.\n */\nexport type MarkPropFieldDef<F extends Field, T extends Type = Type> = ScaleFieldDef<\n  F,\n  T,\n  boolean | BinParams | null\n> & {\n  /**\n   * An object defining properties of the legend.\n   * If `null`, the legend for the encoding channel will be removed.\n   *\n   * __Default value:__ If undefined, default [legend properties](https://vega.github.io/vega-lite/docs/legend.html) are applied.\n   */\n  legend?: Legend | null;\n};\n\n// Detail\n\n// Order Path have no scale\n\nexport interface OrderFieldDef<F extends Field> extends FieldDefWithoutScale<F> {\n  /**\n   * The sort order. One of `\"ascending\"` (default) or `\"descending\"`.\n   */\n  sort?: SortOrder;\n}\n\nexport interface TextFieldDef<F extends Field> extends FieldDefWithoutScale<F, StandardType>, FormatMixins {}\n\nexport type FieldDef<F extends Field> = SecondaryFieldDef<F> | TypedFieldDef<F>;\nexport type ChannelDef<FD extends FieldDef<any> = FieldDef<string>, V extends Value = Value> = ChannelDefWithCondition<\n  FD,\n  V\n>;\n\nexport function isConditionalDef<F extends Field, V extends Value>(\n  channelDef: ChannelDef<FieldDef<F>, V>\n): channelDef is ChannelDefWithCondition<FieldDef<F>, V> {\n  return !!channelDef && !!channelDef.condition;\n}\n\n/**\n * Return if a channelDef is a ConditionalValueDef with ConditionFieldDef\n */\n\nexport function hasConditionalFieldDef<F extends Field, V extends Value>(\n  channelDef: ChannelDef<FieldDef<F>, V>\n): channelDef is ValueDef<V> & {condition: Conditional<TypedFieldDef<F>>} {\n  return !!channelDef && !!channelDef.condition && !isArray(channelDef.condition) && isFieldDef(channelDef.condition);\n}\n\nexport function hasConditionalValueDef<F extends Field, V extends Value>(\n  channelDef: ChannelDef<FieldDef<F>, V>\n): channelDef is ValueDef<V> & {condition: Conditional<ValueDef<V>> | Conditional<ValueDef<V>>[]} {\n  return !!channelDef && !!channelDef.condition && (isArray(channelDef.condition) || isValueDef(channelDef.condition));\n}\n\nexport function isFieldDef<F extends Field>(\n  channelDef: ChannelDef<FieldDef<F>>\n): channelDef is\n  | TypedFieldDef<F>\n  | SecondaryFieldDef<F>\n  | PositionFieldDef<F>\n  | ScaleFieldDef<F>\n  | MarkPropFieldDef<F>\n  | OrderFieldDef<F>\n  | TextFieldDef<F> {\n  return !!channelDef && (!!channelDef['field'] || channelDef['aggregate'] === 'count');\n}\n\nexport function isTypedFieldDef<F extends Field>(channelDef: ChannelDef<FieldDef<F>>): channelDef is TypedFieldDef<F> {\n  return !!channelDef && ((!!channelDef['field'] && !!channelDef['type']) || channelDef['aggregate'] === 'count');\n}\n\nexport function isStringFieldDef(channelDef: ChannelDef<FieldDef<Field>>): channelDef is TypedFieldDef<string> {\n  return isFieldDef(channelDef) && isString(channelDef.field);\n}\n\nexport function isValueDef<F extends Field, V extends Value>(\n  channelDef: ChannelDef<FieldDef<F>, V>\n): channelDef is ValueDef<V> {\n  return channelDef && 'value' in channelDef && channelDef['value'] !== undefined;\n}\n\nexport function isScaleFieldDef<F extends Field>(channelDef: ChannelDef<FieldDef<F>>): channelDef is ScaleFieldDef<F> {\n  return !!channelDef && (!!channelDef['scale'] || !!channelDef['sort']);\n}\n\nexport function isPositionFieldDef<F extends Field>(\n  channelDef: ChannelDef<FieldDef<F>>\n): channelDef is PositionFieldDef<F> {\n  return !!channelDef && (!!channelDef['axis'] || !!channelDef['stack'] || !!channelDef['impute']);\n}\n\nexport function isMarkPropFieldDef<F extends Field>(\n  channelDef: ChannelDef<FieldDef<F>>\n): channelDef is MarkPropFieldDef<F> {\n  return !!channelDef && !!channelDef['legend'];\n}\n\nexport function isTextFieldDef<F extends Field>(channelDef: ChannelDef<FieldDef<F>>): channelDef is TextFieldDef<F> {\n  return !!channelDef && !!channelDef['format'];\n}\n\nexport interface FieldRefOption {\n  /** Exclude bin, aggregate, timeUnit */\n  nofn?: boolean;\n  /** Wrap the field with datum, parent, or datum.datum (e.g., datum['...'] for Vega Expression */\n  expr?: 'datum' | 'parent' | 'datum.datum';\n  /** Prepend fn with custom function prefix */\n  prefix?: string;\n  /** Append suffix to the field ref for bin (default='start') */\n  binSuffix?: 'end' | 'range' | 'mid';\n  /** Append suffix to the field ref (general) */\n  suffix?: string;\n  /**\n   * Use the field name for `as` in a transform.\n   * We will not escape nested accesses because Vega transform outputs cannot be nested.\n   */\n  forAs?: boolean;\n}\n\nfunction isOpFieldDef(\n  fieldDef: FieldDefBase<string> | WindowFieldDef | AggregatedFieldDef\n): fieldDef is WindowFieldDef | AggregatedFieldDef {\n  return !!fieldDef['op'];\n}\n\n/**\n * Get a Vega field reference from a Vega-Lite field def.\n */\nexport function vgField(\n  fieldDef: FieldDefBase<string> | WindowFieldDef | AggregatedFieldDef,\n  opt: FieldRefOption = {}\n): string {\n  let field = fieldDef.field;\n  const prefix = opt.prefix;\n  let suffix = opt.suffix;\n\n  let argAccessor = ''; // for accessing argmin/argmax field at the end without getting escaped\n\n  if (isCount(fieldDef)) {\n    field = internalField('count');\n  } else {\n    let fn: string;\n\n    if (!opt.nofn) {\n      if (isOpFieldDef(fieldDef)) {\n        fn = fieldDef.op;\n      } else {\n        const {bin, aggregate, timeUnit} = fieldDef;\n        if (isBinning(bin)) {\n          fn = binToString(bin);\n          suffix = (opt.binSuffix || '') + (opt.suffix || '');\n        } else if (aggregate) {\n          if (isArgmaxDef(aggregate)) {\n            argAccessor = `.${field}`;\n            field = `argmax_${aggregate.argmax}`;\n          } else if (isArgminDef(aggregate)) {\n            argAccessor = `.${field}`;\n            field = `argmin_${aggregate.argmin}`;\n          } else {\n            fn = String(aggregate);\n          }\n        } else if (timeUnit) {\n          fn = String(timeUnit);\n        }\n      }\n    }\n\n    if (fn) {\n      field = field ? `${fn}_${field}` : fn;\n    }\n  }\n\n  if (suffix) {\n    field = `${field}_${suffix}`;\n  }\n\n  if (prefix) {\n    field = `${prefix}_${field}`;\n  }\n\n  if (opt.forAs) {\n    return field;\n  } else if (opt.expr) {\n    // Expression to access flattened field. No need to escape dots.\n    return flatAccessWithDatum(field, opt.expr) + argAccessor;\n  } else {\n    // We flattened all fields so paths should have become dot.\n    return replacePathInField(field) + argAccessor;\n  }\n}\n\nexport function isDiscrete(fieldDef: TypedFieldDef<Field>) {\n  switch (fieldDef.type) {\n    case 'nominal':\n    case 'ordinal':\n    case 'geojson':\n      return true;\n    case 'quantitative':\n      return !!fieldDef.bin;\n    case 'temporal':\n      return false;\n  }\n  throw new Error(log.message.invalidFieldType(fieldDef.type));\n}\n\nexport function isContinuous(fieldDef: TypedFieldDef<Field>) {\n  return !isDiscrete(fieldDef);\n}\n\nexport function isCount(fieldDef: FieldDefBase<Field>) {\n  return fieldDef.aggregate === 'count';\n}\n\nexport type FieldTitleFormatter = (fieldDef: FieldDefBase<string>, config: Config) => string;\n\nexport function verbalTitleFormatter(fieldDef: FieldDefBase<string>, config: Config) {\n  const {field, bin, timeUnit, aggregate} = fieldDef;\n  if (aggregate === 'count') {\n    return config.countTitle;\n  } else if (isBinning(bin)) {\n    return `${field} (binned)`;\n  } else if (timeUnit) {\n    const units = getTimeUnitParts(timeUnit).join('-');\n    return `${field} (${units})`;\n  } else if (aggregate) {\n    if (isArgmaxDef(aggregate)) {\n      return `${field} for max ${aggregate.argmax}`;\n    } else if (isArgminDef(aggregate)) {\n      return `${field} for min ${aggregate.argmin}`;\n    } else {\n      return `${titlecase(aggregate)} of ${field}`;\n    }\n  }\n  return field;\n}\n\nexport function functionalTitleFormatter(fieldDef: FieldDefBase<string>) {\n  const {aggregate, bin, timeUnit, field} = fieldDef;\n  if (isArgmaxDef(aggregate)) {\n    return `${field} for argmax(${aggregate.argmax})`;\n  } else if (isArgminDef(aggregate)) {\n    return `${field} for argmin(${aggregate.argmin})`;\n  }\n\n  const fn = aggregate || timeUnit || (isBinning(bin) && 'bin');\n  if (fn) {\n    return fn.toUpperCase() + '(' + field + ')';\n  } else {\n    return field;\n  }\n}\n\nexport const defaultTitleFormatter: FieldTitleFormatter = (fieldDef: FieldDefBase<string>, config: Config) => {\n  switch (config.fieldTitle) {\n    case 'plain':\n      return fieldDef.field;\n    case 'functional':\n      return functionalTitleFormatter(fieldDef);\n    default:\n      return verbalTitleFormatter(fieldDef, config);\n  }\n};\n\nlet titleFormatter = defaultTitleFormatter;\n\nexport function setTitleFormatter(formatter: FieldTitleFormatter) {\n  titleFormatter = formatter;\n}\n\nexport function resetTitleFormatter() {\n  setTitleFormatter(defaultTitleFormatter);\n}\n\nexport function title(\n  fieldDef: TypedFieldDef<string> | SecondaryFieldDef<string>,\n  config: Config,\n  {allowDisabling, includeDefault = true}: {allowDisabling: boolean; includeDefault?: boolean}\n) {\n  const guide = getGuide(fieldDef) || {};\n  const guideTitle = guide.title;\n  const def = includeDefault ? defaultTitle(fieldDef, config) : undefined;\n\n  if (allowDisabling) {\n    return getFirstDefined(guideTitle, fieldDef.title, def);\n  } else {\n    return guideTitle || fieldDef.title || def;\n  }\n}\n\nexport function getGuide(fieldDef: TypedFieldDef<string> | SecondaryFieldDef<string>): Guide {\n  if (isPositionFieldDef(fieldDef) && fieldDef.axis) {\n    return fieldDef.axis;\n  } else if (isMarkPropFieldDef(fieldDef) && fieldDef.legend) {\n    return fieldDef.legend;\n  } else if (isFacetFieldDef(fieldDef) && fieldDef.header) {\n    return fieldDef.header;\n  }\n  return undefined;\n}\n\nexport function defaultTitle(fieldDef: FieldDefBase<string>, config: Config) {\n  return titleFormatter(fieldDef, config);\n}\n\nexport function format(fieldDef: TypedFieldDef<string>) {\n  if (isTextFieldDef(fieldDef) && fieldDef.format) {\n    return fieldDef.format;\n  } else {\n    const guide = getGuide(fieldDef) || {};\n    return guide.format;\n  }\n}\n\nexport function defaultType(fieldDef: TypedFieldDef<Field>, channel: Channel): Type {\n  if (fieldDef.timeUnit) {\n    return 'temporal';\n  }\n  if (isBinning(fieldDef.bin)) {\n    return 'quantitative';\n  }\n  switch (rangeType(channel)) {\n    case 'continuous':\n      return 'quantitative';\n    case 'discrete':\n      return 'nominal';\n    case 'flexible': // color\n      return 'nominal';\n    default:\n      return 'quantitative';\n  }\n}\n\n/**\n * Returns the fieldDef -- either from the outer channelDef or from the condition of channelDef.\n * @param channelDef\n */\n\nexport function getFieldDef<F extends Field>(channelDef: ChannelDef<FieldDef<F>>): FieldDef<F> {\n  if (isFieldDef(channelDef)) {\n    return channelDef;\n  } else if (hasConditionalFieldDef(channelDef)) {\n    return channelDef.condition;\n  }\n  return undefined;\n}\n\nexport function getTypedFieldDef<F extends Field>(channelDef: ChannelDef<TypedFieldDef<F>>): TypedFieldDef<F> {\n  if (isFieldDef(channelDef)) {\n    return channelDef;\n  } else if (hasConditionalFieldDef(channelDef)) {\n    return channelDef.condition;\n  }\n  return undefined;\n}\n\n/**\n * Convert type to full, lowercase type, or augment the fieldDef with a default type if missing.\n */\nexport function normalize(channelDef: ChannelDef, channel: Channel): ChannelDef<any> {\n  if (isString(channelDef) || isNumber(channelDef) || isBoolean(channelDef)) {\n    const primitiveType = isString(channelDef) ? 'string' : isNumber(channelDef) ? 'number' : 'boolean';\n    log.warn(log.message.primitiveChannelDef(channel, primitiveType, channelDef));\n    return {value: channelDef};\n  }\n\n  // If a fieldDef contains a field, we need type.\n  if (isFieldDef(channelDef)) {\n    return normalizeFieldDef(channelDef, channel);\n  } else if (hasConditionalFieldDef(channelDef)) {\n    return {\n      ...channelDef,\n      // Need to cast as normalizeFieldDef normally return FieldDef, but here we know that it is definitely Condition<FieldDef>\n      condition: normalizeFieldDef(channelDef.condition, channel) as Conditional<TypedFieldDef<string>>\n    };\n  }\n  return channelDef;\n}\nexport function normalizeFieldDef(fieldDef: FieldDef<string>, channel: Channel) {\n  const {aggregate, timeUnit, bin} = fieldDef;\n  // Drop invalid aggregate\n  if (aggregate && !isAggregateOp(aggregate) && !isArgmaxDef(aggregate) && !isArgminDef(aggregate)) {\n    const {aggregate: _, ...fieldDefWithoutAggregate} = fieldDef;\n    log.warn(log.message.invalidAggregate(aggregate));\n    fieldDef = fieldDefWithoutAggregate;\n  }\n\n  // Normalize Time Unit\n  if (timeUnit) {\n    fieldDef = {\n      ...fieldDef,\n      timeUnit: normalizeTimeUnit(timeUnit)\n    };\n  }\n\n  // Normalize bin\n  if (isBinning(bin)) {\n    fieldDef = {\n      ...fieldDef,\n      bin: normalizeBin(bin, channel)\n    } as FieldDef<string>;\n  }\n\n  if (isBinned(bin) && !contains(POSITION_SCALE_CHANNELS, channel)) {\n    log.warn(`Channel ${channel} should not be used with \"binned\" bin`);\n  }\n\n  // Normalize Type\n  if (isTypedFieldDef(fieldDef)) {\n    const {type} = fieldDef;\n    const fullType = getFullName(type);\n    if (type !== fullType) {\n      // convert short type to full type\n      fieldDef = {\n        ...fieldDef,\n        type: fullType\n      };\n    }\n    if (type !== 'quantitative') {\n      if (isCountingAggregateOp(aggregate)) {\n        log.warn(log.message.invalidFieldTypeForCountAggregate(type, aggregate));\n        fieldDef = {\n          ...fieldDef,\n          type: 'quantitative'\n        };\n      }\n    }\n  } else if (!isSecondaryRangeChannel(channel)) {\n    // If type is empty / invalid, then augment with default type\n    const newType = defaultType(fieldDef as TypedFieldDef<any>, channel);\n    log.warn(log.message.missingFieldType(channel, newType));\n\n    fieldDef = {\n      ...fieldDef,\n      type: newType\n    };\n  }\n\n  if (isTypedFieldDef(fieldDef)) {\n    const {compatible, warning} = channelCompatibility(fieldDef, channel);\n    if (!compatible) {\n      log.warn(warning);\n    }\n  }\n  return fieldDef;\n}\n\nexport function normalizeBin(bin: BinParams | boolean | 'binned', channel: Channel) {\n  if (isBoolean(bin)) {\n    return {maxbins: autoMaxBins(channel)};\n  } else if (bin === 'binned') {\n    return {\n      binned: true\n    };\n  } else if (!bin.maxbins && !bin.step) {\n    return {...bin, maxbins: autoMaxBins(channel)};\n  } else {\n    return bin;\n  }\n}\n\nconst COMPATIBLE = {compatible: true};\nexport function channelCompatibility(\n  fieldDef: TypedFieldDef<Field>,\n  channel: Channel\n): {compatible: boolean; warning?: string} {\n  const type = fieldDef.type;\n\n  if (type === 'geojson' && channel !== 'shape') {\n    return {\n      compatible: false,\n      warning: `Channel ${channel} should not be used with a geojson data.`\n    };\n  }\n\n  switch (channel) {\n    case 'row':\n    case 'column':\n    case 'facet':\n      if (isContinuous(fieldDef)) {\n        return {\n          compatible: false,\n          warning: log.message.facetChannelShouldBeDiscrete(channel)\n        };\n      }\n      return COMPATIBLE;\n\n    case 'x':\n    case 'y':\n    case 'color':\n    case 'fill':\n    case 'stroke':\n    case 'text':\n    case 'detail':\n    case 'key':\n    case 'tooltip':\n    case 'href':\n      return COMPATIBLE;\n\n    case 'longitude':\n    case 'longitude2':\n    case 'latitude':\n    case 'latitude2':\n      if (type !== QUANTITATIVE) {\n        return {\n          compatible: false,\n          warning: `Channel ${channel} should be used with a quantitative field only, not ${fieldDef.type} field.`\n        };\n      }\n      return COMPATIBLE;\n\n    case 'opacity':\n    case 'fillOpacity':\n    case 'strokeOpacity':\n    case 'strokeWidth':\n    case 'size':\n    case 'x2':\n    case 'y2':\n      if (type === 'nominal' && !fieldDef['sort']) {\n        return {\n          compatible: false,\n          warning: `Channel ${channel} should not be used with an unsorted discrete field.`\n        };\n      }\n      return COMPATIBLE;\n\n    case 'shape':\n      if (!contains(['ordinal', 'nominal', 'geojson'], fieldDef.type)) {\n        return {\n          compatible: false,\n          warning: 'Shape channel should be used with only either discrete or geojson data.'\n        };\n      }\n      return COMPATIBLE;\n\n    case 'order':\n      if (fieldDef.type === 'nominal' && !('sort' in fieldDef)) {\n        return {\n          compatible: false,\n          warning: `Channel order is inappropriate for nominal field, which has no inherent order.`\n        };\n      }\n      return COMPATIBLE;\n  }\n  throw new Error('channelCompatability not implemented for channel ' + channel);\n}\n\nexport function isNumberFieldDef(fieldDef: TypedFieldDef<any>) {\n  return fieldDef.type === 'quantitative' || isBinning(fieldDef.bin);\n}\n\n/**\n * Check if the field def uses a time format or does not use any format but is temporal (this does not cover field defs that are temporal but use a number format).\n */\nexport function isTimeFormatFieldDef(fieldDef: TypedFieldDef<string>): boolean {\n  const formatType =\n    (isPositionFieldDef(fieldDef) && fieldDef.axis && fieldDef.axis.formatType) ||\n    (isMarkPropFieldDef(fieldDef) && fieldDef.legend && fieldDef.legend.formatType) ||\n    (isTextFieldDef(fieldDef) && fieldDef.formatType);\n  return formatType === 'time' || (!formatType && isTimeFieldDef(fieldDef));\n}\n\n/**\n * Check if field def has tye `temporal`. If you want to also cover field defs that use a time format, use `isTimeFormatFieldDef`.\n */\nexport function isTimeFieldDef(fieldDef: TypedFieldDef<any>) {\n  return fieldDef.type === 'temporal' || !!fieldDef.timeUnit;\n}\n\n/**\n * Getting a value associated with a fielddef.\n * Convert the value to Vega expression if applicable (for datetime object, or string if the field def is temporal or has timeUnit)\n */\nexport function valueExpr(\n  v: number | string | boolean | DateTime,\n  {\n    timeUnit,\n    type,\n    time,\n    undefinedIfExprNotRequired\n  }: {\n    timeUnit: TimeUnit;\n    type?: Type;\n    time?: boolean;\n    undefinedIfExprNotRequired?: boolean;\n  }\n): string {\n  let expr;\n  if (isDateTime(v)) {\n    expr = dateTimeExpr(v, true);\n  } else if (isString(v) || isNumber(v)) {\n    if (timeUnit || type === 'temporal') {\n      if (isLocalSingleTimeUnit(timeUnit)) {\n        expr = dateTimeExpr({[timeUnit]: v}, true);\n      } else if (isUtcSingleTimeUnit(timeUnit)) {\n        // FIXME is this really correct?\n        expr = valueExpr(v, {timeUnit: getLocalTimeUnit(timeUnit)});\n      } else {\n        // just pass the string to date function (which will call JS Date.parse())\n        expr = `datetime(${JSON.stringify(v)})`;\n      }\n    }\n  }\n  if (expr) {\n    return time ? `time(${expr})` : expr;\n  }\n  // number or boolean or normal string\n  return undefinedIfExprNotRequired ? undefined : JSON.stringify(v);\n}\n\n/**\n * Standardize value array -- convert each value to Vega expression if applicable\n */\nexport function valueArray(fieldDef: TypedFieldDef<string>, values: (number | string | boolean | DateTime)[]) {\n  const {timeUnit, type} = fieldDef;\n  return values.map(v => {\n    const expr = valueExpr(v, {timeUnit, type, undefinedIfExprNotRequired: true});\n    // return signal for the expression if we need an expression\n    if (expr !== undefined) {\n      return {signal: expr};\n    }\n    // otherwise just return the original value\n    return v;\n  });\n}\n\n/**\n * Checks whether a fieldDef for a particular channel requires a computed bin range.\n */\nexport function binRequiresRange(fieldDef: TypedFieldDef<string>, channel: Channel) {\n  if (!isBinning(fieldDef.bin)) {\n    console.warn('Only use this method with binned field defs');\n    return false;\n  }\n\n  // We need the range only when the user explicitly forces a binned field to be use discrete scale. In this case, bin range is used in axis and legend labels.\n  // We could check whether the axis or legend exists (not disabled) but that seems overkill.\n  return isScaleChannel(channel) && contains(['ordinal', 'nominal'], fieldDef.type);\n}\n","import * as TYPE from 'vega-lite/build/src/type';\nimport {Type} from 'vega-lite/build/src/type';\n\nexport namespace ExpandedType {\n  export const QUANTITATIVE = TYPE.QUANTITATIVE;\n  export const ORDINAL = TYPE.ORDINAL;\n  export const TEMPORAL = TYPE.TEMPORAL;\n  export const NOMINAL = TYPE.NOMINAL;\n  export const KEY: 'key' = 'key';\n}\n\nexport type ExpandedType = Type | typeof ExpandedType.KEY;\n\nexport function isDiscrete(fieldType: any) {\n  return fieldType === TYPE.ORDINAL || fieldType === TYPE.NOMINAL || fieldType === ExpandedType.KEY;\n}\n","import {isBinning} from '../../bin';\nimport {Channel, isColorChannel, isScaleChannel, rangeType} from '../../channel';\nimport {TypedFieldDef} from '../../channeldef';\nimport * as log from '../../log';\nimport {Mark} from '../../mark';\nimport {channelSupportScaleType, Scale, ScaleType, scaleTypeSupportDataType} from '../../scale';\nimport * as util from '../../util';\n\nexport type RangeType = 'continuous' | 'discrete' | 'flexible' | undefined;\n\n/**\n * Determine if there is a specified scale type and if it is appropriate,\n * or determine default type if type is unspecified or inappropriate.\n */\n// NOTE: CompassQL uses this method.\nexport function scaleType(\n  specifiedScale: Scale,\n  channel: Channel,\n  fieldDef: TypedFieldDef<string>,\n  mark: Mark\n): ScaleType {\n  const defaultScaleType = defaultType(channel, fieldDef, mark);\n  const {type} = specifiedScale;\n\n  if (!isScaleChannel(channel)) {\n    // There is no scale for these channels\n    return null;\n  }\n  if (type !== undefined) {\n    // Check if explicitly specified scale type is supported by the channel\n    if (!channelSupportScaleType(channel, type)) {\n      log.warn(log.message.scaleTypeNotWorkWithChannel(channel, type, defaultScaleType));\n      return defaultScaleType;\n    }\n\n    // Check if explicitly specified scale type is supported by the data type\n    if (!scaleTypeSupportDataType(type, fieldDef.type)) {\n      log.warn(log.message.scaleTypeNotWorkWithFieldDef(type, defaultScaleType));\n      return defaultScaleType;\n    }\n\n    return type;\n  }\n\n  return defaultScaleType;\n}\n\n/**\n * Determine appropriate default scale type.\n */\n// NOTE: Voyager uses this method.\nfunction defaultType(channel: Channel, fieldDef: TypedFieldDef<string>, mark: Mark): ScaleType {\n  switch (fieldDef.type) {\n    case 'nominal':\n    case 'ordinal':\n      if (isColorChannel(channel) || rangeType(channel) === 'discrete') {\n        if (channel === 'shape' && fieldDef.type === 'ordinal') {\n          log.warn(log.message.discreteChannelCannotEncode(channel, 'ordinal'));\n        }\n        return 'ordinal';\n      }\n\n      if (util.contains(['x', 'y'], channel)) {\n        if (util.contains(['rect', 'bar', 'rule'], mark)) {\n          // The rect/bar mark should fit into a band.\n          // For rule, using band scale to make rule align with axis ticks better https://github.com/vega/vega-lite/issues/3429\n          return 'band';\n        }\n        if (mark === 'bar') {\n          return 'band';\n        }\n      }\n      // Otherwise, use ordinal point scale so we can easily get center positions of the marks.\n      return 'point';\n\n    case 'temporal':\n      if (isColorChannel(channel)) {\n        return 'time';\n      } else if (rangeType(channel) === 'discrete') {\n        log.warn(log.message.discreteChannelCannotEncode(channel, 'temporal'));\n        // TODO: consider using quantize (equivalent to binning) once we have it\n        return 'ordinal';\n      }\n      return 'time';\n\n    case 'quantitative':\n      if (isColorChannel(channel)) {\n        if (isBinning(fieldDef.bin)) {\n          return 'bin-ordinal';\n        }\n\n        return 'linear';\n      } else if (rangeType(channel) === 'discrete') {\n        log.warn(log.message.discreteChannelCannotEncode(channel, 'quantitative'));\n        // TODO: consider using quantize (equivalent to binning) once we have it\n        return 'ordinal';\n      }\n\n      return 'linear';\n\n    case 'geojson':\n      return undefined;\n  }\n\n  /* istanbul ignore next: should never reach this */\n  throw new Error(log.message.invalidFieldType(fieldDef.type));\n}\n","import { Dict, keys } from './util';\nimport {\n  Property, toKey,\n} from './property';\n\nexport interface PropIndexReader<T> {\n  has(p: Property): boolean;\n  get(p: Property): T;\n}\n\n/**\n * Dictionary that takes property as a key.\n */\nexport class PropIndex<T> implements PropIndexReader<T> {\n  private index: Dict<T>;\n\n  constructor(i: Dict<T> = null) {\n    this.index = i ? { ...i } : {};\n  }\n\n  public has(p: Property) {\n    return toKey(p) in this.index;\n  }\n\n  public get(p: Property) {\n    return this.index[toKey(p)];\n  }\n\n  public set(p: Property, value: T) {\n    this.index[toKey(p)] = value;\n    return this;\n  }\n\n  public setByKey(key: string, value: T) {\n    this.index[key] = value;\n  }\n\n  public map<U>(f: (t: T) => U): PropIndex<U> {\n    const i = new PropIndex<U>();\n    for (const k in this.index) {\n      i.index[k] = f(this.index[k]);\n    }\n    return i;\n  }\n\n  public size() {\n    return keys(this.index).length;\n  }\n\n  public duplicate(): PropIndex<T> {\n    return new PropIndex<T>(this.index);\n  }\n}\n","import {AggregateOp} from 'vega';\nimport {isArray} from 'vega-util';\nimport {isArgmaxDef, isArgminDef} from './aggregate';\nimport {isBinning} from './bin';\nimport {Channel, CHANNELS, isChannel, isNonPositionScaleChannel, isSecondaryRangeChannel, supportMark} from './channel';\nimport {\n  binRequiresRange,\n  ChannelDef,\n  Field,\n  FieldDef,\n  FieldDefWithoutScale,\n  getFieldDef,\n  getGuide,\n  getTypedFieldDef,\n  hasConditionalFieldDef,\n  isConditionalDef,\n  isFieldDef,\n  isTypedFieldDef,\n  isValueDef,\n  LatLongFieldDef,\n  normalize,\n  normalizeFieldDef,\n  NumericFieldDefWithCondition,\n  NumericValueDefWithCondition,\n  OrderFieldDef,\n  PositionFieldDef,\n  SecondaryFieldDef,\n  ShapeFieldDefWithCondition,\n  ShapeValueDefWithCondition,\n  StringFieldDefWithCondition,\n  StringValueDefWithCondition,\n  TextFieldDef,\n  TextFieldDefWithCondition,\n  TextValueDefWithCondition,\n  title,\n  TypedFieldDef,\n  ValueDef,\n  vgField\n} from './channeldef';\nimport {Config} from './config';\nimport * as log from './log';\nimport {Mark} from './mark';\nimport {EncodingFacetMapping} from './spec/facet';\nimport {getDateTimeComponents} from './timeunit';\nimport {AggregatedFieldDef, BinTransform, TimeUnitTransform} from './transform';\nimport {TEMPORAL} from './type';\nimport {keys, some} from './util';\n\nexport interface Encoding<F extends Field> {\n  /**\n   * X coordinates of the marks, or width of horizontal `\"bar\"` and `\"area\"` without `x2`.\n   *\n   * The `value` of this channel can be a number or a string `\"width\"`.\n   */\n  x?: PositionFieldDef<F> | ValueDef<number | 'width'>;\n\n  /**\n   * Y coordinates of the marks, or height of vertical `\"bar\"` and `\"area\"` without `y2`\n   *\n   * The `value` of this channel can be a number or a string `\"height\"`.\n   */\n  y?: PositionFieldDef<F> | ValueDef<number | 'height'>;\n\n  /**\n   * X2 coordinates for ranged `\"area\"`, `\"bar\"`, `\"rect\"`, and  `\"rule\"`.\n   *\n   * The `value` of this channel can be a number or a string `\"width\"`.\n   */\n  // TODO: Ham need to add default behavior\n  // `x2` cannot have type as it should have the same type as `x`\n  x2?: SecondaryFieldDef<F> | ValueDef<number | 'width'>;\n\n  /**\n   * Y2 coordinates for ranged `\"area\"`, `\"bar\"`, `\"rect\"`, and  `\"rule\"`.\n   *\n   * The `value` of this channel can be a number or a string `\"height\"`.\n   */\n  // TODO: Ham need to add default behavior\n  // `y2` cannot have type as it should have the same type as `y`\n  y2?: SecondaryFieldDef<F> | ValueDef<number | 'height'>;\n\n  /**\n   * Longitude position of geographically projected marks.\n   */\n  longitude?: LatLongFieldDef<F> | ValueDef<number>;\n\n  /**\n   * Latitude position of geographically projected marks.\n   */\n  latitude?: LatLongFieldDef<F> | ValueDef<number>;\n\n  /**\n   * Longitude-2 position for geographically projected ranged `\"area\"`, `\"bar\"`, `\"rect\"`, and  `\"rule\"`.\n   */\n  // `longitude2` cannot have type as it should have the same type as `longitude`\n  longitude2?: SecondaryFieldDef<F> | ValueDef<number>;\n\n  /**\n   * Latitude-2 position for geographically projected ranged `\"area\"`, `\"bar\"`, `\"rect\"`, and  `\"rule\"`.\n   */\n  // `latitude2` cannot have type as it should have the same type as `latitude`\n  latitude2?: SecondaryFieldDef<F> | ValueDef<number>;\n\n  /**\n   * Color of the marks – either fill or stroke color based on  the `filled` property of mark definition.\n   * By default, `color` represents fill color for `\"area\"`, `\"bar\"`, `\"tick\"`,\n   * `\"text\"`, `\"trail\"`, `\"circle\"`, and `\"square\"` / stroke color for `\"line\"` and `\"point\"`.\n   *\n   * __Default value:__ If undefined, the default color depends on [mark config](https://vega.github.io/vega-lite/docs/config.html#mark)'s `color` property.\n   *\n   * _Note:_\n   * 1) For fine-grained control over both fill and stroke colors of the marks, please use the `fill` and `stroke` channels.  If either `fill` or `stroke` channel is specified, `color` channel will be ignored.\n   * 2) See the scale documentation for more information about customizing [color scheme](https://vega.github.io/vega-lite/docs/scale.html#scheme).\n   */\n  color?: StringFieldDefWithCondition<F> | StringValueDefWithCondition<F>;\n\n  /**\n   * Fill color of the marks.\n   * __Default value:__ If undefined, the default color depends on [mark config](https://vega.github.io/vega-lite/docs/config.html#mark)'s `color` property.\n   *\n   * _Note:_ When using `fill` channel, `color ` channel will be ignored. To customize both fill and stroke, please use `fill` and `stroke` channels (not `fill` and `color`).\n   */\n  fill?: StringFieldDefWithCondition<F> | StringValueDefWithCondition<F>;\n\n  /**\n   * Stroke color of the marks.\n   * __Default value:__ If undefined, the default color depends on [mark config](https://vega.github.io/vega-lite/docs/config.html#mark)'s `color` property.\n   *\n   * _Note:_ When using `stroke` channel, `color ` channel will be ignored. To customize both stroke and fill, please use `stroke` and `fill` channels (not `stroke` and `color`).\n   */\n\n  stroke?: StringFieldDefWithCondition<F> | StringValueDefWithCondition<F>;\n\n  /**\n   * Opacity of the marks.\n   *\n   * __Default value:__ If undefined, the default opacity depends on [mark config](https://vega.github.io/vega-lite/docs/config.html#mark)'s `opacity` property.\n   */\n  opacity?: NumericFieldDefWithCondition<F> | NumericValueDefWithCondition<F>;\n\n  /**\n   * Fill opacity of the marks.\n   *\n   * __Default value:__ If undefined, the default opacity depends on [mark config](https://vega.github.io/vega-lite/docs/config.html#mark)'s `fillOpacity` property.\n   */\n  fillOpacity?: NumericFieldDefWithCondition<F> | NumericValueDefWithCondition<F>;\n\n  /**\n   * Stroke opacity of the marks.\n   *\n   * __Default value:__ If undefined, the default opacity depends on [mark config](https://vega.github.io/vega-lite/docs/config.html#mark)'s `strokeOpacity` property.\n   */\n  strokeOpacity?: NumericFieldDefWithCondition<F> | NumericValueDefWithCondition<F>;\n\n  /**\n   * Stroke width of the marks.\n   *\n   * __Default value:__ If undefined, the default stroke width depends on [mark config](https://vega.github.io/vega-lite/docs/config.html#mark)'s `strokeWidth` property.\n   */\n  strokeWidth?: NumericFieldDefWithCondition<F> | NumericValueDefWithCondition<F>;\n\n  /**\n   * Size of the mark.\n   * - For `\"point\"`, `\"square\"` and `\"circle\"`, – the symbol size, or pixel area of the mark.\n   * - For `\"bar\"` and `\"tick\"` – the bar and tick's size.\n   * - For `\"text\"` – the text's font size.\n   * - Size is unsupported for `\"line\"`, `\"area\"`, and `\"rect\"`. (Use `\"trail\"` instead of line with varying size)\n   */\n  size?: NumericFieldDefWithCondition<F> | NumericValueDefWithCondition<F>;\n\n  /**\n   * Shape of the mark.\n   *\n   * 1. For `point` marks the supported values include:\n   *   - plotting shapes: `\"circle\"`, `\"square\"`, `\"cross\"`, `\"diamond\"`, `\"triangle-up\"`, `\"triangle-down\"`, `\"triangle-right\"`, or `\"triangle-left\"`.\n   *   - the line symbol `\"stroke\"`\n   *   - centered directional shapes `\"arrow\"`, `\"wedge\"`, or `\"triangle\"`\n   *   - a custom [SVG path string](https://developer.mozilla.org/en-US/docs/Web/SVG/Tutorial/Paths) (For correct sizing, custom shape paths should be defined within a square bounding box with coordinates ranging from -1 to 1 along both the x and y dimensions.)\n   *\n   * 2. For `geoshape` marks it should be a field definition of the geojson data\n   *\n   * __Default value:__ If undefined, the default shape depends on [mark config](https://vega.github.io/vega-lite/docs/config.html#point-config)'s `shape` property. (`\"circle\"` if unset.)\n   */\n  shape?: ShapeFieldDefWithCondition<F> | ShapeValueDefWithCondition<F>;\n  /**\n   * Additional levels of detail for grouping data in aggregate views and\n   * in line, trail, and area marks without mapping data to a specific visual channel.\n   */\n  detail?: FieldDefWithoutScale<F> | FieldDefWithoutScale<F>[];\n\n  /**\n   * A data field to use as a unique key for data binding. When a visualization’s data is updated, the key value will be used to match data elements to existing mark instances. Use a key channel to enable object constancy for transitions over dynamic data.\n   */\n  key?: FieldDefWithoutScale<F>;\n\n  /**\n   * Text of the `text` mark.\n   */\n  text?: TextFieldDefWithCondition<F> | TextValueDefWithCondition<F>;\n\n  /**\n   * The tooltip text to show upon mouse hover.\n   */\n  tooltip?: TextFieldDefWithCondition<F> | TextValueDefWithCondition<F> | TextFieldDef<F>[] | null;\n\n  /**\n   * A URL to load upon mouse click.\n   */\n  href?: TextFieldDefWithCondition<F> | TextValueDefWithCondition<F>;\n\n  /**\n   * Order of the marks.\n   * - For stacked marks, this `order` channel encodes [stack order](https://vega.github.io/vega-lite/docs/stack.html#order).\n   * - For line and trail marks, this `order` channel encodes order of data points in the lines. This can be useful for creating [a connected scatterplot](https://vega.github.io/vega-lite/examples/connected_scatterplot.html).  Setting `order` to `{\"value\": null}` makes the line marks use the original order in the data sources.\n   * - Otherwise, this `order` channel encodes layer order of the marks.\n   *\n   * __Note__: In aggregate plots, `order` field should be `aggregate`d to avoid creating additional aggregation grouping.\n   */\n  order?: OrderFieldDef<F> | OrderFieldDef<F>[] | ValueDef<number>;\n}\n\nexport interface EncodingWithFacet<F extends Field> extends Encoding<F>, EncodingFacetMapping<F> {}\n\nexport function channelHasField<F extends Field>(encoding: EncodingWithFacet<F>, channel: Channel): boolean {\n  const channelDef = encoding && encoding[channel];\n  if (channelDef) {\n    if (isArray(channelDef)) {\n      return some(channelDef, fieldDef => !!fieldDef.field);\n    } else {\n      return isFieldDef(channelDef) || hasConditionalFieldDef(channelDef);\n    }\n  }\n  return false;\n}\n\nexport function isAggregate(encoding: EncodingWithFacet<Field>) {\n  return some(CHANNELS, channel => {\n    if (channelHasField(encoding, channel)) {\n      const channelDef = encoding[channel];\n      if (isArray(channelDef)) {\n        return some(channelDef, fieldDef => !!fieldDef.aggregate);\n      } else {\n        const fieldDef = getFieldDef(channelDef);\n        return fieldDef && !!fieldDef.aggregate;\n      }\n    }\n    return false;\n  });\n}\nexport function extractTransformsFromEncoding(oldEncoding: Encoding<Field>, config: Config) {\n  const groupby: string[] = [];\n  const bins: BinTransform[] = [];\n  const timeUnits: TimeUnitTransform[] = [];\n  const aggregate: AggregatedFieldDef[] = [];\n  const encoding: Encoding<string> = {};\n\n  forEach(oldEncoding, (channelDef, channel) => {\n    // Extract potential embedded transformations along with remaining properties\n    if (isFieldDef(channelDef)) {\n      const {field, aggregate: aggOp, timeUnit, bin, ...remaining} = channelDef;\n      if (aggOp || timeUnit || bin) {\n        const guide = getGuide(channelDef);\n        const isTitleDefined = guide && guide.title;\n        let newField = vgField(channelDef, {forAs: true});\n        const newFieldDef: FieldDef<string> = {\n          // Only add title if it doesn't exist\n          ...(isTitleDefined ? [] : {title: title(channelDef, config, {allowDisabling: true})}),\n          ...remaining,\n          // Always overwrite field\n          field: newField\n        };\n        const isPositionChannel: boolean = channel === 'x' || channel === 'y';\n\n        if (aggOp) {\n          let op: AggregateOp;\n\n          if (isArgmaxDef(aggOp)) {\n            op = 'argmax';\n            newField = vgField({aggregate: 'argmax', field: aggOp.argmax}, {forAs: true});\n            newFieldDef.field = `${newField}.${field}`;\n          } else if (isArgminDef(aggOp)) {\n            op = 'argmin';\n            newField = vgField({aggregate: 'argmin', field: aggOp.argmin}, {forAs: true});\n            newFieldDef.field = `${newField}.${field}`;\n          } else if (aggOp !== 'boxplot' && aggOp !== 'errorbar' && aggOp !== 'errorband') {\n            op = aggOp;\n          }\n\n          if (op) {\n            const aggregateEntry: AggregatedFieldDef = {\n              op,\n              as: newField\n            };\n            if (field) {\n              aggregateEntry.field = field;\n            }\n            aggregate.push(aggregateEntry);\n          }\n        } else if (isTypedFieldDef(channelDef) && isBinning(bin)) {\n          bins.push({bin, field, as: newField});\n          // Add additional groupbys for range and end of bins\n          groupby.push(vgField(channelDef, {binSuffix: 'end'}));\n          if (binRequiresRange(channelDef, channel)) {\n            groupby.push(vgField(channelDef, {binSuffix: 'range'}));\n          }\n          // Create accompanying 'x2' or 'y2' field if channel is 'x' or 'y' respectively\n          if (isPositionChannel) {\n            const secondaryChannel: SecondaryFieldDef<string> = {\n              field: newField + '_end'\n            };\n            encoding[channel + '2'] = secondaryChannel;\n          }\n          newFieldDef.bin = 'binned';\n          if (!isSecondaryRangeChannel(channel)) {\n            newFieldDef['type'] = 'quantitative';\n          }\n        } else if (timeUnit) {\n          timeUnits.push({timeUnit, field, as: newField});\n\n          // Add formatting to appropriate property based on the type of channel we're processing\n          const format = getDateTimeComponents(timeUnit, config.axis.shortTimeLabels).join(' ');\n          const formatType = isTypedFieldDef(channelDef) && channelDef.type !== TEMPORAL && 'time';\n          if (channel === 'text' || channel === 'tooltip') {\n            newFieldDef['format'] = newFieldDef['format'] || format;\n            if (formatType) {\n              newFieldDef['formatType'] = formatType;\n            }\n          } else if (isNonPositionScaleChannel(channel)) {\n            newFieldDef['legend'] = {format, ...(formatType ? {formatType} : {}), ...newFieldDef['legend']};\n          } else if (isPositionChannel) {\n            newFieldDef['axis'] = {format, ...(formatType ? {formatType} : {}), ...newFieldDef['axis']};\n          }\n        }\n        if (!aggOp) {\n          groupby.push(newField);\n        }\n        // now the field should refer to post-transformed field instead\n        encoding[channel] = newFieldDef;\n      } else {\n        groupby.push(field);\n        encoding[channel] = oldEncoding[channel];\n      }\n    } else {\n      // For value def, just copy\n      encoding[channel] = oldEncoding[channel];\n    }\n  });\n\n  return {\n    bins,\n    timeUnits,\n    aggregate,\n    groupby,\n    encoding\n  };\n}\n\nexport function markChannelCompatible(encoding: Encoding<string>, channel: Channel, mark: Mark) {\n  const markSupported = supportMark(channel, mark);\n  if (!markSupported) {\n    return false;\n  } else if (markSupported === 'binned') {\n    const primaryFieldDef = encoding[channel === 'x2' ? 'x' : 'y'];\n\n    // circle, point, square and tick only support x2/y2 when their corresponding x/y fieldDef\n    // has \"binned\" data and thus need x2/y2 to specify the bin-end field.\n    if (isFieldDef(primaryFieldDef) && isFieldDef(encoding[channel]) && primaryFieldDef.bin === 'binned') {\n      return true;\n    } else {\n      return false;\n    }\n  }\n  return true;\n}\n\nexport function normalizeEncoding(encoding: Encoding<string>, mark: Mark): Encoding<string> {\n  return keys(encoding).reduce((normalizedEncoding: Encoding<string>, channel: Channel | string) => {\n    if (!isChannel(channel)) {\n      // Drop invalid channel\n      log.warn(log.message.invalidEncodingChannel(channel));\n      return normalizedEncoding;\n    }\n\n    if (!markChannelCompatible(encoding, channel, mark)) {\n      // Drop unsupported channel\n      log.warn(log.message.incompatibleChannel(channel, mark));\n      return normalizedEncoding;\n    }\n\n    // Drop line's size if the field is aggregated.\n    if (channel === 'size' && mark === 'line') {\n      const fieldDef = getTypedFieldDef(encoding[channel]);\n      if (fieldDef && fieldDef.aggregate) {\n        log.warn(log.message.LINE_WITH_VARYING_SIZE);\n        return normalizedEncoding;\n      }\n    }\n\n    // Drop color if either fill or stroke is specified\n    if (channel === 'color' && ('fill' in encoding || 'stroke' in encoding)) {\n      log.warn(log.message.droppingColor('encoding', {fill: 'fill' in encoding, stroke: 'stroke' in encoding}));\n      return normalizedEncoding;\n    }\n\n    const channelDef = encoding[channel];\n    if (\n      channel === 'detail' ||\n      (channel === 'order' && !isArray(channelDef) && !isValueDef(channelDef)) ||\n      (channel === 'tooltip' && isArray(channelDef))\n    ) {\n      if (channelDef) {\n        // Array of fieldDefs for detail channel (or production rule)\n        normalizedEncoding[channel] = (isArray(channelDef) ? channelDef : [channelDef]).reduce(\n          (defs: FieldDef<string>[], fieldDef: FieldDef<string>) => {\n            if (!isFieldDef(fieldDef)) {\n              log.warn(log.message.emptyFieldDef(fieldDef, channel));\n            } else {\n              defs.push(normalizeFieldDef(fieldDef, channel));\n            }\n            return defs;\n          },\n          []\n        );\n      }\n    } else {\n      if (channel === 'tooltip' && channelDef === null) {\n        // Preserve null so we can use it to disable tooltip\n        normalizedEncoding[channel] = null;\n      } else if (!isFieldDef(channelDef) && !isValueDef(channelDef) && !isConditionalDef(channelDef)) {\n        log.warn(log.message.emptyFieldDef(channelDef, channel));\n        return normalizedEncoding;\n      }\n      normalizedEncoding[channel] = normalize(channelDef as ChannelDef, channel);\n    }\n    return normalizedEncoding;\n  }, {});\n}\n\nexport function isRanged(encoding: EncodingWithFacet<any>) {\n  return encoding && ((!!encoding.x && !!encoding.x2) || (!!encoding.y && !!encoding.y2));\n}\n\nexport function fieldDefs<F extends Field>(encoding: EncodingWithFacet<F>): FieldDef<F>[] {\n  const arr: FieldDef<F>[] = [];\n  for (const channel of keys(encoding)) {\n    if (channelHasField(encoding, channel)) {\n      const channelDef = encoding[channel];\n      (isArray(channelDef) ? channelDef : [channelDef]).forEach(def => {\n        if (isFieldDef(def)) {\n          arr.push(def);\n        } else if (hasConditionalFieldDef(def)) {\n          arr.push(def.condition);\n        }\n      });\n    }\n  }\n  return arr;\n}\n\nexport function forEach<U extends {[k in Channel]?: any}>(\n  mapping: U,\n  f: (cd: ChannelDef, c: Channel) => void,\n  thisArg?: any\n) {\n  if (!mapping) {\n    return;\n  }\n\n  for (const channel of keys(mapping)) {\n    const el = mapping[channel];\n    if (isArray(el)) {\n      el.forEach((channelDef: ChannelDef) => {\n        f.call(thisArg, channelDef, channel);\n      });\n    } else {\n      f.call(thisArg, el, channel);\n    }\n  }\n}\n\nexport function reduce<T, U extends {[k in Channel]?: any}>(\n  mapping: U,\n  f: (acc: any, fd: TypedFieldDef<string>, c: Channel) => U,\n  init: T,\n  thisArg?: any\n) {\n  if (!mapping) {\n    return init;\n  }\n\n  return keys(mapping).reduce((r, channel) => {\n    const map = mapping[channel];\n    if (isArray(map)) {\n      return map.reduce((r1: T, channelDef: ChannelDef) => {\n        return f.call(thisArg, r1, channelDef, channel);\n      }, r);\n    } else {\n      return f.call(thisArg, r, map, channel);\n    }\n  }, init);\n}\n","import {isArray, isBoolean} from 'vega-util';\nimport {SUM_OPS} from './aggregate';\nimport {NonPositionChannel, NONPOSITION_CHANNELS, X, X2, Y2} from './channel';\nimport {\n  Field,\n  getTypedFieldDef,\n  isFieldDef,\n  isStringFieldDef,\n  PositionFieldDef,\n  TypedFieldDef,\n  vgField\n} from './channeldef';\nimport {channelHasField, Encoding} from './encoding';\nimport * as log from './log';\nimport {AREA, BAR, CIRCLE, isMarkDef, isPathMark, LINE, Mark, MarkDef, POINT, RULE, SQUARE, TEXT, TICK} from './mark';\nimport {ScaleType} from './scale';\nimport {contains, Flag, getFirstDefined} from './util';\n\nexport type StackOffset = 'zero' | 'center' | 'normalize';\n\nconst STACK_OFFSET_INDEX: Flag<StackOffset> = {\n  zero: 1,\n  center: 1,\n  normalize: 1\n};\n\nexport function isStackOffset(s: string): s is StackOffset {\n  return !!STACK_OFFSET_INDEX[s];\n}\n\nexport interface StackProperties {\n  /** Dimension axis of the stack. */\n  groupbyChannel: 'x' | 'y';\n\n  /** Measure axis of the stack. */\n  fieldChannel: 'x' | 'y';\n\n  /** Stack-by fields e.g., color, detail */\n  stackBy: {\n    fieldDef: TypedFieldDef<string>;\n    channel: NonPositionChannel;\n  }[];\n\n  /**\n   * See `\"stack\"` property of Position Field Def.\n   */\n  offset: StackOffset;\n\n  /**\n   * Whether this stack will produce impute transform\n   */\n  impute: boolean;\n}\n\nexport const STACKABLE_MARKS = [BAR, AREA, RULE, POINT, CIRCLE, SQUARE, LINE, TEXT, TICK];\nexport const STACK_BY_DEFAULT_MARKS = [BAR, AREA];\n\nfunction potentialStackedChannel(encoding: Encoding<Field>): 'x' | 'y' | undefined {\n  const xDef = encoding.x;\n  const yDef = encoding.y;\n\n  if (isFieldDef(xDef) && isFieldDef(yDef)) {\n    if (xDef.type === 'quantitative' && yDef.type === 'quantitative') {\n      if (xDef.stack) {\n        return 'x';\n      } else if (yDef.stack) {\n        return 'y';\n      }\n      // if there is no explicit stacking, only apply stack if there is only one aggregate for x or y\n      if (!!xDef.aggregate !== !!yDef.aggregate) {\n        return xDef.aggregate ? 'x' : 'y';\n      }\n    } else if (xDef.type === 'quantitative') {\n      return 'x';\n    } else if (yDef.type === 'quantitative') {\n      return 'y';\n    }\n  } else if (isFieldDef(xDef) && xDef.type === 'quantitative') {\n    return 'x';\n  } else if (isFieldDef(yDef) && yDef.type === 'quantitative') {\n    return 'y';\n  }\n  return undefined;\n}\n\n// Note: CompassQL uses this method and only pass in required properties of each argument object.\n// If required properties change, make sure to update CompassQL.\nexport function stack(\n  m: Mark | MarkDef,\n  encoding: Encoding<Field>,\n  stackConfig: StackOffset,\n  opt: {\n    disallowNonLinearStack?: boolean; // This option is for CompassQL\n  } = {}\n): StackProperties {\n  const mark = isMarkDef(m) ? m.type : m;\n  // Should have stackable mark\n  if (!contains(STACKABLE_MARKS, mark)) {\n    return null;\n  }\n\n  const fieldChannel = potentialStackedChannel(encoding);\n  if (!fieldChannel) {\n    return null;\n  }\n\n  const stackedFieldDef = encoding[fieldChannel] as PositionFieldDef<string>;\n  const stackedField = isStringFieldDef(stackedFieldDef) ? vgField(stackedFieldDef, {}) : undefined;\n\n  const dimensionChannel = fieldChannel === 'x' ? 'y' : 'x';\n  const dimensionDef = encoding[dimensionChannel];\n  const dimensionField = isStringFieldDef(dimensionDef) ? vgField(dimensionDef, {}) : undefined;\n\n  // Should have grouping level of detail that is different from the dimension field\n  const stackBy = NONPOSITION_CHANNELS.reduce((sc, channel) => {\n    // Ignore tooltip in stackBy (https://github.com/vega/vega-lite/issues/4001)\n    if (channel !== 'tooltip' && channelHasField(encoding, channel)) {\n      const channelDef = encoding[channel];\n      (isArray(channelDef) ? channelDef : [channelDef]).forEach(cDef => {\n        const fieldDef = getTypedFieldDef(cDef);\n        if (fieldDef.aggregate) {\n          return;\n        }\n\n        // Check whether the channel's field is identical to x/y's field or if the channel is a repeat\n        const f = isStringFieldDef(fieldDef) ? vgField(fieldDef, {}) : undefined;\n        if (\n          // if fielddef is a repeat, just include it in the stack by\n          !f ||\n          // otherwise, the field must be different from x and y fields.\n          (f !== dimensionField && f !== stackedField)\n        ) {\n          sc.push({channel, fieldDef});\n        }\n      });\n    }\n    return sc;\n  }, []);\n\n  if (stackBy.length === 0) {\n    return null;\n  }\n\n  // Automatically determine offset\n  let offset: StackOffset;\n  if (stackedFieldDef.stack !== undefined) {\n    if (isBoolean(stackedFieldDef.stack)) {\n      offset = stackedFieldDef.stack ? 'zero' : null;\n    } else {\n      offset = stackedFieldDef.stack;\n    }\n  } else if (contains(STACK_BY_DEFAULT_MARKS, mark)) {\n    // Bar and Area with sum ops are automatically stacked by default\n    offset = getFirstDefined(stackConfig, 'zero');\n  } else {\n    offset = stackConfig;\n  }\n\n  if (!offset || !isStackOffset(offset)) {\n    return null;\n  }\n\n  // warn when stacking non-linear\n  if (stackedFieldDef.scale && stackedFieldDef.scale.type && stackedFieldDef.scale.type !== ScaleType.LINEAR) {\n    if (opt.disallowNonLinearStack) {\n      return null;\n    } else {\n      log.warn(log.message.cannotStackNonLinearScale(stackedFieldDef.scale.type));\n    }\n  }\n\n  // Check if it is a ranged mark\n  if (channelHasField(encoding, fieldChannel === X ? X2 : Y2)) {\n    if (stackedFieldDef.stack !== undefined) {\n      log.warn(log.message.cannotStackRangedMark(fieldChannel));\n    }\n    return null;\n  }\n\n  // Warn if stacking summative aggregate\n  if (stackedFieldDef.aggregate && !contains(SUM_OPS, stackedFieldDef.aggregate)) {\n    log.warn(log.message.stackNonSummativeAggregate(stackedFieldDef.aggregate));\n  }\n\n  return {\n    groupbyChannel: dimensionDef ? dimensionChannel : undefined,\n    fieldChannel,\n    impute: isPathMark(mark),\n    stackBy,\n    offset\n  };\n}\n","import {toMap} from 'datalib/src/util';\nimport {Channel} from 'vega-lite/build/src/channel';\nimport {Config} from 'vega-lite/build/src/config';\nimport {Data} from 'vega-lite/build/src/data';\nimport {Mark} from 'vega-lite/build/src/mark';\nimport {FacetedUnitSpec, TopLevel} from 'vega-lite/build/src/spec';\nimport {stack, StackOffset, StackProperties} from 'vega-lite/build/src/stack';\nimport {TitleParams} from 'vega-lite/build/src/title';\nimport {ALL_ENCODING_PROPS, getEncodingNestedProp, isEncodingTopLevelProperty, Property, toKey} from '../property';\nimport {contains, extend, isObject, keys, some, without} from '../util';\nimport {isWildcard, WildcardProperty} from '../wildcard';\nimport {EncodingQuery, isDisabledAutoCountQuery, isEnabledAutoCountQuery, isFieldQuery, toEncoding} from './encoding';\nimport {TransformQuery} from './transform';\n\n/**\n * A \"query\" version of a [Vega-Lite](https://github.com/vega/vega-lite)'s `UnitSpec` (single view specification).\n * This interface and most of  its children have `Query` suffixes to hint that their instanced are queries that\n * can contain wildcards to describe a collection of specifications.\n */\nexport interface SpecQuery {\n  data?: Data;\n\n  // TODO: support mark definition object\n  mark: WildcardProperty<Mark>;\n  transform?: TransformQuery[];\n\n  /**\n   * Array of encoding query mappings.\n   * Note: Vega-Lite's `encoding` is an object whose keys are unique encoding channels.\n   * However, for CompassQL, the `channel` property of encoding query mappings can be wildcards.\n   * Thus the `encoding` object in Vega-Lite is flatten as the `encodings` array in CompassQL.\n   */\n  encodings: EncodingQuery[];\n\n  /**\n   * The width of the resulting encodings.\n   * __NOTE:__ Does not support wildcards.\n   */\n  width?: number;\n\n  /**\n   * The height of the resulting encodings.\n   * __NOTE:__ Does not support wildcards.\n   */\n  height?: number;\n\n  /**\n   * CSS color property to use as the background of visualization.\n   * __NOTE:__ Does not support wildcards.\n   */\n  background?: string;\n\n  /**\n   * The default visualization padding, in pixels, from the edge of the\n   * visualization canvas to the data rectangle. If a number, specifies\n   * padding for all sides. If an object, the value should have the\n   * format {\"left\": 5, \"top\": 5, \"right\": 5, \"bottom\": 5}\n   * to specify padding for each side of the visualization.\n   *\n   * __NOTE:__ Does not support wildcards.\n   */\n  padding?: number | Object;\n\n  /**\n   * Title for the plot.\n   * __NOTE:__ Does not support wildcards.\n   */\n  title?: string | TitleParams;\n\n  // TODO: make config query (not important at all, only for the sake of completeness.)\n  /**\n   * Vega-Lite Configuration\n   */\n  config?: Config;\n}\n\n/**\n * Convert a Vega-Lite's ExtendedUnitSpec into a CompassQL's SpecQuery\n * @param {ExtendedUnitSpec} spec\n * @returns\n */\nexport function fromSpec(spec: TopLevel<FacetedUnitSpec>): SpecQuery {\n  return extend(\n    spec.data ? {data: spec.data} : {},\n    spec.transform ? {transform: spec.transform} : {},\n    spec.width ? {width: spec.width} : {},\n    spec.height ? {height: spec.height} : {},\n    spec.background ? {background: spec.background} : {},\n    spec.padding ? {padding: spec.padding} : {},\n    spec.title ? {title: spec.title} : {},\n    {\n      mark: spec.mark,\n      encodings: keys(spec.encoding).map((channel: Channel) => {\n        let encQ: EncodingQuery = {channel: channel};\n        let channelDef = spec.encoding[channel];\n\n        for (const prop in channelDef) {\n          if (isEncodingTopLevelProperty(prop as Property) && channelDef[prop] !== undefined) {\n            // Currently bin, scale, axis, legend only support boolean, but not null.\n            // Therefore convert null to false.\n            if (contains(['bin', 'scale', 'axis', 'legend'], prop) && channelDef[prop] === null) {\n              encQ[prop] = false;\n            } else {\n              encQ[prop] = channelDef[prop];\n            }\n          }\n        }\n\n        if (isFieldQuery(encQ) && encQ.aggregate === 'count' && !encQ.field) {\n          encQ.field = '*';\n        }\n\n        return encQ;\n      })\n    },\n    spec.config ? {config: spec.config} : {}\n  );\n}\n\nexport function isAggregate(specQ: SpecQuery) {\n  return some(specQ.encodings, (encQ: EncodingQuery) => {\n    return (isFieldQuery(encQ) && !isWildcard(encQ.aggregate) && !!encQ.aggregate) || isEnabledAutoCountQuery(encQ);\n  });\n}\n\n/**\n * @return The Vega-Lite `StackProperties` object that describes the stack\n * configuration of `specQ`. Returns `null` if this is not stackable.\n */\nexport function getVlStack(specQ: SpecQuery): StackProperties {\n  if (!hasRequiredStackProperties(specQ)) {\n    return null;\n  }\n\n  const encoding = toEncoding(specQ.encodings, {schema: null, wildcardMode: 'null'});\n  const mark = specQ.mark as Mark;\n\n  return stack(mark, encoding, undefined, {disallowNonLinearStack: true});\n}\n\n/**\n * @return The `StackOffset` specified in `specQ`, `undefined` if none\n * is specified.\n */\nexport function getStackOffset(specQ: SpecQuery): StackOffset {\n  for (const encQ of specQ.encodings) {\n    if (encQ[Property.STACK] !== undefined && !isWildcard(encQ[Property.STACK])) {\n      return encQ[Property.STACK];\n    }\n  }\n  return undefined;\n}\n\n/**\n * @return The `Channel` in which `stack` is specified in `specQ`, or\n * `null` if none is specified.\n */\nexport function getStackChannel(specQ: SpecQuery): Channel {\n  for (const encQ of specQ.encodings) {\n    if (encQ[Property.STACK] !== undefined && !isWildcard(encQ.channel)) {\n      return encQ.channel;\n    }\n  }\n  return null;\n}\n\n/**\n * Returns true iff the given SpecQuery has the properties defined\n * to be a potential Stack spec.\n * @param specQ The SpecQuery in question.\n */\nexport function hasRequiredStackProperties(specQ: SpecQuery) {\n  // TODO(haldenl): make this leaner, a lot of encQ properties aren't required for stack.\n  // TODO(haldenl): check mark, then encodings\n  if (isWildcard(specQ.mark)) {\n    return false;\n  }\n\n  const requiredEncodingProps = [\n    Property.STACK,\n    Property.CHANNEL,\n    Property.MARK,\n    Property.FIELD,\n    Property.AGGREGATE,\n    Property.AUTOCOUNT,\n    Property.SCALE,\n    getEncodingNestedProp('scale', 'type'),\n    Property.TYPE\n  ];\n  const exclude = toMap(without(ALL_ENCODING_PROPS, requiredEncodingProps));\n\n  const encodings = specQ.encodings.filter(encQ => !isDisabledAutoCountQuery(encQ));\n  for (const encQ of encodings) {\n    if (objectContainsWildcard(encQ, {exclude: exclude})) {\n      return false;\n    }\n  }\n  return true;\n}\n\n/**\n * Returns true iff the given object does not contain a nested wildcard.\n * @param obj The object in question.\n * @param opt With optional `exclude` property, which defines properties to\n * ignore when testing for wildcards.\n */\n// TODO(haldenl): rename to objectHasWildcard, rename prop to obj\nfunction objectContainsWildcard(obj: any, opt: {exclude?: {[key: string]: 1}} = {}) {\n  if (!isObject(obj)) {\n    return false;\n  }\n\n  for (const childProp in obj) {\n    if (obj.hasOwnProperty(childProp)) {\n      const wildcard = isWildcard(obj[childProp]);\n      if ((wildcard && (!opt.exclude || !opt.exclude[childProp])) || objectContainsWildcard(obj[childProp], opt)) {\n        return true;\n      }\n    }\n  }\n  return false;\n}\n\n/**\n * Returns true iff the given `specQ` contains a wildcard.\n * @param specQ The `SpecQuery` in question.\n * @param opt With optional `exclude` property, which defines properties to\n * ignore when testing for wildcards.\n */\nexport function hasWildcard(specQ: SpecQuery, opt: {exclude?: Property[]} = {}) {\n  const exclude = opt.exclude ? toMap(opt.exclude.map(toKey)) : {};\n  if (isWildcard(specQ.mark) && !exclude['mark']) {\n    return true;\n  }\n\n  for (const encQ of specQ.encodings) {\n    if (objectContainsWildcard(encQ, exclude)) {\n      return true;\n    }\n  }\n  return false;\n}\n","import {isString} from 'datalib/src/util';\nimport {isAggregateOp} from 'vega-lite/build/src/aggregate';\nimport {Channel, isChannel} from 'vega-lite/build/src/channel';\nimport {Mark} from 'vega-lite/build/src/mark';\nimport {FacetedUnitSpec} from 'vega-lite/build/src/spec';\nimport {StackProperties} from 'vega-lite/build/src/stack';\nimport {isTimeUnit} from 'vega-lite/build/src/timeunit';\nimport * as TYPE from 'vega-lite/build/src/type';\nimport {getFullName} from 'vega-lite/build/src/type';\nimport {\n  DEFAULT_PROP_PRECEDENCE,\n  EncodingNestedChildProp,\n  getEncodingNestedProp,\n  isEncodingNestedParent,\n  Property,\n  SORT_PROPS,\n  VIEW_PROPS\n} from '../property';\nimport {PropIndex} from '../propindex';\nimport {Dict, isArray, isBoolean, keys} from '../util';\nimport {isShortWildcard, isWildcard, SHORT_WILDCARD} from '../wildcard';\nimport {\n  EncodingQuery,\n  FieldQuery,\n  FieldQueryBase,\n  isAutoCountQuery,\n  isDisabledAutoCountQuery,\n  isEnabledAutoCountQuery,\n  isFieldQuery,\n  isValueQuery\n} from './encoding';\nimport {fromSpec, getVlStack, SpecQuery} from './spec';\n\nexport type Replacer = (s: string) => string;\n\nexport function getReplacerIndex(replaceIndex: PropIndex<Dict<string>>): PropIndex<Replacer> {\n  return replaceIndex.map(r => getReplacer(r));\n}\n\nexport function getReplacer(replace: Dict<string>): Replacer {\n  return (s: string) => {\n    if (replace[s] !== undefined) {\n      return replace[s];\n    }\n    return s;\n  };\n}\n\nexport function value(v: any, replacer: Replacer): any {\n  if (isWildcard(v)) {\n    // Return the enum array if it's a full wildcard, or just return SHORT_WILDCARD for short ones.\n    if (!isShortWildcard(v) && v.enum) {\n      return SHORT_WILDCARD + JSON.stringify(v.enum);\n    } else {\n      return SHORT_WILDCARD;\n    }\n  }\n  if (replacer) {\n    return replacer(v);\n  }\n  return v;\n}\n\nexport function replace(v: any, replacer: Replacer): any {\n  if (replacer) {\n    return replacer(v);\n  }\n  return v;\n}\n\nexport const REPLACE_NONE = new PropIndex<Replacer>();\n\nexport const INCLUDE_ALL: PropIndex<boolean> =\n  // FIXME: remove manual TRANSFORM concat once we really support enumerating transform.\n  []\n    .concat(DEFAULT_PROP_PRECEDENCE, SORT_PROPS, [Property.TRANSFORM, Property.STACK], VIEW_PROPS)\n    .reduce((pi, prop: Property) => pi.set(prop, true), new PropIndex<boolean>());\n\nexport function vlSpec(\n  vlspec: FacetedUnitSpec,\n  include: PropIndex<boolean> = INCLUDE_ALL,\n  replace: PropIndex<Replacer> = REPLACE_NONE\n) {\n  const specQ = fromSpec(vlspec);\n  return spec(specQ, include, replace);\n}\n\nexport const PROPERTY_SUPPORTED_CHANNELS = {\n  axis: {x: true, y: true, row: true, column: true},\n  legend: {color: true, opacity: true, size: true, shape: true},\n  scale: {x: true, y: true, color: true, opacity: true, row: true, column: true, size: true, shape: true},\n  sort: {x: true, y: true, path: true, order: true},\n  stack: {x: true, y: true}\n};\n\n/**\n * Returns a shorthand for a spec query\n * @param specQ a spec query\n * @param include Dict Set listing property types (key) to be included in the shorthand\n * @param replace Dictionary of replace function for values of a particular property type (key)\n */\nexport function spec(\n  specQ: SpecQuery,\n  include: PropIndex<boolean> = INCLUDE_ALL,\n  replace: PropIndex<Replacer> = REPLACE_NONE\n): string {\n  const parts: string[] = [];\n\n  if (include.get(Property.MARK)) {\n    parts.push(value(specQ.mark, replace.get(Property.MARK)));\n  }\n\n  if (specQ.transform && specQ.transform.length > 0) {\n    parts.push('transform:' + JSON.stringify(specQ.transform));\n  }\n\n  let stack: StackProperties;\n  if (include.get(Property.STACK)) {\n    stack = getVlStack(specQ);\n  }\n\n  if (specQ.encodings) {\n    const encodings = specQ.encodings\n      .reduce((encQs, encQ) => {\n        // Exclude encoding mapping with autoCount=false as they are basically disabled.\n        if (!isDisabledAutoCountQuery(encQ)) {\n          let str;\n          if (!!stack && encQ.channel === stack.fieldChannel) {\n            str = encoding({...encQ, stack: stack.offset}, include, replace);\n          } else {\n            str = encoding(encQ, include, replace);\n          }\n          if (str) {\n            // only add if the shorthand isn't an empty string.\n            encQs.push(str);\n          }\n        }\n        return encQs;\n      }, [])\n      .sort() // sort at the end to ignore order\n      .join('|');\n\n    if (encodings) {\n      parts.push(encodings);\n    }\n  }\n\n  for (let viewProp of VIEW_PROPS) {\n    const propString = viewProp.toString();\n    if (include.get(viewProp) && !!specQ[propString]) {\n      const value = specQ[propString];\n      parts.push(`${propString}=${JSON.stringify(value)}`);\n    }\n  }\n\n  return parts.join('|');\n}\n\n/**\n * Returns a shorthand for an encoding query\n * @param encQ an encoding query\n * @param include Dict Set listing property types (key) to be included in the shorthand\n * @param replace Dictionary of replace function for values of a particular property type (key)\n */\nexport function encoding(\n  encQ: EncodingQuery,\n  include: PropIndex<boolean> = INCLUDE_ALL,\n  replace: PropIndex<Replacer> = REPLACE_NONE\n): string {\n  const parts = [];\n  if (include.get(Property.CHANNEL)) {\n    parts.push(value(encQ.channel, replace.get(Property.CHANNEL)));\n  }\n\n  if (isFieldQuery(encQ)) {\n    const fieldDefStr = fieldDef(encQ, include, replace);\n\n    if (fieldDefStr) {\n      parts.push(fieldDefStr);\n    }\n  } else if (isValueQuery(encQ)) {\n    parts.push(encQ.value);\n  } else if (isAutoCountQuery(encQ)) {\n    parts.push('autocount()');\n  }\n\n  return parts.join(':');\n}\n\n/**\n * Returns a field definition shorthand for an encoding query\n * @param encQ an encoding query\n * @param include Dict Set listing property types (key) to be included in the shorthand\n * @param replace Dictionary of replace function for values of a particular property type (key)\n */\nexport function fieldDef(\n  encQ: EncodingQuery,\n  include: PropIndex<boolean> = INCLUDE_ALL,\n  replacer: PropIndex<Replacer> = REPLACE_NONE\n): string {\n  if (include.get(Property.AGGREGATE) && isDisabledAutoCountQuery(encQ)) {\n    return '-';\n  }\n\n  const fn = func(encQ, include, replacer);\n  const props = fieldDefProps(encQ, include, replacer);\n\n  let fieldAndParams;\n  if (isFieldQuery(encQ)) {\n    // field\n    fieldAndParams = include.get('field') ? value(encQ.field, replacer.get('field')) : '...';\n    // type\n    if (include.get(Property.TYPE)) {\n      if (isWildcard(encQ.type)) {\n        fieldAndParams += ',' + value(encQ.type, replacer.get(Property.TYPE));\n      } else {\n        const typeShort = ((encQ.type || TYPE.QUANTITATIVE) + '').substr(0, 1);\n        fieldAndParams += ',' + value(typeShort, replacer.get(Property.TYPE));\n      }\n    }\n    // encoding properties\n    fieldAndParams += props\n      .map(p => {\n        let val = p.value instanceof Array ? '[' + p.value + ']' : p.value;\n        return ',' + p.key + '=' + val;\n      })\n      .join('');\n  } else if (isAutoCountQuery(encQ)) {\n    fieldAndParams = '*,q';\n  }\n\n  if (!fieldAndParams) {\n    return null;\n  }\n  if (fn) {\n    let fnPrefix = isString(fn) ? fn : SHORT_WILDCARD + (keys(fn).length > 0 ? JSON.stringify(fn) : '');\n\n    return fnPrefix + '(' + fieldAndParams + ')';\n  }\n  return fieldAndParams;\n}\n\n/**\n * Return function part of\n */\nfunction func(fieldQ: FieldQuery, include: PropIndex<boolean>, replacer: PropIndex<Replacer>): string | Object {\n  if (include.get(Property.AGGREGATE) && fieldQ.aggregate && !isWildcard(fieldQ.aggregate)) {\n    return replace(fieldQ.aggregate, replacer.get(Property.AGGREGATE));\n  } else if (include.get(Property.AGGREGATE) && isEnabledAutoCountQuery(fieldQ)) {\n    // autoCount is considered a part of aggregate\n    return replace('count', replacer.get(Property.AGGREGATE));\n  } else if (include.get(Property.TIMEUNIT) && fieldQ.timeUnit && !isWildcard(fieldQ.timeUnit)) {\n    return replace(fieldQ.timeUnit, replacer.get(Property.TIMEUNIT));\n  } else if (include.get(Property.BIN) && fieldQ.bin && !isWildcard(fieldQ.bin)) {\n    return 'bin';\n  } else {\n    let fn: any = null;\n    for (const prop of [Property.AGGREGATE, Property.AUTOCOUNT, Property.TIMEUNIT, Property.BIN]) {\n      const val = fieldQ[prop];\n      if (include.get(prop) && fieldQ[prop] && isWildcard(val)) {\n        // assign fnEnumIndex[prop] = array of enum values or just \"?\" if it is SHORT_WILDCARD\n        fn = fn || {};\n        fn[prop] = isShortWildcard(val) ? val : val.enum;\n      }\n    }\n    if (fn && fieldQ.hasFn) {\n      fn.hasFn = true;\n    }\n    return fn;\n  }\n}\n\n/**\n * Return key-value of parameters of field defs\n */\nfunction fieldDefProps(fieldQ: FieldQuery, include: PropIndex<boolean>, replacer: PropIndex<Replacer>) {\n  /** Encoding properties e.g., Scale, Axis, Legend */\n  const props: {key: string; value: boolean | Object}[] = [];\n\n  // Parameters of function such as bin will be just top-level properties\n  if (!isBoolean(fieldQ.bin) && !isShortWildcard(fieldQ.bin)) {\n    const bin = fieldQ.bin;\n    for (const child in bin) {\n      const prop = getEncodingNestedProp('bin', child as EncodingNestedChildProp);\n      if (prop && include.get(prop) && bin[child] !== undefined) {\n        props.push({\n          key: child,\n          value: value(bin[child], replacer.get(prop))\n        });\n      }\n    }\n    // Sort to make sure that parameter are ordered consistently\n    props.sort((a, b) => a.key.localeCompare(b.key));\n  }\n\n  for (const parent of [Property.SCALE, Property.SORT, Property.STACK, Property.AXIS, Property.LEGEND]) {\n    if (!isWildcard(fieldQ.channel) && !PROPERTY_SUPPORTED_CHANNELS[parent][fieldQ.channel as Channel]) {\n      continue;\n    }\n\n    if (include.get(parent) && fieldQ[parent] !== undefined) {\n      const parentValue = fieldQ[parent];\n      if (isBoolean(parentValue) || parentValue === null) {\n        // `scale`, `axis`, `legend` can be false/null.\n        props.push({\n          key: parent + '',\n          value: parentValue || false // return true or false (false if null)\n        });\n      } else if (isString(parentValue)) {\n        // `sort` can be a string (ascending/descending).\n        props.push({\n          key: parent + '',\n          value: replace(JSON.stringify(parentValue), replacer.get(parent))\n        });\n      } else {\n        let nestedPropChildren = [];\n        for (const child in parentValue) {\n          const nestedProp = getEncodingNestedProp(parent, child as EncodingNestedChildProp);\n          if (nestedProp && include.get(nestedProp) && parentValue[child] !== undefined) {\n            nestedPropChildren.push({\n              key: child,\n              value: value(parentValue[child], replacer.get(nestedProp))\n            });\n          }\n        }\n\n        if (nestedPropChildren.length > 0) {\n          const nestedPropObject = nestedPropChildren\n            .sort((a, b) => a.key.localeCompare(b.key))\n            .reduce((o, item) => {\n              o[item.key] = item.value;\n              return o;\n            }, {});\n\n          // Sort to make sure that parameter are ordered consistently\n          props.push({\n            key: parent + '',\n            value: JSON.stringify(nestedPropObject)\n          });\n        }\n      }\n    }\n  }\n  return props;\n}\n\nexport function parse(shorthand: string): SpecQuery {\n  // TODO(https://github.com/uwdata/compassql/issues/259):\n  // Do not split directly, but use an upgraded version of `getClosingBraceIndex()`\n  let splitShorthand = shorthand.split('|');\n\n  let specQ: SpecQuery = {\n    mark: splitShorthand[0] as Mark,\n    encodings: [] as EncodingQuery[]\n  };\n\n  for (let i = 1; i < splitShorthand.length; i++) {\n    let part = splitShorthand[i];\n    const splitPart = splitWithTail(part, ':', 1);\n    const splitPartKey = splitPart[0];\n    const splitPartValue = splitPart[1];\n\n    if (isChannel(splitPartKey) || splitPartKey === '?') {\n      const encQ = shorthandParser.encoding(splitPartKey, splitPartValue);\n      specQ.encodings.push(encQ);\n      continue;\n    }\n\n    if (splitPartKey === 'transform') {\n      specQ.transform = JSON.parse(splitPartValue);\n      continue;\n    }\n  }\n\n  return specQ;\n}\n\n/**\n * Split a string n times into substrings with the specified delimiter and return them as an array.\n * @param str The string to be split\n * @param delim The delimiter string used to separate the string\n * @param number The value used to determine how many times the string is split\n */\nexport function splitWithTail(str: string, delim: string, count: number): string[] {\n  let result = [];\n  let lastIndex = 0;\n\n  for (let i = 0; i < count; i++) {\n    let indexOfDelim = str.indexOf(delim, lastIndex);\n\n    if (indexOfDelim !== -1) {\n      result.push(str.substring(lastIndex, indexOfDelim));\n      lastIndex = indexOfDelim + 1;\n    } else {\n      break;\n    }\n  }\n\n  result.push(str.substr(lastIndex));\n\n  // If the specified count is greater than the number of delimiters that exist in the string,\n  // an empty string will be pushed count minus number of delimiter occurence times.\n  if (result.length !== count + 1) {\n    while (result.length !== count + 1) {\n      result.push('');\n    }\n  }\n\n  return result;\n}\n\nexport namespace shorthandParser {\n  export function encoding(channel: Channel | SHORT_WILDCARD, fieldDefShorthand: string): EncodingQuery {\n    let encQMixins =\n      fieldDefShorthand.indexOf('(') !== -1\n        ? fn(fieldDefShorthand)\n        : rawFieldDef(splitWithTail(fieldDefShorthand, ',', 2));\n    return {\n      channel,\n      ...encQMixins\n    };\n  }\n\n  export function rawFieldDef(fieldDefPart: string[]): FieldQueryBase {\n    const fieldQ: FieldQueryBase = {};\n    fieldQ.field = fieldDefPart[0];\n    fieldQ.type = getFullName(fieldDefPart[1].toUpperCase()) || '?';\n\n    let partParams = fieldDefPart[2];\n    let closingBraceIndex = 0;\n    let i = 0;\n\n    while (i < partParams.length) {\n      let propEqualSignIndex = partParams.indexOf('=', i);\n      let parsedValue;\n      if (propEqualSignIndex !== -1) {\n        let prop = partParams.substring(i, propEqualSignIndex);\n        if (partParams[i + prop.length + 1] === '{') {\n          let openingBraceIndex = i + prop.length + 1;\n          closingBraceIndex = getClosingIndex(openingBraceIndex, partParams, '}');\n          const value = partParams.substring(openingBraceIndex, closingBraceIndex + 1);\n          parsedValue = JSON.parse(value);\n\n          // index after next comma\n          i = closingBraceIndex + 2;\n        } else if (partParams[i + prop.length + 1] === '[') {\n          // find closing square bracket\n          let openingBracketIndex = i + prop.length + 1;\n          let closingBracketIndex = getClosingIndex(openingBracketIndex, partParams, ']');\n          const value = partParams.substring(openingBracketIndex, closingBracketIndex + 1);\n          parsedValue = JSON.parse(value);\n\n          // index after next comma\n          i = closingBracketIndex + 2;\n        } else {\n          let propIndex = i;\n          // Substring until the next comma (or end of the string)\n          let nextCommaIndex = partParams.indexOf(',', i + prop.length);\n          if (nextCommaIndex === -1) {\n            nextCommaIndex = partParams.length;\n          }\n          // index after next comma\n          i = nextCommaIndex + 1;\n\n          parsedValue = JSON.parse(partParams.substring(propIndex + prop.length + 1, nextCommaIndex));\n        }\n\n        if (isEncodingNestedParent(prop)) {\n          fieldQ[prop] = parsedValue;\n        } else {\n          // prop is a property of the aggregation function such as bin\n          fieldQ.bin = fieldQ.bin || {};\n          fieldQ.bin[prop] = parsedValue;\n        }\n      } else {\n        // something is wrong with the format of the partParams\n        // exits loop if don't have then infintie loop\n        break;\n      }\n    }\n    return fieldQ;\n  }\n\n  export function getClosingIndex(openingBraceIndex: number, str: string, closingChar: string): number {\n    for (let i = openingBraceIndex; i < str.length; i++) {\n      if (str[i] === closingChar) {\n        return i;\n      }\n    }\n  }\n\n  export function fn(fieldDefShorthand: string): FieldQueryBase {\n    const fieldQ: FieldQueryBase = {};\n    // Aggregate, Bin, TimeUnit as wildcard case\n    if (fieldDefShorthand[0] === '?') {\n      let closingBraceIndex = getClosingIndex(1, fieldDefShorthand, '}');\n\n      let fnEnumIndex = JSON.parse(fieldDefShorthand.substring(1, closingBraceIndex + 1));\n\n      for (let encodingProperty in fnEnumIndex) {\n        if (isArray(fnEnumIndex[encodingProperty])) {\n          fieldQ[encodingProperty] = {enum: fnEnumIndex[encodingProperty]};\n        } else {\n          // Definitely a `SHORT_WILDCARD`\n          fieldQ[encodingProperty] = fnEnumIndex[encodingProperty];\n        }\n      }\n\n      return {\n        ...fieldQ,\n        ...rawFieldDef(\n          splitWithTail(fieldDefShorthand.substring(closingBraceIndex + 2, fieldDefShorthand.length - 1), ',', 2)\n        )\n      };\n    } else {\n      let func = fieldDefShorthand.substring(0, fieldDefShorthand.indexOf('('));\n      let insideFn = fieldDefShorthand.substring(func.length + 1, fieldDefShorthand.length - 1);\n      let insideFnParts = splitWithTail(insideFn, ',', 2);\n\n      if (isAggregateOp(func)) {\n        return {\n          aggregate: func,\n          ...rawFieldDef(insideFnParts)\n        };\n      } else if (isTimeUnit(func)) {\n        return {\n          timeUnit: func,\n          ...rawFieldDef(insideFnParts)\n        };\n      } else if (func === 'bin') {\n        return {\n          bin: {},\n          ...rawFieldDef(insideFnParts)\n        };\n      }\n    }\n  }\n}\n","import {isObject} from 'datalib/src/util';\nimport {AggregateOp} from 'vega';\nimport {Axis} from 'vega-lite/build/src/axis';\nimport {BinParams} from 'vega-lite/build/src/bin';\nimport {Channel} from 'vega-lite/build/src/channel';\nimport * as vlChannelDef from 'vega-lite/build/src/channeldef';\nimport {ValueDef} from 'vega-lite/build/src/channeldef';\nimport {scaleType as compileScaleType} from 'vega-lite/build/src/compile/scale/type';\nimport {Encoding} from 'vega-lite/build/src/encoding';\nimport {Legend} from 'vega-lite/build/src/legend';\nimport {Mark} from 'vega-lite/build/src/mark';\nimport {Scale} from 'vega-lite/build/src/scale';\nimport {EncodingSortField, SortOrder} from 'vega-lite/build/src/sort';\nimport {StackOffset} from 'vega-lite/build/src/stack';\nimport {TimeUnit} from 'vega-lite/build/src/timeunit';\nimport * as TYPE from 'vega-lite/build/src/type';\nimport {Type as VLType} from 'vega-lite/build/src/type';\nimport {FlatProp, isEncodingNestedParent, Property} from '../property';\nimport {Schema} from '../schema';\nimport {isWildcard, SHORT_WILDCARD, Wildcard, WildcardProperty} from '../wildcard';\nimport {ExpandedType} from './expandedtype';\nimport {PROPERTY_SUPPORTED_CHANNELS} from './shorthand';\n\nexport type EncodingQuery = FieldQuery | ValueQuery | AutoCountQuery;\n\nexport interface EncodingQueryBase {\n  channel: WildcardProperty<Channel>;\n\n  description?: string;\n}\n\nexport interface ValueQuery extends EncodingQueryBase {\n  value: WildcardProperty<boolean | number | string>;\n}\n\nexport function isValueQuery(encQ: EncodingQuery): encQ is ValueQuery {\n  return encQ !== null && encQ !== undefined && encQ['value'] !== undefined;\n}\n\nexport function isFieldQuery(encQ: EncodingQuery): encQ is FieldQuery {\n  return encQ !== null && encQ !== undefined && (encQ['field'] || encQ['aggregate'] === 'count');\n}\n\nexport function isAutoCountQuery(encQ: EncodingQuery): encQ is AutoCountQuery {\n  return encQ !== null && encQ !== undefined && 'autoCount' in encQ;\n}\n\nexport function isDisabledAutoCountQuery(encQ: EncodingQuery) {\n  return isAutoCountQuery(encQ) && encQ.autoCount === false;\n}\n\nexport function isEnabledAutoCountQuery(encQ: EncodingQuery) {\n  return isAutoCountQuery(encQ) && encQ.autoCount === true;\n}\n\n/**\n * A special encoding query that gets added internally if the `config.autoCount` flag is on. See SpecQueryModel.build for its generation.\n *\n * __Note:__ this type of query should not be specified by users.\n */\nexport interface AutoCountQuery extends EncodingQueryBase {\n  /**\n   * A count function that gets added internally if the config.autoCount flag in on.\n   * This allows us to add one extra encoding mapping if needed when the query produces\n   * plot that only have discrete fields.\n   * In such cases, adding count make the output plots way more meaningful.\n   */\n  autoCount: WildcardProperty<boolean>;\n  type: 'quantitative';\n}\n\nexport interface FieldQueryBase {\n  // FieldDef\n  aggregate?: WildcardProperty<AggregateOp>;\n  timeUnit?: WildcardProperty<TimeUnit>;\n\n  /**\n   * Special flag for enforcing that the field should have a fuction (one of timeUnit, bin, or aggregate).\n   *\n   * For example, if you enumerate both bin and aggregate then you need `undefined` for both.\n   *\n   * ```\n   * {aggregate: {enum: [undefined, 'mean', 'sum']}, bin: {enum: [false, true]}}\n   * ```\n   *\n   * This would enumerate a fieldDef with \"mean\", \"sum\", bin:true, and no function at all.\n   * If you want only \"mean\", \"sum\", bin:true, then use `hasFn: true`\n   *\n   * ```\n   * {aggregate: {enum: [undefined, 'mean', 'sum']}, bin: {enum: [false, true]}, hasFn: true}\n   * ```\n   */\n  hasFn?: boolean;\n\n  bin?: boolean | BinQuery | SHORT_WILDCARD;\n  scale?: boolean | ScaleQuery | SHORT_WILDCARD;\n\n  sort?: SortOrder | EncodingSortField<string>;\n  stack?: StackOffset | SHORT_WILDCARD;\n\n  field?: WildcardProperty<string>;\n  type?: WildcardProperty<ExpandedType>;\n\n  axis?: boolean | AxisQuery | SHORT_WILDCARD;\n  legend?: boolean | LegendQuery | SHORT_WILDCARD;\n\n  format?: string;\n}\n\nexport type FieldQuery = EncodingQueryBase & FieldQueryBase;\n\n// Using Mapped Type from TS2.1 to declare query for an object without nested property\n// https://www.typescriptlang.org/docs/handbook/release-notes/typescript-2-1.html#mapped-types\nexport type FlatQuery<T> = {[P in keyof T]: WildcardProperty<T[P]>};\n\nexport type FlatQueryWithEnableFlag<T> = (Wildcard<boolean> | {}) & FlatQuery<T>;\n\nexport type BinQuery = FlatQueryWithEnableFlag<BinParams>;\nexport type ScaleQuery = FlatQueryWithEnableFlag<Scale>;\nexport type AxisQuery = FlatQueryWithEnableFlag<Axis>;\nexport type LegendQuery = FlatQueryWithEnableFlag<Legend>;\n\nconst DEFAULT_PROPS = [\n  Property.AGGREGATE,\n  Property.BIN,\n  Property.TIMEUNIT,\n  Property.FIELD,\n  Property.TYPE,\n  Property.SCALE,\n  Property.SORT,\n  Property.AXIS,\n  Property.LEGEND,\n  Property.STACK,\n  Property.FORMAT\n];\n\nexport interface ConversionParams {\n  schema?: Schema;\n  props?: FlatProp[];\n  wildcardMode?: 'skip' | 'null';\n}\n\nexport function toEncoding(encQs: EncodingQuery[], params: ConversionParams): Encoding<string> {\n  const {wildcardMode = 'skip'} = params;\n  let encoding: Encoding<string> = {};\n\n  for (const encQ of encQs) {\n    if (isDisabledAutoCountQuery(encQ)) {\n      continue; // Do not include this in the output.\n    }\n\n    const {channel} = encQ;\n\n    // if channel is a wildcard, return null\n    if (isWildcard(channel)) {\n      throw new Error('Cannot convert wildcard channel to a fixed channel');\n    }\n    const channelDef = isValueQuery(encQ) ? toValueDef(encQ) : toFieldDef(encQ, params);\n\n    if (channelDef === null) {\n      if (params.wildcardMode === 'null') {\n        // contains invalid property (e.g., wildcard, thus cannot return a proper spec.)\n        return null;\n      }\n      continue;\n    }\n    // Otherwise, we can set the channelDef\n    encoding[channel] = channelDef;\n  }\n  return encoding;\n}\n\nexport function toValueDef(valueQ: ValueQuery): ValueDef {\n  const {value} = valueQ;\n  if (isWildcard(value)) {\n    return null;\n  }\n  return {value};\n}\n\nexport function toFieldDef(\n  encQ: FieldQuery | AutoCountQuery,\n  params: ConversionParams = {}\n): vlChannelDef.TypedFieldDef<string> {\n  const {props = DEFAULT_PROPS, schema, wildcardMode = 'skip'} = params;\n\n  if (isFieldQuery(encQ)) {\n    const fieldDef = {} as vlChannelDef.TypedFieldDef<string>;\n    for (const prop of props) {\n      let encodingProperty = encQ[prop];\n      if (isWildcard(encodingProperty)) {\n        if (wildcardMode === 'skip') continue;\n        return null;\n      }\n\n      if (encodingProperty !== undefined) {\n        // if the channel supports this prop\n        const isSupportedByChannel =\n          !PROPERTY_SUPPORTED_CHANNELS[prop] || PROPERTY_SUPPORTED_CHANNELS[prop][encQ.channel as Channel];\n        if (!isSupportedByChannel) {\n          continue;\n        }\n\n        if (isEncodingNestedParent(prop) && isObject(encodingProperty)) {\n          encodingProperty = {...encodingProperty}; // Make a shallow copy first\n          for (const childProp in encodingProperty) {\n            // ensure nested properties are not wildcard before assigning to field def\n            if (isWildcard(encodingProperty[childProp])) {\n              if (wildcardMode === 'null') {\n                return null;\n              }\n              delete encodingProperty[childProp]; // skip\n            }\n          }\n        }\n\n        if (prop === 'bin' && encodingProperty === false) {\n          continue;\n        } else if (prop === 'type' && encodingProperty === 'key') {\n          fieldDef.type = 'nominal';\n        } else {\n          fieldDef[prop] = encodingProperty;\n        }\n      }\n\n      if (prop === Property.SCALE && schema && encQ.type === TYPE.ORDINAL) {\n        const scale = encQ.scale;\n        const {ordinalDomain} = schema.fieldSchema(encQ.field as string);\n\n        if (scale !== null && ordinalDomain) {\n          fieldDef[Property.SCALE] = {\n            domain: ordinalDomain,\n            // explicitly specfied domain property should override ordinalDomain\n            ...(isObject(scale) ? scale : {})\n          };\n        }\n      }\n    }\n    return fieldDef;\n  } else {\n    if (encQ.autoCount === false) {\n      throw new Error(`Cannot convert {autoCount: false} into a field def`);\n    } else {\n      return {\n        aggregate: 'count',\n        field: '*',\n        type: 'quantitative'\n      };\n    }\n  }\n}\n\n/**\n * Is a field query continuous field?\n * This method is applicable only for fieldQuery without wildcard\n */\nexport function isContinuous(encQ: EncodingQuery) {\n  if (isFieldQuery(encQ)) {\n    return vlChannelDef.isContinuous(toFieldDef(encQ, {props: ['bin', 'timeUnit', 'field', 'type']}));\n  }\n  return isAutoCountQuery(encQ);\n}\n\nexport function isMeasure(encQ: EncodingQuery) {\n  if (isFieldQuery(encQ)) {\n    return !isDimension(encQ) && encQ.type !== 'temporal';\n  }\n  return isAutoCountQuery(encQ);\n}\n\n/**\n * Is a field query discrete field?\n * This method is applicable only for fieldQuery without wildcard\n */\nexport function isDimension(encQ: EncodingQuery) {\n  if (isFieldQuery(encQ)) {\n    const fieldDef = toFieldDef(encQ, {props: ['bin', 'timeUnit', 'type']});\n    return vlChannelDef.isDiscrete(fieldDef) || !!fieldDef.timeUnit;\n  }\n  return false;\n}\n\n/**\n *  Returns the true scale type of an encoding.\n *  @returns {ScaleType} If the scale type was not specified, it is inferred from the encoding's TYPE.\n *  @returns {undefined} If the scale type was not specified and Type (or TimeUnit if applicable) is a Wildcard, there is no clear scale type\n */\n\nexport function scaleType(fieldQ: FieldQuery) {\n  const scale: ScaleQuery = fieldQ.scale === true || fieldQ.scale === SHORT_WILDCARD ? {} : fieldQ.scale || {};\n\n  const {type, channel, timeUnit, bin} = fieldQ;\n\n  // HACK: All of markType, and scaleConfig only affect\n  // sub-type of ordinal to quantitative scales (point or band)\n  // Currently, most of scaleType usage in CompassQL doesn't care about this subtle difference.\n  // Thus, instead of making this method requiring the global mark,\n  // we will just call it with mark = undefined .\n  // Thus, currently, we will always get a point scale unless a CompassQuery specifies band.\n  const markType: Mark = undefined;\n\n  if (isWildcard(scale.type) || isWildcard(type) || isWildcard(channel) || isWildcard(bin)) {\n    return undefined;\n  }\n\n  // If scale type is specified, then use scale.type\n  if (scale.type) {\n    return scale.type;\n  }\n\n  // if type is fixed and it's not temporal, we can ignore time unit.\n  if (type === 'temporal' && isWildcard(timeUnit)) {\n    return undefined;\n  }\n\n  // if type is fixed and it's not quantitative, we can ignore bin\n  if (type === 'quantitative' && isWildcard(bin)) {\n    return undefined;\n  }\n\n  let vegaLiteType: VLType = type === ExpandedType.KEY ? 'nominal' : type;\n\n  const fieldDef = {\n    type: vegaLiteType,\n    timeUnit: timeUnit as TimeUnit,\n    bin: bin as BinParams\n  };\n  return compileScaleType({type: scale.type}, channel, fieldDef, markType);\n}\n","(function (global, factory) {\n  typeof exports === 'object' && typeof module !== 'undefined' ? factory(exports) :\n  typeof define === 'function' && define.amd ? define('d3-time', ['exports'], factory) :\n  factory((global.d3_time = {}));\n}(this, function (exports) { 'use strict';\n\n  var t0 = new Date;\n  var t1 = new Date;\n  function newInterval(floori, offseti, count, field) {\n\n    function interval(date) {\n      return floori(date = new Date(+date)), date;\n    }\n\n    interval.floor = interval;\n\n    interval.round = function(date) {\n      var d0 = new Date(+date),\n          d1 = new Date(date - 1);\n      floori(d0), floori(d1), offseti(d1, 1);\n      return date - d0 < d1 - date ? d0 : d1;\n    };\n\n    interval.ceil = function(date) {\n      return floori(date = new Date(date - 1)), offseti(date, 1), date;\n    };\n\n    interval.offset = function(date, step) {\n      return offseti(date = new Date(+date), step == null ? 1 : Math.floor(step)), date;\n    };\n\n    interval.range = function(start, stop, step) {\n      var range = [];\n      start = new Date(start - 1);\n      stop = new Date(+stop);\n      step = step == null ? 1 : Math.floor(step);\n      if (!(start < stop) || !(step > 0)) return range; // also handles Invalid Date\n      offseti(start, 1), floori(start);\n      if (start < stop) range.push(new Date(+start));\n      while (offseti(start, step), floori(start), start < stop) range.push(new Date(+start));\n      return range;\n    };\n\n    interval.filter = function(test) {\n      return newInterval(function(date) {\n        while (floori(date), !test(date)) date.setTime(date - 1);\n      }, function(date, step) {\n        while (--step >= 0) while (offseti(date, 1), !test(date));\n      });\n    };\n\n    if (count) {\n      interval.count = function(start, end) {\n        t0.setTime(+start), t1.setTime(+end);\n        floori(t0), floori(t1);\n        return Math.floor(count(t0, t1));\n      };\n\n      interval.every = function(step) {\n        step = Math.floor(step);\n        return !isFinite(step) || !(step > 0) ? null\n            : !(step > 1) ? interval\n            : interval.filter(field\n                ? function(d) { return field(d) % step === 0; }\n                : function(d) { return interval.count(0, d) % step === 0; });\n      };\n    }\n\n    return interval;\n  };\n\n  var millisecond = newInterval(function() {\n    // noop\n  }, function(date, step) {\n    date.setTime(+date + step);\n  }, function(start, end) {\n    return end - start;\n  });\n\n  // An optimized implementation for this simple case.\n  millisecond.every = function(k) {\n    k = Math.floor(k);\n    if (!isFinite(k) || !(k > 0)) return null;\n    if (!(k > 1)) return millisecond;\n    return newInterval(function(date) {\n      date.setTime(Math.floor(date / k) * k);\n    }, function(date, step) {\n      date.setTime(+date + step * k);\n    }, function(start, end) {\n      return (end - start) / k;\n    });\n  };\n\n  var second = newInterval(function(date) {\n    date.setMilliseconds(0);\n  }, function(date, step) {\n    date.setTime(+date + step * 1e3);\n  }, function(start, end) {\n    return (end - start) / 1e3;\n  }, function(date) {\n    return date.getSeconds();\n  });\n\n  var minute = newInterval(function(date) {\n    date.setSeconds(0, 0);\n  }, function(date, step) {\n    date.setTime(+date + step * 6e4);\n  }, function(start, end) {\n    return (end - start) / 6e4;\n  }, function(date) {\n    return date.getMinutes();\n  });\n\n  var hour = newInterval(function(date) {\n    date.setMinutes(0, 0, 0);\n  }, function(date, step) {\n    date.setTime(+date + step * 36e5);\n  }, function(start, end) {\n    return (end - start) / 36e5;\n  }, function(date) {\n    return date.getHours();\n  });\n\n  var day = newInterval(function(date) {\n    date.setHours(0, 0, 0, 0);\n  }, function(date, step) {\n    date.setDate(date.getDate() + step);\n  }, function(start, end) {\n    return (end - start - (end.getTimezoneOffset() - start.getTimezoneOffset()) * 6e4) / 864e5;\n  }, function(date) {\n    return date.getDate() - 1;\n  });\n\n  function weekday(i) {\n    return newInterval(function(date) {\n      date.setHours(0, 0, 0, 0);\n      date.setDate(date.getDate() - (date.getDay() + 7 - i) % 7);\n    }, function(date, step) {\n      date.setDate(date.getDate() + step * 7);\n    }, function(start, end) {\n      return (end - start - (end.getTimezoneOffset() - start.getTimezoneOffset()) * 6e4) / 6048e5;\n    });\n  }\n\n  var sunday = weekday(0);\n  var monday = weekday(1);\n  var tuesday = weekday(2);\n  var wednesday = weekday(3);\n  var thursday = weekday(4);\n  var friday = weekday(5);\n  var saturday = weekday(6);\n\n  var month = newInterval(function(date) {\n    date.setHours(0, 0, 0, 0);\n    date.setDate(1);\n  }, function(date, step) {\n    date.setMonth(date.getMonth() + step);\n  }, function(start, end) {\n    return end.getMonth() - start.getMonth() + (end.getFullYear() - start.getFullYear()) * 12;\n  }, function(date) {\n    return date.getMonth();\n  });\n\n  var year = newInterval(function(date) {\n    date.setHours(0, 0, 0, 0);\n    date.setMonth(0, 1);\n  }, function(date, step) {\n    date.setFullYear(date.getFullYear() + step);\n  }, function(start, end) {\n    return end.getFullYear() - start.getFullYear();\n  }, function(date) {\n    return date.getFullYear();\n  });\n\n  var utcSecond = newInterval(function(date) {\n    date.setUTCMilliseconds(0);\n  }, function(date, step) {\n    date.setTime(+date + step * 1e3);\n  }, function(start, end) {\n    return (end - start) / 1e3;\n  }, function(date) {\n    return date.getUTCSeconds();\n  });\n\n  var utcMinute = newInterval(function(date) {\n    date.setUTCSeconds(0, 0);\n  }, function(date, step) {\n    date.setTime(+date + step * 6e4);\n  }, function(start, end) {\n    return (end - start) / 6e4;\n  }, function(date) {\n    return date.getUTCMinutes();\n  });\n\n  var utcHour = newInterval(function(date) {\n    date.setUTCMinutes(0, 0, 0);\n  }, function(date, step) {\n    date.setTime(+date + step * 36e5);\n  }, function(start, end) {\n    return (end - start) / 36e5;\n  }, function(date) {\n    return date.getUTCHours();\n  });\n\n  var utcDay = newInterval(function(date) {\n    date.setUTCHours(0, 0, 0, 0);\n  }, function(date, step) {\n    date.setUTCDate(date.getUTCDate() + step);\n  }, function(start, end) {\n    return (end - start) / 864e5;\n  }, function(date) {\n    return date.getUTCDate() - 1;\n  });\n\n  function utcWeekday(i) {\n    return newInterval(function(date) {\n      date.setUTCHours(0, 0, 0, 0);\n      date.setUTCDate(date.getUTCDate() - (date.getUTCDay() + 7 - i) % 7);\n    }, function(date, step) {\n      date.setUTCDate(date.getUTCDate() + step * 7);\n    }, function(start, end) {\n      return (end - start) / 6048e5;\n    });\n  }\n\n  var utcSunday = utcWeekday(0);\n  var utcMonday = utcWeekday(1);\n  var utcTuesday = utcWeekday(2);\n  var utcWednesday = utcWeekday(3);\n  var utcThursday = utcWeekday(4);\n  var utcFriday = utcWeekday(5);\n  var utcSaturday = utcWeekday(6);\n\n  var utcMonth = newInterval(function(date) {\n    date.setUTCHours(0, 0, 0, 0);\n    date.setUTCDate(1);\n  }, function(date, step) {\n    date.setUTCMonth(date.getUTCMonth() + step);\n  }, function(start, end) {\n    return end.getUTCMonth() - start.getUTCMonth() + (end.getUTCFullYear() - start.getUTCFullYear()) * 12;\n  }, function(date) {\n    return date.getUTCMonth();\n  });\n\n  var utcYear = newInterval(function(date) {\n    date.setUTCHours(0, 0, 0, 0);\n    date.setUTCMonth(0, 1);\n  }, function(date, step) {\n    date.setUTCFullYear(date.getUTCFullYear() + step);\n  }, function(start, end) {\n    return end.getUTCFullYear() - start.getUTCFullYear();\n  }, function(date) {\n    return date.getUTCFullYear();\n  });\n\n  var milliseconds = millisecond.range;\n  var seconds = second.range;\n  var minutes = minute.range;\n  var hours = hour.range;\n  var days = day.range;\n  var sundays = sunday.range;\n  var mondays = monday.range;\n  var tuesdays = tuesday.range;\n  var wednesdays = wednesday.range;\n  var thursdays = thursday.range;\n  var fridays = friday.range;\n  var saturdays = saturday.range;\n  var weeks = sunday.range;\n  var months = month.range;\n  var years = year.range;\n\n  var utcMillisecond = millisecond;\n  var utcMilliseconds = milliseconds;\n  var utcSeconds = utcSecond.range;\n  var utcMinutes = utcMinute.range;\n  var utcHours = utcHour.range;\n  var utcDays = utcDay.range;\n  var utcSundays = utcSunday.range;\n  var utcMondays = utcMonday.range;\n  var utcTuesdays = utcTuesday.range;\n  var utcWednesdays = utcWednesday.range;\n  var utcThursdays = utcThursday.range;\n  var utcFridays = utcFriday.range;\n  var utcSaturdays = utcSaturday.range;\n  var utcWeeks = utcSunday.range;\n  var utcMonths = utcMonth.range;\n  var utcYears = utcYear.range;\n\n  var version = \"0.1.1\";\n\n  exports.version = version;\n  exports.milliseconds = milliseconds;\n  exports.seconds = seconds;\n  exports.minutes = minutes;\n  exports.hours = hours;\n  exports.days = days;\n  exports.sundays = sundays;\n  exports.mondays = mondays;\n  exports.tuesdays = tuesdays;\n  exports.wednesdays = wednesdays;\n  exports.thursdays = thursdays;\n  exports.fridays = fridays;\n  exports.saturdays = saturdays;\n  exports.weeks = weeks;\n  exports.months = months;\n  exports.years = years;\n  exports.utcMillisecond = utcMillisecond;\n  exports.utcMilliseconds = utcMilliseconds;\n  exports.utcSeconds = utcSeconds;\n  exports.utcMinutes = utcMinutes;\n  exports.utcHours = utcHours;\n  exports.utcDays = utcDays;\n  exports.utcSundays = utcSundays;\n  exports.utcMondays = utcMondays;\n  exports.utcTuesdays = utcTuesdays;\n  exports.utcWednesdays = utcWednesdays;\n  exports.utcThursdays = utcThursdays;\n  exports.utcFridays = utcFridays;\n  exports.utcSaturdays = utcSaturdays;\n  exports.utcWeeks = utcWeeks;\n  exports.utcMonths = utcMonths;\n  exports.utcYears = utcYears;\n  exports.millisecond = millisecond;\n  exports.second = second;\n  exports.minute = minute;\n  exports.hour = hour;\n  exports.day = day;\n  exports.sunday = sunday;\n  exports.monday = monday;\n  exports.tuesday = tuesday;\n  exports.wednesday = wednesday;\n  exports.thursday = thursday;\n  exports.friday = friday;\n  exports.saturday = saturday;\n  exports.week = sunday;\n  exports.month = month;\n  exports.year = year;\n  exports.utcSecond = utcSecond;\n  exports.utcMinute = utcMinute;\n  exports.utcHour = utcHour;\n  exports.utcDay = utcDay;\n  exports.utcSunday = utcSunday;\n  exports.utcMonday = utcMonday;\n  exports.utcTuesday = utcTuesday;\n  exports.utcWednesday = utcWednesday;\n  exports.utcThursday = utcThursday;\n  exports.utcFriday = utcFriday;\n  exports.utcSaturday = utcSaturday;\n  exports.utcWeek = utcSunday;\n  exports.utcMonth = utcMonth;\n  exports.utcYear = utcYear;\n  exports.interval = newInterval;\n\n}));","var d3_time = require('d3-time');\n\nvar tempDate = new Date(),\n    baseDate = new Date(0, 0, 1).setFullYear(0), // Jan 1, 0 AD\n    utcBaseDate = new Date(Date.UTC(0, 0, 1)).setUTCFullYear(0);\n\nfunction date(d) {\n  return (tempDate.setTime(+d), tempDate);\n}\n\n// create a time unit entry\nfunction entry(type, date, unit, step, min, max) {\n  var e = {\n    type: type,\n    date: date,\n    unit: unit\n  };\n  if (step) {\n    e.step = step;\n  } else {\n    e.minstep = 1;\n  }\n  if (min != null) e.min = min;\n  if (max != null) e.max = max;\n  return e;\n}\n\nfunction create(type, unit, base, step, min, max) {\n  return entry(type,\n    function(d) { return unit.offset(base, d); },\n    function(d) { return unit.count(base, d); },\n    step, min, max);\n}\n\nvar locale = [\n  create('second', d3_time.second, baseDate),\n  create('minute', d3_time.minute, baseDate),\n  create('hour',   d3_time.hour,   baseDate),\n  create('day',    d3_time.day,    baseDate, [1, 7]),\n  create('month',  d3_time.month,  baseDate, [1, 3, 6]),\n  create('year',   d3_time.year,   baseDate),\n\n  // periodic units\n  entry('seconds',\n    function(d) { return new Date(1970, 0, 1, 0, 0, d); },\n    function(d) { return date(d).getSeconds(); },\n    null, 0, 59\n  ),\n  entry('minutes',\n    function(d) { return new Date(1970, 0, 1, 0, d); },\n    function(d) { return date(d).getMinutes(); },\n    null, 0, 59\n  ),\n  entry('hours',\n    function(d) { return new Date(1970, 0, 1, d); },\n    function(d) { return date(d).getHours(); },\n    null, 0, 23\n  ),\n  entry('weekdays',\n    function(d) { return new Date(1970, 0, 4+d); },\n    function(d) { return date(d).getDay(); },\n    [1], 0, 6\n  ),\n  entry('dates',\n    function(d) { return new Date(1970, 0, d); },\n    function(d) { return date(d).getDate(); },\n    [1], 1, 31\n  ),\n  entry('months',\n    function(d) { return new Date(1970, d % 12, 1); },\n    function(d) { return date(d).getMonth(); },\n    [1], 0, 11\n  )\n];\n\nvar utc = [\n  create('second', d3_time.utcSecond, utcBaseDate),\n  create('minute', d3_time.utcMinute, utcBaseDate),\n  create('hour',   d3_time.utcHour,   utcBaseDate),\n  create('day',    d3_time.utcDay,    utcBaseDate, [1, 7]),\n  create('month',  d3_time.utcMonth,  utcBaseDate, [1, 3, 6]),\n  create('year',   d3_time.utcYear,   utcBaseDate),\n\n  // periodic units\n  entry('seconds',\n    function(d) { return new Date(Date.UTC(1970, 0, 1, 0, 0, d)); },\n    function(d) { return date(d).getUTCSeconds(); },\n    null, 0, 59\n  ),\n  entry('minutes',\n    function(d) { return new Date(Date.UTC(1970, 0, 1, 0, d)); },\n    function(d) { return date(d).getUTCMinutes(); },\n    null, 0, 59\n  ),\n  entry('hours',\n    function(d) { return new Date(Date.UTC(1970, 0, 1, d)); },\n    function(d) { return date(d).getUTCHours(); },\n    null, 0, 23\n  ),\n  entry('weekdays',\n    function(d) { return new Date(Date.UTC(1970, 0, 4+d)); },\n    function(d) { return date(d).getUTCDay(); },\n    [1], 0, 6\n  ),\n  entry('dates',\n    function(d) { return new Date(Date.UTC(1970, 0, d)); },\n    function(d) { return date(d).getUTCDate(); },\n    [1], 1, 31\n  ),\n  entry('months',\n    function(d) { return new Date(Date.UTC(1970, d % 12, 1)); },\n    function(d) { return date(d).getUTCMonth(); },\n    [1], 0, 11\n  )\n];\n\nvar STEPS = [\n  [31536e6, 5],  // 1-year\n  [7776e6, 4],   // 3-month\n  [2592e6, 4],   // 1-month\n  [12096e5, 3],  // 2-week\n  [6048e5, 3],   // 1-week\n  [1728e5, 3],   // 2-day\n  [864e5, 3],    // 1-day\n  [432e5, 2],    // 12-hour\n  [216e5, 2],    // 6-hour\n  [108e5, 2],    // 3-hour\n  [36e5, 2],     // 1-hour\n  [18e5, 1],     // 30-minute\n  [9e5, 1],      // 15-minute\n  [3e5, 1],      // 5-minute\n  [6e4, 1],      // 1-minute\n  [3e4, 0],      // 30-second\n  [15e3, 0],     // 15-second\n  [5e3, 0],      // 5-second\n  [1e3, 0]       // 1-second\n];\n\nfunction find(units, span, minb, maxb) {\n  var step = STEPS[0], i, n, bins;\n\n  for (i=1, n=STEPS.length; i<n; ++i) {\n    step = STEPS[i];\n    if (span > step[0]) {\n      bins = span / step[0];\n      if (bins > maxb) {\n        return units[STEPS[i-1][1]];\n      }\n      if (bins >= minb) {\n        return units[step[1]];\n      }\n    }\n  }\n  return units[STEPS[n-1][1]];\n}\n\nfunction toUnitMap(units) {\n  var map = {}, i, n;\n  for (i=0, n=units.length; i<n; ++i) {\n    map[units[i].type] = units[i];\n  }\n  map.find = function(span, minb, maxb) {\n    return find(units, span, minb, maxb);\n  };\n  return map;\n}\n\nmodule.exports = toUnitMap(locale);\nmodule.exports.utc = toUnitMap(utc);","var util = require('../util'),\n    time = require('../time'),\n    EPSILON = 1e-15;\n\nfunction bins(opt) {\n  if (!opt) { throw Error(\"Missing binning options.\"); }\n\n  // determine range\n  var maxb = opt.maxbins || 15,\n      base = opt.base || 10,\n      logb = Math.log(base),\n      div = opt.div || [5, 2],\n      min = opt.min,\n      max = opt.max,\n      span = max - min,\n      step, level, minstep, precision, v, i, eps;\n\n  if (opt.step) {\n    // if step size is explicitly given, use that\n    step = opt.step;\n  } else if (opt.steps) {\n    // if provided, limit choice to acceptable step sizes\n    step = opt.steps[Math.min(\n      opt.steps.length - 1,\n      bisect(opt.steps, span/maxb, 0, opt.steps.length)\n    )];\n  } else {\n    // else use span to determine step size\n    level = Math.ceil(Math.log(maxb) / logb);\n    minstep = opt.minstep || 0;\n    step = Math.max(\n      minstep,\n      Math.pow(base, Math.round(Math.log(span) / logb) - level)\n    );\n\n    // increase step size if too many bins\n    while (Math.ceil(span/step) > maxb) { step *= base; }\n\n    // decrease step size if allowed\n    for (i=0; i<div.length; ++i) {\n      v = step / div[i];\n      if (v >= minstep && span / v <= maxb) step = v;\n    }\n  }\n\n  // update precision, min and max\n  v = Math.log(step);\n  precision = v >= 0 ? 0 : ~~(-v / logb) + 1;\n  eps = Math.pow(base, -precision - 1);\n  min = Math.min(min, Math.floor(min / step + eps) * step);\n  max = Math.ceil(max / step) * step;\n\n  return {\n    start: min,\n    stop:  max,\n    step:  step,\n    unit:  {precision: precision},\n    value: value,\n    index: index\n  };\n}\n\nfunction bisect(a, x, lo, hi) {\n  while (lo < hi) {\n    var mid = lo + hi >>> 1;\n    if (util.cmp(a[mid], x) < 0) { lo = mid + 1; }\n    else { hi = mid; }\n  }\n  return lo;\n}\n\nfunction value(v) {\n  return this.step * Math.floor(v / this.step + EPSILON);\n}\n\nfunction index(v) {\n  return Math.floor((v - this.start) / this.step + EPSILON);\n}\n\nfunction date_value(v) {\n  return this.unit.date(value.call(this, v));\n}\n\nfunction date_index(v) {\n  return index.call(this, this.unit.unit(v));\n}\n\nbins.date = function(opt) {\n  if (!opt) { throw Error(\"Missing date binning options.\"); }\n\n  // find time step, then bin\n  var units = opt.utc ? time.utc : time,\n      dmin = opt.min,\n      dmax = opt.max,\n      maxb = opt.maxbins || 20,\n      minb = opt.minbins || 4,\n      span = (+dmax) - (+dmin),\n      unit = opt.unit ? units[opt.unit] : units.find(span, minb, maxb),\n      spec = bins({\n        min:     unit.min != null ? unit.min : unit.unit(dmin),\n        max:     unit.max != null ? unit.max : unit.unit(dmax),\n        maxbins: maxb,\n        minstep: unit.minstep,\n        steps:   unit.step\n      });\n\n  spec.unit = unit;\n  spec.index = date_index;\n  if (!opt.raw) spec.value = date_value;\n  return spec;\n};\n\nmodule.exports = bins;\n","var util = require('../util');\n\nvar TYPES = '__types__';\n\nvar PARSERS = {\n  boolean: util.boolean,\n  integer: util.number,\n  number:  util.number,\n  date:    util.date,\n  string:  function(x) { return x == null || x === '' ? null : x + ''; }\n};\n\nvar TESTS = {\n  boolean: function(x) { return x==='true' || x==='false' || util.isBoolean(x); },\n  integer: function(x) { return TESTS.number(x) && (x=+x) === ~~x; },\n  number: function(x) { return !isNaN(+x) && !util.isDate(x); },\n  date: function(x) { return !isNaN(Date.parse(x)); }\n};\n\nfunction annotation(data, types) {\n  if (!types) return data && data[TYPES] || null;\n  data[TYPES] = types;\n}\n\nfunction fieldNames(datum) {\n  return util.keys(datum);\n}\n\nfunction bracket(fieldName) {\n  return '[' + fieldName + ']';\n}\n\nfunction type(values, f) {\n  values = util.array(values);\n  f = util.$(f);\n  var v, i, n;\n\n  // if data array has type annotations, use them\n  if (values[TYPES]) {\n    v = f(values[TYPES]);\n    if (util.isString(v)) return v;\n  }\n\n  for (i=0, n=values.length; !util.isValid(v) && i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n  }\n\n  return util.isDate(v) ? 'date' :\n    util.isNumber(v)    ? 'number' :\n    util.isBoolean(v)   ? 'boolean' :\n    util.isString(v)    ? 'string' : null;\n}\n\nfunction typeAll(data, fields) {\n  if (!data.length) return;\n  var get = fields ? util.identity : (fields = fieldNames(data[0]), bracket);\n  return fields.reduce(function(types, f) {\n    return (types[f] = type(data, get(f)), types);\n  }, {});\n}\n\nfunction infer(values, f) {\n  values = util.array(values);\n  f = util.$(f);\n  var i, j, v;\n\n  // types to test for, in precedence order\n  var types = ['boolean', 'integer', 'number', 'date'];\n\n  for (i=0; i<values.length; ++i) {\n    // get next value to test\n    v = f ? f(values[i]) : values[i];\n    // test value against remaining types\n    for (j=0; j<types.length; ++j) {\n      if (util.isValid(v) && !TESTS[types[j]](v)) {\n        types.splice(j, 1);\n        j -= 1;\n      }\n    }\n    // if no types left, return 'string'\n    if (types.length === 0) return 'string';\n  }\n\n  return types[0];\n}\n\nfunction inferAll(data, fields) {\n  var get = fields ? util.identity : (fields = fieldNames(data[0]), bracket);\n  return fields.reduce(function(types, f) {\n    types[f] = infer(data, get(f));\n    return types;\n  }, {});\n}\n\ntype.annotation = annotation;\ntype.all = typeAll;\ntype.infer = infer;\ntype.inferAll = inferAll;\ntype.parsers = PARSERS;\nmodule.exports = type;\n","var util = require('./util'),\n    gen = module.exports;\n\ngen.repeat = function(val, n) {\n  var a = Array(n), i;\n  for (i=0; i<n; ++i) a[i] = val;\n  return a;\n};\n\ngen.zeros = function(n) {\n  return gen.repeat(0, n);\n};\n\ngen.range = function(start, stop, step) {\n  if (arguments.length < 3) {\n    step = 1;\n    if (arguments.length < 2) {\n      stop = start;\n      start = 0;\n    }\n  }\n  if ((stop - start) / step == Infinity) throw new Error('Infinite range');\n  var range = [], i = -1, j;\n  if (step < 0) while ((j = start + step * ++i) > stop) range.push(j);\n  else while ((j = start + step * ++i) < stop) range.push(j);\n  return range;\n};\n\ngen.random = {};\n\ngen.random.uniform = function(min, max) {\n  if (max === undefined) {\n    max = min === undefined ? 1 : min;\n    min = 0;\n  }\n  var d = max - min;\n  var f = function() {\n    return min + d * Math.random();\n  };\n  f.samples = function(n) {\n    return gen.zeros(n).map(f);\n  };\n  f.pdf = function(x) {\n    return (x >= min && x <= max) ? 1/d : 0;\n  };\n  f.cdf = function(x) {\n    return x < min ? 0 : x > max ? 1 : (x - min) / d;\n  };\n  f.icdf = function(p) {\n    return (p >= 0 && p <= 1) ? min + p*d : NaN;\n  };\n  return f;\n};\n\ngen.random.integer = function(a, b) {\n  if (b === undefined) {\n    b = a;\n    a = 0;\n  }\n  var d = b - a;\n  var f = function() {\n    return a + Math.floor(d * Math.random());\n  };\n  f.samples = function(n) {\n    return gen.zeros(n).map(f);\n  };\n  f.pdf = function(x) {\n    return (x === Math.floor(x) && x >= a && x < b) ? 1/d : 0;\n  };\n  f.cdf = function(x) {\n    var v = Math.floor(x);\n    return v < a ? 0 : v >= b ? 1 : (v - a + 1) / d;\n  };\n  f.icdf = function(p) {\n    return (p >= 0 && p <= 1) ? a - 1 + Math.floor(p*d) : NaN;\n  };\n  return f;\n};\n\ngen.random.normal = function(mean, stdev) {\n  mean = mean || 0;\n  stdev = stdev || 1;\n  var next;\n  var f = function() {\n    var x = 0, y = 0, rds, c;\n    if (next !== undefined) {\n      x = next;\n      next = undefined;\n      return x;\n    }\n    do {\n      x = Math.random()*2-1;\n      y = Math.random()*2-1;\n      rds = x*x + y*y;\n    } while (rds === 0 || rds > 1);\n    c = Math.sqrt(-2*Math.log(rds)/rds); // Box-Muller transform\n    next = mean + y*c*stdev;\n    return mean + x*c*stdev;\n  };\n  f.samples = function(n) {\n    return gen.zeros(n).map(f);\n  };\n  f.pdf = function(x) {\n    var exp = Math.exp(Math.pow(x-mean, 2) / (-2 * Math.pow(stdev, 2)));\n    return (1 / (stdev * Math.sqrt(2*Math.PI))) * exp;\n  };\n  f.cdf = function(x) {\n    // Approximation from West (2009)\n    // Better Approximations to Cumulative Normal Functions\n    var cd,\n        z = (x - mean) / stdev,\n        Z = Math.abs(z);\n    if (Z > 37) {\n      cd = 0;\n    } else {\n      var sum, exp = Math.exp(-Z*Z/2);\n      if (Z < 7.07106781186547) {\n        sum = 3.52624965998911e-02 * Z + 0.700383064443688;\n        sum = sum * Z + 6.37396220353165;\n        sum = sum * Z + 33.912866078383;\n        sum = sum * Z + 112.079291497871;\n        sum = sum * Z + 221.213596169931;\n        sum = sum * Z + 220.206867912376;\n        cd = exp * sum;\n        sum = 8.83883476483184e-02 * Z + 1.75566716318264;\n        sum = sum * Z + 16.064177579207;\n        sum = sum * Z + 86.7807322029461;\n        sum = sum * Z + 296.564248779674;\n        sum = sum * Z + 637.333633378831;\n        sum = sum * Z + 793.826512519948;\n        sum = sum * Z + 440.413735824752;\n        cd = cd / sum;\n      } else {\n        sum = Z + 0.65;\n        sum = Z + 4 / sum;\n        sum = Z + 3 / sum;\n        sum = Z + 2 / sum;\n        sum = Z + 1 / sum;\n        cd = exp / sum / 2.506628274631;\n      }\n    }\n    return z > 0 ? 1 - cd : cd;\n  };\n  f.icdf = function(p) {\n    // Approximation of Probit function using inverse error function.\n    if (p <= 0 || p >= 1) return NaN;\n    var x = 2*p - 1,\n        v = (8 * (Math.PI - 3)) / (3 * Math.PI * (4-Math.PI)),\n        a = (2 / (Math.PI*v)) + (Math.log(1 - Math.pow(x,2)) / 2),\n        b = Math.log(1 - (x*x)) / v,\n        s = (x > 0 ? 1 : -1) * Math.sqrt(Math.sqrt((a*a) - b) - a);\n    return mean + stdev * Math.SQRT2 * s;\n  };\n  return f;\n};\n\ngen.random.bootstrap = function(domain, smooth) {\n  // Generates a bootstrap sample from a set of observations.\n  // Smooth bootstrapping adds random zero-centered noise to the samples.\n  var val = domain.filter(util.isValid),\n      len = val.length,\n      err = smooth ? gen.random.normal(0, smooth) : null;\n  var f = function() {\n    return val[~~(Math.random()*len)] + (err ? err() : 0);\n  };\n  f.samples = function(n) {\n    return gen.zeros(n).map(f);\n  };\n  return f;\n};","var util = require('./util');\nvar type = require('./import/type');\nvar gen = require('./generate');\n\nvar stats = module.exports;\n\n// Collect unique values.\n// Output: an array of unique values, in first-observed order\nstats.unique = function(values, f, results) {\n  f = util.$(f);\n  results = results || [];\n  var u = {}, v, i, n;\n  for (i=0, n=values.length; i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n    if (v in u) continue;\n    u[v] = 1;\n    results.push(v);\n  }\n  return results;\n};\n\n// Return the length of the input array.\nstats.count = function(values) {\n  return values && values.length || 0;\n};\n\n// Count the number of non-null, non-undefined, non-NaN values.\nstats.count.valid = function(values, f) {\n  f = util.$(f);\n  var v, i, n, valid = 0;\n  for (i=0, n=values.length; i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n    if (util.isValid(v)) valid += 1;\n  }\n  return valid;\n};\n\n// Count the number of null or undefined values.\nstats.count.missing = function(values, f) {\n  f = util.$(f);\n  var v, i, n, count = 0;\n  for (i=0, n=values.length; i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n    if (v == null) count += 1;\n  }\n  return count;\n};\n\n// Count the number of distinct values.\n// Null, undefined and NaN are each considered distinct values.\nstats.count.distinct = function(values, f) {\n  f = util.$(f);\n  var u = {}, v, i, n, count = 0;\n  for (i=0, n=values.length; i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n    if (v in u) continue;\n    u[v] = 1;\n    count += 1;\n  }\n  return count;\n};\n\n// Construct a map from distinct values to occurrence counts.\nstats.count.map = function(values, f) {\n  f = util.$(f);\n  var map = {}, v, i, n;\n  for (i=0, n=values.length; i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n    map[v] = (v in map) ? map[v] + 1 : 1;\n  }\n  return map;\n};\n\n// Compute the median of an array of numbers.\nstats.median = function(values, f) {\n  if (f) values = values.map(util.$(f));\n  values = values.filter(util.isValid).sort(util.cmp);\n  return stats.quantile(values, 0.5);\n};\n\n// Computes the quartile boundaries of an array of numbers.\nstats.quartile = function(values, f) {\n  if (f) values = values.map(util.$(f));\n  values = values.filter(util.isValid).sort(util.cmp);\n  var q = stats.quantile;\n  return [q(values, 0.25), q(values, 0.50), q(values, 0.75)];\n};\n\n// Compute the quantile of a sorted array of numbers.\n// Adapted from the D3.js implementation.\nstats.quantile = function(values, f, p) {\n  if (p === undefined) { p = f; f = util.identity; }\n  f = util.$(f);\n  var H = (values.length - 1) * p + 1,\n      h = Math.floor(H),\n      v = +f(values[h - 1]),\n      e = H - h;\n  return e ? v + e * (f(values[h]) - v) : v;\n};\n\n// Compute the sum of an array of numbers.\nstats.sum = function(values, f) {\n  f = util.$(f);\n  for (var sum=0, i=0, n=values.length, v; i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n    if (util.isValid(v)) sum += v;\n  }\n  return sum;\n};\n\n// Compute the mean (average) of an array of numbers.\nstats.mean = function(values, f) {\n  f = util.$(f);\n  var mean = 0, delta, i, n, c, v;\n  for (i=0, c=0, n=values.length; i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n    if (util.isValid(v)) {\n      delta = v - mean;\n      mean = mean + delta / (++c);\n    }\n  }\n  return mean;\n};\n\n// Compute the geometric mean of an array of numbers.\nstats.mean.geometric = function(values, f) {\n  f = util.$(f);\n  var mean = 1, c, n, v, i;\n  for (i=0, c=0, n=values.length; i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n    if (util.isValid(v)) {\n      if (v <= 0) {\n        throw Error(\"Geometric mean only defined for positive values.\");\n      }\n      mean *= v;\n      ++c;\n    }\n  }\n  mean = c > 0 ? Math.pow(mean, 1/c) : 0;\n  return mean;\n};\n\n// Compute the harmonic mean of an array of numbers.\nstats.mean.harmonic = function(values, f) {\n  f = util.$(f);\n  var mean = 0, c, n, v, i;\n  for (i=0, c=0, n=values.length; i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n    if (util.isValid(v)) {\n      mean += 1/v;\n      ++c;\n    }\n  }\n  return c / mean;\n};\n\n// Compute the sample variance of an array of numbers.\nstats.variance = function(values, f) {\n  f = util.$(f);\n  if (!util.isArray(values) || values.length < 2) return 0;\n  var mean = 0, M2 = 0, delta, i, c, v;\n  for (i=0, c=0; i<values.length; ++i) {\n    v = f ? f(values[i]) : values[i];\n    if (util.isValid(v)) {\n      delta = v - mean;\n      mean = mean + delta / (++c);\n      M2 = M2 + delta * (v - mean);\n    }\n  }\n  M2 = M2 / (c - 1);\n  return M2;\n};\n\n// Compute the sample standard deviation of an array of numbers.\nstats.stdev = function(values, f) {\n  return Math.sqrt(stats.variance(values, f));\n};\n\n// Compute the Pearson mode skewness ((median-mean)/stdev) of an array of numbers.\nstats.modeskew = function(values, f) {\n  var avg = stats.mean(values, f),\n      med = stats.median(values, f),\n      std = stats.stdev(values, f);\n  return std === 0 ? 0 : (avg - med) / std;\n};\n\n// Find the minimum value in an array.\nstats.min = function(values, f) {\n  return stats.extent(values, f)[0];\n};\n\n// Find the maximum value in an array.\nstats.max = function(values, f) {\n  return stats.extent(values, f)[1];\n};\n\n// Find the minimum and maximum of an array of values.\nstats.extent = function(values, f) {\n  f = util.$(f);\n  var a, b, v, i, n = values.length;\n  for (i=0; i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n    if (util.isValid(v)) { a = b = v; break; }\n  }\n  for (; i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n    if (util.isValid(v)) {\n      if (v < a) a = v;\n      if (v > b) b = v;\n    }\n  }\n  return [a, b];\n};\n\n// Find the integer indices of the minimum and maximum values.\nstats.extent.index = function(values, f) {\n  f = util.$(f);\n  var x = -1, y = -1, a, b, v, i, n = values.length;\n  for (i=0; i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n    if (util.isValid(v)) { a = b = v; x = y = i; break; }\n  }\n  for (; i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n    if (util.isValid(v)) {\n      if (v < a) { a = v; x = i; }\n      if (v > b) { b = v; y = i; }\n    }\n  }\n  return [x, y];\n};\n\n// Compute the dot product of two arrays of numbers.\nstats.dot = function(values, a, b) {\n  var sum = 0, i, v;\n  if (!b) {\n    if (values.length !== a.length) {\n      throw Error('Array lengths must match.');\n    }\n    for (i=0; i<values.length; ++i) {\n      v = values[i] * a[i];\n      if (v === v) sum += v;\n    }\n  } else {\n    a = util.$(a);\n    b = util.$(b);\n    for (i=0; i<values.length; ++i) {\n      v = a(values[i]) * b(values[i]);\n      if (v === v) sum += v;\n    }\n  }\n  return sum;\n};\n\n// Compute the vector distance between two arrays of numbers.\n// Default is Euclidean (exp=2) distance, configurable via exp argument.\nstats.dist = function(values, a, b, exp) {\n  var f = util.isFunction(b) || util.isString(b),\n      X = values,\n      Y = f ? values : a,\n      e = f ? exp : b,\n      L2 = e === 2 || e == null,\n      n = values.length, s = 0, d, i;\n  if (f) {\n    a = util.$(a);\n    b = util.$(b);\n  }\n  for (i=0; i<n; ++i) {\n    d = f ? (a(X[i])-b(Y[i])) : (X[i]-Y[i]);\n    s += L2 ? d*d : Math.pow(Math.abs(d), e);\n  }\n  return L2 ? Math.sqrt(s) : Math.pow(s, 1/e);\n};\n\n// Compute the Cohen's d effect size between two arrays of numbers.\nstats.cohensd = function(values, a, b) {\n  var X = b ? values.map(util.$(a)) : values,\n      Y = b ? values.map(util.$(b)) : a,\n      x1 = stats.mean(X),\n      x2 = stats.mean(Y),\n      n1 = stats.count.valid(X),\n      n2 = stats.count.valid(Y);\n\n  if ((n1+n2-2) <= 0) {\n    // if both arrays are size 1, or one is empty, there's no effect size\n    return 0;\n  }\n  // pool standard deviation\n  var s1 = stats.variance(X),\n      s2 = stats.variance(Y),\n      s = Math.sqrt((((n1-1)*s1) + ((n2-1)*s2)) / (n1+n2-2));\n  // if there is no variance, there's no effect size\n  return s===0 ? 0 : (x1 - x2) / s;\n};\n\n// Computes the covariance between two arrays of numbers\nstats.covariance = function(values, a, b) {\n  var X = b ? values.map(util.$(a)) : values,\n      Y = b ? values.map(util.$(b)) : a,\n      n = X.length,\n      xm = stats.mean(X),\n      ym = stats.mean(Y),\n      sum = 0, c = 0, i, x, y, vx, vy;\n\n  if (n !== Y.length) {\n    throw Error('Input lengths must match.');\n  }\n\n  for (i=0; i<n; ++i) {\n    x = X[i]; vx = util.isValid(x);\n    y = Y[i]; vy = util.isValid(y);\n    if (vx && vy) {\n      sum += (x-xm) * (y-ym);\n      ++c;\n    } else if (vx || vy) {\n      throw Error('Valid values must align.');\n    }\n  }\n  return sum / (c-1);\n};\n\n// Compute ascending rank scores for an array of values.\n// Ties are assigned their collective mean rank.\nstats.rank = function(values, f) {\n  f = util.$(f) || util.identity;\n  var a = values.map(function(v, i) {\n      return {idx: i, val: f(v)};\n    })\n    .sort(util.comparator('val'));\n\n  var n = values.length,\n      r = Array(n),\n      tie = -1, p = {}, i, v, mu;\n\n  for (i=0; i<n; ++i) {\n    v = a[i].val;\n    if (tie < 0 && p === v) {\n      tie = i - 1;\n    } else if (tie > -1 && p !== v) {\n      mu = 1 + (i-1 + tie) / 2;\n      for (; tie<i; ++tie) r[a[tie].idx] = mu;\n      tie = -1;\n    }\n    r[a[i].idx] = i + 1;\n    p = v;\n  }\n\n  if (tie > -1) {\n    mu = 1 + (n-1 + tie) / 2;\n    for (; tie<n; ++tie) r[a[tie].idx] = mu;\n  }\n\n  return r;\n};\n\n// Compute the sample Pearson product-moment correlation of two arrays of numbers.\nstats.cor = function(values, a, b) {\n  var fn = b;\n  b = fn ? values.map(util.$(b)) : a;\n  a = fn ? values.map(util.$(a)) : values;\n\n  var dot = stats.dot(a, b),\n      mua = stats.mean(a),\n      mub = stats.mean(b),\n      sda = stats.stdev(a),\n      sdb = stats.stdev(b),\n      n = values.length;\n\n  return (dot - n*mua*mub) / ((n-1) * sda * sdb);\n};\n\n// Compute the Spearman rank correlation of two arrays of values.\nstats.cor.rank = function(values, a, b) {\n  var ra = b ? stats.rank(values, a) : stats.rank(values),\n      rb = b ? stats.rank(values, b) : stats.rank(a),\n      n = values.length, i, s, d;\n\n  for (i=0, s=0; i<n; ++i) {\n    d = ra[i] - rb[i];\n    s += d * d;\n  }\n\n  return 1 - 6*s / (n * (n*n-1));\n};\n\n// Compute the distance correlation of two arrays of numbers.\n// http://en.wikipedia.org/wiki/Distance_correlation\nstats.cor.dist = function(values, a, b) {\n  var X = b ? values.map(util.$(a)) : values,\n      Y = b ? values.map(util.$(b)) : a;\n\n  var A = stats.dist.mat(X),\n      B = stats.dist.mat(Y),\n      n = A.length,\n      i, aa, bb, ab;\n\n  for (i=0, aa=0, bb=0, ab=0; i<n; ++i) {\n    aa += A[i]*A[i];\n    bb += B[i]*B[i];\n    ab += A[i]*B[i];\n  }\n\n  return Math.sqrt(ab / Math.sqrt(aa*bb));\n};\n\n// Simple linear regression.\n// Returns a \"fit\" object with slope (m), intercept (b),\n// r value (R), and sum-squared residual error (rss).\nstats.linearRegression = function(values, a, b) {\n  var X = b ? values.map(util.$(a)) : values,\n      Y = b ? values.map(util.$(b)) : a,\n      n = X.length,\n      xy = stats.covariance(X, Y), // will throw err if valid vals don't align\n      sx = stats.stdev(X),\n      sy = stats.stdev(Y),\n      slope = xy / (sx*sx),\n      icept = stats.mean(Y) - slope * stats.mean(X),\n      fit = {slope: slope, intercept: icept, R: xy / (sx*sy), rss: 0},\n      res, i;\n\n  for (i=0; i<n; ++i) {\n    if (util.isValid(X[i]) && util.isValid(Y[i])) {\n      res = (slope*X[i] + icept) - Y[i];\n      fit.rss += res * res;\n    }\n  }\n\n  return fit;\n};\n\n// Namespace for bootstrap\nstats.bootstrap = {};\n\n// Construct a bootstrapped confidence interval at a given percentile level\n// Arguments are an array, an optional n (defaults to 1000),\n//  an optional alpha (defaults to 0.05), and an optional smoothing parameter\nstats.bootstrap.ci = function(values, a, b, c, d) {\n  var X, N, alpha, smooth, bs, means, i;\n  if (util.isFunction(a) || util.isString(a)) {\n    X = values.map(util.$(a));\n    N = b;\n    alpha = c;\n    smooth = d;\n  } else {\n    X = values;\n    N = a;\n    alpha = b;\n    smooth = c;\n  }\n  N = N ? +N : 1000;\n  alpha = alpha || 0.05;\n\n  bs = gen.random.bootstrap(X, smooth);\n  for (i=0, means = Array(N); i<N; ++i) {\n    means[i] = stats.mean(bs.samples(X.length));\n  }\n  means.sort(util.numcmp);\n  return [\n    stats.quantile(means, alpha/2),\n    stats.quantile(means, 1-(alpha/2))\n  ];\n};\n\n// Namespace for z-tests\nstats.z = {};\n\n// Construct a z-confidence interval at a given significance level\n// Arguments are an array and an optional alpha (defaults to 0.05).\nstats.z.ci = function(values, a, b) {\n  var X = values, alpha = a;\n  if (util.isFunction(a) || util.isString(a)) {\n    X = values.map(util.$(a));\n    alpha = b;\n  }\n  alpha = alpha || 0.05;\n\n  var z = alpha===0.05 ? 1.96 : gen.random.normal(0, 1).icdf(1-(alpha/2)),\n      mu = stats.mean(X),\n      SE = stats.stdev(X) / Math.sqrt(stats.count.valid(X));\n  return [mu - (z*SE), mu + (z*SE)];\n};\n\n// Perform a z-test of means. Returns the p-value.\n// If a single array is provided, performs a one-sample location test.\n// If two arrays or a table and two accessors are provided, performs\n// a two-sample location test. A paired test is performed if specified\n// by the options hash.\n// The options hash format is: {paired: boolean, nullh: number}.\n// http://en.wikipedia.org/wiki/Z-test\n// http://en.wikipedia.org/wiki/Paired_difference_test\nstats.z.test = function(values, a, b, opt) {\n  if (util.isFunction(b) || util.isString(b)) { // table and accessors\n    return (opt && opt.paired ? ztestP : ztest2)(opt, values, a, b);\n  } else if (util.isArray(a)) { // two arrays\n    return (b && b.paired ? ztestP : ztest2)(b, values, a);\n  } else if (util.isFunction(a) || util.isString(a)) {\n    return ztest1(b, values, a); // table and accessor\n  } else {\n    return ztest1(a, values); // one array\n  }\n};\n\n// Perform a z-test of means. Returns the p-value.\n// Assuming we have a list of values, and a null hypothesis. If no null\n// hypothesis, assume our null hypothesis is mu=0.\nfunction ztest1(opt, X, f) {\n  var nullH = opt && opt.nullh || 0,\n      gaussian = gen.random.normal(0, 1),\n      mu = stats.mean(X,f),\n      SE = stats.stdev(X,f) / Math.sqrt(stats.count.valid(X,f));\n\n  if (SE===0) {\n    // Test not well defined when standard error is 0.\n    return (mu - nullH) === 0 ? 1 : 0;\n  }\n  // Two-sided, so twice the one-sided cdf.\n  var z = (mu - nullH) / SE;\n  return 2 * gaussian.cdf(-Math.abs(z));\n}\n\n// Perform a two sample paired z-test of means. Returns the p-value.\nfunction ztestP(opt, values, a, b) {\n  var X = b ? values.map(util.$(a)) : values,\n      Y = b ? values.map(util.$(b)) : a,\n      n1 = stats.count(X),\n      n2 = stats.count(Y),\n      diffs = Array(), i;\n\n  if (n1 !== n2) {\n    throw Error('Array lengths must match.');\n  }\n  for (i=0; i<n1; ++i) {\n    // Only valid differences should contribute to the test statistic\n    if (util.isValid(X[i]) && util.isValid(Y[i])) {\n      diffs.push(X[i] - Y[i]);\n    }\n  }\n  return stats.z.test(diffs, opt && opt.nullh || 0);\n}\n\n// Perform a two sample z-test of means. Returns the p-value.\nfunction ztest2(opt, values, a, b) {\n  var X = b ? values.map(util.$(a)) : values,\n      Y = b ? values.map(util.$(b)) : a,\n      n1 = stats.count.valid(X),\n      n2 = stats.count.valid(Y),\n      gaussian = gen.random.normal(0, 1),\n      meanDiff = stats.mean(X) - stats.mean(Y) - (opt && opt.nullh || 0),\n      SE = Math.sqrt(stats.variance(X)/n1 + stats.variance(Y)/n2);\n\n  if (SE===0) {\n    // Not well defined when pooled standard error is 0.\n    return meanDiff===0 ? 1 : 0;\n  }\n  // Two-tailed, so twice the one-sided cdf.\n  var z = meanDiff / SE;\n  return 2 * gaussian.cdf(-Math.abs(z));\n}\n\n// Construct a mean-centered distance matrix for an array of numbers.\nstats.dist.mat = function(X) {\n  var n = X.length,\n      m = n*n,\n      A = Array(m),\n      R = gen.zeros(n),\n      M = 0, v, i, j;\n\n  for (i=0; i<n; ++i) {\n    A[i*n+i] = 0;\n    for (j=i+1; j<n; ++j) {\n      A[i*n+j] = (v = Math.abs(X[i] - X[j]));\n      A[j*n+i] = v;\n      R[i] += v;\n      R[j] += v;\n    }\n  }\n\n  for (i=0; i<n; ++i) {\n    M += R[i];\n    R[i] /= n;\n  }\n  M /= m;\n\n  for (i=0; i<n; ++i) {\n    for (j=i; j<n; ++j) {\n      A[i*n+j] += M - R[i] - R[j];\n      A[j*n+i] = A[i*n+j];\n    }\n  }\n\n  return A;\n};\n\n// Compute the Shannon entropy (log base 2) of an array of counts.\nstats.entropy = function(counts, f) {\n  f = util.$(f);\n  var i, p, s = 0, H = 0, n = counts.length;\n  for (i=0; i<n; ++i) {\n    s += (f ? f(counts[i]) : counts[i]);\n  }\n  if (s === 0) return 0;\n  for (i=0; i<n; ++i) {\n    p = (f ? f(counts[i]) : counts[i]) / s;\n    if (p) H += p * Math.log(p);\n  }\n  return -H / Math.LN2;\n};\n\n// Compute the mutual information between two discrete variables.\n// Returns an array of the form [MI, MI_distance]\n// MI_distance is defined as 1 - I(a,b) / H(a,b).\n// http://en.wikipedia.org/wiki/Mutual_information\nstats.mutual = function(values, a, b, counts) {\n  var x = counts ? values.map(util.$(a)) : values,\n      y = counts ? values.map(util.$(b)) : a,\n      z = counts ? values.map(util.$(counts)) : b;\n\n  var px = {},\n      py = {},\n      n = z.length,\n      s = 0, I = 0, H = 0, p, t, i;\n\n  for (i=0; i<n; ++i) {\n    px[x[i]] = 0;\n    py[y[i]] = 0;\n  }\n\n  for (i=0; i<n; ++i) {\n    px[x[i]] += z[i];\n    py[y[i]] += z[i];\n    s += z[i];\n  }\n\n  t = 1 / (s * Math.LN2);\n  for (i=0; i<n; ++i) {\n    if (z[i] === 0) continue;\n    p = (s * z[i]) / (px[x[i]] * py[y[i]]);\n    I += z[i] * t * Math.log(p);\n    H += z[i] * t * Math.log(z[i]/s);\n  }\n\n  return [I, 1 + I/H];\n};\n\n// Compute the mutual information between two discrete variables.\nstats.mutual.info = function(values, a, b, counts) {\n  return stats.mutual(values, a, b, counts)[0];\n};\n\n// Compute the mutual information distance between two discrete variables.\n// MI_distance is defined as 1 - I(a,b) / H(a,b).\nstats.mutual.dist = function(values, a, b, counts) {\n  return stats.mutual(values, a, b, counts)[1];\n};\n\n// Compute a profile of summary statistics for a variable.\nstats.profile = function(values, f) {\n  var mean = 0,\n      valid = 0,\n      missing = 0,\n      distinct = 0,\n      min = null,\n      max = null,\n      M2 = 0,\n      vals = [],\n      u = {}, delta, sd, i, v, x;\n\n  // compute summary stats\n  for (i=0; i<values.length; ++i) {\n    v = f ? f(values[i]) : values[i];\n\n    // update unique values\n    u[v] = (v in u) ? u[v] + 1 : (distinct += 1, 1);\n\n    if (v == null) {\n      ++missing;\n    } else if (util.isValid(v)) {\n      // update stats\n      x = (typeof v === 'string') ? v.length : v;\n      if (min===null || x < min) min = x;\n      if (max===null || x > max) max = x;\n      delta = x - mean;\n      mean = mean + delta / (++valid);\n      M2 = M2 + delta * (x - mean);\n      vals.push(x);\n    }\n  }\n  M2 = M2 / (valid - 1);\n  sd = Math.sqrt(M2);\n\n  // sort values for median and iqr\n  vals.sort(util.cmp);\n\n  return {\n    type:     type(values, f),\n    unique:   u,\n    count:    values.length,\n    valid:    valid,\n    missing:  missing,\n    distinct: distinct,\n    min:      min,\n    max:      max,\n    mean:     mean,\n    stdev:    sd,\n    median:   (v = stats.quantile(vals, 0.5)),\n    q1:       stats.quantile(vals, 0.25),\n    q3:       stats.quantile(vals, 0.75),\n    modeskew: sd === 0 ? 0 : (mean - v) / sd\n  };\n};\n\n// Compute profiles for all variables in a data set.\nstats.summary = function(data, fields) {\n  fields = fields || util.keys(data[0]);\n  var s = fields.map(function(f) {\n    var p = stats.profile(data, util.$(f));\n    return (p.field = f, p);\n  });\n  return (s.__summary__ = true, s);\n};\n","import dlBin_ from 'datalib/src/bins/bins';\nimport {inferAll} from 'datalib/src/import/type';\nimport {summary} from 'datalib/src/stats';\nimport {autoMaxBins} from 'vega-lite/build/src/bin';\nimport {Channel} from 'vega-lite/build/src/channel';\nimport {containsTimeUnit, convert, TimeUnit, TIMEUNIT_PARTS} from 'vega-lite/build/src/timeunit';\nimport * as TYPE from 'vega-lite/build/src/type';\nimport {DEFAULT_QUERY_CONFIG, QueryConfig} from './config';\nimport {BinQuery, EncodingQuery, FieldQuery, isAutoCountQuery} from './query/encoding';\nimport {ExpandedType} from './query/expandedtype';\nimport {cmp, duplicate, extend, keys} from './util';\n\nconst dlBin = dlBin_;\n\n/**\n * Table Schema Field Descriptor interface\n * see: https://specs.frictionlessdata.io/table-schema/\n */\nexport interface TableSchemaFieldDescriptor {\n  /* name of field **/\n  name: string;\n\n  /* A nicer human readable label or title for the field **/\n  title?: string;\n\n  /* number, integer, string, datetime  */\n  type: PrimitiveType;\n\n  /* A string specifying a format */\n  format?: string;\n\n  /* A description for the field */\n  description?: string;\n}\n\n/**\n * Field Schema\n */\nexport interface FieldSchema extends TableSchemaFieldDescriptor {\n  vlType?: ExpandedType;\n\n  index?: number;\n  // Need to keep original index for re-exporting TableSchema\n  originalIndex?: number;\n\n  stats: DLFieldProfile;\n  binStats?: {[maxbins: string]: DLFieldProfile};\n  timeStats?: {[timeUnit: string]: DLFieldProfile};\n\n  // array of valid input values (fields)\n  ordinalDomain?: string[];\n}\n\n/**\n * Table Schema\n * see: https://specs.frictionlessdata.io/table-schema/\n */\nexport interface TableSchema<F extends TableSchemaFieldDescriptor> {\n  fields: F[];\n  missingValues?: string[];\n  primaryKey?: string | string[];\n  foreignKeys?: object[];\n}\n\n/**\n * Build a Schema object.\n *\n * @param data - a set of raw data in the same format that Vega-Lite / Vega takes\n * Basically, it's an array in the form of:\n *\n * [\n *   {a: 1, b:2},\n *   {a: 2, b:3},\n *   ...\n * ]\n *\n * @return a Schema object\n */\nexport function build(\n  data: any,\n  opt: QueryConfig = {},\n  tableSchema: TableSchema<TableSchemaFieldDescriptor> = {fields: []}\n): Schema {\n  opt = extend({}, DEFAULT_QUERY_CONFIG, opt);\n\n  // create profiles for each variable\n  let summaries: DLFieldProfile[] = summary(data);\n  let types = inferAll(data); // inferAll does stronger type inference than summary\n\n  let tableSchemaFieldIndex = tableSchema.fields.reduce((m, field: TableSchemaFieldDescriptor) => {\n    m[field.name] = field;\n    return m;\n  }, {});\n\n  let fieldSchemas: FieldSchema[] = summaries.map(function(fieldProfile, index) {\n    const name: string = fieldProfile.field;\n    // In Table schema, 'date' doesn't include time so use 'datetime'\n    const type: PrimitiveType = types[name] === 'date' ? PrimitiveType.DATETIME : (types[name] as any);\n    let distinct: number = fieldProfile.distinct;\n    let vlType: ExpandedType;\n\n    if (type === PrimitiveType.NUMBER) {\n      vlType = TYPE.QUANTITATIVE;\n    } else if (type === PrimitiveType.INTEGER) {\n      // use ordinal or nominal when cardinality of integer type is relatively low and the distinct values are less than an amount specified in options\n      if (distinct < opt.numberNominalLimit && distinct / fieldProfile.count < opt.numberNominalProportion) {\n        vlType = TYPE.NOMINAL;\n      } else {\n        vlType = TYPE.QUANTITATIVE;\n      }\n    } else if (type === PrimitiveType.DATETIME) {\n      vlType = TYPE.TEMPORAL;\n      // need to get correct min/max of date data because datalib's summary method does not\n      // calculate this correctly for date types.\n      fieldProfile.min = new Date(data[0][name]);\n      fieldProfile.max = new Date(data[0][name]);\n      for (const dataEntry of data) {\n        const time = new Date(dataEntry[name]).getTime();\n        if (time < (fieldProfile.min as Date).getTime()) {\n          fieldProfile.min = new Date(time);\n        }\n        if (time > (fieldProfile.max as Date).getTime()) {\n          fieldProfile.max = new Date(time);\n        }\n      }\n    } else {\n      vlType = TYPE.NOMINAL;\n    }\n\n    if (\n      vlType === TYPE.NOMINAL &&\n      distinct / fieldProfile.count > opt.minPercentUniqueForKey &&\n      fieldProfile.count > opt.minCardinalityForKey\n    ) {\n      vlType = ExpandedType.KEY;\n    }\n\n    let fieldSchema = {\n      name: name,\n      // Need to keep original index for re-exporting TableSchema\n      originalIndex: index,\n      vlType: vlType,\n      type: type,\n      stats: fieldProfile,\n      timeStats: {} as {[timeUnit: string]: DLFieldProfile},\n      binStats: {} as {[key: string]: DLFieldProfile}\n    };\n\n    // extend field schema with table schema field - if present\n    const orgFieldSchema = tableSchemaFieldIndex[fieldSchema.name];\n    fieldSchema = extend(fieldSchema, orgFieldSchema);\n\n    return fieldSchema;\n  });\n\n  // calculate preset bins for quantitative and temporal data\n  for (let fieldSchema of fieldSchemas) {\n    if (fieldSchema.vlType === TYPE.QUANTITATIVE) {\n      for (let maxbins of opt.enum.binProps.maxbins) {\n        fieldSchema.binStats[maxbins] = binSummary(maxbins, fieldSchema.stats);\n      }\n    } else if (fieldSchema.vlType === TYPE.TEMPORAL) {\n      for (let unit of opt.enum.timeUnit) {\n        if (unit !== undefined) {\n          fieldSchema.timeStats[unit] = timeSummary(unit, fieldSchema.stats);\n        }\n      }\n    }\n  }\n\n  const derivedTableSchema: TableSchema<FieldSchema> = {\n    ...tableSchema,\n    fields: fieldSchemas\n  };\n\n  return new Schema(derivedTableSchema);\n}\n\n// order the field schema when we construct a new Schema\n// this orders the fields in the UI\nconst order = {\n  nominal: 0,\n  key: 1,\n  ordinal: 2,\n  temporal: 3,\n  quantitative: 4\n};\n\nexport class Schema {\n  private _tableSchema: TableSchema<FieldSchema>;\n  private _fieldSchemaIndex: {[field: string]: FieldSchema};\n\n  constructor(tableSchema: TableSchema<FieldSchema>) {\n    this._tableSchema = tableSchema;\n\n    tableSchema.fields.sort(function(a: FieldSchema, b: FieldSchema) {\n      // first order by vlType: nominal < temporal < quantitative < ordinal\n      if (order[a.vlType] < order[b.vlType]) {\n        return -1;\n      } else if (order[a.vlType] > order[b.vlType]) {\n        return 1;\n      } else {\n        // then order by field (alphabetically)\n        return a.name.localeCompare(b.name);\n      }\n    });\n\n    // Add index for sorting\n    tableSchema.fields.forEach((fieldSchema, index) => (fieldSchema.index = index));\n\n    this._fieldSchemaIndex = tableSchema.fields.reduce((m, fieldSchema: FieldSchema) => {\n      m[fieldSchema.name] = fieldSchema;\n      return m;\n    }, {});\n  }\n\n  /** @return a list of the field names (for enumerating). */\n  public fieldNames() {\n    return this._tableSchema.fields.map(fieldSchema => fieldSchema.name);\n  }\n\n  /** @return a list of FieldSchemas */\n  public get fieldSchemas() {\n    return this._tableSchema.fields;\n  }\n\n  public fieldSchema(fieldName: string) {\n    return this._fieldSchemaIndex[fieldName];\n  }\n\n  public tableSchema() {\n    // the fieldschemas are re-arranged\n    // but this is not allowed in table schema.\n    // so we will re-order based on original index.\n    const tableSchema = duplicate(this._tableSchema);\n    tableSchema.fields.sort((a, b) => a.originalIndex - b.originalIndex);\n    return tableSchema;\n  }\n\n  /**\n   * @return primitive type of the field if exist, otherwise return null\n   */\n  public primitiveType(fieldName: string) {\n    return this._fieldSchemaIndex[fieldName] ? this._fieldSchemaIndex[fieldName].type : null;\n  }\n\n  /**\n   * @return vlType of measturement of the field if exist, otherwise return null\n   */\n  public vlType(fieldName: string) {\n    return this._fieldSchemaIndex[fieldName] ? this._fieldSchemaIndex[fieldName].vlType : null;\n  }\n\n  /** @return cardinality of the field associated with encQ, null if it doesn't exist.\n   *  @param augmentTimeUnitDomain - TimeUnit field domains will not be augmented if explicitly set to false.\n   */\n  public cardinality(fieldQ: FieldQuery, augmentTimeUnitDomain: boolean = true, excludeInvalid: boolean = false) {\n    const fieldSchema = this._fieldSchemaIndex[fieldQ.field as string];\n    if (fieldQ.aggregate || (isAutoCountQuery(fieldQ) && fieldQ.autoCount)) {\n      return 1;\n    } else if (fieldQ.bin) {\n      // encQ.bin will either be a boolean or a BinQuery\n      let bin: BinQuery;\n      if (typeof fieldQ.bin === 'boolean') {\n        // autoMaxBins defaults to 10 if channel is Wildcard\n        bin = {\n          maxbins: autoMaxBins(fieldQ.channel as Channel)\n        };\n      } else if (fieldQ.bin === '?') {\n        bin = {\n          enum: [true, false]\n        };\n      } else {\n        bin = fieldQ.bin;\n      }\n      const maxbins: any = bin.maxbins;\n      if (!fieldSchema.binStats[maxbins]) {\n        // need to calculate\n        fieldSchema.binStats[maxbins] = binSummary(maxbins, fieldSchema.stats);\n      }\n      // don't need to worry about excludeInvalid here because invalid values don't affect linearly binned field's cardinality\n      return fieldSchema.binStats[maxbins].distinct;\n    } else if (fieldQ.timeUnit) {\n      if (augmentTimeUnitDomain) {\n        switch (fieldQ.timeUnit) {\n          // TODO: this should not always be the case once Vega-Lite supports turning off domain augmenting (VL issue #1385)\n          case TimeUnit.SECONDS:\n            return 60;\n          case TimeUnit.MINUTES:\n            return 60;\n          case TimeUnit.HOURS:\n            return 24;\n          case TimeUnit.DAY:\n            return 7;\n          case TimeUnit.DATE:\n            return 31;\n          case TimeUnit.MONTH:\n            return 12;\n          case TimeUnit.QUARTER:\n            return 4;\n          case TimeUnit.MILLISECONDS:\n            return 1000;\n        }\n      }\n      let unit = fieldQ.timeUnit as string;\n      let timeStats = fieldSchema.timeStats;\n      // if the cardinality for the timeUnit is not cached, calculate it\n      if (!timeStats || !timeStats[unit]) {\n        timeStats = {\n          ...timeStats,\n          [unit]: timeSummary(fieldQ.timeUnit as TimeUnit, fieldSchema.stats)\n        };\n      }\n\n      if (excludeInvalid) {\n        return timeStats[unit].distinct - invalidCount(timeStats[unit].unique, ['Invalid Date', null]);\n      } else {\n        return timeStats[unit].distinct;\n      }\n    } else {\n      if (fieldSchema) {\n        if (excludeInvalid) {\n          return fieldSchema.stats.distinct - invalidCount(fieldSchema.stats.unique, [NaN, null]);\n        } else {\n          return fieldSchema.stats.distinct;\n        }\n      } else {\n        return null;\n      }\n    }\n  }\n\n  /**\n   * Given an EncodingQuery with a timeUnit, returns true if the date field\n   * has multiple distinct values for all parts of the timeUnit. Returns undefined\n   * if the timeUnit is undefined.\n   * i.e.\n   * ('yearmonth', [Jan 1 2000, Feb 2 2000] returns false)\n   * ('yearmonth', [Jan 1 2000, Feb 2 2001] returns true)\n   */\n  public timeUnitHasVariation(fieldQ: FieldQuery): boolean {\n    if (!fieldQ.timeUnit) {\n      return;\n    }\n\n    // if there is no variation in `date`, there should not be variation in `day`\n    if (fieldQ.timeUnit === TimeUnit.DAY) {\n      const dateEncQ: EncodingQuery = extend({}, fieldQ, {timeUnit: TimeUnit.DATE});\n      if (this.cardinality(dateEncQ, false, true) <= 1) {\n        return false;\n      }\n    }\n\n    let fullTimeUnit = fieldQ.timeUnit;\n    for (let timeUnitPart of TIMEUNIT_PARTS) {\n      if (containsTimeUnit(fullTimeUnit as TimeUnit, timeUnitPart)) {\n        // Create a clone of encQ, but with singleTimeUnit\n        const singleUnitEncQ = extend({}, fieldQ, {timeUnit: timeUnitPart});\n        if (this.cardinality(singleUnitEncQ, false, true) <= 1) {\n          return false;\n        }\n      }\n    }\n    return true;\n  }\n\n  public domain(fieldQueryParts: {field: string}): any[] {\n    // TODO: differentiate for field with bin / timeUnit\n    const fieldSchema = this._fieldSchemaIndex[fieldQueryParts.field as string];\n    let domain: any[] = keys(fieldSchema.stats.unique);\n    if (fieldSchema.vlType === TYPE.QUANTITATIVE) {\n      // return [min, max], coerced into number types\n      return [+fieldSchema.stats.min, +fieldSchema.stats.max];\n    } else if (fieldSchema.type === PrimitiveType.DATETIME) {\n      // return [min, max] dates\n      return [fieldSchema.stats.min, fieldSchema.stats.max];\n    } else if (fieldSchema.type === PrimitiveType.INTEGER || fieldSchema.type === PrimitiveType.NUMBER) {\n      // coerce non-quantitative numerical data into number type\n      domain = domain.map(x => +x);\n      return domain.sort(cmp);\n    } else if (fieldSchema.vlType === TYPE.ORDINAL && fieldSchema.ordinalDomain) {\n      return fieldSchema.ordinalDomain;\n    }\n\n    return domain\n      .map(x => {\n        // Convert 'null' to null as it is encoded similarly in datalib.\n        // This is wrong when it is a string 'null' but that rarely happens.\n        return x === 'null' ? null : x;\n      })\n      .sort(cmp);\n  }\n\n  /**\n   * @return a Summary corresponding to the field of the given EncodingQuery\n   */\n  public stats(fieldQ: FieldQuery) {\n    // TODO: differentiate for field with bin / timeUnit vs without\n    const fieldSchema = this._fieldSchemaIndex[fieldQ.field as string];\n    return fieldSchema ? fieldSchema.stats : null;\n  }\n}\n\n/**\n * @return a summary of the binning scheme determined from the given max number of bins\n */\nfunction binSummary(maxbins: number, summary: DLFieldProfile): DLFieldProfile {\n  const bin = dlBin({\n    min: summary.min,\n    max: summary.max,\n    maxbins: maxbins\n  });\n\n  // start with summary, pre-binning\n  const result = extend({}, summary);\n  result.unique = binUnique(bin, summary.unique);\n  result.distinct = (bin.stop - bin.start) / bin.step;\n  result.min = bin.start;\n  result.max = bin.stop;\n\n  return result;\n}\n\n/** @return a modified version of the passed summary with unique and distinct set according to the timeunit.\n *  Maps 'null' (string) keys to the null value and invalid dates to 'Invalid Date' in the unique dictionary.\n */\nfunction timeSummary(timeunit: TimeUnit, summary: DLFieldProfile): DLFieldProfile {\n  const result = extend({}, summary);\n\n  let unique: {[value: string]: number} = {};\n  keys(summary.unique).forEach(function(dateString) {\n    // don't convert null value because the Date constructor will actually convert it to a date\n    let date: Date = dateString === 'null' ? null : new Date(dateString);\n    // at this point, `date` is either the null value, a valid Date object, or \"Invalid Date\" which is a Date\n    let key: string;\n    if (date === null) {\n      key = null;\n    } else if (isNaN(date.getTime())) {\n      key = 'Invalid Date';\n    } else {\n      key = (timeunit === TimeUnit.DAY ? date.getDay() : convert(timeunit, date)).toString();\n    }\n    unique[key] = (unique[key] || 0) + summary.unique[dateString];\n  });\n\n  result.unique = unique;\n  result.distinct = keys(unique).length;\n\n  return result;\n}\n\n/**\n * @return a new unique object based off of the old unique count and a binning scheme\n */\nfunction binUnique(bin: any, oldUnique: any) {\n  const newUnique = {};\n  for (let value in oldUnique) {\n    let bucket: number;\n    if (value === null) {\n      bucket = null;\n    } else if (isNaN(Number(value))) {\n      bucket = NaN;\n    } else {\n      bucket = bin.value(Number(value)) as number;\n    }\n    newUnique[bucket] = (newUnique[bucket] || 0) + oldUnique[value];\n  }\n  return newUnique;\n}\n\n/** @return the number of items in list that occur as keys of unique */\nfunction invalidCount(unique: {}, list: any[]) {\n  return list.reduce(function(prev, cur) {\n    return unique[cur] ? prev + 1 : prev;\n  }, 0);\n}\n\nexport enum PrimitiveType {\n  STRING = 'string' as any,\n  NUMBER = 'number' as any,\n  INTEGER = 'integer' as any,\n  BOOLEAN = 'boolean' as any,\n  DATETIME = 'datetime' as any\n}\n","import {QueryConfig} from '../config';\nimport {isEncodingNestedProp, Property} from '../property';\nimport {PropIndex} from '../propindex';\nimport {isWildcard, Wildcard} from '../wildcard';\nimport {Schema} from '../schema';\nimport { every} from '../util';\n\nimport {EncodingQueryBase} from '../query/encoding';\n\n/**\n * Abstract interface for a constraint.\n */\nexport interface AbstractConstraint {\n  name: string;\n  description: string;\n  properties: Property[];\n\n  /**\n   * Whether this constraint requires all specified properties types to be specific\n   * in order to call satisfy function.\n   */\n  allowWildcardForProperties: boolean;\n\n  /**\n   * Whether this constraint is strict (not optional).\n   */\n  strict: boolean;\n}\n\n/**\n * Abstract model for a constraint.\n */\nexport class AbstractConstraintModel {\n  protected constraint: AbstractConstraint;\n\n  constructor(constraint: AbstractConstraint) {\n    this.constraint = constraint;\n  }\n\n  public name(): string {\n    return this.constraint.name;\n  }\n\n  public description(): string {\n    return this.constraint.description;\n  }\n\n  public properties(): Property[] {\n    return this.constraint.properties;\n  }\n\n  public strict(): boolean {\n    return this.constraint.strict;\n  }\n}\n\n/**\n * Collection of constraints for a single encoding mapping.\n */\n\n/** A method for satisfying whether the provided encoding query satisfy the constraint. */\nexport interface EncodingConstraintChecker<E extends EncodingQueryBase> {\n  (encQ: E, schema: Schema, encWildcardIndex: PropIndex<Wildcard<any>>, opt: QueryConfig): boolean;\n}\n\nexport class EncodingConstraintModel<E extends EncodingQueryBase> extends AbstractConstraintModel {\n  constructor(constraint: EncodingConstraint<E>) {\n    super(constraint);\n  }\n\n  public hasAllRequiredPropertiesSpecific(encQ: E): boolean {\n    return every(this.constraint.properties, (prop: Property) => {\n\n      if (isEncodingNestedProp(prop)) {\n        let parent = prop.parent;\n        let child = prop.child;\n\n        if (!encQ[parent]) {\n          return true;\n        }\n\n        return !isWildcard(encQ[parent][child]);\n      }\n\n      if (!encQ[prop]) {\n        return true;\n      }\n\n      return !isWildcard(encQ[prop]);\n    });\n  }\n\n  public satisfy(encQ: E, schema: Schema, encWildcardIndex: PropIndex<Wildcard<any>>, opt: QueryConfig): boolean {\n    // TODO: Re-order logic to optimize the \"allowWildcardForProperties\" check\n    if (!this.constraint.allowWildcardForProperties) {\n      // TODO: extract as a method and do unit test\n\n      if (!this.hasAllRequiredPropertiesSpecific(encQ)) {\n        return true;\n      }\n    }\n    return (this.constraint as EncodingConstraint<E>).satisfy(encQ, schema, encWildcardIndex, opt);\n  }\n}\n\n/** Constraint for a single encoding mapping */\nexport interface EncodingConstraint<E extends EncodingQueryBase> extends AbstractConstraint {\n  /** Method for checking if the encoding query satisfies this constraint. */\n  satisfy: EncodingConstraintChecker<E>;\n}\n","import * as CHANNEL from 'vega-lite/build/src/channel';\nimport {Channel} from 'vega-lite/build/src/channel';\nimport {channelCompatibility, TypedFieldDef} from 'vega-lite/build/src/channeldef';\nimport {\n  channelScalePropertyIncompatability,\n  hasDiscreteDomain,\n  Scale,\n  ScaleType,\n  scaleTypeSupportProperty\n} from 'vega-lite/build/src/scale';\nimport {isLocalSingleTimeUnit, isUtcSingleTimeUnit} from 'vega-lite/build/src/timeunit';\nimport * as TYPE from 'vega-lite/build/src/type';\nimport {QueryConfig} from '../config';\nimport {getEncodingNestedProp, Property, SCALE_PROPS} from '../property';\nimport {PropIndex} from '../propindex';\nimport {AutoCountQuery, FieldQuery, isFieldQuery, ScaleQuery, scaleType, toFieldDef} from '../query/encoding';\nimport {ExpandedType, isDiscrete} from '../query/expandedtype';\nimport {PrimitiveType, Schema} from '../schema';\nimport {contains} from '../util';\nimport {isWildcard, Wildcard} from '../wildcard';\nimport {EncodingConstraint, EncodingConstraintModel} from './base';\n\nexport const FIELD_CONSTRAINTS: EncodingConstraintModel<FieldQuery>[] = [\n  {\n    name: 'aggregateOpSupportedByType',\n    description: 'Aggregate function should be supported by data type.',\n    properties: [Property.TYPE, Property.AGGREGATE],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (fieldQ: FieldQuery, _: Schema, __: PropIndex<Wildcard<any>>, ___: QueryConfig) => {\n      if (fieldQ.aggregate) {\n        return !isDiscrete(fieldQ.type);\n      }\n      // TODO: some aggregate function are actually supported by ordinal\n      return true; // no aggregate is okay with any type.\n    }\n  },\n  {\n    name: 'asteriskFieldWithCountOnly',\n    description: 'Field=\"*\" should be disallowed except aggregate=\"count\"',\n    properties: [Property.FIELD, Property.AGGREGATE],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (fieldQ: FieldQuery, _: Schema, __: PropIndex<Wildcard<any>>, ___: QueryConfig) => {\n      return (fieldQ.field === '*') === (fieldQ.aggregate === 'count');\n    }\n  },\n  {\n    name: 'minCardinalityForBin',\n    description: 'binned quantitative field should not have too low cardinality',\n    properties: [Property.BIN, Property.FIELD, Property.TYPE],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (fieldQ: FieldQuery, schema: Schema, _: PropIndex<Wildcard<any>>, opt: QueryConfig) => {\n      if (fieldQ.bin && fieldQ.type === TYPE.QUANTITATIVE) {\n        // We remove bin so schema can infer the raw unbinned cardinality.\n        let fieldQwithoutBin: FieldQuery = {\n          channel: fieldQ.channel,\n          field: fieldQ.field,\n          type: fieldQ.type\n        };\n        return schema.cardinality(fieldQwithoutBin) >= opt.minCardinalityForBin;\n      }\n      return true;\n    }\n  },\n  {\n    name: 'binAppliedForQuantitative',\n    description: 'bin should be applied to quantitative field only.',\n    properties: [Property.TYPE, Property.BIN],\n    allowWildcardForProperties: false,\n    strict: true, // FIXME VL2.0 actually support ordinal type for bin\n    satisfy: (fieldQ: FieldQuery, _: Schema, __: PropIndex<Wildcard<any>>, ___: QueryConfig) => {\n      if (fieldQ.bin) {\n        // If binned, the type must be quantitative\n        return fieldQ.type === TYPE.QUANTITATIVE;\n      }\n      return true;\n    }\n  },\n  {\n    name: 'channelFieldCompatible',\n    description: `encoding channel's range type be compatible with channel type.`,\n    properties: [Property.CHANNEL, Property.TYPE, Property.BIN, Property.TIMEUNIT],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (fieldQ: FieldQuery, schema: Schema, encWildcardIndex: PropIndex<Wildcard<any>>, opt: QueryConfig) => {\n      const fieldDef: TypedFieldDef<string> = {\n        field: 'f', // actual field doesn't really matter here\n        ...toFieldDef(fieldQ, {schema, props: ['bin', 'timeUnit', 'type']})\n      };\n\n      const {compatible} = channelCompatibility(fieldDef, fieldQ.channel as Channel);\n\n      if (compatible) {\n        return true;\n      } else {\n        // In VL, facet's field def must be discrete (O/N), but in CompassQL we can relax this a bit.\n        const isFacet = fieldQ.channel === 'row' || fieldQ.channel === 'column';\n\n        if (isFacet && (isLocalSingleTimeUnit(fieldDef.timeUnit) || isUtcSingleTimeUnit(fieldDef.timeUnit))) {\n          return true;\n        }\n        return false;\n      }\n    }\n  },\n  {\n    name: 'hasFn',\n    description: 'A field with as hasFn flag should have one of aggregate, timeUnit, or bin.',\n    properties: [Property.AGGREGATE, Property.BIN, Property.TIMEUNIT],\n    allowWildcardForProperties: true,\n    strict: true,\n    satisfy: (fieldQ: FieldQuery, _: Schema, __: PropIndex<Wildcard<any>>, ___: QueryConfig) => {\n      if (fieldQ.hasFn) {\n        return !!fieldQ.aggregate || !!fieldQ.bin || !!fieldQ.timeUnit;\n      }\n      return true;\n    }\n  },\n  {\n    name: 'omitScaleZeroWithBinnedField',\n    description: 'Do not use scale zero with binned field',\n    properties: [Property.SCALE, getEncodingNestedProp('scale', 'zero'), Property.BIN],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (fieldQ: FieldQuery, _: Schema, __: PropIndex<Wildcard<any>>, ___: QueryConfig) => {\n      if (fieldQ.bin && fieldQ.scale) {\n        if ((fieldQ.scale as ScaleQuery).zero === true) {\n          return false;\n        }\n      }\n      return true;\n    }\n  },\n  {\n    name: 'onlyOneTypeOfFunction',\n    description: 'Only of of aggregate, autoCount, timeUnit, or bin should be applied at the same time.',\n    properties: [Property.AGGREGATE, Property.AUTOCOUNT, Property.TIMEUNIT, Property.BIN],\n    allowWildcardForProperties: true,\n    strict: true,\n    satisfy: (fieldQ: FieldQuery | AutoCountQuery, _: Schema, __: PropIndex<Wildcard<any>>, ___: QueryConfig) => {\n      if (isFieldQuery(fieldQ)) {\n        const numFn =\n          (!isWildcard(fieldQ.aggregate) && !!fieldQ.aggregate ? 1 : 0) +\n          (!isWildcard(fieldQ.bin) && !!fieldQ.bin ? 1 : 0) +\n          (!isWildcard(fieldQ.timeUnit) && !!fieldQ.timeUnit ? 1 : 0);\n        return numFn <= 1;\n      }\n      // For autoCount there is always only one type of function\n      return true;\n    }\n  },\n  {\n    name: 'timeUnitAppliedForTemporal',\n    description: 'Time unit should be applied to temporal field only.',\n    properties: [Property.TYPE, Property.TIMEUNIT],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (fieldQ: FieldQuery, _: Schema, __: PropIndex<Wildcard<any>>, ___: QueryConfig) => {\n      if (fieldQ.timeUnit && fieldQ.type !== TYPE.TEMPORAL) {\n        return false;\n      }\n      return true;\n    }\n  },\n  {\n    name: 'timeUnitShouldHaveVariation',\n    description: 'A particular time unit should be applied only if they produce unique values.',\n    properties: [Property.TIMEUNIT, Property.TYPE],\n    allowWildcardForProperties: false,\n    strict: false,\n    satisfy: (fieldQ: FieldQuery, schema: Schema, encWildcardIndex: PropIndex<Wildcard<any>>, opt: QueryConfig) => {\n      if (fieldQ.timeUnit && fieldQ.type === TYPE.TEMPORAL) {\n        if (!encWildcardIndex.has('timeUnit') && !opt.constraintManuallySpecifiedValue) {\n          // Do not have to check this as this is manually specified by users.\n          return true;\n        }\n        return schema.timeUnitHasVariation(fieldQ);\n      }\n      return true;\n    }\n  },\n  {\n    name: 'scalePropertiesSupportedByScaleType',\n    description: 'Scale properties must be supported by correct scale type',\n    properties: [].concat(SCALE_PROPS, [Property.SCALE, Property.TYPE]),\n    allowWildcardForProperties: true,\n    strict: true,\n    satisfy: (fieldQ: FieldQuery, _: Schema, __: PropIndex<Wildcard<any>>, ___: QueryConfig) => {\n      if (fieldQ.scale) {\n        const scale: ScaleQuery = fieldQ.scale as ScaleQuery;\n\n        //  If fieldQ.type is an Wildcard and scale.type is undefined, it is equivalent\n        //  to scale type is Wildcard. If scale type is an Wildcard, we do not yet know\n        //  what the scale type is, and thus can ignore the constraint.\n\n        const sType = scaleType(fieldQ);\n\n        if (sType === undefined || sType === null) {\n          // If still ambiguous, doesn't check the constraint\n          return true;\n        }\n\n        for (let scaleProp in scale) {\n          if (scaleProp === 'type' || scaleProp === 'name' || scaleProp === 'enum') {\n            // ignore type and properties of wildcards\n            continue;\n          }\n          const sProp = scaleProp as keyof Scale;\n          if (sType === 'point') {\n            // HACK: our current implementation of scaleType() can return point\n            // when the scaleType is a band since we didn't pass all parameter to Vega-Lite's scale type method.\n            if (!scaleTypeSupportProperty('point', sProp) && !scaleTypeSupportProperty('band', sProp)) {\n              return false;\n            }\n          } else if (!scaleTypeSupportProperty(sType, sProp)) {\n            return false;\n          }\n        }\n      }\n      return true;\n    }\n  },\n  {\n    name: 'scalePropertiesSupportedByChannel',\n    description: 'Not all scale properties are supported by all encoding channels',\n    properties: [].concat(SCALE_PROPS, [Property.SCALE, Property.CHANNEL]),\n    allowWildcardForProperties: true,\n    strict: true,\n    satisfy: (fieldQ: FieldQuery, _: Schema, __: PropIndex<Wildcard<any>>, ___: QueryConfig) => {\n      if (fieldQ) {\n        let channel: Channel = fieldQ.channel as Channel;\n        let scale: ScaleQuery = fieldQ.scale as ScaleQuery;\n        if (channel && !isWildcard(channel) && scale) {\n          if (channel === 'row' || channel === 'column') {\n            // row / column do not have scale\n            return false;\n          }\n          for (let scaleProp in scale) {\n            if (!scale.hasOwnProperty(scaleProp)) continue;\n            if (scaleProp === 'type' || scaleProp === 'name' || scaleProp === 'enum') {\n              // ignore type and properties of wildcards\n              continue;\n            }\n            let isSupported = channelScalePropertyIncompatability(channel, scaleProp as keyof Scale) === undefined;\n            if (!isSupported) {\n              return false;\n            }\n          }\n        }\n      }\n      return true;\n    }\n  },\n  {\n    name: 'typeMatchesPrimitiveType',\n    description: \"Data type should be supported by field's primitive type.\",\n    properties: [Property.FIELD, Property.TYPE],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (fieldQ: FieldQuery, schema: Schema, encWildcardIndex: PropIndex<Wildcard<any>>, opt: QueryConfig) => {\n      if (fieldQ.field === '*') {\n        return true;\n      }\n\n      const primitiveType = schema.primitiveType(fieldQ.field as string);\n      const type = fieldQ.type;\n\n      if (!encWildcardIndex.has('field') && !encWildcardIndex.has('type') && !opt.constraintManuallySpecifiedValue) {\n        // Do not have to check this as this is manually specified by users.\n        return true;\n      }\n\n      switch (primitiveType) {\n        case PrimitiveType.BOOLEAN:\n        case PrimitiveType.STRING:\n          return type !== TYPE.QUANTITATIVE && type !== TYPE.TEMPORAL;\n        case PrimitiveType.NUMBER:\n        case PrimitiveType.INTEGER:\n          return type !== TYPE.TEMPORAL;\n        case PrimitiveType.DATETIME:\n          // TODO: add NOMINAL, ORDINAL support after we support this in Vega-Lite\n          return type === TYPE.TEMPORAL;\n        case null:\n          // field does not exist in the schema\n          return false;\n      }\n      throw new Error('Not implemented');\n    }\n  },\n  {\n    name: 'typeMatchesSchemaType',\n    description: \"Enumerated data type of a field should match the field's type in the schema.\",\n    properties: [Property.FIELD, Property.TYPE],\n    allowWildcardForProperties: false,\n    strict: false,\n    satisfy: (fieldQ: FieldQuery, schema: Schema, encWildcardIndex: PropIndex<Wildcard<any>>, opt: QueryConfig) => {\n      if (!encWildcardIndex.has('field') && !encWildcardIndex.has('type') && !opt.constraintManuallySpecifiedValue) {\n        // Do not have to check this as this is manually specified by users.\n        return true;\n      }\n\n      if (fieldQ.field === '*') {\n        return fieldQ.type === TYPE.QUANTITATIVE;\n      }\n\n      return schema.vlType(fieldQ.field as string) === fieldQ.type;\n    }\n  },\n  {\n    name: 'maxCardinalityForCategoricalColor',\n    description: 'Categorical channel should not have too high cardinality',\n    properties: [Property.CHANNEL, Property.FIELD],\n    allowWildcardForProperties: false,\n    strict: false,\n    satisfy: (fieldQ: FieldQuery, schema: Schema, _: PropIndex<Wildcard<any>>, opt: QueryConfig) => {\n      // TODO: missing case where ordinal / temporal use categorical color\n      // (once we do so, need to add Property.BIN, Property.TIMEUNIT)\n      if (fieldQ.channel === CHANNEL.COLOR && (fieldQ.type === TYPE.NOMINAL || fieldQ.type === ExpandedType.KEY)) {\n        return schema.cardinality(fieldQ) <= opt.maxCardinalityForCategoricalColor;\n      }\n      return true; // other channel is irrelevant to this constraint\n    }\n  },\n  {\n    name: 'maxCardinalityForFacet',\n    description: 'Row/column channel should not have too high cardinality',\n    properties: [Property.CHANNEL, Property.FIELD, Property.BIN, Property.TIMEUNIT],\n    allowWildcardForProperties: false,\n    strict: false,\n    satisfy: (fieldQ: FieldQuery, schema: Schema, _: PropIndex<Wildcard<any>>, opt: QueryConfig) => {\n      if (fieldQ.channel === CHANNEL.ROW || fieldQ.channel === CHANNEL.COLUMN) {\n        return schema.cardinality(fieldQ) <= opt.maxCardinalityForFacet;\n      }\n      return true; // other channel is irrelevant to this constraint\n    }\n  },\n  {\n    name: 'maxCardinalityForShape',\n    description: 'Shape channel should not have too high cardinality',\n    properties: [Property.CHANNEL, Property.FIELD, Property.BIN, Property.TIMEUNIT],\n    allowWildcardForProperties: false,\n    strict: false,\n    satisfy: (fieldQ: FieldQuery, schema: Schema, _: PropIndex<Wildcard<any>>, opt: QueryConfig) => {\n      if (fieldQ.channel === CHANNEL.SHAPE) {\n        return schema.cardinality(fieldQ) <= opt.maxCardinalityForShape;\n      }\n      return true; // other channel is irrelevant to this constraint\n    }\n  },\n  {\n    name: 'dataTypeAndFunctionMatchScaleType',\n    description: 'Scale type must match data type',\n    properties: [\n      Property.TYPE,\n      Property.SCALE,\n      getEncodingNestedProp('scale', 'type'),\n      Property.TIMEUNIT,\n      Property.BIN\n    ],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (fieldQ: FieldQuery, _: Schema, __: PropIndex<Wildcard<any>>, ___: QueryConfig) => {\n      if (fieldQ.scale) {\n        const type = fieldQ.type;\n        const sType = scaleType(fieldQ);\n\n        if (isDiscrete(type)) {\n          return sType === undefined || hasDiscreteDomain(sType);\n        } else if (type === TYPE.TEMPORAL) {\n          if (!fieldQ.timeUnit) {\n            return contains([ScaleType.TIME, ScaleType.UTC, undefined], sType);\n          } else {\n            return contains([ScaleType.TIME, ScaleType.UTC, undefined], sType) || hasDiscreteDomain(sType);\n          }\n        } else if (type === TYPE.QUANTITATIVE) {\n          if (fieldQ.bin) {\n            return contains([ScaleType.LINEAR, undefined], sType);\n          } else {\n            return contains(\n              [\n                ScaleType.LOG,\n                ScaleType.POW,\n                ScaleType.SQRT,\n                ScaleType.QUANTILE,\n                ScaleType.QUANTIZE,\n                ScaleType.LINEAR,\n                undefined\n              ],\n              sType\n            );\n          }\n        }\n      }\n      return true;\n    }\n  },\n  {\n    name: 'stackIsOnlyUsedWithXY',\n    description: 'stack should only be allowed for x and y channels',\n    properties: [Property.STACK, Property.CHANNEL],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (fieldQ: FieldQuery, _: Schema, __: PropIndex<Wildcard<any>>, ___: QueryConfig) => {\n      if (!!fieldQ.stack) {\n        return fieldQ.channel === CHANNEL.X || fieldQ.channel === CHANNEL.Y;\n      }\n      return true;\n    }\n  }\n].map((ec: EncodingConstraint<FieldQuery>) => new EncodingConstraintModel<FieldQuery>(ec));\n\nexport const FIELD_CONSTRAINT_INDEX: {\n  [name: string]: EncodingConstraintModel<FieldQuery | AutoCountQuery>;\n} = FIELD_CONSTRAINTS.reduce((m, ec: EncodingConstraintModel<FieldQuery | AutoCountQuery>) => {\n  m[ec.name()] = ec;\n  return m;\n}, {});\n\nexport const FIELD_CONSTRAINTS_BY_PROPERTY = FIELD_CONSTRAINTS.reduce((index, c) => {\n  for (const prop of c.properties()) {\n    // Initialize array and use it\n    index.set(prop, index.get(prop) || []);\n    index.get(prop).push(c);\n  }\n  return index;\n}, new PropIndex<EncodingConstraintModel<FieldQuery>[]>());\n","import {QueryConfig} from '../config';\nimport {Property} from '../property';\nimport {PropIndex} from '../propindex';\nimport {Wildcard} from '../wildcard';\nimport {Schema} from '../schema';\nimport {contains} from '../util';\n\nimport {ValueQuery} from '../query/encoding';\nimport {EncodingConstraintModel, EncodingConstraint} from './base';\n\nexport const VALUE_CONSTRAINTS: EncodingConstraintModel<ValueQuery>[] = [\n  {\n    name: 'doesNotSupportConstantValue',\n    description: 'row, column, x, y, order, and detail should not work with constant values.',\n    properties: [Property.TYPE, Property.AGGREGATE],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (valueQ: ValueQuery, _: Schema, __: PropIndex<Wildcard<any>>, ___: QueryConfig) => {\n\n     return !(contains(['row', 'column', 'x', 'y', 'detail', 'order'], valueQ.channel));\n    }\n  }\n].map((ec: EncodingConstraint<ValueQuery>) => new EncodingConstraintModel<ValueQuery>(ec));\n\nexport const VALUE_CONSTRAINT_INDEX: {[name: string]: EncodingConstraintModel<ValueQuery>} =\n  VALUE_CONSTRAINTS.reduce((m, ec: EncodingConstraintModel<ValueQuery>) => {\n    m[ec.name()] = ec;\n    return m;\n  }, {});\n\nexport const VALUE_CONSTRAINTS_BY_PROPERTY =\n  VALUE_CONSTRAINTS.reduce((index, c) => {\n    for (const prop of c.properties()) {\n      index.set(prop, index.get(prop) || []);\n      index.get(prop).push(c);\n    }\n\n    return index;\n  }, new PropIndex<EncodingConstraintModel<ValueQuery>[]>());\n","import {QueryConfig} from '../config';\nimport {SpecQueryModel} from '../model';\nimport {Property} from '../property';\nimport {Wildcard} from '../wildcard';\nimport {Schema} from '../schema';\n\nimport {isValueQuery} from '../query/encoding';\nimport {FIELD_CONSTRAINTS_BY_PROPERTY} from './field';\nimport {VALUE_CONSTRAINTS_BY_PROPERTY} from './value';\n\n/**\n * Check all encoding constraints for a particular property and index tuple\n */\nexport function checkEncoding(prop: Property, wildcard: Wildcard<any>, index: number,\n  specM: SpecQueryModel, schema: Schema, opt: QueryConfig): string {\n\n  // Check encoding constraint\n  const encodingConstraints = FIELD_CONSTRAINTS_BY_PROPERTY.get(prop) || [];\n  const encQ = specM.getEncodingQueryByIndex(index);\n\n  for (const c of encodingConstraints) {\n    // Check if the constraint is enabled\n    if (c.strict() || !!opt[c.name()]) {\n      // For strict constraint, or enabled non-strict, check the constraints\n\n      const satisfy = c.satisfy(encQ, schema, specM.wildcardIndex.encodings[index], opt);\n      if (!satisfy) {\n        let violatedConstraint = '(enc) ' + c.name();\n        /* istanbul ignore if */\n        if (opt.verbose) {\n          console.log(violatedConstraint + ' failed with ' + specM.toShorthand() + ' for ' + wildcard.name);\n        }\n        return violatedConstraint;\n      }\n    }\n  }\n\n  const valueContraints = VALUE_CONSTRAINTS_BY_PROPERTY.get(prop) || [];\n\n  for (const c of valueContraints) {\n    // Check if the constraint is enabled\n    if ((c.strict() || !!opt[c.name()]) && isValueQuery(encQ)) {\n      // For strict constraint, or enabled non-strict, check the constraints\n      const satisfy = c.satisfy(encQ, schema, specM.wildcardIndex.encodings[index], opt);\n      if (!satisfy) {\n        let violatedConstraint = '(enc) ' + c.name();\n        /* istanbul ignore if */\n        if (opt.verbose) {\n          console.log(violatedConstraint + ' failed with ' + specM.toShorthand() + ' for ' + wildcard.name);\n        }\n        return violatedConstraint;\n      }\n    }\n  }\n  return null;\n}\n","import {SUM_OPS} from 'vega-lite/build/src/aggregate';\nimport * as CHANNEL from 'vega-lite/build/src/channel';\nimport {NONPOSITION_CHANNELS, supportMark} from 'vega-lite/build/src/channel';\nimport * as MARK from 'vega-lite/build/src/mark';\nimport {Mark} from 'vega-lite/build/src/mark';\nimport {ScaleType} from 'vega-lite/build/src/scale';\nimport * as TYPE from 'vega-lite/build/src/type';\nimport {QueryConfig} from '../config';\nimport {SpecQueryModel} from '../model';\nimport {getEncodingNestedProp, isEncodingNestedProp, isEncodingProperty, Property} from '../property';\nimport {PropIndex} from '../propindex';\nimport {\n  EncodingQuery,\n  FieldQuery,\n  isAutoCountQuery,\n  isDimension,\n  isDisabledAutoCountQuery,\n  isEnabledAutoCountQuery,\n  isFieldQuery,\n  isMeasure,\n  isValueQuery,\n  ScaleQuery,\n  scaleType\n} from '../query/encoding';\nimport {ExpandedType} from '../query/expandedtype';\nimport {Schema} from '../schema';\nimport {contains, every, some} from '../util';\nimport {isWildcard, Wildcard} from '../wildcard';\nimport {AbstractConstraint, AbstractConstraintModel} from './base';\n\nconst NONPOSITION_CHANNELS_INDEX = NONPOSITION_CHANNELS.reduce((m, channel) => {\n  m[channel] = true;\n  return m;\n}, {});\n\nexport interface SpecConstraintChecker {\n  (specM: SpecQueryModel, schema: Schema, opt: QueryConfig): boolean;\n}\n\nexport class SpecConstraintModel extends AbstractConstraintModel {\n  constructor(specConstraint: SpecConstraint) {\n    super(specConstraint);\n  }\n\n  public hasAllRequiredPropertiesSpecific(specM: SpecQueryModel): boolean {\n    return every(this.constraint.properties, prop => {\n      if (prop === Property.MARK) {\n        return !isWildcard(specM.getMark());\n      }\n\n      // TODO: transform\n\n      if (isEncodingNestedProp(prop)) {\n        let parent = prop.parent;\n        let child = prop.child;\n\n        return every(specM.getEncodings(), encQ => {\n          if (!encQ[parent]) {\n            return true;\n          }\n\n          return !isWildcard(encQ[parent][child]);\n        });\n      }\n\n      if (!isEncodingProperty(prop)) {\n        throw new Error('UNIMPLEMENTED');\n      }\n\n      return every(specM.getEncodings(), encQ => {\n        if (!encQ[prop]) {\n          return true;\n        }\n        return !isWildcard(encQ[prop]);\n      });\n    });\n  }\n\n  public satisfy(specM: SpecQueryModel, schema: Schema, opt: QueryConfig) {\n    // TODO: Re-order logic to optimize the \"allowWildcardForProperties\" check\n    if (!this.constraint.allowWildcardForProperties) {\n      if (!this.hasAllRequiredPropertiesSpecific(specM)) {\n        return true;\n      }\n    }\n\n    return (this.constraint as SpecConstraint).satisfy(specM, schema, opt);\n  }\n}\n\nexport interface SpecConstraint extends AbstractConstraint {\n  /** Method for checking if the spec query satisfies this constraint. */\n  satisfy: SpecConstraintChecker;\n}\n\nexport const SPEC_CONSTRAINTS: SpecConstraintModel[] = [\n  {\n    name: 'noRepeatedChannel',\n    description: 'Each encoding channel should only be used once.',\n    properties: [Property.CHANNEL],\n    allowWildcardForProperties: true,\n    strict: true,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      let usedChannel = {};\n\n      // channel for all encodings should be valid\n      return every(specM.getEncodings(), encQ => {\n        if (!isWildcard(encQ.channel)) {\n          // If channel is specified, it should no be used already\n          if (usedChannel[encQ.channel]) {\n            return false;\n          }\n          usedChannel[encQ.channel] = true;\n          return true;\n        }\n        return true; // unspecified channel is valid\n      });\n    }\n  },\n  {\n    name: 'alwaysIncludeZeroInScaleWithBarMark',\n    description: 'Do not recommend bar mark if scale does not start at zero',\n    properties: [\n      Property.MARK,\n      Property.SCALE,\n      getEncodingNestedProp('scale', 'zero'),\n      Property.CHANNEL,\n      Property.TYPE\n    ],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      const mark = specM.getMark();\n      const encodings = specM.getEncodings();\n\n      if (mark === MARK.BAR) {\n        for (let encQ of encodings) {\n          if (\n            isFieldQuery(encQ) &&\n            (encQ.channel === CHANNEL.X || encQ.channel === CHANNEL.Y) &&\n            encQ.type === TYPE.QUANTITATIVE &&\n            (encQ.scale && (encQ.scale as ScaleQuery).zero === false)\n          ) {\n            // TODO: zero shouldn't be manually specified\n            return false;\n          }\n        }\n      }\n\n      return true;\n    }\n  },\n  {\n    name: 'autoAddCount',\n    description:\n      'Automatically adding count only for plots with only ordinal, binned quantitative, or temporal with timeunit fields.',\n    properties: [Property.BIN, Property.TIMEUNIT, Property.TYPE, Property.AUTOCOUNT],\n    allowWildcardForProperties: true,\n    strict: false,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      const hasAutoCount = some(specM.getEncodings(), (encQ: EncodingQuery) => isEnabledAutoCountQuery(encQ));\n\n      if (hasAutoCount) {\n        // Auto count should only be applied if all fields are nominal, ordinal, temporal with timeUnit, binned quantitative, or autoCount\n        return every(specM.getEncodings(), (encQ: EncodingQuery) => {\n          if (isValueQuery(encQ)) {\n            return true;\n          }\n\n          if (isAutoCountQuery(encQ)) {\n            return true;\n          }\n\n          switch (encQ.type) {\n            case TYPE.QUANTITATIVE:\n              return !!encQ.bin;\n            case TYPE.TEMPORAL:\n              return !!encQ.timeUnit;\n            case TYPE.ORDINAL:\n            case ExpandedType.KEY:\n            case TYPE.NOMINAL:\n              return true;\n          }\n          /* istanbul ignore next */\n          throw new Error('Unsupported Type');\n        });\n      } else {\n        const autoCountEncIndex = specM.wildcardIndex.encodingIndicesByProperty.get('autoCount') || [];\n        const neverHaveAutoCount = every(autoCountEncIndex, (index: number) => {\n          let encQ = specM.getEncodingQueryByIndex(index);\n          return isAutoCountQuery(encQ) && !isWildcard(encQ.autoCount);\n        });\n        if (neverHaveAutoCount) {\n          // If the query surely does not have autoCount\n          // then one of the field should be\n          // (1) unbinned quantitative\n          // (2) temporal without time unit\n          // (3) nominal or ordinal field\n          // or at least have potential to be (still ambiguous).\n          return some(specM.getEncodings(), (encQ: EncodingQuery) => {\n            if ((isFieldQuery(encQ) || isAutoCountQuery(encQ)) && encQ.type === TYPE.QUANTITATIVE) {\n              if (isDisabledAutoCountQuery(encQ)) {\n                return false;\n              } else {\n                return isFieldQuery(encQ) && (!encQ.bin || isWildcard(encQ.bin));\n              }\n            } else if (isFieldQuery(encQ) && encQ.type === TYPE.TEMPORAL) {\n              return !encQ.timeUnit || isWildcard(encQ.timeUnit);\n            }\n            return false; // nominal or ordinal\n          });\n        }\n      }\n\n      return true; // no auto count, no constraint\n    }\n  },\n  {\n    name: 'channelPermittedByMarkType',\n    description: 'Each encoding channel should be supported by the mark type',\n    properties: [Property.CHANNEL, Property.MARK],\n    allowWildcardForProperties: true, // only require mark\n    strict: true,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      const mark = specM.getMark();\n\n      // if mark is unspecified, no need to check\n      if (isWildcard(mark)) return true;\n\n      // TODO: can optimize this to detect only what's the changed property if needed.\n      return every(specM.getEncodings(), encQ => {\n        // channel unspecified, no need to check\n        if (isWildcard(encQ.channel)) return true;\n\n        return !!supportMark(encQ.channel, mark as Mark);\n      });\n    }\n  },\n  {\n    name: 'hasAllRequiredChannelsForMark',\n    description: 'All required channels for the specified mark should be specified',\n    properties: [Property.CHANNEL, Property.MARK],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      const mark = specM.getMark();\n\n      switch (mark) {\n        case MARK.AREA:\n        case MARK.LINE:\n          return specM.channelUsed(CHANNEL.X) && specM.channelUsed(CHANNEL.Y);\n        case MARK.TEXT:\n          return specM.channelUsed(CHANNEL.TEXT);\n        case MARK.BAR:\n        case MARK.CIRCLE:\n        case MARK.SQUARE:\n        case MARK.TICK:\n        case MARK.RULE:\n        case MARK.RECT:\n          return specM.channelUsed(CHANNEL.X) || specM.channelUsed(CHANNEL.Y);\n        case MARK.POINT:\n          // This allows generating a point plot if channel was not a wildcard.\n          return (\n            !specM.wildcardIndex.hasProperty(Property.CHANNEL) ||\n            specM.channelUsed(CHANNEL.X) ||\n            specM.channelUsed(CHANNEL.Y)\n          );\n      }\n      /* istanbul ignore next */\n      throw new Error('hasAllRequiredChannelsForMark not implemented for mark' + JSON.stringify(mark));\n    }\n  },\n  {\n    name: 'omitAggregate',\n    description: 'Omit aggregate plots.',\n    properties: [Property.AGGREGATE, Property.AUTOCOUNT],\n    allowWildcardForProperties: true,\n    strict: false,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      if (specM.isAggregate()) {\n        return false;\n      }\n      return true;\n    }\n  },\n  {\n    name: 'omitAggregatePlotWithDimensionOnlyOnFacet',\n    description: 'Omit aggregate plots with dimensions only on facets as that leads to inefficient use of space.',\n    properties: [Property.CHANNEL, Property.AGGREGATE, Property.AUTOCOUNT],\n    allowWildcardForProperties: false,\n    strict: false,\n    satisfy: (specM: SpecQueryModel, _: Schema, opt: QueryConfig) => {\n      if (specM.isAggregate()) {\n        let hasNonFacetDim = false,\n          hasDim = false,\n          hasEnumeratedFacetDim = false;\n        specM.specQuery.encodings.forEach((encQ, index) => {\n          if (isValueQuery(encQ) || isDisabledAutoCountQuery(encQ)) return; // skip unused field\n\n          // FieldQuery & !encQ.aggregate\n          if (isFieldQuery(encQ) && !encQ.aggregate) {\n            // isDimension\n            hasDim = true;\n            if (contains([CHANNEL.ROW, CHANNEL.COLUMN], encQ.channel)) {\n              if (specM.wildcardIndex.hasEncodingProperty(index, Property.CHANNEL)) {\n                hasEnumeratedFacetDim = true;\n              }\n            } else {\n              hasNonFacetDim = true;\n            }\n          }\n        });\n        if (hasDim && !hasNonFacetDim) {\n          if (hasEnumeratedFacetDim || opt.constraintManuallySpecifiedValue) {\n            return false;\n          }\n        }\n      }\n      return true;\n    }\n  },\n  {\n    name: 'omitAggregatePlotWithoutDimension',\n    description: 'Aggregate plots without dimension should be omitted',\n    properties: [Property.AGGREGATE, Property.AUTOCOUNT, Property.BIN, Property.TIMEUNIT, Property.TYPE],\n    allowWildcardForProperties: false,\n    strict: false,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      if (specM.isAggregate()) {\n        // TODO relax\n        return some(specM.getEncodings(), (encQ: EncodingQuery) => {\n          if (isDimension(encQ) || (isFieldQuery(encQ) && encQ.type === 'temporal')) {\n            return true;\n          }\n          return false;\n        });\n      }\n      return true;\n    }\n  },\n  {\n    // TODO: we can be smarter and check if bar has occlusion based on profiling statistics\n    name: 'omitBarLineAreaWithOcclusion',\n    description: \"Don't use bar, line or area to visualize raw plot as they often lead to occlusion.\",\n    properties: [Property.MARK, Property.AGGREGATE, Property.AUTOCOUNT],\n    allowWildcardForProperties: false,\n    strict: false,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      if (contains([MARK.BAR, MARK.LINE, MARK.AREA], specM.getMark())) {\n        return specM.isAggregate();\n      }\n      return true;\n    }\n  },\n  {\n    name: 'omitBarTickWithSize',\n    description: 'Do not map field to size channel with bar and tick mark',\n    properties: [Property.CHANNEL, Property.MARK],\n    allowWildcardForProperties: true,\n    strict: false,\n    satisfy: (specM: SpecQueryModel, _: Schema, opt: QueryConfig) => {\n      const mark = specM.getMark();\n      if (contains([MARK.TICK, MARK.BAR], mark)) {\n        if (specM.channelEncodingField(CHANNEL.SIZE)) {\n          if (opt.constraintManuallySpecifiedValue) {\n            // If size is used and we constraintManuallySpecifiedValue,\n            // then the spec violates this constraint.\n            return false;\n          } else {\n            // Otherwise have to search for the size channel and check if it is enumerated\n            const encodings = specM.specQuery.encodings;\n            for (let i = 0; i < encodings.length; i++) {\n              const encQ = encodings[i];\n              if (encQ.channel === CHANNEL.SIZE) {\n                if (specM.wildcardIndex.hasEncodingProperty(i, Property.CHANNEL)) {\n                  // If enumerated, then this is bad\n                  return false;\n                } else {\n                  // If it's manually specified, no need to continue searching, just return.\n                  return true;\n                }\n              }\n            }\n          }\n        }\n      }\n      return true; // skip\n    }\n  },\n  {\n    name: 'omitBarAreaForLogScale',\n    description: \"Do not use bar and area mark for x and y's log scale\",\n    properties: [\n      Property.MARK,\n      Property.CHANNEL,\n      Property.SCALE,\n      getEncodingNestedProp('scale', 'type'),\n      Property.TYPE\n    ],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      const mark = specM.getMark();\n      const encodings = specM.getEncodings();\n\n      // TODO: mark or scale type should be enumerated\n      if (mark === MARK.AREA || mark === MARK.BAR) {\n        for (let encQ of encodings) {\n          if (isFieldQuery(encQ) && ((encQ.channel === CHANNEL.X || encQ.channel === CHANNEL.Y) && encQ.scale)) {\n            let sType = scaleType(encQ);\n\n            if (sType === ScaleType.LOG) {\n              return false;\n            }\n          }\n        }\n      }\n      return true;\n    }\n  },\n  {\n    name: 'omitMultipleNonPositionalChannels',\n    description:\n      'Unless manually specified, do not use multiple non-positional encoding channel to avoid over-encoding.',\n    properties: [Property.CHANNEL],\n    allowWildcardForProperties: true,\n    strict: false,\n    satisfy: (specM: SpecQueryModel, _: Schema, opt: QueryConfig) => {\n      // have to use specM.specQuery.encodings insetad of specM.getEncodings()\n      // since specM.getEncodings() remove encQ with autoCount===false from the array\n      // and thus might shift the index\n      const encodings = specM.specQuery.encodings;\n      let nonPositionChannelCount = 0;\n      let hasEnumeratedNonPositionChannel = false;\n\n      for (let i = 0; i < encodings.length; i++) {\n        const encQ = encodings[i];\n        if (isValueQuery(encQ) || isDisabledAutoCountQuery(encQ)) {\n          continue; // ignore skipped encoding\n        }\n\n        const channel = encQ.channel;\n        if (!isWildcard(channel)) {\n          if (NONPOSITION_CHANNELS_INDEX[channel + '']) {\n            nonPositionChannelCount += 1;\n            if (specM.wildcardIndex.hasEncodingProperty(i, Property.CHANNEL)) {\n              hasEnumeratedNonPositionChannel = true;\n            }\n            if (\n              nonPositionChannelCount > 1 &&\n              (hasEnumeratedNonPositionChannel || opt.constraintManuallySpecifiedValue)\n            ) {\n              return false;\n            }\n          }\n        }\n      }\n      return true;\n    }\n  },\n  {\n    name: 'omitNonPositionalOrFacetOverPositionalChannels',\n    description: 'Do not use non-positional channels unless all positional channels are used',\n    properties: [Property.CHANNEL],\n    allowWildcardForProperties: false,\n    strict: false,\n    satisfy: (specM: SpecQueryModel, _: Schema, opt: QueryConfig) => {\n      const encodings = specM.specQuery.encodings;\n      let hasNonPositionalChannelOrFacet = false;\n      let hasEnumeratedNonPositionOrFacetChannel = false;\n      let hasX = false,\n        hasY = false;\n      for (let i = 0; i < encodings.length; i++) {\n        const encQ = encodings[i];\n        if (isValueQuery(encQ) || isDisabledAutoCountQuery(encQ)) {\n          continue; // ignore skipped encoding\n        }\n\n        const channel = encQ.channel;\n        if (channel === CHANNEL.X) {\n          hasX = true;\n        } else if (channel === CHANNEL.Y) {\n          hasY = true;\n        } else if (!isWildcard(channel)) {\n          // All non positional channel / Facet\n          hasNonPositionalChannelOrFacet = true;\n          if (specM.wildcardIndex.hasEncodingProperty(i, Property.CHANNEL)) {\n            hasEnumeratedNonPositionOrFacetChannel = true;\n          }\n        }\n      }\n\n      if (\n        hasEnumeratedNonPositionOrFacetChannel ||\n        (opt.constraintManuallySpecifiedValue && hasNonPositionalChannelOrFacet)\n      ) {\n        return hasX && hasY;\n      }\n      return true;\n    }\n  },\n  {\n    name: 'omitRaw',\n    description: 'Omit raw plots.',\n    properties: [Property.AGGREGATE, Property.AUTOCOUNT],\n    allowWildcardForProperties: false,\n    strict: false,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      if (!specM.isAggregate()) {\n        return false;\n      }\n      return true;\n    }\n  },\n  {\n    name: 'omitRawContinuousFieldForAggregatePlot',\n    description:\n      'Aggregate plot should not use raw continuous field as group by values. ' +\n      '(Quantitative should be binned. Temporal should have time unit.)',\n    properties: [Property.AGGREGATE, Property.AUTOCOUNT, Property.TIMEUNIT, Property.BIN, Property.TYPE],\n    allowWildcardForProperties: true,\n    strict: false,\n    satisfy: (specM: SpecQueryModel, _: Schema, opt: QueryConfig) => {\n      if (specM.isAggregate()) {\n        const encodings = specM.specQuery.encodings;\n        for (let i = 0; i < encodings.length; i++) {\n          const encQ = encodings[i];\n          if (isValueQuery(encQ) || isDisabledAutoCountQuery(encQ)) continue; // skip unused encoding\n\n          // TODO: aggregate for ordinal and temporal\n\n          if (isFieldQuery(encQ) && encQ.type === TYPE.TEMPORAL) {\n            // Temporal fields should have timeUnit or is still a wildcard\n            if (\n              !encQ.timeUnit &&\n              (specM.wildcardIndex.hasEncodingProperty(i, Property.TIMEUNIT) || opt.constraintManuallySpecifiedValue)\n            ) {\n              return false;\n            }\n          }\n          if (encQ.type === TYPE.QUANTITATIVE) {\n            if (isFieldQuery(encQ) && !encQ.bin && !encQ.aggregate) {\n              // If Raw Q\n              if (\n                specM.wildcardIndex.hasEncodingProperty(i, Property.BIN) ||\n                specM.wildcardIndex.hasEncodingProperty(i, Property.AGGREGATE) ||\n                specM.wildcardIndex.hasEncodingProperty(i, Property.AUTOCOUNT)\n              ) {\n                // and it's raw from enumeration\n                return false;\n              }\n              if (opt.constraintManuallySpecifiedValue) {\n                // or if we constraintManuallySpecifiedValue\n                return false;\n              }\n            }\n          }\n        }\n      }\n      return true;\n    }\n  },\n  {\n    name: 'omitRawDetail',\n    description: 'Do not use detail channel with raw plot.',\n    properties: [Property.CHANNEL, Property.AGGREGATE, Property.AUTOCOUNT],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (specM: SpecQueryModel, _: Schema, opt: QueryConfig) => {\n      if (specM.isAggregate()) {\n        return true;\n      }\n      return every(specM.specQuery.encodings, (encQ, index) => {\n        if (isValueQuery(encQ) || isDisabledAutoCountQuery(encQ)) return true; // ignore autoCount field\n\n        if (encQ.channel === CHANNEL.DETAIL) {\n          // Detail channel for raw plot is not good, except when its enumerated\n          // or when it's manually specified but we constraintManuallySpecifiedValue.\n          if (\n            specM.wildcardIndex.hasEncodingProperty(index, Property.CHANNEL) ||\n            opt.constraintManuallySpecifiedValue\n          ) {\n            return false;\n          }\n        }\n        return true;\n      });\n    }\n  },\n  {\n    name: 'omitRepeatedField',\n    description: 'Each field should be mapped to only one channel',\n    properties: [Property.FIELD],\n    allowWildcardForProperties: true,\n    strict: false, // over-encoding is sometimes good, but let's turn it off by default\n    satisfy: (specM: SpecQueryModel, _: Schema, opt: QueryConfig) => {\n      let fieldUsed = {};\n      let fieldEnumerated = {};\n\n      const encodings = specM.specQuery.encodings;\n      for (let i = 0; i < encodings.length; i++) {\n        const encQ = encodings[i];\n\n        if (isValueQuery(encQ) || isAutoCountQuery(encQ)) continue;\n\n        let field;\n        if (encQ.field && !isWildcard(encQ.field)) {\n          field = encQ.field as string;\n        }\n        if (isAutoCountQuery(encQ) && !isWildcard(encQ.autoCount)) {\n          field = 'count_*';\n        }\n\n        if (field) {\n          if (specM.wildcardIndex.hasEncodingProperty(i, Property.FIELD)) {\n            fieldEnumerated[field] = true;\n          }\n          // When the field is specified previously,\n          // if it is enumerated (either previously or in this encQ)\n          // or if the opt.constraintManuallySpecifiedValue is true,\n          // then it violates the constraint.\n\n          if (fieldUsed[field]) {\n            if (fieldEnumerated[field] || opt.constraintManuallySpecifiedValue) {\n              return false;\n            }\n          }\n\n          fieldUsed[field] = true;\n        }\n      }\n      return true;\n    }\n  },\n  // TODO: omitShapeWithBin\n  {\n    name: 'omitVerticalDotPlot',\n    description: 'Do not output vertical dot plot.',\n    properties: [Property.CHANNEL],\n    allowWildcardForProperties: true,\n    strict: false,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      const encodings = specM.getEncodings();\n      if (encodings.length === 1 && encodings[0].channel === CHANNEL.Y) {\n        return false;\n      }\n      return true;\n    }\n  },\n  // EXPENSIVE CONSTRAINTS -- check them later!\n  {\n    name: 'hasAppropriateGraphicTypeForMark',\n    description: 'Has appropriate graphic type for mark',\n    properties: [\n      Property.CHANNEL,\n      Property.MARK,\n      Property.TYPE,\n      Property.TIMEUNIT,\n      Property.BIN,\n      Property.AGGREGATE,\n      Property.AUTOCOUNT\n    ],\n    allowWildcardForProperties: false,\n    strict: false,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      const mark = specM.getMark();\n\n      switch (mark) {\n        case MARK.AREA:\n        case MARK.LINE:\n          if (specM.isAggregate()) {\n            // TODO: refactor based on profiling statistics\n            const xEncQ = specM.getEncodingQueryByChannel(CHANNEL.X);\n            const yEncQ = specM.getEncodingQueryByChannel(CHANNEL.Y);\n            const xIsMeasure = isMeasure(xEncQ);\n            const yIsMeasure = isMeasure(yEncQ);\n\n            // for aggregate line / area, we need at least one group-by axis and one measure axis.\n            return (\n              xEncQ &&\n              yEncQ &&\n              xIsMeasure !== yIsMeasure &&\n              // and the dimension axis should not be nominal\n              // TODO: make this clause optional\n\n              !(isFieldQuery(xEncQ) && !xIsMeasure && contains(['nominal', 'key'], xEncQ.type)) &&\n              !(isFieldQuery(yEncQ) && !yIsMeasure && contains(['nominal', 'key'], yEncQ.type))\n            );\n            // TODO: allow connected scatterplot\n          }\n          return true;\n        case MARK.TEXT:\n          // FIXME correctly when we add text\n          return true;\n        case MARK.BAR:\n        case MARK.TICK:\n          // Bar and tick should not use size.\n          if (specM.channelEncodingField(CHANNEL.SIZE)) {\n            return false;\n          } else {\n            // Tick and Bar should have one and only one measure\n            const xEncQ = specM.getEncodingQueryByChannel(CHANNEL.X);\n            const yEncQ = specM.getEncodingQueryByChannel(CHANNEL.Y);\n            const xIsMeasure = isMeasure(xEncQ);\n            const yIsMeasure = isMeasure(yEncQ);\n            if (xIsMeasure !== yIsMeasure) {\n              return true;\n            }\n            return false;\n          }\n        case MARK.RECT:\n          // Until CompassQL supports layering, it only makes sense for\n          // rect to encode DxD or 1xD (otherwise just use bar).\n          // Furthermore, color should only be used in a 'heatmap' fashion\n          // (with a measure field).\n          const xEncQ = specM.getEncodingQueryByChannel(CHANNEL.X);\n          const yEncQ = specM.getEncodingQueryByChannel(CHANNEL.Y);\n          const xIsDimension = isDimension(xEncQ);\n          const yIsDimension = isDimension(yEncQ);\n\n          const colorEncQ = specM.getEncodingQueryByChannel(CHANNEL.COLOR);\n          const colorIsQuantitative = isMeasure(colorEncQ);\n          const colorIsOrdinal = isFieldQuery(colorEncQ) ? colorEncQ.type === TYPE.ORDINAL : false;\n\n          const correctChannels =\n            (xIsDimension && yIsDimension) ||\n            (xIsDimension && !specM.channelUsed(CHANNEL.Y)) ||\n            (yIsDimension && !specM.channelUsed(CHANNEL.X));\n\n          const correctColor = !colorEncQ || (colorEncQ && (colorIsQuantitative || colorIsOrdinal));\n\n          return correctChannels && correctColor;\n        case MARK.CIRCLE:\n        case MARK.POINT:\n        case MARK.SQUARE:\n        case MARK.RULE:\n          return true;\n      }\n      /* istanbul ignore next */\n      throw new Error('hasAllRequiredChannelsForMark not implemented for mark' + mark);\n    }\n  },\n  {\n    name: 'omitInvalidStackSpec',\n    description: 'If stack is specified, must follow Vega-Lite stack rules',\n    properties: [\n      Property.STACK,\n      Property.FIELD,\n      Property.CHANNEL,\n      Property.MARK,\n      Property.AGGREGATE,\n      Property.AUTOCOUNT,\n      Property.SCALE,\n      getEncodingNestedProp('scale', 'type'),\n      Property.TYPE\n    ],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      if (!specM.wildcardIndex.hasProperty(Property.STACK)) {\n        return true;\n      }\n\n      const stackProps = specM.getVlStack();\n      if (stackProps === null && specM.getStackOffset() !== null) {\n        return false;\n      }\n\n      if (stackProps.fieldChannel !== specM.getStackChannel()) {\n        return false;\n      }\n\n      return true;\n    }\n  },\n  {\n    name: 'omitNonSumStack',\n    description: 'Stack specifications that use non-summative aggregates should be omitted (even implicit ones)',\n    properties: [\n      Property.CHANNEL,\n      Property.MARK,\n      Property.AGGREGATE,\n      Property.AUTOCOUNT,\n      Property.SCALE,\n      getEncodingNestedProp('scale', 'type'),\n      Property.TYPE\n    ],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      const specStack = specM.getVlStack();\n      if (specStack != null) {\n        const stackParentEncQ = specM.getEncodingQueryByChannel(specStack.fieldChannel) as FieldQuery;\n        if (!contains(SUM_OPS, stackParentEncQ.aggregate)) {\n          return false;\n        }\n      }\n      return true;\n    }\n  },\n  {\n    name: 'omitTableWithOcclusionIfAutoAddCount',\n    description:\n      'Plots without aggregation or autocount where x and y are both discrete should be omitted if autoAddCount is enabled as they often lead to occlusion',\n    properties: [\n      Property.CHANNEL,\n      Property.TYPE,\n      Property.TIMEUNIT,\n      Property.BIN,\n      Property.AGGREGATE,\n      Property.AUTOCOUNT\n    ],\n    allowWildcardForProperties: false,\n    strict: false,\n    satisfy: (specM: SpecQueryModel, _: Schema, opt: QueryConfig) => {\n      if (opt.autoAddCount) {\n        const xEncQ = specM.getEncodingQueryByChannel('x');\n        const yEncQ = specM.getEncodingQueryByChannel('y');\n\n        if ((!isFieldQuery(xEncQ) || isDimension(xEncQ)) && (!isFieldQuery(yEncQ) || isDimension(yEncQ))) {\n          if (!specM.isAggregate()) {\n            return false;\n          } else {\n            return every(specM.getEncodings(), encQ => {\n              let channel = encQ.channel;\n\n              if (\n                channel !== CHANNEL.X &&\n                channel !== CHANNEL.Y &&\n                channel !== CHANNEL.ROW &&\n                channel !== CHANNEL.COLUMN\n              ) {\n                // Non-position fields should not be unaggreated fields\n                if (isFieldQuery(encQ) && !encQ.aggregate) {\n                  return false;\n                }\n              }\n              return true;\n            });\n          }\n        }\n      }\n      return true;\n    }\n  }\n].map(sc => new SpecConstraintModel(sc));\n\n// For testing\nexport const SPEC_CONSTRAINT_INDEX: {[name: string]: SpecConstraintModel} = SPEC_CONSTRAINTS.reduce(\n  (m: any, c: SpecConstraintModel) => {\n    m[c.name()] = c;\n    return m;\n  },\n  {}\n);\n\nconst SPEC_CONSTRAINTS_BY_PROPERTY = SPEC_CONSTRAINTS.reduce((index, c) => {\n  for (const prop of c.properties()) {\n    // Initialize array and use it\n    index.set(prop, index.get(prop) || []);\n    index.get(prop).push(c);\n  }\n  return index;\n}, new PropIndex<SpecConstraintModel[]>());\n\n/**\n * Check all encoding constraints for a particular property and index tuple\n */\nexport function checkSpec(\n  prop: Property,\n  wildcard: Wildcard<any>,\n  specM: SpecQueryModel,\n  schema: Schema,\n  opt: QueryConfig\n): string {\n  // Check encoding constraint\n  const specConstraints = SPEC_CONSTRAINTS_BY_PROPERTY.get(prop) || [];\n\n  for (const c of specConstraints) {\n    // Check if the constraint is enabled\n    if (c.strict() || !!opt[c.name()]) {\n      // For strict constraint, or enabled non-strict, check the constraints\n\n      const satisfy = c.satisfy(specM, schema, opt);\n      if (!satisfy) {\n        let violatedConstraint = '(spec) ' + c.name();\n        /* istanbul ignore if */\n        if (opt.verbose) {\n          console.log(violatedConstraint + ' failed with ' + specM.toShorthand() + ' for ' + wildcard.name);\n        }\n        return violatedConstraint;\n      }\n    }\n  }\n  return null;\n}\n","import {Mark} from 'vega-lite/build/src/mark';\n\nimport {QueryConfig} from './config';\nimport {checkEncoding} from './constraint/encoding';\nimport {checkSpec} from './constraint/spec';\nimport {WildcardIndex} from './wildcardindex';\nimport {SpecQueryModel} from './model';\nimport {Property, ENCODING_TOPLEVEL_PROPS, ENCODING_NESTED_PROPS} from './property';\nimport {PropIndex} from './propindex';\nimport {Wildcard} from './wildcard';\nimport {Schema} from './schema';\nimport {isValueQuery, isDisabledAutoCountQuery} from './query/encoding';\n\nconst ENUMERATOR_INDEX = new PropIndex<EnumeratorFactory>();\n\nexport interface Enumerator {\n  (answerSets: SpecQueryModel[], specM: SpecQueryModel): SpecQueryModel[];\n}\n\nexport function getEnumerator(prop: Property) {\n  return ENUMERATOR_INDEX.get(prop);\n}\n\nexport interface EnumeratorFactory {\n  (wildcardIndex: WildcardIndex, schema: Schema, opt: QueryConfig): Enumerator;\n}\n\nENUMERATOR_INDEX.set('mark', (wildcardIndex: WildcardIndex, schema: Schema, opt: QueryConfig): Enumerator => {\n  return (answerSet, specM: SpecQueryModel) => {\n    const markWildcard = specM.getMark() as Wildcard<Mark>;\n\n    // enumerate the value\n    markWildcard.enum.forEach((mark) => {\n      specM.setMark(mark);\n      // Check spec constraint\n      const violatedSpecConstraint = checkSpec('mark', wildcardIndex.mark, specM, schema, opt);\n      if (!violatedSpecConstraint) {\n        // emit\n        answerSet.push(specM.duplicate());\n      }\n    });\n\n    // Reset to avoid side effect\n    specM.resetMark();\n\n    return answerSet;\n  };\n});\n\nENCODING_TOPLEVEL_PROPS.forEach((prop) => {\n  ENUMERATOR_INDEX.set(prop, EncodingPropertyGeneratorFactory(prop));\n});\n\nENCODING_NESTED_PROPS.forEach((nestedProp) => {\n  ENUMERATOR_INDEX.set(nestedProp, EncodingPropertyGeneratorFactory(nestedProp));\n});\n\n/**\n * @param prop property type.\n * @return an answer set reducer factory for the given prop.\n */\nexport function EncodingPropertyGeneratorFactory(prop: Property): EnumeratorFactory {\n  /**\n   * @return as reducer that takes a specQueryModel as input and output an answer set array.\n   */\n  return (wildcardIndex: WildcardIndex, schema: Schema, opt: QueryConfig): Enumerator => {\n\n    return (answerSet: SpecQueryModel[], specM: SpecQueryModel) => {\n      // index of encoding mappings that require enumeration\n      const indices = wildcardIndex.encodingIndicesByProperty.get(prop);\n\n      function enumerate(jobIndex: number) {\n        if (jobIndex === indices.length) {\n          // emit and terminate\n          answerSet.push(specM.duplicate());\n          return;\n        }\n        const index = indices[jobIndex];\n        const wildcard: Wildcard<any> = wildcardIndex.encodings[index].get(prop);\n        const encQ = specM.getEncodingQueryByIndex(index);\n        const propWildcard = specM.getEncodingProperty(index, prop);\n\n        if (isValueQuery(encQ) || (\n              // TODO: encQ.exclude\n              // If this encoding query is an excluded autoCount, there is no point enumerating other properties\n              // for this encoding query because they will be excluded anyway.\n              // Thus, we can just move on to the next encoding to enumerate.\n              (isDisabledAutoCountQuery(encQ)) ||\n              // nested encoding property might have its parent set to false\n              // therefore, we no longer have to enumerate them\n              !propWildcard\n            )\n          ) { // TODO: encQ.excluded\n          enumerate(jobIndex + 1);\n        } else {\n          wildcard.enum.forEach((propVal) => {\n            if (propVal === null) {\n              // our duplicate() method use JSON.stringify, parse and thus can accidentally\n              // convert undefined in an array into null\n              propVal = undefined;\n            }\n            specM.setEncodingProperty(index, prop, propVal, wildcard);\n\n            // Check encoding constraint\n            const violatedEncodingConstraint = checkEncoding(prop, wildcard, index, specM, schema, opt);\n            if (violatedEncodingConstraint) {\n              return; // do not keep searching\n            }\n            // Check spec constraint\n            const violatedSpecConstraint = checkSpec(prop, wildcard, specM, schema, opt);\n            if (violatedSpecConstraint) {\n              return; // do not keep searching\n            }\n            // If qualify all of the constraints, keep enumerating\n            enumerate(jobIndex + 1);\n          });\n\n          // Reset to avoid side effect\n          specM.resetEncodingProperty(index, prop, wildcard);\n        }\n      }\n\n      // start enumerating from 0\n      enumerate(0);\n\n      return answerSet;\n    };\n  };\n}\n","import {isArray, isObject} from 'datalib/src/util';\n\nimport {getReplacerIndex} from './shorthand';\nimport {Property} from '../property';\nimport {PropIndex} from '../propindex';\nimport {Dict,keys} from '../util';\n\n\nexport interface ExtendedGroupBy {\n  property: string;\n  replace?: Dict<string>;\n}\n\nexport const REPLACE_BLANK_FIELDS: Dict<string> = {'*': ''};\nexport const REPLACE_XY_CHANNELS: Dict<string> = {x: 'xy', y: 'xy'};\nexport const REPLACE_FACET_CHANNELS: Dict<string> = {row: 'facet', column: 'facet'};\nexport const REPLACE_MARK_STYLE_CHANNELS: Dict<string> = {color: 'style', opacity: 'style', shape: 'style', size: 'style'};\n\nexport function isExtendedGroupBy(g: string | ExtendedGroupBy): g is ExtendedGroupBy {\n  return isObject(g) && !!g['property'];\n}\n\nexport type GroupBy = string | Array<string | ExtendedGroupBy>;\n\nexport interface Nest {\n  groupBy: GroupBy;\n  orderGroupBy?: string | string[];\n}\n\n\nexport function parseGroupBy(groupBy: Array<string | ExtendedGroupBy>,\n    include?: PropIndex<boolean>,\n    replaceIndex?: PropIndex<Dict<string>>\n  ) {\n\n  include = include || new PropIndex<boolean>();\n  replaceIndex = replaceIndex || new PropIndex<Dict<string>>();\n\n  groupBy.forEach((grpBy: string | ExtendedGroupBy) => {\n    if (isExtendedGroupBy(grpBy)) {\n      include.setByKey(grpBy.property, true);\n      replaceIndex.setByKey(grpBy.property, grpBy.replace);\n    } else {\n      include.setByKey(grpBy, true);\n    }\n  });\n\n  return {\n    include: include,\n    replaceIndex: replaceIndex,\n    replacer: getReplacerIndex(replaceIndex)\n  };\n}\n\nexport function toString(groupBy: GroupBy): string {\n  if (isArray(groupBy)) {\n    return groupBy.map((g: string | ExtendedGroupBy) => {\n      if (isExtendedGroupBy(g)) {\n        if (g.replace) {\n          let replaceIndex = keys(g.replace).reduce((index, valFrom) => {\n          const valTo = g.replace[valFrom];\n            (index[valTo] = index[valTo] || []).push(valFrom);\n            return index;\n          }, {});\n\n          return g.property + '[' + keys(replaceIndex).map((valTo) => {\n            const valsFrom = replaceIndex[valTo].sort();\n            return valsFrom.join(',') + '=>' + valTo;\n          }).join(';') + ']';\n        }\n        return g.property;\n      }\n      return g;\n    }).join(',');\n  } else {\n    return groupBy;\n  }\n}\n\nexport const GROUP_BY_FIELD_TRANSFORM = [\n  Property.FIELD, Property.TYPE,\n  Property.AGGREGATE, Property.BIN, Property.TIMEUNIT, Property.STACK\n];\n\nexport const GROUP_BY_ENCODING = (GROUP_BY_FIELD_TRANSFORM as Array<string | ExtendedGroupBy>).concat([\n  {\n    property: Property.CHANNEL,\n    replace: {\n      'x': 'xy', 'y': 'xy',\n      'color': 'style', 'size': 'style', 'shape': 'style', 'opacity': 'style',\n      'row': 'facet', 'column': 'facet'\n    }\n  }\n]);\n\n","import {isArray} from 'datalib/src/util';\nimport {SpecQueryModel, SpecQueryModelGroup} from './model';\nimport {Property} from './property';\nimport {PropIndex} from './propindex';\nimport {GROUP_BY_ENCODING, GROUP_BY_FIELD_TRANSFORM, Nest, parseGroupBy} from './query/groupby';\nimport {Replacer, spec as specShorthand} from './query/shorthand';\nimport {SpecQuery} from './query/spec';\nimport {Dict} from './util';\n\n/**\n * Registry for all possible grouping key functions.\n */\nlet groupRegistry: Dict<(specM: SpecQuery) => string> = {};\n\n/**\n * Add a grouping function to the registry.\n */\nexport function registerKeyFn(name: string, keyFn: (specM: SpecQuery) => string) {\n  groupRegistry[name] = keyFn;\n}\n\nexport const FIELD = 'field';\nexport const FIELD_TRANSFORM = 'fieldTransform';\nexport const ENCODING = 'encoding';\nexport const SPEC = 'spec';\n\n/**\n * Group the input spec query model by a key function registered in the group registry\n * @return\n */\nexport function nest(specModels: SpecQueryModel[], queryNest: Nest[]): SpecQueryModelGroup {\n  if (queryNest) {\n    const rootGroup: SpecQueryModelGroup = {\n      name: '',\n      path: '',\n      items: []\n    };\n    let groupIndex: Dict<SpecQueryModelGroup> = {};\n\n    // global `includes` and `replaces` will get augmented by each level's groupBy.\n    // Upper level's `groupBy` will get cascaded to lower-level groupBy.\n    // `replace` can be overriden in a lower-level to support different grouping.\n    let includes: Array<PropIndex<boolean>> = [];\n    let replaces: Array<PropIndex<Dict<string>>> = [];\n    let replacers: Array<PropIndex<Replacer>> = [];\n\n    for (let l = 0; l < queryNest.length; l++) {\n      includes.push(l > 0 ? includes[l - 1].duplicate() : new PropIndex<boolean>());\n      replaces.push(l > 0 ? replaces[l - 1].duplicate() : new PropIndex<Dict<string>>());\n\n      const groupBy = queryNest[l].groupBy;\n      if (isArray(groupBy)) {\n        // If group is array, it's an array of extended group by that need to be parsed\n        let parsedGroupBy = parseGroupBy(groupBy, includes[l], replaces[l]);\n        replacers.push(parsedGroupBy.replacer);\n      }\n    }\n\n    // With includes and replacers, now we can construct the nesting tree\n\n    specModels.forEach(specM => {\n      let path = '';\n      let group: SpecQueryModelGroup = rootGroup;\n      for (let l = 0; l < queryNest.length; l++) {\n        const groupBy = (group.groupBy = queryNest[l].groupBy);\n        group.orderGroupBy = queryNest[l].orderGroupBy;\n\n        const key = isArray(groupBy)\n          ? specShorthand(specM.specQuery, includes[l], replacers[l])\n          : groupRegistry[groupBy](specM.specQuery);\n\n        path += '/' + key;\n        if (!groupIndex[path]) {\n          // this item already exists on the path\n          groupIndex[path] = {\n            name: key,\n            path: path,\n            items: []\n          };\n\n          group.items.push(groupIndex[path]);\n        }\n        group = groupIndex[path];\n      }\n      group.items.push(specM);\n    });\n    return rootGroup;\n  } else {\n    // no nesting, just return a flat group\n    return {\n      name: '',\n      path: '',\n      items: specModels\n    };\n  }\n}\n\n// TODO: move this to groupBy, rename properly, and export\nconst GROUP_BY_FIELD = [Property.FIELD];\nconst PARSED_GROUP_BY_FIELD = parseGroupBy(GROUP_BY_FIELD);\n\nexport function getGroupByKey(specM: SpecQuery, groupBy: string) {\n  return groupRegistry[groupBy](specM);\n}\n\nregisterKeyFn(FIELD, (specQ: SpecQuery) => {\n  return specShorthand(specQ, PARSED_GROUP_BY_FIELD.include, PARSED_GROUP_BY_FIELD.replacer);\n});\n\nexport const PARSED_GROUP_BY_FIELD_TRANSFORM = parseGroupBy(GROUP_BY_FIELD_TRANSFORM);\n\nregisterKeyFn(FIELD_TRANSFORM, (specQ: SpecQuery) => {\n  return specShorthand(specQ, PARSED_GROUP_BY_FIELD_TRANSFORM.include, PARSED_GROUP_BY_FIELD_TRANSFORM.replacer);\n});\n\nexport const PARSED_GROUP_BY_ENCODING = parseGroupBy(GROUP_BY_ENCODING);\n\nregisterKeyFn(ENCODING, (specQ: SpecQuery) => {\n  return specShorthand(specQ, PARSED_GROUP_BY_ENCODING.include, PARSED_GROUP_BY_ENCODING.replacer);\n});\n\nregisterKeyFn(SPEC, (specQ: SpecQuery) => JSON.stringify(specQ));\n","import {Mark} from 'vega-lite/build/src/mark';\n\nimport {Wildcard} from './wildcard';\nimport {Property, isEncodingProperty} from './property';\nimport {PropIndex} from './propindex';\n\n\nexport interface EncodingsWildcardIndex {\n  [index: number]: PropIndex<Wildcard<any>>;\n}\n\nexport class WildcardIndex {\n  private _mark: Wildcard<Mark>;\n  // TODO: transform\n\n  /**\n   * Dictionary mapping encoding index to an encoding wildcard index.\n   */\n\n  private _encodings: EncodingsWildcardIndex;\n  private _encodingIndicesByProperty: PropIndex<number[]>;\n\n  constructor() {\n    this._mark = undefined;\n    this._encodings = {};\n    this._encodingIndicesByProperty = new PropIndex<number[]>();\n  }\n\n  public setEncodingProperty(index: number, prop: Property, wildcard: Wildcard<any>) {\n    const encodingsIndex = this._encodings;\n\n    // Init encoding index and set prop\n    const encIndex = encodingsIndex[index] = encodingsIndex[index] || new PropIndex<Wildcard<any>>();\n    encIndex.set(prop, wildcard);\n\n    // Initialize indicesByProperty[prop] and add index\n    const indicesByProp = this._encodingIndicesByProperty;\n    indicesByProp.set(prop, (indicesByProp.get(prop) || []));\n    indicesByProp.get(prop).push(index);\n\n    return this;\n  }\n\n  public hasEncodingProperty(index: number, prop: Property) {\n    return !!this._encodings[index] && this._encodings[index].has(prop);\n  }\n\n  public hasProperty(prop: Property) {\n    if (isEncodingProperty(prop)) {\n      return this.encodingIndicesByProperty.has(prop);\n    } else if (prop === 'mark') {\n      return !!this.mark;\n    }\n    /* istanbul ignore next */\n    throw new Error('Unimplemented for property ' + prop);\n  }\n\n  public isEmpty() {\n    return !this.mark && this.encodingIndicesByProperty.size() === 0;\n  }\n\n  public setMark(mark: Wildcard<Mark>) {\n    this._mark = mark;\n    return this;\n  }\n\n  public get mark() {\n    return this._mark;\n  }\n\n  public get encodings() {\n    return this._encodings;\n  }\n\n  public get encodingIndicesByProperty() {\n    return this._encodingIndicesByProperty;\n  }\n}\n","import {isString} from 'datalib/src/util';\nimport {Channel} from 'vega-lite/build/src/channel';\nimport {Data} from 'vega-lite/build/src/data';\nimport {Mark} from 'vega-lite/build/src/mark';\nimport {FacetedUnitSpec, TopLevel} from 'vega-lite/build/src/spec';\nimport {StackOffset, StackProperties} from 'vega-lite/build/src/stack';\nimport * as TYPE from 'vega-lite/build/src/type';\nimport {QueryConfig} from './config';\nimport {getGroupByKey} from './nest';\nimport {\n  ENCODING_NESTED_PROPS,\n  ENCODING_TOPLEVEL_PROPS,\n  isEncodingNestedParent,\n  isEncodingNestedProp,\n  Property\n} from './property';\nimport {\n  AutoCountQuery,\n  EncodingQuery,\n  isAutoCountQuery,\n  isDisabledAutoCountQuery,\n  isFieldQuery,\n  toEncoding\n} from './query/encoding';\nimport {ExtendedGroupBy, parseGroupBy} from './query/groupby';\nimport {spec as specShorthand} from './query/shorthand';\nimport {getStackChannel, getStackOffset, getVlStack, isAggregate, SpecQuery} from './query/spec';\nimport {RankingScore} from './ranking/ranking';\nimport {ResultTree} from './result';\nimport {Schema} from './schema';\nimport {Dict, duplicate, extend} from './util';\nimport {getDefaultEnumValues, getDefaultName, initWildcard, isWildcard, SHORT_WILDCARD, Wildcard} from './wildcard';\nimport {WildcardIndex} from './wildcardindex';\n\n/**\n * Internal class for specQuery that provides helper for the enumeration process.\n */\nexport class SpecQueryModel {\n  private _spec: SpecQuery;\n\n  /** channel => EncodingQuery */\n  private _channelFieldCount: Dict<number>;\n  private _wildcardIndex: WildcardIndex;\n  private _assignedWildcardIndex: Dict<any>;\n  private _schema: Schema;\n  private _opt: QueryConfig;\n\n  private _rankingScore: Dict<RankingScore> = {};\n\n  /**\n   * Build a WildcardIndex by detecting wildcards\n   * in the input specQuery and replacing short wildcards (\"?\")\n   * with full ones (objects with `name` and `enum` values).\n   *\n   * @return a SpecQueryModel that wraps the specQuery and the WildcardIndex.\n   */\n  public static build(specQ: SpecQuery, schema: Schema, opt: QueryConfig): SpecQueryModel {\n    let wildcardIndex: WildcardIndex = new WildcardIndex();\n    // mark\n    if (isWildcard(specQ.mark)) {\n      const name = getDefaultName(Property.MARK);\n      specQ.mark = initWildcard(specQ.mark, name, opt.enum.mark);\n      wildcardIndex.setMark(specQ.mark);\n    }\n\n    // TODO: transform\n\n    // encodings\n    specQ.encodings.forEach((encQ, index) => {\n      if (isAutoCountQuery(encQ)) {\n        // This is only for testing purpose\n        console.warn('A field with autoCount should not be included as autoCount meant to be an internal object.');\n\n        encQ.type = TYPE.QUANTITATIVE; // autoCount is always quantitative\n      }\n\n      if (isFieldQuery(encQ) && encQ.type === undefined) {\n        // type is optional -- we automatically augment wildcard if not specified\n        encQ.type = SHORT_WILDCARD;\n      }\n\n      // For each property of the encodingQuery, enumerate\n      ENCODING_TOPLEVEL_PROPS.forEach(prop => {\n        if (isWildcard(encQ[prop])) {\n          // Assign default wildcard name and enum values.\n          const defaultWildcardName = getDefaultName(prop) + index;\n          const defaultEnumValues = getDefaultEnumValues(prop, schema, opt);\n          const wildcard = (encQ[prop] = initWildcard(encQ[prop], defaultWildcardName, defaultEnumValues));\n\n          // Add index of the encoding mapping to the property's wildcard index.\n          wildcardIndex.setEncodingProperty(index, prop, wildcard);\n        }\n      });\n\n      // For each nested property of the encoding query  (e.g., encQ.bin.maxbins)\n      ENCODING_NESTED_PROPS.forEach(prop => {\n        const propObj = encQ[prop.parent]; // the property object e.g., encQ.bin\n        if (propObj) {\n          const child = prop.child;\n          if (isWildcard(propObj[child])) {\n            // Assign default wildcard name and enum values.\n            const defaultWildcardName = getDefaultName(prop) + index;\n            const defaultEnumValues = getDefaultEnumValues(prop, schema, opt);\n            const wildcard = (propObj[child] = initWildcard(propObj[child], defaultWildcardName, defaultEnumValues));\n\n            // Add index of the encoding mapping to the property's wildcard index.\n            wildcardIndex.setEncodingProperty(index, prop, wildcard);\n          }\n        }\n      });\n    });\n\n    // AUTO COUNT\n    // Add Auto Count Field\n    if (opt.autoAddCount) {\n      const channel: Wildcard<Channel> = {\n        name: getDefaultName(Property.CHANNEL) + specQ.encodings.length,\n        enum: getDefaultEnumValues(Property.CHANNEL, schema, opt)\n      };\n      const autoCount: Wildcard<boolean> = {\n        name: getDefaultName(Property.AUTOCOUNT) + specQ.encodings.length,\n        enum: [false, true]\n      };\n      const countEncQ: AutoCountQuery = {\n        channel,\n        autoCount,\n        type: TYPE.QUANTITATIVE\n      };\n      specQ.encodings.push(countEncQ);\n\n      const index = specQ.encodings.length - 1;\n\n      // Add index of the encoding mapping to the property's wildcard index.\n      wildcardIndex.setEncodingProperty(index, Property.CHANNEL, channel);\n      wildcardIndex.setEncodingProperty(index, Property.AUTOCOUNT, autoCount);\n    }\n\n    return new SpecQueryModel(specQ, wildcardIndex, schema, opt, {});\n  }\n\n  constructor(\n    spec: SpecQuery,\n    wildcardIndex: WildcardIndex,\n    schema: Schema,\n    opt: QueryConfig,\n    wildcardAssignment: Dict<any>\n  ) {\n    this._spec = spec;\n    this._channelFieldCount = spec.encodings.reduce(\n      (m, encQ) => {\n        if (!isWildcard(encQ.channel) && (!isAutoCountQuery(encQ) || encQ.autoCount !== false)) {\n          m[encQ.channel + ''] = 1;\n        }\n        return m;\n      },\n      {} as Dict<number>\n    );\n\n    this._wildcardIndex = wildcardIndex;\n    this._assignedWildcardIndex = wildcardAssignment;\n    this._opt = opt;\n    this._schema = schema;\n  }\n\n  public get wildcardIndex() {\n    return this._wildcardIndex;\n  }\n\n  public get schema() {\n    return this._schema;\n  }\n\n  public get specQuery() {\n    return this._spec;\n  }\n\n  public duplicate(): SpecQueryModel {\n    return new SpecQueryModel(\n      duplicate(this._spec),\n      this._wildcardIndex,\n      this._schema,\n      this._opt,\n      duplicate(this._assignedWildcardIndex)\n    );\n  }\n\n  public setMark(mark: Mark) {\n    const name = this._wildcardIndex.mark.name;\n    this._assignedWildcardIndex[name] = this._spec.mark = mark;\n  }\n\n  public resetMark() {\n    const wildcard = (this._spec.mark = this._wildcardIndex.mark);\n    delete this._assignedWildcardIndex[wildcard.name];\n  }\n\n  public getMark() {\n    return this._spec.mark;\n  }\n\n  public getEncodingProperty(index: number, prop: Property) {\n    const encQ = this._spec.encodings[index];\n    if (isEncodingNestedProp(prop)) {\n      // nested encoding property\n      return encQ[prop.parent][prop.child];\n    }\n    return encQ[prop]; // encoding property (non-nested)\n  }\n\n  public setEncodingProperty(index: number, prop: Property, value: any, wildcard: Wildcard<any>) {\n    const encQ = this._spec.encodings[index];\n\n    if (prop === Property.CHANNEL && encQ.channel && !isWildcard(encQ.channel)) {\n      // If there is an old channel\n      this._channelFieldCount[encQ.channel as Channel]--;\n    }\n\n    if (isEncodingNestedProp(prop)) {\n      // nested encoding property\n      encQ[prop.parent][prop.child] = value;\n    } else if (isEncodingNestedParent(prop) && value === true) {\n      encQ[prop] = extend(\n        {},\n        encQ[prop], // copy all existing properties\n        {enum: undefined, name: undefined} // except name and values to it no longer an wildcard\n      );\n    } else {\n      // encoding property (non-nested)\n      encQ[prop] = value;\n    }\n\n    this._assignedWildcardIndex[wildcard.name] = value;\n\n    if (prop === Property.CHANNEL) {\n      // If there is a new channel, make sure it exists and add it to the count.\n      this._channelFieldCount[value] = (this._channelFieldCount[value] || 0) + 1;\n    }\n  }\n\n  public resetEncodingProperty(index: number, prop: Property, wildcard: Wildcard<any>) {\n    const encQ = this._spec.encodings[index];\n    if (prop === Property.CHANNEL) {\n      this._channelFieldCount[encQ.channel as Channel]--;\n    }\n\n    // reset it to wildcard\n    if (isEncodingNestedProp(prop)) {\n      // nested encoding property\n      encQ[prop.parent][prop.child] = wildcard;\n    } else {\n      // encoding property (non-nested)\n      encQ[prop] = wildcard;\n    }\n\n    // add remove value that is reset from the assignment map\n    delete this._assignedWildcardIndex[wildcard.name];\n  }\n\n  public channelUsed(channel: Channel) {\n    // do not include encoding that has autoCount = false because it is not a part of the output spec.\n    return this._channelFieldCount[channel] > 0;\n  }\n\n  public channelEncodingField(channel: Channel) {\n    const encodingQuery = this.getEncodingQueryByChannel(channel);\n    return isFieldQuery(encodingQuery);\n  }\n\n  public getEncodings(): EncodingQuery[] {\n    // do not include encoding that has autoCount = false because it is not a part of the output spec.\n    return this._spec.encodings.filter(encQ => !isDisabledAutoCountQuery(encQ));\n  }\n\n  public getEncodingQueryByChannel(channel: Channel) {\n    for (let specEncoding of this._spec.encodings) {\n      if (specEncoding.channel === channel) {\n        return specEncoding;\n      }\n    }\n    return undefined;\n  }\n\n  public getEncodingQueryByIndex(i: number) {\n    return this._spec.encodings[i];\n  }\n\n  public isAggregate() {\n    return isAggregate(this._spec);\n  }\n\n  /**\n   * @return The Vega-Lite `StackProperties` object that describes the stack\n   * configuration of `this`. Returns `null` if this is not stackable.\n   */\n  public getVlStack(): StackProperties {\n    return getVlStack(this._spec);\n  }\n\n  /**\n   * @return The `StackOffset` specified in `this`, `undefined` if none\n   * is specified.\n   */\n  public getStackOffset(): StackOffset {\n    return getStackOffset(this._spec);\n  }\n\n  /**\n   * @return The `Channel` in which `stack` is specified in `this`, or\n   * `null` if none is specified.\n   */\n  public getStackChannel(): Channel {\n    return getStackChannel(this._spec);\n  }\n\n  public toShorthand(groupBy?: string | (string | ExtendedGroupBy)[]): string {\n    if (groupBy) {\n      if (isString(groupBy)) {\n        return getGroupByKey(this.specQuery, groupBy);\n      }\n      const parsedGroupBy = parseGroupBy(groupBy);\n      return specShorthand(this._spec, parsedGroupBy.include, parsedGroupBy.replacer);\n    }\n    return specShorthand(this._spec);\n  }\n\n  /**\n   * Convert a query to a Vega-Lite spec if it is completed.\n   * @return a Vega-Lite spec if completed, null otherwise.\n   */\n  public toSpec(data?: Data): TopLevel<FacetedUnitSpec> {\n    if (isWildcard(this._spec.mark)) return null;\n\n    let spec: any = {};\n    data = data || this._spec.data;\n    if (data) {\n      spec.data = data;\n    }\n\n    if (this._spec.transform) {\n      spec.transform = this._spec.transform;\n    }\n\n    spec.mark = this._spec.mark as Mark;\n    spec.encoding = toEncoding(this.specQuery.encodings, {schema: this._schema, wildcardMode: 'null'});\n\n    if (this._spec.width) {\n      spec.width = this._spec.width;\n    }\n    if (this._spec.height) {\n      spec.height = this._spec.height;\n    }\n    if (this._spec.background) {\n      spec.background = this._spec.background;\n    }\n    if (this._spec.padding) {\n      spec.padding = this._spec.padding;\n    }\n    if (this._spec.title) {\n      spec.title = this._spec.title;\n    }\n\n    if (spec.encoding === null) {\n      return null;\n    }\n    if (this._spec.config || this._opt.defaultSpecConfig)\n      spec.config = extend({}, this._opt.defaultSpecConfig, this._spec.config);\n\n    return spec;\n  }\n\n  public getRankingScore(rankingName: string) {\n    return this._rankingScore[rankingName];\n  }\n\n  public setRankingScore(rankingName: string, score: RankingScore) {\n    this._rankingScore[rankingName] = score;\n  }\n}\nexport type SpecQueryModelGroup = ResultTree<SpecQueryModel>;\n","import {Query} from './query';\nimport {Nest} from './groupby';\nimport {duplicate} from '../util';\n\n/**\n * Normalize the non-nested version of the query\n * (basically when you have a `groupBy`)\n * to a standardize nested.\n */\nexport function normalize(q: Query): Query {\n  if (q.groupBy) {\n    let nest: Nest = {\n      groupBy: q.groupBy\n    };\n\n    if (q.orderBy) {\n      nest.orderGroupBy = q.orderBy;\n    }\n\n    let normalizedQ: Query = {\n      spec: duplicate(q.spec), // We will cause side effect to q.spec in SpecQueryModel.build\n      nest: [nest],\n    };\n\n    if (q.chooseBy) {\n      normalizedQ.chooseBy = q.chooseBy;\n    }\n\n    if (q.config) {\n      normalizedQ.config = q.config;\n    }\n\n    return normalizedQ;\n  }\n  return duplicate(q); // We will cause side effect to q.spec in SpecQueryModel.build\n}\n","import {GroupBy} from './query/groupby';\n\n/**\n * An ordered tree structure for storing query results.\n */\nexport interface ResultTree<T> {\n  name: string;\n  path: string;\n  items: (ResultTree<T> | T)[];\n  groupBy?: GroupBy;\n  orderGroupBy?: string | string[];\n}\n\nexport function isResultTree<T>(item: ResultTree<T> | T): item is ResultTree<T> {\n  return (<ResultTree<T>>item).items !== undefined;\n}\n\nexport function getTopResultTreeItem<T>(specQuery: ResultTree<T>): T {\n  let topItem = specQuery.items[0];\n  while (topItem && isResultTree(topItem)) {\n    topItem = topItem.items[0];\n  }\n  return <T>topItem;\n}\n\nexport function mapLeaves<T, U>(group: ResultTree<T>, f: (item: T) => U): ResultTree<U> {\n  return {\n    ...group,\n    items: group.items.map(item => (isResultTree(item) ? mapLeaves(item, f) : f(item)))\n  };\n}\n","import {hasDiscreteDomain} from 'vega-lite/build/src/scale';\nimport * as TYPE from 'vega-lite/build/src/type';\nimport {FieldQuery, scaleType} from '../../query/encoding';\nimport {ExpandedType} from '../../query/expandedtype';\n\n/**\n * Finer grained data types that takes binning and timeUnit into account.\n */\nexport enum ExtendedType {\n  Q = TYPE.QUANTITATIVE as any,\n  BIN_Q = ('bin_' + TYPE.QUANTITATIVE) as any,\n  T = TYPE.TEMPORAL as any,\n\n  /**\n   * Time Unit Temporal Field with time scale.\n   */\n  TIMEUNIT_T = 'timeUnit_time' as any,\n  /**\n   * Time Unit Temporal Field with ordinal scale.\n   */\n  TIMEUNIT_O = ('timeUnit_' + TYPE.ORDINAL) as any,\n  O = TYPE.ORDINAL as any,\n  N = TYPE.NOMINAL as any,\n  K = ExpandedType.KEY as any,\n  NONE = '-' as any\n}\n\nexport const Q = ExtendedType.Q;\nexport const BIN_Q = ExtendedType.BIN_Q;\nexport const T = ExtendedType.T;\nexport const TIMEUNIT_T = ExtendedType.TIMEUNIT_T;\nexport const TIMEUNIT_O = ExtendedType.TIMEUNIT_O;\nexport const O = ExtendedType.O;\nexport const N = ExtendedType.N;\nexport const K = ExtendedType.K;\nexport const NONE = ExtendedType.NONE;\n\nexport function getExtendedType(fieldQ: FieldQuery): ExtendedType {\n  if (fieldQ.bin) {\n    return ExtendedType.BIN_Q;\n  } else if (fieldQ.timeUnit) {\n    const sType = scaleType(fieldQ);\n    return hasDiscreteDomain(sType) ? ExtendedType.TIMEUNIT_O : ExtendedType.TIMEUNIT_T;\n  }\n  return fieldQ.type as ExtendedType;\n}\n","import {SpecQueryModel} from '../../model';\nimport {Schema} from '../../schema';\nimport {QueryConfig} from '../../config';\nimport {FeatureScore} from '../ranking';\nimport {Dict} from '../../util';\n\n\nexport abstract class Scorer {\n  public readonly type: string;\n  public readonly scoreIndex: Dict<number>;\n  constructor(type: string) {\n    this.type = type;\n    this.scoreIndex = this.initScore();\n  }\n\n  protected abstract initScore(): Dict<number>;\n\n  protected getFeatureScore(feature: string): FeatureScore {\n    const type = this.type;\n    const score = this.scoreIndex[feature];\n    if (score !== undefined) {\n      return {type, feature, score};\n    }\n    return undefined;\n  }\n\n  public abstract getScore(specM: SpecQueryModel, schema: Schema, opt: QueryConfig): FeatureScore[];\n}\n","\n\n\nimport {QueryConfig} from '../../config';\nimport {SpecQueryModel} from '../../model';\nimport {fieldDef as fieldDefShorthand} from '../../query/shorthand';\nimport {EncodingQuery, isFieldQuery, isAutoCountQuery} from '../../query/encoding';\nimport {Dict, extend, forEach, keys, contains} from '../../util';\n\nimport {Schema} from '../../schema';\nimport {FeatureScore} from '../ranking';\nimport {BIN_Q, TIMEUNIT_T, TIMEUNIT_O, Q, N, O, T, ExtendedType, getExtendedType, K} from './type';\n\n\nimport {Scorer} from './base';\nimport {Channel} from 'vega-lite/build/src/channel';\n\n\n\nexport const TERRIBLE = -10;\n\n/**\n * Effectiveness score for relationship between\n * Field Type (with Bin and TimeUnit) and Channel Score (Cleveland / Mackinlay based)\n */\nexport class TypeChannelScorer extends Scorer {\n  constructor() {\n    super('TypeChannel');\n  }\n  protected initScore() {\n    let SCORE = {} as Dict<number>;\n\n    // Continuous Quantitative / Temporal Fields\n    const CONTINUOUS_TYPE_CHANNEL_SCORE = {\n      x: 0,\n      y: 0,\n      size: -0.575,\n      color: -0.725,  // Middle between -0.7 and -0.75\n      text: -2,\n      opacity: -3,\n\n      shape: TERRIBLE,\n      row: TERRIBLE,\n      column: TERRIBLE,\n      detail: 2 * TERRIBLE\n    };\n\n    [Q, T, TIMEUNIT_T].forEach((type) => {\n      keys(CONTINUOUS_TYPE_CHANNEL_SCORE).forEach((channel: Channel) => {\n        SCORE[this.featurize(type, channel)] = CONTINUOUS_TYPE_CHANNEL_SCORE[channel];\n      });\n    });\n\n    // Discretized Quantitative / Temporal Fields / Ordinal\n\n    const ORDERED_TYPE_CHANNEL_SCORE = extend({}, CONTINUOUS_TYPE_CHANNEL_SCORE, {\n      row: -0.75,\n      column: -0.75,\n\n      shape: -3.1,\n      text: -3.2,\n      detail: -4\n    });\n\n    [BIN_Q, TIMEUNIT_O, O].forEach((type) => {\n      keys(ORDERED_TYPE_CHANNEL_SCORE).forEach((channel: Channel) => {\n        SCORE[this.featurize(type, channel)] = ORDERED_TYPE_CHANNEL_SCORE[channel];\n      });\n    });\n\n    const NOMINAL_TYPE_CHANNEL_SCORE = {\n      x: 0,\n      y: 0,\n      color: -0.6, // TODO: make it adjustable based on preference (shape is better for black and white)\n      shape: -0.65,\n      row: -0.7,\n      column: -0.7,\n      text: -0.8,\n\n      detail: -2,\n      size: -3,\n      opacity: -3.1,\n    };\n\n    keys(NOMINAL_TYPE_CHANNEL_SCORE).forEach((channel: Channel) => {\n      SCORE[this.featurize(N, channel)] = NOMINAL_TYPE_CHANNEL_SCORE[channel];\n      SCORE[this.featurize(K, channel)] =\n        // Putting key on position or detail isn't terrible\n        contains(['x', 'y', 'detail'], channel) ? -1 :\n          NOMINAL_TYPE_CHANNEL_SCORE[channel] - 2;\n    });\n\n    return SCORE;\n  }\n\n  public featurize(type: ExtendedType, channel: Channel) {\n    return type + '_' + channel;\n  }\n\n  public getScore(specM: SpecQueryModel, schema: Schema, opt: QueryConfig): FeatureScore[] {\n    const encodingQueryByField = specM.getEncodings().reduce((m, encQ) => {\n      if (isFieldQuery(encQ) || isAutoCountQuery(encQ)) {\n        const fieldKey = fieldDefShorthand(encQ);\n        (m[fieldKey] = m[fieldKey] || []).push(encQ);\n      }\n      return m;\n    }, {});\n\n    const features: FeatureScore[] = [];\n\n    forEach(encodingQueryByField, (encQs: EncodingQuery[]) => {\n      const bestFieldFeature = encQs.reduce((best: FeatureScore, encQ) => {\n        if (isFieldQuery(encQ) || isAutoCountQuery(encQ)) {\n          const type = getExtendedType(encQ);\n          const feature = this.featurize(type, encQ.channel as Channel);\n          const featureScore = this.getFeatureScore(feature);\n\n          if (best === null || featureScore.score > best.score) {\n            return featureScore;\n          }\n        }\n        return best;\n      }, null);\n\n      features.push(bestFieldFeature);\n\n      // TODO: add plus for over-encoding of one field\n    });\n    return features;\n  }\n}\n","import * as CHANNEL from 'vega-lite/build/src/channel';\nimport * as MARK from 'vega-lite/build/src/mark';\nimport {Mark} from 'vega-lite/build/src/mark';\nimport {QueryConfig} from '../../config';\nimport {SpecQueryModel} from '../../model';\nimport {Schema} from '../../schema';\nimport {Dict, forEach} from '../../util';\nimport {FeatureScore} from '../ranking';\nimport {Scorer} from './base';\nimport {BIN_Q, ExtendedType, getExtendedType, K, N, NONE, O, Q, T, TIMEUNIT_O, TIMEUNIT_T} from './type';\n\nexport class MarkScorer extends Scorer {\n  constructor() {\n    super('Mark');\n  }\n\n  protected initScore() {\n    return init();\n  }\n\n  public getScore(specM: SpecQueryModel, _: Schema, __: QueryConfig): FeatureScore[] {\n    let mark = specM.getMark() as Mark;\n    if (mark === MARK.CIRCLE || mark === MARK.SQUARE) {\n      mark = MARK.POINT;\n    }\n    const xEncQ = specM.getEncodingQueryByChannel(CHANNEL.X);\n    const xType = xEncQ ? getExtendedType(xEncQ) : NONE;\n\n    const yEncQ = specM.getEncodingQueryByChannel(CHANNEL.Y);\n    const yType = yEncQ ? getExtendedType(yEncQ) : NONE;\n\n    const isOccluded = !specM.isAggregate(); // FIXME\n\n    const feature = xType + '_' + yType + '_' + isOccluded + '_' + mark;\n    const featureScore = this.getFeatureScore(feature);\n\n    if (featureScore) {\n      return [featureScore];\n    }\n    console.error('feature score missing for', feature);\n    return [];\n  }\n}\n\nexport function featurize(xType: ExtendedType, yType: ExtendedType, hasOcclusion: boolean, mark: Mark) {\n  return xType + '_' + yType + '_' + hasOcclusion + '_' + mark;\n}\n\nfunction init() {\n  const MEASURES = [Q, T];\n  const DISCRETE = [BIN_Q, TIMEUNIT_O, O, N, K];\n  const DISCRETE_OR_NONE = DISCRETE.concat([NONE]);\n\n  let SCORE = {} as Dict<number>;\n  // QxQ\n  MEASURES.forEach(xType => {\n    MEASURES.forEach(yType => {\n      // has occlusion\n      const occludedQQMark = {\n        point: 0,\n        text: -0.2,\n        tick: -0.5,\n        rect: -1,\n        bar: -2,\n        line: -2,\n        area: -2,\n        rule: -2.5\n      };\n      forEach(occludedQQMark, (score, mark: Mark) => {\n        const feature = featurize(xType, yType, true, mark);\n        SCORE[feature] = score;\n      });\n\n      // no occlusion\n      // TODO: possible to use connected scatter plot\n      const noOccludedQQMark = {\n        point: 0,\n        text: -0.2,\n        tick: -0.5,\n        bar: -2,\n        line: -2,\n        area: -2,\n        rule: -2.5\n      };\n      forEach(noOccludedQQMark, (score, mark: Mark) => {\n        const feature = featurize(xType, yType, false, mark);\n        SCORE[feature] = score;\n      });\n    });\n  });\n\n  // DxQ, QxD\n  MEASURES.forEach(xType => {\n    // HAS OCCLUSION\n    DISCRETE_OR_NONE.forEach(yType => {\n      const occludedDimensionMeasureMark = {\n        tick: 0,\n        point: -0.2,\n        text: -0.5,\n        bar: -2,\n        line: -2,\n        area: -2,\n        rule: -2.5\n      };\n      forEach(occludedDimensionMeasureMark, (score, mark: Mark) => {\n        const feature = featurize(xType, yType, true, mark);\n        SCORE[feature] = score;\n        // also do the inverse\n        const feature2 = featurize(yType, xType, true, mark);\n        SCORE[feature2] = score;\n      });\n    });\n\n    [TIMEUNIT_T].forEach(yType => {\n      const occludedDimensionMeasureMark = {\n        // For Time Dimension with time scale, tick is not good\n        point: 0,\n        text: -0.5,\n        tick: -1,\n        bar: -2,\n        line: -2,\n        area: -2,\n        rule: -2.5\n      };\n      forEach(occludedDimensionMeasureMark, (score, mark: Mark) => {\n        const feature = featurize(xType, yType, true, mark);\n        SCORE[feature] = score;\n        // also do the inverse\n        const feature2 = featurize(yType, xType, true, mark);\n        SCORE[feature2] = score;\n      });\n    });\n\n    // NO OCCLUSION\n    [NONE, N, O, K].forEach(yType => {\n      const noOccludedQxN = {\n        bar: 0,\n        point: -0.2,\n        tick: -0.25,\n        text: -0.3,\n        // Line / Area can mislead trend for N\n        line: -2, // FIXME line vs area?\n        area: -2,\n        // Non-sense to use rule here\n        rule: -2.5\n      };\n      forEach(noOccludedQxN, (score, mark: Mark) => {\n        const feature = featurize(xType, yType, false, mark);\n        SCORE[feature] = score;\n\n        // also do the inverse\n        const feature2 = featurize(yType, xType, false, mark);\n        SCORE[feature2] = score;\n      });\n    });\n\n    [BIN_Q].forEach(yType => {\n      const noOccludedQxBinQ = {\n        bar: 0,\n        point: -0.2,\n        tick: -0.25,\n        text: -0.3,\n        // Line / Area isn't the best fit for bin\n        line: -0.5, // FIXME line vs area?\n        area: -0.5,\n        // Non-sense to use rule here\n        rule: -2.5\n      };\n      forEach(noOccludedQxBinQ, (score, mark: Mark) => {\n        const feature = featurize(xType, yType, false, mark);\n        SCORE[feature] = score;\n\n        // also do the inverse\n        const feature2 = featurize(yType, xType, false, mark);\n        SCORE[feature2] = score;\n      });\n    });\n\n    [TIMEUNIT_T, TIMEUNIT_O].forEach(yType => {\n      // For aggregate / surely no occlusion plot, Temporal with time or ordinal\n      // are not that different.\n      const noOccludedQxBinQ = {\n        line: 0,\n        area: -0.1,\n        bar: -0.2,\n        point: -0.3,\n        tick: -0.35,\n        text: -0.4,\n        // Non-sense to use rule here\n        rule: -2.5\n      };\n      forEach(noOccludedQxBinQ, (score, mark: Mark) => {\n        const feature = featurize(xType, yType, false, mark);\n        SCORE[feature] = score;\n\n        // also do the inverse\n        const feature2 = featurize(yType, xType, false, mark);\n        SCORE[feature2] = score;\n      });\n    });\n  });\n\n  [TIMEUNIT_T].forEach(xType => {\n    [TIMEUNIT_T].forEach(yType => {\n      // has occlusion\n      const ttMark = {\n        point: 0,\n        rect: -0.1, // assuming rect will be small\n        text: -0.5,\n        tick: -1,\n        bar: -2,\n        line: -2,\n        area: -2,\n        rule: -2.5\n      };\n      // No difference between has occlusion and no occlusion\n      // as most of the time, it will be the occluded case.\n      forEach(ttMark, (score, mark: Mark) => {\n        const feature = featurize(xType, yType, true, mark);\n        SCORE[feature] = score;\n      });\n      forEach(ttMark, (score, mark: Mark) => {\n        const feature = featurize(xType, yType, false, mark);\n        SCORE[feature] = score;\n      });\n    });\n\n    DISCRETE_OR_NONE.forEach(yType => {\n      // has occlusion\n      const tdMark = {\n        tick: 0,\n        point: -0.2,\n        text: -0.5,\n        rect: -1,\n        bar: -2,\n        line: -2,\n        area: -2,\n        rule: -2.5\n      };\n      // No difference between has occlusion and no occlusion\n      // as most of the time, it will be the occluded case.\n      forEach(tdMark, (score, mark: Mark) => {\n        const feature = featurize(xType, yType, true, mark);\n        SCORE[feature] = score;\n      });\n      forEach(tdMark, (score, mark: Mark) => {\n        const feature = featurize(yType, xType, true, mark);\n        SCORE[feature] = score;\n      });\n      forEach(tdMark, (score, mark: Mark) => {\n        const feature = featurize(xType, yType, false, mark);\n        SCORE[feature] = score;\n      });\n      forEach(tdMark, (score, mark: Mark) => {\n        const feature = featurize(yType, xType, false, mark);\n        SCORE[feature] = score;\n      });\n    });\n  });\n\n  // DxD\n  // Note: We use for loop here because using forEach sometimes leads to a mysterious bug\n  for (const xType of DISCRETE_OR_NONE) {\n    for (const yType of DISCRETE_OR_NONE) {\n      // has occlusion\n      const ddMark = {\n        point: 0,\n        rect: 0,\n        text: -0.1,\n        tick: -1,\n        bar: -2,\n        line: -2,\n        area: -2,\n        rule: -2.5\n      };\n\n      forEach(ddMark, (score, mark: Mark) => {\n        const feature = featurize(xType, yType, true, mark);\n        SCORE[feature] = score;\n      });\n\n      // same for no occlusion.\n      forEach(ddMark, (score, mark: Mark) => {\n        const feature = featurize(xType, yType, false, mark);\n        SCORE[feature] = score;\n      });\n    }\n  }\n\n  return SCORE;\n}\n","import {SpecQueryModel} from '../../model';\nimport {Schema} from '../../schema';\nimport {QueryConfig} from '../../config';\nimport {RankingScore, FeatureScore} from '../ranking';\nimport {AxisScorer} from './axis';\nimport {DimensionScorer} from './dimension';\nimport {FacetScorer} from './facet';\nimport {SizeChannelScorer} from './sizechannel';\nimport {TypeChannelScorer} from './typechannel';\nimport {MarkScorer} from './mark';\n\nconst SCORERS = [\n  new AxisScorer(),\n  new DimensionScorer(),\n  new FacetScorer(),\n  new MarkScorer(),\n  new SizeChannelScorer(),\n  new TypeChannelScorer()\n];\n\n// TODO: x/y, row/column preference\n// TODO: stacking\n// TODO: Channel, Cardinality\n// TODO: Penalize over encoding\nexport function effectiveness(specM: SpecQueryModel, schema: Schema, opt: QueryConfig): RankingScore {\n  const features = SCORERS.reduce((f, scorer) => {\n    const scores = scorer.getScore(specM, schema, opt);\n    return f.concat(scores);\n  }, [] as FeatureScore[]);\n\n  return {\n    score: features.reduce((s, f) => {\n      return s + f.score;\n    }, 0),\n    features: features\n  };\n}\n","/**\n * Field Type (with Bin and TimeUnit) and Channel Score (Cleveland / Mackinlay based)\n */\n\nimport * as CHANNEL from 'vega-lite/build/src/channel';\nimport {Channel} from 'vega-lite/build/src/channel';\nimport {DEFAULT_QUERY_CONFIG, QueryConfig} from '../../config';\nimport {SpecQueryModel} from '../../model';\nimport {EncodingQuery, isAutoCountQuery, isFieldQuery} from '../../query/encoding';\nimport {Schema} from '../../schema';\nimport {Dict} from '../../util';\nimport {FeatureScore} from '../ranking';\nimport {Scorer} from './base';\nimport {BIN_Q, ExtendedType, getExtendedType, N, O, T, TIMEUNIT_O, TIMEUNIT_T} from './type';\n\n/**\n * Effectiveness Score for preferred axis.\n */\nexport class AxisScorer extends Scorer {\n  constructor() {\n    super('Axis');\n  }\n  protected initScore(opt: QueryConfig = {}) {\n    opt = {...DEFAULT_QUERY_CONFIG, ...opt};\n    let score: Dict<number> = {};\n\n    const preferredAxes = [\n      {\n        feature: BIN_Q,\n        opt: 'preferredBinAxis'\n      },\n      {\n        feature: T,\n        opt: 'preferredTemporalAxis'\n      },\n      {\n        feature: TIMEUNIT_T,\n        opt: 'preferredTemporalAxis'\n      },\n      {\n        feature: TIMEUNIT_O,\n        opt: 'preferredTemporalAxis'\n      },\n      {\n        feature: O,\n        opt: 'preferredOrdinalAxis'\n      },\n      {\n        feature: N,\n        opt: 'preferredNominalAxis'\n      }\n    ];\n\n    preferredAxes.forEach(pAxis => {\n      if (opt[pAxis.opt] === CHANNEL.X) {\n        // penalize the other axis\n        score[pAxis.feature + '_' + CHANNEL.Y] = -0.01;\n      } else if (opt[pAxis.opt] === CHANNEL.Y) {\n        // penalize the other axis\n        score[pAxis.feature + '_' + CHANNEL.X] = -0.01;\n      }\n    });\n\n    return score;\n  }\n\n  public featurize(type: ExtendedType, channel: Channel) {\n    return type + '_' + channel;\n  }\n\n  public getScore(specM: SpecQueryModel, _: Schema, __: QueryConfig): FeatureScore[] {\n    return specM.getEncodings().reduce((features, encQ: EncodingQuery) => {\n      if (isFieldQuery(encQ) || isAutoCountQuery(encQ)) {\n        const type = getExtendedType(encQ);\n        const feature = this.featurize(type, encQ.channel as Channel);\n        const featureScore = this.getFeatureScore(feature);\n\n        if (featureScore) {\n          features.push(featureScore);\n        }\n      }\n      return features;\n    }, []);\n  }\n}\n","import {Dict} from '../../util';\nimport {Scorer} from './base';\nimport {SpecQueryModel} from '../../model';\nimport {Schema} from '../../schema';\nimport {QueryConfig} from '../../config';\nimport {FeatureScore} from '../ranking';\nimport {EncodingQuery, isFieldQuery, isAutoCountQuery} from '../../query/encoding';\n\n/**\n * Penalize if facet channels are the only dimensions\n */\nexport class DimensionScorer extends Scorer {\n  constructor() {\n    super('Dimension');\n  }\n\n  protected initScore() {\n    return {\n      row: -2,\n      column: -2,\n      color: 0,\n      opacity: 0,\n      size: 0,\n      shape: 0\n    } as Dict<number>;\n  }\n\n  public getScore(specM: SpecQueryModel, _: Schema, __: QueryConfig): FeatureScore[] {\n    if (specM.isAggregate()) {\n      specM.getEncodings().reduce((maxFScore, encQ: EncodingQuery) => {\n        if (isAutoCountQuery(encQ) || (isFieldQuery(encQ) && !encQ.aggregate)) { // isDimension\n          const featureScore = this.getFeatureScore(encQ.channel + '');\n          if (featureScore && featureScore.score > maxFScore.score) {\n            return featureScore;\n          }\n        }\n        return maxFScore;\n      }, {type: 'Dimension', feature: 'No Dimension', score: -5});\n    }\n    return [];\n  }\n}\n","import * as CHANNEL from 'vega-lite/build/src/channel';\nimport {DEFAULT_QUERY_CONFIG, QueryConfig} from '../../config';\nimport {SpecQueryModel} from '../../model';\nimport {EncodingQuery, isAutoCountQuery, isFieldQuery} from '../../query/encoding';\nimport {Schema} from '../../schema';\nimport {Dict} from '../../util';\nimport {FeatureScore} from '../ranking';\nimport {Scorer} from './base';\n\n/**\n * Effective Score for preferred facet\n */\nexport class FacetScorer extends Scorer {\n  constructor() {\n    super('Facet');\n  }\n  protected initScore(opt?: QueryConfig) {\n    opt = {...DEFAULT_QUERY_CONFIG, ...opt};\n    let score: Dict<number> = {};\n\n    if (opt.preferredFacet === CHANNEL.ROW) {\n      // penalize the other axis\n      score[CHANNEL.COLUMN] = -0.01;\n    } else if (opt.preferredFacet === CHANNEL.COLUMN) {\n      // penalize the other axis\n      score[CHANNEL.ROW] = -0.01;\n    }\n\n    return score;\n  }\n  public getScore(specM: SpecQueryModel, _: Schema, __: QueryConfig): FeatureScore[] {\n    return specM.getEncodings().reduce((features, encQ: EncodingQuery) => {\n      if (isFieldQuery(encQ) || isAutoCountQuery(encQ)) {\n        const featureScore = this.getFeatureScore(encQ.channel as string);\n        if (featureScore) {\n          features.push(featureScore);\n        }\n      }\n      return features;\n    }, []);\n  }\n}\n","import {Dict} from '../../util';\nimport {Scorer} from './base';\nimport {SpecQueryModel} from '../../model';\nimport {Schema} from '../../schema';\nimport {QueryConfig} from '../../config';\nimport {FeatureScore} from '../ranking';\nimport {isFieldQuery, isAutoCountQuery} from '../../query/encoding';\n\n/**\n * Effectivenss score that penalize size for bar and tick\n */\nexport class SizeChannelScorer extends Scorer {\n  constructor() {\n    super('SizeChannel');\n  }\n\n  protected initScore() {\n    return {\n      bar_size: -2,\n      tick_size: -2\n    } as Dict<number>;\n  }\n\n  public getScore(specM: SpecQueryModel, _: Schema, __: QueryConfig): FeatureScore[] {\n    const mark = specM.getMark();\n    return specM.getEncodings().reduce((featureScores, encQ) => {\n      if (isFieldQuery(encQ) || isAutoCountQuery(encQ)) {\n        const feature = mark + '_' + encQ.channel;\n        const featureScore = this.getFeatureScore(feature);\n        if (featureScore) {\n          featureScores.push(featureScore);\n        }\n      }\n      return featureScores;\n    }, []);\n  }\n}\n","import * as TYPE from 'vega-lite/build/src/type';\nimport {QueryConfig} from '../config';\nimport {SpecQueryModel} from '../model';\nimport {EncodingQuery, isDimension, isEnabledAutoCountQuery, isFieldQuery} from '../query/encoding';\nimport {Schema} from '../schema';\nimport {some} from '../util';\nimport {FeatureScore, RankingScore} from './ranking';\n\nexport const name = 'aggregationQuality';\n\nexport function score(specM: SpecQueryModel, schema: Schema, opt: QueryConfig): RankingScore {\n  const feature = aggregationQualityFeature(specM, schema, opt);\n  return {\n    score: feature.score,\n    features: [feature]\n  };\n}\n\nfunction aggregationQualityFeature(specM: SpecQueryModel, _: Schema, __: QueryConfig): FeatureScore {\n  const encodings = specM.getEncodings();\n  if (specM.isAggregate()) {\n    const isRawContinuous = (encQ: EncodingQuery) => {\n      return (\n        isFieldQuery(encQ) &&\n        ((encQ.type === TYPE.QUANTITATIVE && !encQ.bin && !encQ.aggregate) ||\n          (encQ.type === TYPE.TEMPORAL && !encQ.timeUnit))\n      );\n    };\n\n    if (some(encodings, isRawContinuous)) {\n      // These are plots that pollute continuous fields as dimension.\n      // They are often intermediate visualizations rather than what users actually want.\n      return {\n        type: name,\n        score: 0.1,\n        feature: 'Aggregate with raw continuous'\n      };\n    }\n\n    if (some(encodings, encQ => isFieldQuery(encQ) && isDimension(encQ))) {\n      let hasCount = some(encodings, (encQ: EncodingQuery) => {\n        return (isFieldQuery(encQ) && encQ.aggregate === 'count') || isEnabledAutoCountQuery(encQ);\n      });\n      let hasBin = some(encodings, (encQ: EncodingQuery) => {\n        return isFieldQuery(encQ) && !!encQ.bin;\n      });\n\n      if (hasCount) {\n        // If there is count, we might add additional count field, making it a little less simple\n        // then when we just apply aggregate to Q field\n        return {\n          type: name,\n          score: 0.8,\n          feature: 'Aggregate with count'\n        };\n      } else if (hasBin) {\n        // This is not as good as binning all the Q and show heatmap\n        return {\n          type: name,\n          score: 0.7,\n          feature: 'Aggregate with bin but without count'\n        };\n      } else {\n        return {\n          type: name,\n          score: 0.9,\n          feature: 'Aggregate without count and without bin'\n        };\n      }\n    }\n    // no dimension -- often not very useful\n    return {\n      type: name,\n      score: 0.3,\n      feature: 'Aggregate without dimension'\n    };\n  } else {\n    if (some(encodings, encQ => isFieldQuery(encQ) && !isDimension(encQ))) {\n      // raw plots with measure -- simplest of all!\n      return {\n        type: name,\n        score: 1,\n        feature: 'Raw with measure'\n      };\n    }\n    // raw plots with no measure -- often a lot of occlusion\n    return {\n      type: name,\n      score: 0.2,\n      feature: 'Raw without measure'\n    };\n  }\n}\n","import {QueryConfig} from '../config';\nimport {SpecQueryModel} from '../model';\nimport {Schema} from '../schema';\nimport {isFieldQuery} from '../query/encoding';\n\nimport {RankingScore, FeatureScore} from './ranking';\n\nexport const name = 'fieldOrder';\n\n/**\n * Return ranking score based on indices of encoded fields in the schema.\n * If there are multiple fields, prioritize field on the lower indices of encodings.\n *\n * For example, to compare two specs with two encodings each,\n * first we compare the field on the 0-th index\n * and only compare the field on the 1-th index only if the fields on the 0-th index are the same.\n */\nexport function score(specM: SpecQueryModel, schema: Schema, _: QueryConfig): RankingScore {\n  const fieldWildcardIndices = specM.wildcardIndex.encodingIndicesByProperty.get('field');\n  if (!fieldWildcardIndices) {\n    return {\n      score: 0,\n      features: []\n    };\n  }\n\n  const encodings = specM.specQuery.encodings;\n  const numFields = schema.fieldSchemas.length;\n\n  const features: FeatureScore[] = [];\n  let totalScore = 0, base = 1;\n\n  for (let i = fieldWildcardIndices.length - 1; i >= 0; i--) {\n    const index = fieldWildcardIndices[i];\n    const encoding = encodings[index];\n\n    // Skip ValueQuery as we only care about order of fields.\n    let field;\n\n    if (isFieldQuery(encoding)) {\n      field = encoding.field as string;\n    } else { // ignore ValueQuery / AutoCountQuery\n      continue;\n    }\n\n    const fieldWildcard = specM.wildcardIndex.encodings[index].get('field');\n    const fieldIndex = schema.fieldSchema(field).index;\n     // reverse order field with lower index should get higher score and come first\n    const score = - fieldIndex * base;\n    totalScore += score;\n\n    features.push({\n      score: score,\n      type: 'fieldOrder',\n      feature: `field ${fieldWildcard.name} is ${field} (#${fieldIndex} in the schema)`\n    });\n\n    base *= numFields;\n  }\n\n  return {\n    score: totalScore,\n    features: features\n  };\n}\n","import {QueryConfig} from '../config';\nimport {SpecQueryModel, SpecQueryModelGroup} from '../model';\nimport {getTopResultTreeItem} from '../result';\nimport {Query} from '../query/query';\nimport {Dict} from '../util';\nimport {Schema} from '../schema';\nimport {effectiveness} from './effectiveness';\n\nexport * from './effectiveness';\nimport * as aggregation from './aggregation';\nimport * as fieldOrder from './fieldorder';\n\nexport {aggregation, fieldOrder};\n\nexport interface RankingScore {\n  score: number;\n  features: FeatureScore[];\n}\n\nexport interface FeatureScore {\n  score: number;\n  type: string;\n  feature: string;\n}\n\nexport interface FeatureInitializer {\n  (): Dict<number>;\n}\n\nexport interface Featurizer {\n  (specM: SpecQueryModel, schema: Schema, opt: QueryConfig): FeatureScore[];\n}\n\nexport interface FeatureFactory {\n  type: string;\n  init: FeatureInitializer;\n  getScore: Featurizer;\n}\n\nexport interface RankingFunction {\n  (specM: SpecQueryModel, schema: Schema, opt: QueryConfig): RankingScore;\n}\n\n/**\n * Registry for all encoding ranking functions\n */\nlet rankingRegistry: Dict<RankingFunction>  = {};\n\n/**\n * Add an ordering function to the registry.\n */\nexport function register(name: string, keyFn: RankingFunction) {\n  rankingRegistry[name] = keyFn;\n}\n\nexport function get(name: string) {\n  return rankingRegistry[name];\n}\n\nexport function rank(group: SpecQueryModelGroup, query: Query, schema: Schema, level: number): SpecQueryModelGroup {\n  if (!query.nest || level === query.nest.length) {\n    if (query.orderBy || query.chooseBy) {\n      group.items.sort(comparatorFactory(query.orderBy || query.chooseBy, schema, query.config));\n      if (query.chooseBy) {\n        if (group.items.length > 0) {\n          // for chooseBy -- only keep the top-item\n          group.items.splice(1);\n        }\n      }\n    }\n  } else {\n    // sort lower-level nodes first because our ranking takes top-item in the subgroup\n    group.items.forEach((subgroup) => {\n      rank(subgroup as SpecQueryModelGroup, query, schema, level + 1);\n    });\n    if (query.nest[level].orderGroupBy) {\n      group.items.sort(groupComparatorFactory(query.nest[level].orderGroupBy, schema, query.config));\n    }\n  }\n  return group;\n}\n\nexport function comparatorFactory(name: string | string[], schema: Schema, opt: QueryConfig) {\n  return (m1: SpecQueryModel, m2: SpecQueryModel) => {\n    if (name instanceof Array) {\n      return getScoreDifference(name, m1, m2, schema, opt);\n    } else {\n      return getScoreDifference([name], m1, m2, schema, opt);\n    }\n  };\n}\n\nexport function groupComparatorFactory(name: string | string[], schema: Schema, opt: QueryConfig): (g1: SpecQueryModelGroup, g2: SpecQueryModelGroup) => number {\n  return (g1: SpecQueryModelGroup, g2: SpecQueryModelGroup): number => {\n    const m1 = getTopResultTreeItem(g1);\n    const m2 = getTopResultTreeItem(g2);\n    if (name instanceof Array) {\n      return getScoreDifference(name, m1, m2, schema, opt);\n    } else {\n      return getScoreDifference([name], m1, m2, schema, opt);\n    }\n  };\n}\n\nfunction getScoreDifference(name: string[], m1: SpecQueryModel, m2: SpecQueryModel, schema: Schema, opt: QueryConfig): number {\n  for (let rankingName of name) {\n    let scoreDifference = getScore(m2, rankingName, schema, opt).score - getScore(m1, rankingName, schema, opt).score;\n    if (scoreDifference !== 0) {\n      return scoreDifference;\n    }\n  }\n  return 0;\n}\n\nexport function getScore(model: SpecQueryModel, rankingName: string, schema: Schema, opt: QueryConfig) {\n  if (model.getRankingScore(rankingName) !== undefined) {\n    return model.getRankingScore(rankingName);\n  }\n  const fn = get(rankingName);\n  const score = fn(model, schema, opt);\n  model.setRankingScore(rankingName, score);\n  return score;\n}\n\nexport const EFFECTIVENESS = 'effectiveness';\nregister(EFFECTIVENESS, effectiveness);\n\nregister(aggregation.name, aggregation.score);\nregister(fieldOrder.name, fieldOrder.score);\n","import * as CHANNEL from 'vega-lite/build/src/channel';\nimport {hasDiscreteDomain} from 'vega-lite/build/src/scale';\nimport * as TYPE from 'vega-lite/build/src/type';\nimport {QueryConfig} from './config';\nimport {SpecQueryModel} from './model';\nimport {AxisQuery, EncodingQuery, isFieldQuery, ScaleQuery, scaleType} from './query/encoding';\nimport {ExpandedType} from './query/expandedtype';\nimport {Schema} from './schema';\nimport {Dict} from './util';\n\nexport function stylize(answerSet: SpecQueryModel[], schema: Schema, opt: QueryConfig): SpecQueryModel[] {\n  let encQIndex: Dict<EncodingQuery> = {};\n  answerSet = answerSet.map(function(specM) {\n    if (opt.smallRangeStepForHighCardinalityOrFacet) {\n      specM = smallRangeStepForHighCardinalityOrFacet(specM, schema, encQIndex, opt);\n    }\n\n    if (opt.nominalColorScaleForHighCardinality) {\n      specM = nominalColorScaleForHighCardinality(specM, schema, encQIndex, opt);\n    }\n\n    if (opt.xAxisOnTopForHighYCardinalityWithoutColumn) {\n      specM = xAxisOnTopForHighYCardinalityWithoutColumn(specM, schema, encQIndex, opt);\n    }\n    return specM;\n  });\n\n  return answerSet;\n}\n\nexport function smallRangeStepForHighCardinalityOrFacet(\n  specM: SpecQueryModel,\n  schema: Schema,\n  encQIndex: Dict<EncodingQuery>,\n  opt: QueryConfig\n): SpecQueryModel {\n  [CHANNEL.ROW, CHANNEL.Y, CHANNEL.COLUMN, CHANNEL.X].forEach(channel => {\n    encQIndex[channel] = specM.getEncodingQueryByChannel(channel);\n  });\n\n  const yEncQ = encQIndex[CHANNEL.Y];\n  if (yEncQ !== undefined && isFieldQuery(yEncQ)) {\n    if (\n      encQIndex[CHANNEL.ROW] ||\n      schema.cardinality(yEncQ) > opt.smallRangeStepForHighCardinalityOrFacet.maxCardinality\n    ) {\n      // We check for undefined rather than\n      // yEncQ.scale = yEncQ.scale || {} to cover the case where\n      // yEncQ.scale has been set to false/null.\n      // This prevents us from incorrectly overriding scale and\n      // assigning a rangeStep when scale is set to false.\n      if (yEncQ.scale === undefined) {\n        yEncQ.scale = {};\n      }\n\n      // We do not want to assign a rangeStep if scale is set to false\n      // and we only apply this if the scale is (or can be) an ordinal scale.\n      const yScaleType = scaleType(yEncQ);\n      if (yEncQ.scale && (yScaleType === undefined || hasDiscreteDomain(yScaleType))) {\n        if (!(yEncQ.scale as ScaleQuery).rangeStep) {\n          (yEncQ.scale as ScaleQuery).rangeStep = 12;\n        }\n      }\n    }\n  }\n\n  const xEncQ = encQIndex[CHANNEL.X];\n  if (isFieldQuery(xEncQ)) {\n    if (\n      encQIndex[CHANNEL.COLUMN] ||\n      schema.cardinality(xEncQ) > opt.smallRangeStepForHighCardinalityOrFacet.maxCardinality\n    ) {\n      // Just like y, we don't want to do this if scale is null/false\n      if (xEncQ.scale === undefined) {\n        xEncQ.scale = {};\n      }\n\n      // We do not want to assign a rangeStep if scale is set to false\n      // and we only apply this if the scale is (or can be) an ordinal scale.\n      const xScaleType = scaleType(xEncQ);\n      if (xEncQ.scale && (xScaleType === undefined || hasDiscreteDomain(xScaleType))) {\n        if (!(xEncQ.scale as ScaleQuery).rangeStep) {\n          (xEncQ.scale as ScaleQuery).rangeStep = 12;\n        }\n      }\n    }\n  }\n\n  return specM;\n}\n\nexport function nominalColorScaleForHighCardinality(\n  specM: SpecQueryModel,\n  schema: Schema,\n  encQIndex: Dict<EncodingQuery>,\n  opt: QueryConfig\n): SpecQueryModel {\n  encQIndex[CHANNEL.COLOR] = specM.getEncodingQueryByChannel(CHANNEL.COLOR);\n\n  const colorEncQ = encQIndex[CHANNEL.COLOR];\n  if (\n    isFieldQuery(colorEncQ) &&\n    colorEncQ !== undefined &&\n    (colorEncQ.type === TYPE.NOMINAL || colorEncQ.type === ExpandedType.KEY) &&\n    schema.cardinality(colorEncQ) > opt.nominalColorScaleForHighCardinality.maxCardinality\n  ) {\n    if (colorEncQ.scale === undefined) {\n      colorEncQ.scale = {};\n    }\n\n    if (colorEncQ.scale) {\n      if (!(colorEncQ.scale as ScaleQuery).range) {\n        (colorEncQ.scale as ScaleQuery).scheme = opt.nominalColorScaleForHighCardinality.palette;\n      }\n    }\n  }\n\n  return specM;\n}\n\nexport function xAxisOnTopForHighYCardinalityWithoutColumn(\n  specM: SpecQueryModel,\n  schema: Schema,\n  encQIndex: Dict<EncodingQuery>,\n  opt: QueryConfig\n): SpecQueryModel {\n  [CHANNEL.COLUMN, CHANNEL.X, CHANNEL.Y].forEach(channel => {\n    encQIndex[channel] = specM.getEncodingQueryByChannel(channel);\n  });\n\n  if (encQIndex[CHANNEL.COLUMN] === undefined) {\n    const xEncQ = encQIndex[CHANNEL.X];\n    const yEncQ = encQIndex[CHANNEL.Y];\n    if (\n      isFieldQuery(xEncQ) &&\n      isFieldQuery(yEncQ) &&\n      yEncQ !== undefined &&\n      yEncQ.field &&\n      hasDiscreteDomain(scaleType(yEncQ))\n    ) {\n      if (xEncQ !== undefined) {\n        if (schema.cardinality(yEncQ) > opt.xAxisOnTopForHighYCardinalityWithoutColumn.maxCardinality) {\n          if (xEncQ.axis === undefined) {\n            xEncQ.axis = {};\n          }\n\n          if (xEncQ.axis && !(xEncQ.axis as AxisQuery).orient) {\n            (xEncQ.axis as AxisQuery).orient = 'top';\n          }\n        }\n      }\n    }\n  }\n\n  return specM;\n}\n","\nimport {QueryConfig, DEFAULT_QUERY_CONFIG} from './config';\nimport {getEnumerator} from './enumerator';\nimport {SpecQueryModel} from './model';\nimport {fromKey} from'./property';\nimport {SpecQuery} from './query/spec';\nimport {Schema} from './schema';\nimport {stylize} from './stylize';\n\nexport function generate(specQ: SpecQuery, schema: Schema, opt: QueryConfig = DEFAULT_QUERY_CONFIG) {\n  // 1. Build a SpecQueryModel, which also contains wildcardIndex\n  const specM = SpecQueryModel.build(specQ, schema, opt);\n  const wildcardIndex = specM.wildcardIndex;\n\n  // 2. Enumerate each of the properties based on propPrecedence.\n\n  let answerSet = [specM]; // Initialize Answer Set with only the input spec query.\n  opt.propertyPrecedence.forEach((propKey) => {\n    const prop = fromKey(propKey);\n    // If the original specQuery contains wildcard for this prop\n    if (wildcardIndex.hasProperty(prop)) {\n      // update answerset\n      const enumerator = getEnumerator(prop);\n      const reducer = enumerator(wildcardIndex, schema, opt);\n      answerSet = answerSet.reduce(reducer, []);\n    }\n  });\n\n  if (opt.stylize) {\n    if ((opt.nominalColorScaleForHighCardinality !== null) ||\n        (opt.smallRangeStepForHighCardinalityOrFacet !== null) ||\n        (opt.xAxisOnTopForHighYCardinalityWithoutColumn !== null)) {\n      return stylize(answerSet, schema, opt);\n    }\n  }\n\n  return answerSet;\n}\n","import {DEFAULT_QUERY_CONFIG, QueryConfig} from './config';\nimport {generate} from './generate';\nimport {SpecQueryModelGroup} from './model';\nimport {nest} from './nest';\nimport {normalize} from './query/normalize';\nimport {Query} from './query/query';\nimport {rank} from './ranking/ranking';\nimport {Schema} from './schema';\n\nexport function recommend(q: Query, schema: Schema, config?: QueryConfig): {query: Query, result: SpecQueryModelGroup} {\n  // 1. Normalize non-nested `groupBy` to always have `groupBy` inside `nest`\n  //    and merge config with the following precedence\n  //    query.config > config > DEFAULT_QUERY_CONFIG\n  q = {\n    ...normalize(q),\n    config: {\n      ...DEFAULT_QUERY_CONFIG,\n      ...config,\n      ...q.config\n    }\n  };\n  // 2. Generate\n  const answerSet = generate(q.spec, schema, q.config);\n  const nestedAnswerSet = nest(answerSet, q.nest);\n  const result = rank(nestedAnswerSet, q, schema, 0);\n\n  return {\n    query: q,\n    result: result\n  };\n}\n"]}